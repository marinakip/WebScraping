"{'location': 'Lagos, Nigeria', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': [""ML-Logistic-regression-algorithm-challenge\n\n\n\n\nDSN Algorithm Challenge\n\n\n\nA lot of data scientists or machine learning enthusiasts do use various machine learning algorithms as a black box without knowing how they work or the mathematics behind it. The purpose of this challenge is to encourage the mathematical understanding of machine learning algorithms, their break and yield point.\nIn summary, participants are encouraged to understand the fundamental concepts behind machine learning algorithms/models.\nThe rules and guidelines for this challenge are as follows:\n\n\nEnsure to register at https://bit.ly/dsnmlhack\n\n\nThe algorithm challenge is open to all.\n\n\nParticipants are expected to design and develop the Logistic Regression algorithm from scratch using Python or R programming.\n\n\nFor python developers (numpy is advisable).\n\n\nTo push your solution to us, make a pull request to DSN's GitHub page at  https://www.github.com/datasciencenigeria/ML-Logistic-regression-algorithm-challenge. Ensure to add your readme file to understand your code.\n\n\nThe top 3 optimized code will be compensated as follows:\n\n\n\n1st position: 20GB data plan.\n2nd position: 15GB data plan.\n3rd position: 10GB data plan.\n\n\nAdd your scripts and readme.MD file as a folder saved as your full name (surname_first_middle name) by making a pull request to the repository.\n\n\nFor issues on this challenge kindly reach out to the AI+campus/city managers\nTwitter: @DataScienceNIG, @elishatofunmi, @o_funminiyi, @gbganalyst\nor\nCall: +2349062000119,+2349080564419.\nGood luck!\n""], 'url_profile': 'https://github.com/DataScienceNigeria', 'info_list': ['3', 'Updated Apr 25, 2020', 'Updated Apr 10, 2020', '23', 'Python', 'Updated Jan 28, 2021', '22', 'JavaScript', 'BSD-3-Clause license', 'Updated Apr 20, 2020', 'Java', 'Apache-2.0 license', 'Updated Jan 29, 2021', '4', 'Python', 'MIT license', 'Updated Oct 30, 2020', 'Jupyter Notebook', 'Updated Aug 18, 2020', '4', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Shell', 'Updated Feb 27, 2021', '4', 'Python', 'Updated Oct 27, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['first-assignment\npandas, linear regression\n'], 'url_profile': 'https://github.com/myszpolna', 'info_list': ['3', 'Updated Apr 25, 2020', 'Updated Apr 10, 2020', '23', 'Python', 'Updated Jan 28, 2021', '22', 'JavaScript', 'BSD-3-Clause license', 'Updated Apr 20, 2020', 'Java', 'Apache-2.0 license', 'Updated Jan 29, 2021', '4', 'Python', 'MIT license', 'Updated Oct 30, 2020', 'Jupyter Notebook', 'Updated Aug 18, 2020', '4', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Shell', 'Updated Feb 27, 2021', '4', 'Python', 'Updated Oct 27, 2020']}","{'location': 'Guangzhou, China', 'stats_list': [], 'contributions': '17 contributions\n        in the last year', 'description': ['Dense Regression Network for Video Grounding\nThis repo holds the codes and models for the DRN framework presented on CVPR 2020\nDense Regression Network for Video Grounding\nRunhao Zeng, Haoming Xu, Wenbing Huang, Peihao Chen, Mingkui Tan, Chuang Gan, CVPR 2020, Seattle, Washington.\n[Paper]\nContents\n\n\nUsage Guide\n\nModule Preparation\nCode Preparation\nTraining DRN\n\nFirst Stage\nSecond Stage\nThird Stage\n\n\nTesting DRN\n\n\nOther Info\n\nCitation\nContact\n\n\n\n\nUsage Guide\nCode and Data Preparation\n[back to top]\nGet the code\nClone this repo with git\ngit clone https://github.com/Alvin-Zeng/DRN\ncd DRN\nDownload Features\nHere, we provide the C3D features on Charades-STA for training and testing.\nCharades-STA: You can download it from Baidu Cloud (password: smil).\nModule Preparation\n[back to top]\nStart from a clear conda env\nconda create -n DRN\nconda activate DRN\nThis repo is based on FCOS, use the following command to install it\nbash setup.sh\nOther minor Python modules can be installed by running\npip install -r requirements.txt\nTraining DRN\n[back to top]\nPlesse first set the path of features in data/default_config.yaml\nfeature_root: $PATH_OF_FEATURES\nFirst Stage\nUse the following command to train the first stage of DRN\nbash drn_train.sh $PATH_TO_SAVE_FIRST_MODEL is_first_stage\n\n$PATH_TO_SAVE_FIRST_MODEL denotes the path to save the first-stage model\n\nSecond Stage\nUse the following command to train the second stage of DRN\nbash drn_train.sh $PATH_TO_SAVE_SECOND_MODEL is_second_stage $FIRST_CHECKPOINT \n\n\n$PATH_TO_SAVE_SECOND_MODEL denotes the path to save the second-stage model\n\n\n$FIRST_CHECKPOINT denotes the trained model from the first stage\n\n\nThird Stage\nUse the following command to train the third stage of DRN\nbash drn_train.sh $PATH_TO_SAVE_THIRD_MODEL is_third_stage $SECOND_CHECKPOINT\n\n\n$PATH_TO_SAVE_THIRD_MODEL denotes the path to save the third-stage model\n\n\n$SECOND_CHECKPOINT denotes the trained model from the second stage\n\n\nTesting DRN\n[back to top]\nHere, we provide the models trained on Charades-STA for testing.\nCharades-STA: You can download them from Baidu Cloud (password: smil).\nUse the following command to test the trained model\nbash drn_test.sh $TRAINED_CHECKPOINT\n\n$TRAINED_CHECKPOINT denotes the trained model\n\nThe evaluation results will be put in the ""results"" folder\nCharades-STA\n\n\n\nMethod\nR@1 IoU=0.5 (%)\nR@5 IoU=0.5 (%)\n\n\n\n\nDRN (C3D)\n45.40\n89.06\n\n\n\nOther Info\n[back to top]\nCitation\nPlease cite the following paper if you feel DRN useful to your research\n@inproceedings{DRN2020CVPR,\n  author    = {Runhao Zeng and\n               Haoming Xu and\n               Wenbing Huang and\n               Peihao Chen and\n               Mingkui Tan and\n               Chuang Gan},\n  title     = {Dense Regression Network for Video Grounding},\n  booktitle = {CVPR},\n  year      = {2020},\n}\n\nContact\nFor any question, please file an issue or contact\nRunhao Zeng: runhaozeng.cs@gmail.com\n\n'], 'url_profile': 'https://github.com/Alvin-Zeng', 'info_list': ['3', 'Updated Apr 25, 2020', 'Updated Apr 10, 2020', '23', 'Python', 'Updated Jan 28, 2021', '22', 'JavaScript', 'BSD-3-Clause license', 'Updated Apr 20, 2020', 'Java', 'Apache-2.0 license', 'Updated Jan 29, 2021', '4', 'Python', 'MIT license', 'Updated Oct 30, 2020', 'Jupyter Notebook', 'Updated Aug 18, 2020', '4', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Shell', 'Updated Feb 27, 2021', '4', 'Python', 'Updated Oct 27, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '141 contributions\n        in the last year', 'description': ['â™»ï¸ Elm Regression Testing â™»ï¸\n\nRefactor that obscure piece of code that nobody can understand anymore!\n\nWhat is it?\nImagine you start a new job on an already existing product. The former and only developer of the solution hands you over the source code and runs to the exit, leaving you wondering what is happening...\nAnd then you look at the code and damn! You didn\'t even know it was possible to write bad code in Elm, but here it is. The most obfuscated human-written code you\'ve ever seen!\nThe product won\'t survive if you can\'t refactor this to improve the code. Fortunately this is Elm so refactoring is easy, right? Wait a minute, what does this function do? And this one? And what the heck is this type representing? Nor the naming nor the types help you in any way to understand what is happening here.\nYou just know the current implementation works and that you should not break it. You have to refactor without altering a behaviour you don\'t know. How to do that?\nYou\'ve guessed it! Regression testing!\nWhen do I need regression testing?\nWhen you need to refactor a code without knowing exactly what this code does. This could be because it\'s not your code and you do not have the specifications, or maybe because the code has grown more and more complex overtime and nobody knows everything anymore. The only thing you now is that the current implementation is considered correct and you do not want to break it while refactoring it.\nIn fact, even if there are bugs in this piece of code, you don\'t want to fix them during this refactoring: this is something that you will address later, once the code is easier to work with: make the change easy [...] then make the easy change (piece of wisdom from Kent Beck). Discover more on this thanks to Dillon Kearns.\nIf you know well what your code is supposed to do, unit tests or fuzz tests through elm-test directly may suit you better.\nHow does it work?\n\nWatch the video explaining the concept along with a specific use case (hopefully, you will forgive me for my english ðŸ˜…)\nWell, you can take your program, generate an initial model, generate random messages, send them to your update method and save the final model. Without knowing exactly what happened, you now have a test that â€“ given an initial model and some inputs â€“ produces a specific output. Now, generate 100s of them, and save the inputs and the output to run them later again. Refactor the part of the code that you want, and once done run the tests again, comparing the final output with the previous final output. Are they the same for every test? Great, you have improved the code without breaking anything! Some tests don\'t pass? You\'ve just changed the behaviour and should try to fix that mistake!\nThese generated tests are called a test harness and are here to help you improve the code. We can see four steps:\n\nCreate a generator for your test harness\nGenerate and save the test harness\nRefactor your code\nRe-run the tests and compare the outputs with saved outputs\n\nIf this package can\'t help you for step 3 (this is your job!), it can help you for the other steps. Let\'s see how.\nIn the following examples, let\'s imagine that we want to build a test harness for the counter program.\nCreate a generator for your test harness\nThis package will help you generate tests, but it needs a few inputs from you:\n\n\nFirst install the package as a test dependency through elm-test: elm-test install jgrenat/regression-testing.\n\n\nWe need to know how to generate an initial model for your program: your job is to create a generator using the elm/random package. Let\'s see an example for the counter program:\nimport Random exposing (Generator)\nimport Counter exposing (Model)\n\nmodelGenerator : Generator Model\nmodelGenerator = Random.int -10 10\nOr if your initial model is always the same, you can use a constant generator:\nmodelGenerator : Generator Model\nmodelGenerator = Random.constant 0\n\n\nDefine how to generate a message for your application:\nimport Counter exposing (Msg(..))\nimport Random exposing (Generator)\n\nmodelGenerator : Generator Msg\nmodelGenerator = Random.uniform Increment [Decrement]\n\n-- If some messages should be more frequent than others, you can use Random.weighted.\n\n\nDefine how encode your model and your messages into JSON to save them, using the elm/json package.\nimport Counter exposing (Model, Msg(..))\nimport Json.Encode as Encode\n\nencodeModel : Model -> Encode.Value\nencodeModel model = Encode.int model\n\nencodeMessage : Msg -> Encode.Value\nencodeMessage msg =\n    case msg of\n        Increment ->\n            Encode.string ""INCREMENT""\n        Decrement ->\n            Encode.string ""DECREMENT""\n\n-- You can find more complex examples in the ""examples"" folder\n\n\nDeclare a port to get back the generated tests:\nport module RegressionTestGenerator exposing (main)\nimport Json.Encode as Encode\n\n-- The name is important, it should be ""outputPort""\nport outputPort : Encode.Value -> Cmd msg\n\n\nOnce you have everything ready, you can create the generator:\nport module RegressionTestGenerator exposing (main)\n\nimport Counter exposing (Model, Msg, update)\nimport RegressionTest.Generator exposing (RegressionTestGeneratorProgram)\n\nmain : RegressionTestGeneratorProgram Model Msg\nmain = RegressionTest.Generator.sandboxUpdate\n    { modelGenerator = modelGenerator\n    , messageGenerator = messageGenerator\n    , update = update\n    , encodeModel = encodeModel\n    , encodeMessage = encodeMessage\n    , outputPort = outputPort\n    , numberOfTests = 500\n    }\nGenerate and save the test harness\nWe\'re going to use the node module to generate this one, so you\'ll need to have NodeJS installed. Then, you can install the tool:\nnpm install --global @jgrenat/elm-regression-testing\nTo generate the tests, go to the root of your project, assuming that the TestGenerator file is in the tests directory, run this command:\nelm-regression-testing ./tests/RegressionTestGenerator.elm\nThis will generate the file ./tests/GeneratedRegressionTestData.elm containing the tests data. If you want to change the path or the name of the file, you can use the --output option:\nelm-regression-testing ./tests/RegressionTestGenerator.elm --output=./tests/CustomFileName.elm\nRefactor your code\nI\'m afraid I won\'t be of any help here, you don\'t want me to take your job anyway... ðŸ˜\nRe-run the tests and compare the outputs with saved outputs\nThe tests data have been saved, now we need to re-run these tests and compare the results.\nFor that, we need to know how to decode the model and the messages from the generated JSON:\nimport Counter exposing (Model, Msg(..))\nimport Json.Decode as Decode exposing (Decoder)\n\nmodelDecoder : Decoder Model\nmodelDecoder = Decode.int\n\nmessageDecoder : Decoder Msg\nmessageDecoder =\n    Decode.string\n    |> Decode.andThen (\\messageType -> \n        case msg of\n            ""INCREMENT"" ->\n                Decode.succeed Increment\n            ""DECREMENT"" ->\n                Decode.succeed Decrement\n            _ ->\n                Decode.fail (""Invalid message: "" ++ messageType)\n    )\n  \n-- You can find more complex examples in the ""examples"" folder\nThen, you can create a runner:\nmodule RegressionTestRunner exposing (suite)\n\nimport Counter exposing (update)\nimport GeneratedRegressionTestData exposing (testData)\nimport RegressionTest.Runner\nimport Test exposing (Test)\n\n\nsuite : Test\nsuite = \n    RegressionTest.Runner.element \n        { modelDecoder = modelDecoder\n        , messageDecoder = messageDecoder\n        , update = update\n        } testData\n  \nAnd launch it as usual through:\nelm-test\nThis requires that at some point you\'ve set up elm-explorations/test for your project.\nI want to refactor my model / my messages! ðŸ˜±\nIf you want to change the representation of your model or change the messages of your app, there is no problem, your test harness is still there!\nAs the test data are stored as JSON, you can decode it as you want!\nLet\'s imagine that you want to change the model in the Counter example to allow adding more informations in the future:\n-- Previous Model was simply an Int, we want to use a record containing that Int after our refactoring:\n\ntype alias Model = { value : Int }\nYou can change your decoder to follow this change:\nmodelDecoder : Decoder Model\nmodelDecoder = \n    Decode.int\n    |> Decode.map Model\nAnd run your tests with elm-test!\nThanks\nMany thanks to @FBerthelot and @jfmengels for their precious help during the conception of this tool!\n'], 'url_profile': 'https://github.com/jgrenat', 'info_list': ['3', 'Updated Apr 25, 2020', 'Updated Apr 10, 2020', '23', 'Python', 'Updated Jan 28, 2021', '22', 'JavaScript', 'BSD-3-Clause license', 'Updated Apr 20, 2020', 'Java', 'Apache-2.0 license', 'Updated Jan 29, 2021', '4', 'Python', 'MIT license', 'Updated Oct 30, 2020', 'Jupyter Notebook', 'Updated Aug 18, 2020', '4', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Shell', 'Updated Feb 27, 2021', '4', 'Python', 'Updated Oct 27, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['vivo-regression-tests - release 2021-\nFor UQAM-DEV Environment: For UQAM-DEV Environment: https://wiki.uqam.ca/display/VIVOPUB/4%29+vivo-regression-test%3A+a+Test+Bench+Tool++for+the+Continuous+Evaluation+of+VIVO%27s+Development\nSetup\n\nrename example.settings.xml to settings.xml and Update the settings.xml based on the usernames/passwords for your local VIVO installations and the appropriate Selenium driver for your platform.\nin ./src/main/resources rename example.runtime.properties to runtime.properties and example.log4j.properties to log4j.properties\nThe list of tests is available under: ./src/main/resources/testsuites/\nMake sure that the password for http://localhost:8080/vivo_orig is correctly assigned. The first call to this instance requires the password rootPasswd. It is not necessary to do this procedure for http://localhost:8080/vivo_i18n.\n\nBuild\nmvn clean install -s settings.xml\n\n\nRun\nFor all languages\nmvn -s settings.xml clean test -Dxml.file=EmailAddress-testSuite.xml -DskipTests.value=false\n\nFor specific language (eg.: fr_CA)\nmvn -s settings.xml clean test -Dxml.file=fr_CA/EmailAddress-testSuite.xml -DskipTests.value=false\n\n'], 'url_profile': 'https://github.com/vivo-community', 'info_list': ['3', 'Updated Apr 25, 2020', 'Updated Apr 10, 2020', '23', 'Python', 'Updated Jan 28, 2021', '22', 'JavaScript', 'BSD-3-Clause license', 'Updated Apr 20, 2020', 'Java', 'Apache-2.0 license', 'Updated Jan 29, 2021', '4', 'Python', 'MIT license', 'Updated Oct 30, 2020', 'Jupyter Notebook', 'Updated Aug 18, 2020', '4', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Shell', 'Updated Feb 27, 2021', '4', 'Python', 'Updated Oct 27, 2020']}","{'location': 'Sialkot', 'stats_list': [], 'contributions': '179 contributions\n        in the last year', 'description': ['Linear-Regression-Stock-Price-Prediction using Machine Learning\nA small Machine Learning Linear Regression model for live prediction of the stock price changes for next 30 days with 93% accuracy on Google Wiki.\nThe dataset is taken form https://Quandl.org that is live data.\nYeah this is the finest of the prediction regression models.\n'], 'url_profile': 'https://github.com/mrqasimasif', 'info_list': ['3', 'Updated Apr 25, 2020', 'Updated Apr 10, 2020', '23', 'Python', 'Updated Jan 28, 2021', '22', 'JavaScript', 'BSD-3-Clause license', 'Updated Apr 20, 2020', 'Java', 'Apache-2.0 license', 'Updated Jan 29, 2021', '4', 'Python', 'MIT license', 'Updated Oct 30, 2020', 'Jupyter Notebook', 'Updated Aug 18, 2020', '4', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Shell', 'Updated Feb 27, 2021', '4', 'Python', 'Updated Oct 27, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Regression Trees and Model Optimization - Lab\nIntroduction\nIn this lab, we\'ll see how to apply regression analysis using CART trees while making use of some hyperparameter tuning to improve our model.\nObjectives\nIn this lab you will:\n\nPerform the full process of cleaning data, tuning hyperparameters, creating visualizations, and evaluating decision tree models\nDetermine the optimal hyperparameters for a decision tree model and evaluate the performance of decision tree models\n\nAmes Housing dataset\nThe dataset is available in the file \'ames.csv\'.\n\nImport the dataset and examine its dimensions:\n\n# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use(\'ggplot\')\n%matplotlib inline\n\n# Load the Ames housing dataset \ndata = None\n\n# Print the dimensions of data\n\n\n# Check out the info for the dataframe\n\n\n# Show the first 5 rows\nIdentify features and target data\nIn this lab, we will use using 3 predictive continuous features:\nFeatures\n\nLotArea: Lot size in square feet\n1stFlrSF: Size of first floor in square feet\nGrLivArea: Above grade (ground) living area square feet\n\nTarget\n\n\nSalePrice\', the sale price of the home, in dollars\n\n\nCreate DataFrames for the features and the target variable as shown above\n\n\nInspect the contents of both the features and the target variable\n\n\n# Features and target data\ntarget = None\nfeatures = None\nInspect correlations\n\nUse scatter plots to show the correlation between the chosen features and the target variable\nComment on each scatter plot\n\n#\xa0Your code here \nCreate evaluation metrics\n\nImport r2_score and mean_squared_error from sklearn.metrics\nCreate a function performance(true, predicted) to calculate and return both the R-squared score and Root Mean Squared Error (RMSE) for two equal-sized arrays for the given true and predicted values\n\nDepending on your version of sklearn, in order to get the RMSE score you will need to either set squared=False or you will need to take the square root of the output of the mean_squared_error function - check out the documentation or this helpful and related StackOverflow post\nThe benefit of calculating RMSE instead of the Mean Squared Error (MSE) is that RMSE is in the same units at the target - here, this means that RMSE will be in dollars, calculating how far off in dollars our predictions are away from the actual prices for homes, on average\n\n\n\n#\xa0Import metrics\n\n\n# Define the function\ndef performance(y_true, y_predict):\n    """""" \n    Calculates and returns the two performance scores between \n    true and predicted values - first R-Squared, then RMSE\n    """"""\n\n    # Calculate the r2 score between \'y_true\' and \'y_predict\'\n\n    # Calculate the root mean squared error between \'y_true\' and \'y_predict\'\n\n    # Return the score\n\n    pass\n\n\n# Test the function\nscore = performance([3, -0.5, 2, 7, 4.2], [2.5, 0.0, 2.1, 7.8, 5.3])\nscore\n\n# [0.9228556485355649, 0.6870225614927066]\nSplit the data into training and test sets\n\nSplit features and target datasets into training/test data (80/20)\nFor reproducibility, use random_state=42\n\nfrom sklearn.model_selection import train_test_split \n\n# Split the data into training and test subsets\nx_train, x_test, y_train, y_test = None\nGrow a vanilla regression tree\n\nImport the DecisionTreeRegressor class\nRun a baseline model for later comparison using the datasets created above\nGenerate predictions for test dataset and calculate the performance measures using the function created above\nUse random_state=45 for tree instance\nRecord your observations\n\n#\xa0Import DecisionTreeRegressor\n\n\n# Instantiate DecisionTreeRegressor \n# Set random_state=45\nregressor = None\n\n# Fit the model to training data\n\n\n# Make predictions on the test data\ny_pred = None\n\n# Calculate performance using the performance() function \nscore = None\nscore\n\n# [0.5961521990414137, 55656.48543887347] - R2, RMSE\nHyperparameter tuning (I)\n\nFind the best tree depth using depth range: 1-30\nRun the regressor repeatedly in a for loop for each depth value\nUse random_state=45 for reproducibility\nCalculate RMSE and r-squared for each run\nPlot both performance measures for all runs\nComment on the output\n\n#\xa0Your code here \nHyperparameter tuning (II)\n\nRepeat the above process for min_samples_split\nUse a range of values from 2-10 for this hyperparameter\nUse random_state=45 for reproducibility\nVisualize the output and comment on results as above\n\n#\xa0Your code here \nRun the optimized model\n\nUse the best values for max_depth and min_samples_split found in previous runs and run an optimized model with these values\nCalculate the performance and comment on the output\n\n#\xa0Your code here \nLevel up (Optional)\n\nHow about bringing in some more features from the original dataset which may be good predictors?\nAlso, try tuning more hyperparameters like max_features to find a more optimal version of the model\n\n#\xa0Your code here \nSummary\nIn this lab, we looked at applying a decision-tree-based regression analysis on the Ames Housing dataset. We saw how to train various models to find the optimal values for hyperparameters.\n'], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['3', 'Updated Apr 25, 2020', 'Updated Apr 10, 2020', '23', 'Python', 'Updated Jan 28, 2021', '22', 'JavaScript', 'BSD-3-Clause license', 'Updated Apr 20, 2020', 'Java', 'Apache-2.0 license', 'Updated Jan 29, 2021', '4', 'Python', 'MIT license', 'Updated Oct 30, 2020', 'Jupyter Notebook', 'Updated Aug 18, 2020', '4', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Shell', 'Updated Feb 27, 2021', '4', 'Python', 'Updated Oct 27, 2020']}","{'location': 'Turkey', 'stats_list': [], 'contributions': '272 contributions\n        in the last year', 'description': ['Generative Models Regression\nThis is my project on density-based regression. You can find the Python imlementation in this repository. The preprint of the paper is available at https://deepai.org/publication/generative-models-regression.\n'], 'url_profile': 'https://github.com/unverciftci', 'info_list': ['3', 'Updated Apr 25, 2020', 'Updated Apr 10, 2020', '23', 'Python', 'Updated Jan 28, 2021', '22', 'JavaScript', 'BSD-3-Clause license', 'Updated Apr 20, 2020', 'Java', 'Apache-2.0 license', 'Updated Jan 29, 2021', '4', 'Python', 'MIT license', 'Updated Oct 30, 2020', 'Jupyter Notebook', 'Updated Aug 18, 2020', '4', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Shell', 'Updated Feb 27, 2021', '4', 'Python', 'Updated Oct 27, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['\nesmf-test-scripts\nScripts for automated ESMF regression testing.\nHow to set up a new platform for automated regression testing\n$ git clone <this repo>\n$ python setup\n$ cron blah\n\n'], 'url_profile': 'https://github.com/esmf-org', 'info_list': ['3', 'Updated Apr 25, 2020', 'Updated Apr 10, 2020', '23', 'Python', 'Updated Jan 28, 2021', '22', 'JavaScript', 'BSD-3-Clause license', 'Updated Apr 20, 2020', 'Java', 'Apache-2.0 license', 'Updated Jan 29, 2021', '4', 'Python', 'MIT license', 'Updated Oct 30, 2020', 'Jupyter Notebook', 'Updated Aug 18, 2020', '4', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Shell', 'Updated Feb 27, 2021', '4', 'Python', 'Updated Oct 27, 2020']}","{'location': ' Luoyu Road 1037, Wuhan, China', 'stats_list': [], 'contributions': '187 contributions\n        in the last year', 'description': ['AutoScale_regression\n\nAn officical implementation of AutoScale regression-based method, you can find localization-based method from here.\nAutoScale leverages a simple yet effective Learning to Scale (L2S) module to cope with signiï¬cant scale variations in both localization and regression.\n\nStructure\nAutoScale_regression\n|-- data            # generate target\n|-- model           # model path \n|-- README.md       # README\n|-- centerloss.py           \n|-- config.py          \n|-- dataset.py       \n|-- find_contours.py           \n|-- fpn.py         \n|-- image.py\n|-- make_npydata.py\n|-- rate_model.py\n|-- val.py          \n\nVisualizations\n\nEnvironment\npython >=3.6 \npytorch >=1.0 \nopencv-python >=4.0 \nscipy >=1.4.0 \nh5py >=2.10 \npillow >=7.0.0\nDatasets\n\nDownload ShanghaiTech dataset from Baidu-Disk, passward:cjnx ; or Google-Drive\nDownload UCF-QNRF Dataset from  Google-Drive\nDownload JHU-CROWD ++  dataset from here\nDownload NWPU-CROWD dataset from Baidu-Disk, passward:9z97; or Google-Drive\n\nGenerate target\ncd data\nEdit ""distance_generate_xx.py"" to change the path to your original dataset folder.\npython density_generate_xx.py\nâ€œxxâ€ means the dataset name, including sh, jhu, qnrf, and  nwpu.\nModel\nDownload the pretrained model from Baidu-Disk, passward:9qfc ; or Google-Drive\nQuickly test\n\n\ngit clone https://github.com/dk-liang/AutoScale_regression.git\ncd AutoScale\n\n\nDownload Dataset and Model\n\n\nGenerate target\n\n\nGenerate images list\nEdit ""make_npydata.py"" to change the path to your original dataset folder.\nRun python make_npydata.py  .\n\n\nTest \npython val.py  --test_dataset qnrf  --pre ./model/QNRF/model_best.pth --gpu_id 0\npython val.py  --test_dataset jhu  --pre ./model/JHU/model_best.pth --gpu_id 0\npython val.py  --test_dataset nwpu  --pre ./model/NWPU/model_best.pth --gpu_id 0\npython val.py  --test_dataset ShanghaiA  --pre ./model/ShanghaiA/model_best.pth --gpu_id 0\npython val.py  --test_dataset ShanghaiB  --pre ./model/ShanghaiB/model_best.pth --gpu_id 0\nMore config information is  provided in config.py  \n\n\nTraining\ncoming soon.\nReferences\nIf you are interested in AutoScale, please cite our work:\n@article{xu2019autoscale,\n  title={AutoScale: Learning to Scale for Crowd Counting},\n  author={Xu, Chenfeng and Liang, Dingkang and Xu, Yongchao and Bai, Song and Zhan, Wei and Tomizuka, Masayoshi and Bai, Xiang},\n  journal={arXiv preprint arXiv:1912.09632},\n  year={2019}\n}\n\nand\n@inproceedings{xu2019learn,\n  title={Learn to Scale: Generating Multipolar Normalized Density Maps for Crowd Counting},\n  author={Xu, Chenfeng and Qiu, Kai and Fu, Jianlong and Bai, Song and Xu, Yongchao and Bai, Xiang},\n  booktitle={Proceedings of the IEEE International Conference on Computer Vision},\n  pages={8382--8390},\n  year={2019}\n}\n\n'], 'url_profile': 'https://github.com/dk-liang', 'info_list': ['3', 'Updated Apr 25, 2020', 'Updated Apr 10, 2020', '23', 'Python', 'Updated Jan 28, 2021', '22', 'JavaScript', 'BSD-3-Clause license', 'Updated Apr 20, 2020', 'Java', 'Apache-2.0 license', 'Updated Jan 29, 2021', '4', 'Python', 'MIT license', 'Updated Oct 30, 2020', 'Jupyter Notebook', 'Updated Aug 18, 2020', '4', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Shell', 'Updated Feb 27, 2021', '4', 'Python', 'Updated Oct 27, 2020']}"
"{'location': 'Mumbai', 'stats_list': [], 'contributions': '8 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Shreyank1397', 'info_list': ['4', 'Jupyter Notebook', 'Updated Apr 9, 2020', '5', 'TypeScript', 'MIT license', 'Updated Jul 20, 2020', '2', 'Python', 'Updated Apr 11, 2020', '6', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'MATLAB', 'Updated Apr 8, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', '1', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'Zurich, Switzerland', 'stats_list': [], 'contributions': '1,308 contributions\n        in the last year', 'description': ['Polynomial Curve Fitting\n\n\nA React component to interactively compile polyomial curves with D3 using least squares regression\n\nInstallation\nnpm i polynomial-curve-fitting\nUsage\nUse the react component generating a random curve:\n\nJavaScript Example\nimport React from \'react\';\nimport PolynomialCurveFitting from \'polynomial-curve-fitting\';\n\nconst App = () => <PolynomialCurveFitting></PolynomialCurveFitting>;\n\nexport default App;\n\n\nTypeScript Example\nimport React from \'react\';\nimport PolynomialCurveFitting from \'polynomial-curve-fitting\';\n\nconst App = () => <PolynomialCurveFitting></PolynomialCurveFitting>;\n\nexport default App;\n\nThe following sections show:\n\nhow to specify a curve\nhow to provide graph settings\nhow to get the curve as output\n\nSpecify a Curve\nTo provide initial information about the curve, there are four options:\n\n\nUse PropsBaseCurve and specify the following fields (all optional):\n\nJavaScript Example\nconst curve1 = {\n  name: \'Fancy Polynomial\',\n  description: \'This polynomial is a random polynomial.\',\n  xAxis: { label: \'x Axis\', min: 0, max: 10 },\n  yAxis: { label: \'y Axis\', min: 0, max: 10 },\n};\n\n\nTypeScript Example\nimport { PropsBaseCurve } from \'polynomial-curve-fitting/lib/types\';\nconst curve1: PropsBaseCurve = {\n  name: \'Fancy Polynomial\',\n  description: \'This polynomial is a random polynomial.\',\n  xAxis: { label: \'x Axis\', min: 0, max: 10 },\n  yAxis: { label: \'y Axis\', min: 0, max: 10 },\n};\n\n\n\nUse PropsCurvePoints to specify points for the least squares regression. The order of the polynomial will be one less than the number of provided points. The fields of PropsBaseCurve are still optional, but the points field is required:\n\nJavaScript Example\nconst curve2 = {\n  points: [\n    [0, 0],\n    [1, 1],\n  ],\n};\n\n\nTypeScript Example\nimport { PropsCurvePoints } from \'polynomial-curve-fitting/lib/types\';\nconst curve2: PropsCurvePoints = {\n  points: [\n    [0, 0],\n    [1, 1],\n  ],\n};\n\n\n\nUse PropsCurveOrder to specify the order of the polynomial. The points on the curve are randomly generated. The fields of PropsBaseCurve are still optional, but the polynomialOrder field is required:\n\nJavaScript Example\nconst curve3 = {\n  polynomialOrder: 2,\n};\n\n\nTypeScript Example\nimport { PropsCurveOrder } from \'polynomial-curve-fitting/lib/types\';\nconst curve3: PropsCurveOrder = {\n  polynomialOrder: 2,\n};\n\n\n\nUse PropsCurveCoefficients to specify the coefficients of the polynomial. When optionally specifying points, the x values are taken to create points on the curve (ideally the y values match). If no points have been specified, they are randomly generated. The fields of PropsBaseCurve are still optional, but the coefficients field is required:\n\nJavaScript Example\nconst curve4 = {\n  coefficients: [-0.1, 1.25, 5],\n  points: [\n    [0, 5],\n    [1, 6.15],\n    [2, 7.1],\n  ],\n};\n\n\nTypeScript Example\nimport { PropsCurveCoefficients } from \'polynomial-curve-fitting/lib/types\';\nconst curve4: PropsCurveCoefficients = {\n  coefficients: [-0.1, 1.25, 5],\n  points: [\n    [0, 5],\n    [1, 6.15],\n    [2, 7.1],\n  ],\n};\n\n\n\nProvide the information about the curve as follows:\n\nJavaScript Example\nimport PolynomialCurveFitting from \'polynomial-curve-fitting\';\nimport React from \'react\';\n\n// const curve ...\n\nconst App = () => <PolynomialCurveFitting curve={curve}></PolynomialCurveFitting>;\n\nexport default App;\n\n\nTypeScript Example\nimport PolynomialCurveFitting from \'polynomial-curve-fitting\';\nimport React from \'react\';\n\n// const curve ...\n\nconst App = () => <PolynomialCurveFitting curve={curve}></PolynomialCurveFitting>;\n\nexport default App;\n\nProvide Settings\nIn addition to the curve prop, there is also a settings prop that allows to set the style of the drawn graph (e.g, the size of the svg, font sizes, colors, and spacing). Have a look at the default props to see the default settings and what can be changed.\nconst App = () => <PolynomialCurveFitting settings={settings}></PolynomialCurveFitting>;\nGet Curve\nTo get updates on the curve while changing it within the component, use a callback function as shown in the following example:\n\nJavaScript Example\nimport PolynomialCurveFitting from \'polynomial-curve-fitting\';\nimport React from \'react\';\n\nconst App = () => {\n  const [curve, setCurve] = React.useState();\n  return (\n    <div>\n      <PolynomialCurveFitting curveChange={value => setCurve(value)}></PolynomialCurveFitting>\n      <pre>\n        {JSON.stringify(curve, (_, v) => (v instanceof Array ? JSON.stringify(v, null) : v), 3)}\n      </pre>\n    </div>\n  );\n};\n\nexport default App;\n\n\nTypeScript Example\nimport PolynomialCurveFitting from \'polynomial-curve-fitting\';\nimport { CurveOut } from \'polynomial-curve-fitting/lib/types\';\nimport React from \'react\';\n\nconst App = () => {\n  const [curve, setCurve] = React.useState<CurveOut>();\n  return (\n    <div>\n      <PolynomialCurveFitting\n        curveChange={(value: CurveOut) => setCurve(value)}\n      ></PolynomialCurveFitting>\n      <pre>\n        {JSON.stringify(curve, (_, v) => (v instanceof Array ? JSON.stringify(v, null) : v), 3)}\n      </pre>\n    </div>\n  );\n};\n\nexport default App;\n\nSet Translations\nThe internationalization prop accepts a PropsInternationalization object specifying translations. Depending on the current UI language change the i18n object in the following example to either ENGLISH or GERMAN. Have a look at the default props to see the default strings and what can be changed. Note that every string is optional.\n\nJavaScript Example\nimport PolynomialCurveFitting from \'polynomial-curve-fitting\';\nimport React from \'react\';\n\nconst ENGLISH = {\n  textSettings: { title: \'English Title\' },\n};\n\nconst GERMAN = {\n  textSettings: {\n    title: \'German Title\',\n    curveName: {\n      label: \'German Label\',\n    },\n  },\n};\n\nconst App = () => {\n  const [lang, setLang] = React.useState(\'en\');\n  const [i18n, setI18n] = React.useState(ENGLISH);\n\n  const langChange = newLang => {\n    setLang(newLang);\n    newLang === \'en\' && setI18n(ENGLISH);\n    newLang === \'de\' && setI18n(GERMAN);\n  };\n\n  return (\n    <div>\n      <select value={lang} onChange={e => langChange(e.target.value)}>\n        <option value=""en"">EN</option>\n        <option value=""de"">DE</option>\n      </select>\n      <PolynomialCurveFitting internationalization={i18n}></PolynomialCurveFitting>\n    </div>\n  );\n};\n\nexport default App;\n\n\nTypeScript Example\nimport PolynomialCurveFitting from \'polynomial-curve-fitting\';\nimport { PropsInternationalization } from \'polynomial-curve-fitting/lib/types\';\nimport React from \'react\';\n\nconst ENGLISH: PropsInternationalization = {\n  textSettings: { title: \'English Title\' },\n};\n\nconst GERMAN: PropsInternationalization = {\n  textSettings: {\n    title: \'German Title\',\n    curveName: {\n      label: \'German Label\',\n    },\n  },\n};\n\nconst App = () => {\n  const [lang, setLang] = React.useState<string>(\'en\');\n  const [i18n, setI18n] = React.useState<PropsInternationalization>(ENGLISH);\n\n  const langChange = (newLang: string) => {\n    setLang(newLang);\n    newLang === \'en\' && setI18n(ENGLISH);\n    newLang === \'de\' && setI18n(GERMAN);\n  };\n\n  return (\n    <div>\n      <select value={lang} onChange={e => langChange(e.target.value)}>\n        <option value=""en"">EN</option>\n        <option value=""de"">DE</option>\n      </select>\n      <PolynomialCurveFitting internationalization={i18n}></PolynomialCurveFitting>\n    </div>\n  );\n};\n\nexport default App;\n\nDevelopment\nThe following steps show how to make changes to polynomial-curve-fitting and use the component in an pcf-example react app. The commands used below assume that the two projects are sibling directories.\nClone and Build polynomial-curve-fitting\nWithin the terminal, execute the following commands:\n# clone the repository\ngit clone https://github.com/alexscheitlin/polynomial-curve-fitting.git\n\n# install the dependencies\ncd polynomial-curve-fitting\nnpm install\n\n# continuously build the library\nnpm run build:watch\nCreate new React App pcf-example\nOpen a new terminal tab and execute the following commands:\n# create new react app with typescript\nnpx create-react-app pcf-example --template typescript\n\n# install this library as a dependency\ncd pcf-example\nnpm install ../polynomial-curve-fitting\n\n# link react of the library with the one of the example react app\ncd ../polynomial-curve-fitting/\nnpm link ../pcf-example/node_modules/react\n\n# only do this if the example react app uses material ui\n# link material ui of the library with the one of the example react app\nnpm link ../pcf-example/node_modules/@material-ui/core\n\n# start the example react app\ncd ../pcf-example/\nnpm run start\nAdd the react component to the App.tsx file (see Usage)\n'], 'url_profile': 'https://github.com/alexscheitlin', 'info_list': ['4', 'Jupyter Notebook', 'Updated Apr 9, 2020', '5', 'TypeScript', 'MIT license', 'Updated Jul 20, 2020', '2', 'Python', 'Updated Apr 11, 2020', '6', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'MATLAB', 'Updated Apr 8, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', '1', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'Tempe', 'stats_list': [], 'contributions': '87 contributions\n        in the last year', 'description': ['Density-Estimation-and-Classification-using-Regression\nImplementation of Linear Regression & Logistic Regression in density estimation and classification.\n'], 'url_profile': 'https://github.com/Chanyadav', 'info_list': ['4', 'Jupyter Notebook', 'Updated Apr 9, 2020', '5', 'TypeScript', 'MIT license', 'Updated Jul 20, 2020', '2', 'Python', 'Updated Apr 11, 2020', '6', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'MATLAB', 'Updated Apr 8, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', '1', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '88 contributions\n        in the last year', 'description': ['Geely-Auto-Price-Prediction-Linear-Regression\nA Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts\nBusiness Goal:\nYou are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables.\nThey can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market\n'], 'url_profile': 'https://github.com/IshanSingh611', 'info_list': ['4', 'Jupyter Notebook', 'Updated Apr 9, 2020', '5', 'TypeScript', 'MIT license', 'Updated Jul 20, 2020', '2', 'Python', 'Updated Apr 11, 2020', '6', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'MATLAB', 'Updated Apr 8, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', '1', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'Zanjan', 'stats_list': [], 'contributions': '98 contributions\n        in the last year', 'description': ['Multi-class Classification\nIn this repository implementation of some multiclass classification algorithms have been provided. These algorithms have been designed for multi-class input labels except Bayesian Regression which is a binary implementation and uses one-vs-rest strategy. Below you can find the list of the implemented algorithms.\n\nmultinomial Logistic Regression\nWeighted Logistic Regression\nBayesian Logistic Regression (Two classes using one-vs-rest)\nGaussian Generative classification\nGaussian Naive Bayes Classification\nWeighted Voting (an ensemble learning method)\n\nResults\nThree datasets, PIE, VOC, MSRC was used for evaluating the code. Below you can find the result of each algorithm using 5-folding.\n1- PIE Dataset\n\n\n\nAlgo/measure\nPrecision\nRecall\nF1\n\n\n\n\nLogistic Regression\n0.963\n0.962\n0.96\n\n\nWeighted Log Reg\n0.72\n0.7\n0.71\n\n\nBayesian Log Reg\n0.95\n0.93\n0.93\n\n\nGaussian Generative\n0.971\n0.967\n0.969\n\n\nGenerative Naive Bayes\n0.96\n0.95\n0.95\n\n\n\n2- MSRC Dataset\n\n\n\nAlgo/measure\nPrecision\nRecall\nF1\n\n\n\n\nLogistic Regression\n0.78\n0.78\n0.78\n\n\nWeighted Log Reg\n0.18\n0.18\n0.18\n\n\nBayesian Log Reg\n0.64\n0.67\n0.65\n\n\nGaussian Generative\n0.79\n0.74\n0.76\n\n\nGenerative Naive Bayes\n0.89\n0.19\n0.31\n\n\n\n3- VOC Dataset\n\n\n\nAlgo/measure\nPrecision\nRecall\nF1\n\n\n\n\nLogistic Regression\n0.43\n0.37\n0.40\n\n\nWeighted Log Reg\n0.17\n0.18\n0.17\n\n\nBayesian Log Reg\n0.34\n0.34\n0.34\n\n\nGaussian Generative\n0.45\n0.38\n0.41\n\n\nGenerative Naive Bayes\n0.86\n0.2\n0.29\n\n\n\nThe ROC plot for these algorithms has been provided below.\n\nHow to run\n1- add measure function folder (if you cant wait for ""not found in the current folder"" error and click on ""add its folder to the MATLAB path"")\n2- Read the features and labels into fts and labels variables;\n3- Use any of the ML algorithms just like the way used in main.m\n4- run main.m\nsources\nAltought many sources online and offline has been used, Pattern Recognition and Machine Learning by Bishop (Springer) has been the most significant.\n'], 'url_profile': 'https://github.com/arnejad', 'info_list': ['4', 'Jupyter Notebook', 'Updated Apr 9, 2020', '5', 'TypeScript', 'MIT license', 'Updated Jul 20, 2020', '2', 'Python', 'Updated Apr 11, 2020', '6', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'MATLAB', 'Updated Apr 8, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', '1', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'Spain - Madrid', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gianmarcosegura', 'info_list': ['4', 'Jupyter Notebook', 'Updated Apr 9, 2020', '5', 'TypeScript', 'MIT license', 'Updated Jul 20, 2020', '2', 'Python', 'Updated Apr 11, 2020', '6', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'MATLAB', 'Updated Apr 8, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', '1', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '226 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/jrollus', 'info_list': ['4', 'Jupyter Notebook', 'Updated Apr 9, 2020', '5', 'TypeScript', 'MIT license', 'Updated Jul 20, 2020', '2', 'Python', 'Updated Apr 11, 2020', '6', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'MATLAB', 'Updated Apr 8, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', '1', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'Chennai,India', 'stats_list': [], 'contributions': '52 contributions\n        in the last year', 'description': ['Regression\n'], 'url_profile': 'https://github.com/ami-agrl', 'info_list': ['4', 'Jupyter Notebook', 'Updated Apr 9, 2020', '5', 'TypeScript', 'MIT license', 'Updated Jul 20, 2020', '2', 'Python', 'Updated Apr 11, 2020', '6', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'MATLAB', 'Updated Apr 8, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', '1', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'India', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': [""function infected=extrapolation(Day,Y,fit1)\nx=Day;\nData=Y;\np1=fit1.coeff(:,1);\np2=fit1.coeff(:,2);\np3=fit1.coeff(:,3);\np4=fit1.coeff(:,4);\np5=fit1.coeff(:,5);\nfor i=1:x\nx=i;\ninfected(1,i) = p1x^4 + p2x^3 + p3x^2 + p4x^1 + p5;\nend\nfigure;\nplot(Data,'*');\nhold on;\nplot(infected,'-')\nend\n""], 'url_profile': 'https://github.com/satendrasvnit', 'info_list': ['4', 'Jupyter Notebook', 'Updated Apr 9, 2020', '5', 'TypeScript', 'MIT license', 'Updated Jul 20, 2020', '2', 'Python', 'Updated Apr 11, 2020', '6', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'MATLAB', 'Updated Apr 8, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', '1', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '53 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/shub-coder', 'info_list': ['4', 'Jupyter Notebook', 'Updated Apr 9, 2020', '5', 'TypeScript', 'MIT license', 'Updated Jul 20, 2020', '2', 'Python', 'Updated Apr 11, 2020', '6', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'MATLAB', 'Updated Apr 8, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', '1', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}"
"{'location': 'Bangalore', 'stats_list': [], 'contributions': '20 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/data-scientist-2020', 'info_list': ['Jupyter Notebook', 'Updated Jul 15, 2020', 'R', 'Updated May 4, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Jul 8, 2020', '2', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 23, 2020', '2', 'Jupyter Notebook', 'Updated Sep 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/h-karyn', 'info_list': ['Jupyter Notebook', 'Updated Jul 15, 2020', 'R', 'Updated May 4, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Jul 8, 2020', '2', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 23, 2020', '2', 'Jupyter Notebook', 'Updated Sep 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '61 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/nicolasmontano', 'info_list': ['Jupyter Notebook', 'Updated Jul 15, 2020', 'R', 'Updated May 4, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Jul 8, 2020', '2', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 23, 2020', '2', 'Jupyter Notebook', 'Updated Sep 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '956 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Tungetyt', 'info_list': ['Jupyter Notebook', 'Updated Jul 15, 2020', 'R', 'Updated May 4, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Jul 8, 2020', '2', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 23, 2020', '2', 'Jupyter Notebook', 'Updated Sep 8, 2020']}","{'location': 'New Delhi', 'stats_list': [], 'contributions': '71 contributions\n        in the last year', 'description': ['Regression\n'], 'url_profile': 'https://github.com/IAlam0819', 'info_list': ['Jupyter Notebook', 'Updated Jul 15, 2020', 'R', 'Updated May 4, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Jul 8, 2020', '2', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 23, 2020', '2', 'Jupyter Notebook', 'Updated Sep 8, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '48 contributions\n        in the last year', 'description': ['Regression\n'], 'url_profile': 'https://github.com/shekharkhandelwal1983', 'info_list': ['Jupyter Notebook', 'Updated Jul 15, 2020', 'R', 'Updated May 4, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Jul 8, 2020', '2', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 23, 2020', '2', 'Jupyter Notebook', 'Updated Sep 8, 2020']}","{'location': 'Buffalo', 'stats_list': [], 'contributions': '50 contributions\n        in the last year', 'description': ['Regression\nRegression estimates value between the variables. Unlike classification, Regression gives numeric value as an output.\nThe folder contains Logistic and Linear Regression with binary class data.\n'], 'url_profile': 'https://github.com/Malini-AI', 'info_list': ['Jupyter Notebook', 'Updated Jul 15, 2020', 'R', 'Updated May 4, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Jul 8, 2020', '2', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 23, 2020', '2', 'Jupyter Notebook', 'Updated Sep 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['nkarmali-uw.edu\nHello! Thank you for viewing my portfolio. In this repository you will find the following projects:\nLinear Regression: Predicting Peaks in Bike Rentals\nSkills:\n-Cleaning data\n-Dealing with outliers\n-Exploratory data analysis\n-Regression analysis\n-Business impact analysis\nNeural Network Image Classification: predicts whether an image is a hand sign of rock, paper, or scissors\nSkills:\n-Image processing\n-Building Neural Network\n-Building Convulutional Neural Network\n'], 'url_profile': 'https://github.com/natashakarmali', 'info_list': ['Jupyter Notebook', 'Updated Jul 15, 2020', 'R', 'Updated May 4, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Jul 8, 2020', '2', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 23, 2020', '2', 'Jupyter Notebook', 'Updated Sep 8, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '231 contributions\n        in the last year', 'description': ['House-Sale-Price\nPredict House Sale Price using Advanced Regression Techniques\n\n'], 'url_profile': 'https://github.com/vaibhav1595', 'info_list': ['Jupyter Notebook', 'Updated Jul 15, 2020', 'R', 'Updated May 4, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Jul 8, 2020', '2', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 23, 2020', '2', 'Jupyter Notebook', 'Updated Sep 8, 2020']}","{'location': 'India', 'stats_list': [], 'contributions': '28 contributions\n        in the last year', 'description': [""LearnX Sales Forecasting\nLearnX is an online learning platform aimed at professionals and students. LearnX serves as a market place that allows instructors to build online courses on topics of their expertise which is later published after due diligence by the LearnX team. The platform covers a wide variety of topics including Development, Business, Finance & Accounting & Software Marketing and so on\nEffective forecasting for course sales gives essential insight into upcoming cash flow meaning business can more accurately plan the budget to pay instructors and other operational costs and invest in the expansion of the business.\nSales data for more than 2 years from 600 courses of LearnX's top domains is available along with information on\nCompetition in the market for each course\nCourse Type (Course/Program/Degree)\nHoliday Information for each day\nUser Traffic on Course Page for each day\nYour task is to predict the course sales for each course in the test set for the next 60 days\nData Dictionary\nTrain (Historical Sales Data)\nVariable\tDefinition\nID\t: Unique Identifier for a row\nDay_No :\tDay Number\nCourse_ID :\tUnique ID for a course\nCourse_Domain :\tCourse Domain (Development, Finance etc.)\nCourse_Type\t: Course/Program/Degree\nShort_Promotion\t: Whether Short Term Promotion is Live\nPublic_Holiday\t: Regional/Public Holiday\nLong_Promotion: \tWhether Long Term Promotion is Live for the course\nUser_Traffic\t : Number of customers landing on the course page\nCompetition_Metric\t : A metric defining the strength of competition\nSales\t(Target) : Total Course Sales\nTest (Next 60 Days)\nThis file contains the store and day number for which the participant needs to submit predictions/forecasts\nVariable\tDefinition\nID\t: Unique Identifier for a row\nDay_No\t:Day Number\nCourse_ID\t : Unique ID for a course\nCourse_Domain\t: Course Domain (Development, Finance etc.)\nCourse_Type\t: Course/Program/Degree\nShort_Promotion\t: Whether Short Term Promotion is Live\nPublic_Holiday\t: Regional/Public Holiday\nLong_Promotion\t: Whether Long Term Promotion is Live for the course\nCompetition_Metric\t: A metric defining the strength of competition\n""], 'url_profile': 'https://github.com/Ssharma91', 'info_list': ['Jupyter Notebook', 'Updated Jul 15, 2020', 'R', 'Updated May 4, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Jul 8, 2020', '2', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 23, 2020', '2', 'Jupyter Notebook', 'Updated Sep 8, 2020']}"
"{'location': 'Bangalore,India', 'stats_list': [], 'contributions': '49 contributions\n        in the last year', 'description': ['linear-regression\nBasic understanding for the data to build linear regression model and hyper parameter tuning.\n'], 'url_profile': 'https://github.com/saibharath2', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 29, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Jun 28, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '240 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/physics-machinelearning', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 29, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Jun 28, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '81 contributions\n        in the last year', 'description': ['Logistic-Regression\nThis modal has been built to predict if a patient has diabetes or not based on multiple features.\nUsed standard Scaler,imputer,metrics histo graphs and many more.\n'], 'url_profile': 'https://github.com/shankarat', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 29, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Jun 28, 2020']}","{'location': 'Banglore', 'stats_list': [], 'contributions': '61 contributions\n        in the last year', 'description': ['Yield-Prediction\nRegression Problem\n'], 'url_profile': 'https://github.com/iasjkk', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 29, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Jun 28, 2020']}","{'location': 'Banglore,Hyderabad', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Raghava248', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 29, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Jun 28, 2020']}","{'location': 'Greater Noida', 'stats_list': [], 'contributions': '102 contributions\n        in the last year', 'description': ['linear-regression\n'], 'url_profile': 'https://github.com/shreyanshsingh2107', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 29, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Jun 28, 2020']}","{'location': 'Sialkot', 'stats_list': [], 'contributions': '179 contributions\n        in the last year', 'description': ['Multiple-Linear-Regression-CO2-Emission-Prediction\nMultiple Linear Regression Model to Predict the CO2 emission for unknown vehicle using its multiple features unline Linear Regression which uses Single feature only.\nThe model is accurate with the mean variance of 0.01 from the original value.\n2 Models are trained, each using different features.\n'], 'url_profile': 'https://github.com/mrqasimasif', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 29, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Jun 28, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['BI-Project-Bigmart-Sales-Prediction\nPredict the sales of a store.\nGroup Members:\nTanvi Hule-23\nManali Kharat-26\nShivani Mani-30\nLinear Regression algorithm is used.\nDataset Description -\nItem_Identifier- Unique product ID\nItem_Weight- Weight of product\nItem_Fat_Content - Whether the product is low fat or not\nItem_Visibility - The % of total display area of all products in a store allocated to the particular product\nItem_Type - The category to which the product belongs\nItem_MRP - Maximum Retail Price (list price) of the product\nOutlet_Identifier - Unique store ID\nOutlet_Establishment_Year- The year in which store was established\nOutlet_Size - The size of the store in terms of ground area covered\nOutlet_Location_Type- The type of city in which the store is located\nOutlet_Type- Whether the outlet is just a grocery store or some sort of supermarket\nItem_Outlet_Sales - Sales of the product in the particulat store. This is the outcome variable to be predicted.\n'], 'url_profile': 'https://github.com/huletanvi', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 29, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Jun 28, 2020']}","{'location': 'Cambridge ', 'stats_list': [], 'contributions': '364 contributions\n        in the last year', 'description': ['COVID-19\nCOVID 19 - Simple regression to model evolution of case per state\nMethods:\n\nSIR\nExponential regression\n\nWe also allow shift to only focus modeling on points after a certain number of cases has been detected\nData\nData is obtained at https://covidtracking.com/\nLibrary\nNeeds pandas, numpy, matplotlib, scipy, sklearn and us libraries\n'], 'url_profile': 'https://github.com/Jeanselme', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 29, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Jun 28, 2020']}","{'location': 'Thailand', 'stats_list': [], 'contributions': '35 contributions\n        in the last year', 'description': ['Linear-regression (Supermarket Case)\nLinear regression example\n'], 'url_profile': 'https://github.com/Chanon-aumrung', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 29, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Jun 28, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '81 contributions\n        in the last year', 'description': ['Linear-Regression\nThis has 3 modal is to predict\n\nSales based on TV,Radio,Newspaper and find which group(TV,NewsPaper,Radio) contribute most to the sales.\nAdmission Prediction based on the competitive exams\nSalaries based on the levels\n\n'], 'url_profile': 'https://github.com/shankarat', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Jan 12, 2021', 'Python', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/syedhazahra', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Jan 12, 2021', 'Python', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '74 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/kadirdeniz', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Jan 12, 2021', 'Python', 'Updated Apr 7, 2020']}","{'location': 'Dhaka, Bangladesh', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/tasnimnisha2', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Jan 12, 2021', 'Python', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Lecture13\nLogistic Regression Materials\n'], 'url_profile': 'https://github.com/STAT506', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Jan 12, 2021', 'Python', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '140 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/kennyvoo', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Jan 12, 2021', 'Python', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '118 contributions\n        in the last year', 'description': ['pluralSight_Regression_tf\nRegression Models TensorFlow\n'], 'url_profile': 'https://github.com/erichenschel', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Jan 12, 2021', 'Python', 'Updated Apr 7, 2020']}","{'location': 'Ithaca, NY', 'stats_list': [], 'contributions': '563 contributions\n        in the last year', 'description': ['Complete Regression - Lab\nIntroduction\nBy now, you have created all the necessary functions to calculate the slope, intercept, best-fit line, prediction, and visualizations. In this lab you will put them all together to run a regression experiment and calculate the model loss.\nObjectives\nYou will be able to:\n\nPerform a linear regression using self-constructed functions\nCalculate the coefficient of determination using self-constructed functions\nUse the coefficient of determination to determine model performance\n\nThe formulas\nSlope:\n$\\hat m = \\dfrac{\\overline{x}*\\overline{y}-\\overline{xy}}{(\\overline{x})^2-\\overline{x^2}}$\nIntercept: $ \\hat c = \\bar{y} - \\hat m\\bar{x}$\nPrediction: $\\hat{y} = \\hat mx + \\hat c$\nR-Squared:\n$ R^2 = 1- \\dfrac{SS_{RES}}{SS_{TOT}} = 1 - \\dfrac{\\sum_i(y_i - \\hat y_i)^2}{\\sum_i(y_i - \\overline y_i)^2} $\nUse the Python functions created earlier to implement these formulas to run a regression analysis using x and y as input variables.\n# Combine all the functions created so far to run a complete regression experiment. \n# Produce an output similar to the one shown below. \n\nX = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=np.float64)\nY = np.array([7, 7, 8, 9, 9, 10, 10, 11, 11, 12], dtype=np.float64)\n# Basic Regression Diagnostics\n# ----------------------------\n# Slope: 0.56\n# Y-Intercept: 6.33\n# R-Squared: 0.97\n# ----------------------------\n# Model: Y = 0.56 * X + 6.33\nBasic Regression Diagnostics\n----------------------------\nSlope: 0.56\nY-Intercept: 6.33\nR-Squared: 0.97\n----------------------------\nModel: Y = 0.56 * X + 6.33\n\n\nMake Predictions\nPredict and plot the value of y using regression line above for a new value of $x = 4.5$.\n# Make prediction for x = 4.5 and visualize on the scatter plot\n\nLevel up - Optional\nLoad the ""heightweight.csv"" dataset. Use the height as an independent and weight as a dependent variable and draw a regression line to data using your code above. Calculate your R-Squared value for the model and try to predict new values of y.\nSummary\nIn this lab, we ran a complete simple regression analysis experiment using functions created so far. Next up, you\'ll learn how you can use Python\'s built-in modules to perform similar analyses with a much higher level of sophistication.\n'], 'url_profile': 'https://github.com/merb92', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Jan 12, 2021', 'Python', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '138 contributions\n        in the last year', 'description': [""Predictors on the Productivity of Hits in 2017 Major League Baseball\nTable of contents\n\nA Multiple Regression Analysis of Batting Average and Hits\n\nIntroduction\nData Source\nVariables\n\n\nA Simple Regression Model\n\nScatterplot\nThe Linear Regression Model\nSAS Output for the Fitted Model\nAnalysis of Outplot\n\n\nModel Selection\n\nBest Subsets Model Selection\nForward Stepwise Model Selection\nCook's D\nVariance Inflation\n\n\nCross Validation\n\nModel Selection with GLMSelect\nQuality of the Fitted Model: Steps for Cross Validation\n\n\n\nA Multiple Regression Analysis of Batting Average and Hits\nIntroduction\nThe topic of this subject matter is on the starting lineup for all teams in the 2017 MLB season. Iâ€™ve been a baseball fan, specifically of the Yankees, since around 10 years old. I would watch the games with my family and we would cause so much commotion that my mother would think something bad had happened. I became such a giant fan of the Yankees throughout the years that I even got season tickets. Admittingly, I started to grow tired of baseball after that year, maybe it was all the travelling to the Bronx that I had to do, but in recent years my interest has started to slowly grow back. Therefore, for this analysis Iâ€™m interested in seeing how specific variables affect hits.\nData Source\nI was able to pull up the statistic for the starting lineup for 2017 of all Major League Baseball Teams on the following website:\nhttps://www.baseball-reference.com/leagues/MLB/2017.shtml\nVariables\nThere are a total of 246 observations in this dataset. For this analysis the dependent variable is the total number of hits for each player and the independent variables are batting average, age, strikeouts, and at bats.\nHits: When the batter safely reaches first base after hitting the ball in fair territory\nBatting Average: Number of hits divided by at bats\nAge: Age of the batter\nStrikeouts: Occurs when the batter racks up 3 strikes for failure to hit the ball into fair territory\nWalks: occurs when a batter receives four pitches outside the strike zone and is in turn awarded first base\n\nA Simple Regression Model\nScatterplot\n\nI donâ€™t see obvious curvature in my data. We can see a bit of heteroscedasticity towards the bottom of the scatterplot. The pink line illustrates the vertical cut in the data. It could be that these players didnâ€™t play a full season due to an injury or they might have just had a very bad year. No real leverage or outliers exist in this scatterplot. The two points that are separated by the pink line fall in line with the rest of the data and arenâ€™t dramatically far away from the rest of the data points.\nThe Linear Regression Model\nYx= Î²o + Î²1x + Îµ\n(a)\tYx = subpopulation average, which is normally distributed, of hits that share the same batting average.\n(b)\tE(Yx) = the expected value of the random variable, Hits, conditional on knowing the batting average. For example, it is the expected value of the subpopulation average of hits given all the players with 0.250 batting average.\n(c)\tV(Yx) = the variance of the random variable hits given the players with a batting average of 0.250.\nSAS Output for the Fitted Model\n  \nAt a given count of x, say in my case is a batting average of 0.250, we can picture a vertical line down that count, illustrated in green. That vertical line intersects the 2 dotted lines. The y coordinates of those intersections, illustrated by the purple dots, define the endpoints for the 95% prediction interval for the number of hits of the 247th (the next observation) player. As the vertical line passes through the shaded band, given by the pink slanted lines, it defines the 95% confidence interval for the subpopulation expected value of hits given a batting average of 0.250. Where the vertical line intersects the  line, the red dot, it gives us the point prediction of the number of hits of the 247th player with a batting average of 0.250.\nAnalysis of Output\nThe t-test\ni. We are testing if the population slope for hits and batting average is equal to zero.\nho = Î²1 =0\nho = Î²1 â‰  0\nii. Test statistic: t-stat =  (b1 - Î²1/(s/âˆšSSx)  =  (760.15209-0)/59.89739=12.69\nRejection Region: |12.69| > 1.970, Î±=0.05\nt-critcal value with 2 d.f. = 1.970\nConclusion :\tnull hypothesis is rejected because the |t-stat| = |12.69| greater than the t-critical value of 1.970\nThe yhat equation\nThe equation for the fitted model is as follows:\nyhat = -79.721 + 760.152x\nModel Selection\nBest Subsets Model Selection\n\nI tried taking log and square root transformations, but I didnâ€™t notice any obvious improvements in the data. In the scatterplot showing Hits and Age, I donâ€™t see an obvious relationship. It seems to be negatively correlated but it isnâ€™t a very strong one. In the scatterplot showing Hits vs. Walks there are a couple of leverage points which I have circled in purple. They lie a bit far in the horizontal direction, away from the rest of the data.\n \nThe model I prefer includes Walks, Batting Average and Strikeouts. C(p), AIC, BIC, and SBC, all agree that a model with 4 parameters is best, which means the model has 3 regressors. Next to the star aligned with the 4 parameters, a 2 is shown. Therefore, looking at the Summary Table above Model number 2 shows that the best model includes, Walks, Batting Average, and Strikeouts.\nForward Stepwise Model Selection\nAccording to the summary of the Stepwise Model Selection, the first variable selected was Batting Average. Then it added Strikeouts and did not remove Batting Average. Next, it added Walks and did not remove any of the previous variables. Finally, the selection method stopped and did not add the last variable which is Age.\n \nThe Stepwise Selection method choose the same model as the best subsets method.\nCook's D\nBelow are the diagnostic plots for the model selected above. The plots show the flagged players according to Cookâ€™s D and Outlier and Leverage Plot. Aaron Judge seems to be the most obvious influential point according to both diagnostic plots.\n \nVariance Inflation\nVariance Inflation, shows if multicollinearity exists in our analysis. If the VIF is high, the variance of the standard errors of the slope is increased because of collinearity. It helps us identify if we are regressing one variable on another almost identical to itself. All variables are close to 1, therefore multivollinearity does not exist.\n\nCross-Validation\nModel Selection with GLMSelect\nI used Proc GLMSelect in SAS, with AICC as a selection criterion. The first variable selected was Batting Average, then it chose Strikeouts, next it chose Walks. The bold line at 3 indicates that those three variables are the best model for Hits.\n\nQuality of the Fitted Model: Steps for Cross Validation\nI used Cross Validation to judge the quality of the fitted model shown above.\nStep 1: Splitting the Data\nThe first step I took was to split the existing data into two groups. I did this by first randomizing the order of the 246 batters in my data, and then I split them into two groups. The first group, known as the training group, consists of 100 batters and the second group, known as the validation group, consists on 146 batters.\n\nStep 2: Fit the Regression Model\nNow I fit the regression model on the training sample.\n\nStep 3: Out of Sample Forecasting\nNext, I used the resulting  equation to forecast the number of hits for the Validation Sample. Below, I have shown the last 10 observations of the yhat equation Validation Sample.\n\nStep 4: Compare MSE values\nIn order to measure the quality of fit, we need to compare the Internal MSE (MSE for the training sample) with the External MSE (MSE for the validation sample). If the training MSE and the validation MSE are similar in value, then we can say that this is evidence for validating the chosen model.\n\nSince, the slope estimates are computed in such a fashion as to minimize the Internal MSE, we must expect that the External MSE will be larger than the Internal MSE. We can use the following equation to account for how much larger the External MSE will be from the internal MSE:\n(n+p)/(n-p)=  (246+4)/(246-4)=  250/242= 1.033\nNow, I can compare that with the Internal and External MSE:\n(External MSE)/(Internal MSE)=  539.5/389.806=1.384\nThey seem to be close in value, therefore the model has been validated.\n""], 'url_profile': 'https://github.com/Gindely', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Jan 12, 2021', 'Python', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/renatomir', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Jan 12, 2021', 'Python', 'Updated Apr 7, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/renatomir', 'info_list': ['Python', 'Updated Apr 7, 2020', 'Updated Apr 11, 2020', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'MATLAB', 'Updated Jun 24, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['POLYNOMIAL_REGRESSION\nBasic Polynomial Regression\n'], 'url_profile': 'https://github.com/Ilisten2soul', 'info_list': ['Python', 'Updated Apr 7, 2020', 'Updated Apr 11, 2020', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'MATLAB', 'Updated Jun 24, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['regression-testing\nfor testing Visual regression\n'], 'url_profile': 'https://github.com/bwilliam17', 'info_list': ['Python', 'Updated Apr 7, 2020', 'Updated Apr 11, 2020', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'MATLAB', 'Updated Jun 24, 2020']}","{'location': 'Istanbul, TURKEY', 'stats_list': [], 'contributions': '102 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/tekinadem', 'info_list': ['Python', 'Updated Apr 7, 2020', 'Updated Apr 11, 2020', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'MATLAB', 'Updated Jun 24, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['PyAffreg\n(Affinity regression  Python/Cython/C implementation)\nAbout AffReg Class\nClass name: AffReg.\nClass description: Affinity regression(AffReg) explains the interaction between two objects.\nD * W * P.T ~ Y\n\nD is a given object feature, P is the other object feature, Y is the interaction between D and P.\nAfter taining the model, We want to predict the interaction between D and new features of P.\nClass functions:\nfit(D,  P_train, Y_train, lamda = 0.001, rsL2 = 0, spectrumA = 1 spectrumB = 0.7, norm=True )\n\t# train the model \n\t# parameters:\t\t\n\t\tD: left matrix\n\t\tP_train: right matrix, train sample of P\n\t\tY_train: interation, train sample of Y\n\t\tlamda: L1 regulization\n\t\trsL2:  L2 regulization\n\t\tsectrumA: percent spectrum to keep (0,1] for left matrix\n\t\tsectrumB: percent spectrum to keep (0,1] for right matrix\n\npredict(P_test)\n\t# predidct the interaction on test samples of P\n\t# parameters:\n\t\tP_test: test sample of P. \n\nget_W()\n\t# retrieve trained parameters W\n    \ncorPlot (Y_pred, Y_test)\n\t# calculate the correlation between Y_pred with ground truth, and plot the their correlation\n\t# parameters:\n\t\tY_pred: predicted interaction from predict function, \n    \t\tY_test: the ground truth value of Y, usually it is the test dataset from data splitting\n\nHow to run\n1. Download PyAffreg\n2. Build Cython extension module\nAffreg calls 2 cython customerized extensions which need to be built on site\n\nbuild cythLeastR extention modue\n\n1))  Goto folder ""cythKrnPlus built"", then execute command:\n    python setup.py build_ext --inplace\n\nIt will generate the file cythLeastR.cpython-37m-x86_64-linux-gnu.so (Mac or Linux), or cythLeastR.cp37-win_amd64.pyd (Windows).\n2)) Copy the file into pyAffreg folder\n\nbuild cythKrnPlus extention modue\n\n1)) Goto folder ""cythKrnPlus built"", then execute command:\npython setup.py build_ext --inplace\n\nIt will generate the file cythKrnPlus.cpython-37m-x86_64-linux-gnu.so (Mac or Linux), or cythKrnPlus.cp37-win_amd64.pyd (Windows).\n2)) Copy the file into pyAffreg folder\n3. Use AffReg class\n1)) Import the class\n    from AffinityRegression import AffReg\n\n2)) Define the object of the class\n    reg = AffReg()\n\n3)) Train the model\n    reg.fit(D,  P_train, Y_train, lamda = 0.001, rsL2 = 0, spectrumA = 1 spectrumB = 0.7, norm=True )\n    # lamda, reL2, spectrumA, spectrumB can be changed based on characteristics of data, listed above are the default values\n\n4)) Predict Y\n    pred_Y = reg.predict(P_test)\n\nAfter training the model, you can also retrieve the trained parameter W with\n    pred_W = reg.get_W()\n\n5)) Check the performance and plot the correlation\n    corr = reg.corPlot(Y_pred, Y_test)\n\n'], 'url_profile': 'https://github.com/xim2020', 'info_list': ['Python', 'Updated Apr 7, 2020', 'Updated Apr 11, 2020', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'MATLAB', 'Updated Jun 24, 2020']}","{'location': 'Pune', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['SimpleLinearRegressionAnalysis\nLinear Regression Analysis\n'], 'url_profile': 'https://github.com/kprasaad23', 'info_list': ['Python', 'Updated Apr 7, 2020', 'Updated Apr 11, 2020', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'MATLAB', 'Updated Jun 24, 2020']}","{'location': 'Ithaca, NY', 'stats_list': [], 'contributions': '563 contributions\n        in the last year', 'description': [""Simple Linear Regression - Lab\nIntroduction\nIn this lab, you'll get some hand-on practice developing a simple linear regression model. You'll also use your model to make a prediction about new data!\nObjectives\nYou will be able to:\n\nPerform a linear regression using self-constructed functions\nInterpret the parameters of a simple linear regression model in relation to what they signify for specific data\n\nLet's get started\nThe best-fit line's slope $\\hat m$ can be calculated as:\n$$\\hat m = \\rho \\frac{S_Y}{S_X}$$\nWith $\\rho$ being the correlation coefficient and ${S_Y}$ and ${S_X}$ being the standard deviation of $x$ and $y$, respectively. It can be shown that this is also equal to:\n$$\\hat m = \\dfrac{\\overline{x}*\\overline{y}-\\overline{xy}}{(\\overline{x})^2-\\overline{x^2}}$$\nYou'll use the latter formula in this lab. First, break down the formula into its parts. To do this, you'll import the required libraries and define some data points to work with. Next, you'll use some pre-created toy data in NumPy arrays. Let's do this for you to give you a head start.\n# import necessary libraries\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nstyle.use('ggplot')\n%matplotlib inline\n\n# Initialize arrays X and Y with given values\n# X = Independent Variable\nX = np.array([1,2,3,4,5,6,8,8,9,10], dtype=np.float64)\n# Y = Dependent Variable\nY = np.array([7,7,8,9,9,10,10,11,11,12], dtype=np.float64)\nCreate a scatter plot of X and Y and comment on the output\n# Scatter plot\n# Your observations about the relationship between X and Y \n\n\n\n#\nWrite a function calc_slope()\nWrite a function calc_slope() that takes in X and Y and calculates the slope using the formula shown above.\n# Write the function to calculate slope as: \n# (mean(x) * mean(y) â€“ mean(x*y)) / ( mean (x)^2 â€“ mean( x^2))\ndef calc_slope(xs,ys):\n    \n    pass\n\ncalc_slope(X,Y)\n\n# 0.5393518518518512\nGreat, so we have our slope. Next we calculate the intercept.\nAs a reminder, the calculation for the best-fit line's y-intercept is:\n$$\\hat c = \\overline y - \\hat m \\overline x $$\nWrite a function best_fit()\nWrite a function best_fit() that takes in X and Y, calculates the slope and intercept using the formula. The function should return slope and intercept values.\n# use the slope function with intercept formula to return calculate slope and intercept from data points\n\ndef best_fit(xs,ys):\n    \n    pass\n\n# Uncomment below to test your function\n\n#m, c = best_fit(X,Y)\n#m, c\n\n# (0.5393518518518512, 6.379629629629633)\nWe now have a working model with m and c as model parameters. We can create a line for the data points using the calculated slope and intercept:\n\nRecall that $y = mx + c$. We can now use slope and intercept values along with X data points (features) to calculate the Y data points (labels) of the regression line.\n\nWrite a function reg_line()\nWrite a function reg_line() that takes in slope, intercept and X vector and calculates the regression line using $y= mx + c$ for each point in X\ndef reg_line (m, c, xs):\n    \n    pass\n\n# Uncomment below\n#regression_line = reg_line(m,c,X)\nPlot the (x,y) data points and draw the calculated regression line for visual inspection\n# Plot data and regression line\nSo there we have it, our least squares regression line. This is the best fit line and does describe the data pretty well (still not perfect though).\nDescribe your Model Mathematically and in Words\n# Your answer here\n\n\nPredicting new data\nSo, how might you go about actually making a prediction based on this model you just made?\nNow that we have a working model with m and b as model parameters. We can fill in a value of x with these parameters to identify a corresponding value of $\\hat y$ according to our model. Recall the formula:\n$$\\hat y = \\hat mx + \\hat c$$\nLet's try to find a y prediction for a new value of $x = 7$, and plot the new prediction with existing data\nx_new = 7\ny_predicted = None\ny_predicted\n\n# 10.155092592592592\nPlot the prediction with the rest of the data\n# Plot as above and show the predicted value\nYou now know how to create your own models, which is great! Next, you'll find out how to determine the accuracy of your model!\nSummary\nIn this lesson, you learned how to perform linear regression for data that are linearly related. You first calculated the slope and intercept parameters of the regression line that best fit the data. You then used the regression line parameters to predict the value ($\\hat y$-value) of a previously unseen feature ($x$-value).\n""], 'url_profile': 'https://github.com/merb92', 'info_list': ['Python', 'Updated Apr 7, 2020', 'Updated Apr 11, 2020', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'MATLAB', 'Updated Jun 24, 2020']}","{'location': 'New York', 'stats_list': [], 'contributions': '121 contributions\n        in the last year', 'description': ['classification_regression_tasks\nTask 1 Classification on the â€˜credit-gâ€™ dataset (Notebook 1)\nYou can download the dataset with â€˜fetch_openml(â€˜credit_gâ€™)â€™ and see itâ€™s description at\nhttps://www.openml.org/d/31\n1.1 Determine which features are continuous and which are categorical.\n1.2 Visualize the univariate distribution of each continuous feature, and the distribution of the\ntarget.\n1.3 Split data into training and test set. Do not use the test set until a final evaluation in 1.5.\nPreprocess the data (such as treatment of categorical variables) without using a pipeline and\nevaluate an initial LogisticRegression model with an training/validation split.\n1.4 Use ColumnTransformer and pipeline to encode categorical variables (your choice of\nOneHotEncoder or another one from the categorical_encoder package, or both). Evaluate\nLogistic Regression, linear support vector machines and nearest neighbors using\ncross-validation. How different are the results? How does scaling the continuous features with\nStandardScaler influence the results?\n1.5 Tune the parameters using GridSearchCV. Do the results improve? Evaluate only the be\nmodel on the test set.\nVisualize the performance as function of the parameters for all three models.\n1.6 Change the cross-validation strategy from â€˜stratified k-foldâ€™ to â€˜kfoldâ€™ with shuffling. Do the\nparameters that are found change? Do they change if you change the random seed of the\nshuffling? Or if you change the random state of the split into training and test data?\n1.7 Visualize the 20 most important coefficients for LogisticRegression and Linear Support\nVector Machines using hyper-parameters that performed well in the grid-search.\nTask 2 Regression on Sydney Dataset (Notebook 2)\nYou can load the Sydney housing dataset from https://www.kaggle.com/shree1992/housedata\nwhere you can also find a description. The goal is to predict the â€˜priceâ€™ column. For this\nassignment you can ignore the date. Please donâ€™t make any kernels public on Kaggle before\nthe assignment ends.\n2.1 Determine which features are continuous vs categorical. Drop rows without a valid sales\nprice.\n2.2 Visualize the univariate distribution of each continuous feature, and the distribution of the\ntarget. Do you notice anything? Is there something that might require special treatment?\n2.3 Visualize the dependency of the target on each continuous feature (2d scatter plot).\n2.4 Split data in training and test set. Do not use the test-set unless for a final evaluation in 2.5.\nUse ColumnTransformer and pipeline to encode categorical variables (your choice of\nOneHotEncoder or another one from the categorical_encoder package, or both). Impute missing\nvalues using SimpleImputer. Evaluate Linear Regression (OLS), Ridge, Lasso and ElasticNet\nusing cross-validation with the default parameters. Does scaling the data (within the pipeline)\nwith StandardScaler help? Use the preprocessing that works best going forward.\n2.5 Tune the parameters of the models using GridSearchCV. Do the results improve? Visualize\nthe dependence of the validation score on the parameters for Ridge, Lasso and ElasticNet.\n2.6 Visualize the 20 most important coefficients of the resulting models. Do they agree on which\nfeatures are important?\n'], 'url_profile': 'https://github.com/bhsgsh10', 'info_list': ['Python', 'Updated Apr 7, 2020', 'Updated Apr 11, 2020', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'MATLAB', 'Updated Jun 24, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '1 contribution\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/reshma1995', 'info_list': ['Python', 'Updated Apr 7, 2020', 'Updated Apr 11, 2020', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'MATLAB', 'Updated Jun 24, 2020']}","{'location': 'OC, California', 'stats_list': [], 'contributions': '339 contributions\n        in the last year', 'description': [""Description\nWritten in Octave/MATLAB, this repository Contains a set of vectorized algorithms/functions serving to compute logistic regression for classification problems.\nMATLAB/Octave Logistic Regression Class Functions\nmapFeature(X1, X2)\n\n\nmaps polynomial features to function (2 variables)\n\n\ncostFunction(theta, X, y)\n\n\ncomputes cost and gradient for logistic regression parameterized by theta\n\n\ncostFunctionReg(theta, X, y, lambda)\n\n\ncomputes the cost and gradient of using theta as the parameter for regularized logistic regression\nprevents overfitting by keeping thetas relatively small\n\nlambda value should be chosen carefully in avoiding side effects (underfitting, overfitting)\n\n\n\n\noneVsAll(X, y, num_labels, lambda)\n\n\ntrains multiple logistic regression classifiers and returns all where the i-th row of all_theta corresponds to the classifier for label i with thetas regularized\nas known as Multinomial or Multi-class Logistic Regression(regularized)\n\n\npredict(theta, X)\n\n\npredicts whether the label is 0 or 1 using learned logistic regression parameters theta\n\n\npredictOneVsAll(all_theta, X)\n\n\npredicts the label for a trained one-vs-all classifier (label in range 1-K), where K = size(all_theta, 1).\n\n\nsigmoid(z)\n\n\ncomputes the sigmoid of argument z, which can be in the form a scalar, a vector, or a matrix\n\nPython Logistic Regression Template\n\ncreated by SuperDataScience Team\ncan be ran through Jupyter Notebook or in Python terminal\n\nsubstitude 'ENTER_THE_NAME_OF_YOUR_DATASET_HERE.csv' with dataset\n\nensure data is a csv file containing features from first to second last column and labels on the last column\n\n\n\n\n\n""], 'url_profile': 'https://github.com/Xiaocong233', 'info_list': ['Python', 'Updated Apr 7, 2020', 'Updated Apr 11, 2020', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'MATLAB', 'Updated Jun 24, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/rohan-ml', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jun 23, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/umutboz', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jun 23, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'Washington D.C', 'stats_list': [], 'contributions': '210 contributions\n        in the last year', 'description': ['Medical-Cost-Personal-Datasets\nInsurance Forecast by using Regression\nData available in:\nhttps://www.kaggle.com/mirichoi0218/insurance\n'], 'url_profile': 'https://github.com/shosseini811', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jun 23, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['MULTIPLE-REGRESSION\nCalculating Accuracy using Multiple Regression\n'], 'url_profile': 'https://github.com/Ilisten2soul', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jun 23, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'Portugal', 'stats_list': [], 'contributions': '49 contributions\n        in the last year', 'description': ['machine-learning\nUC Machine Learning\n'], 'url_profile': 'https://github.com/tomasfj', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jun 23, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '1 contribution\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/du-zijun', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jun 23, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': ' Lagos, Nigeria', 'stats_list': [], 'contributions': '287 contributions\n        in the last year', 'description': ['Linear-Regression\nPerforming Linear Regression Using Python\n'], 'url_profile': 'https://github.com/makozi', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jun 23, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'Istanbul, TURKEY', 'stats_list': [], 'contributions': '102 contributions\n        in the last year', 'description': ['Decision_boundary_of_Logistic_Regression\n1. Decision boundaries for Logistic Regression\n2. Using PolynomialFeatures with Logistic Regression\nAt times, given features might come short to explain output, or the output might be a polynomial function of inputs.\nIf this is the case, LogisticRegression can be trained on polynomial features.\n3. Cross validation to find the best polynomial degree\n'], 'url_profile': 'https://github.com/tekinadem', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jun 23, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '263 contributions\n        in the last year', 'description': ['MLProject\nClustered Linear Regression in R\n\nDataset is based on the Covid-19 pandemic and retrieved from: https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset\nPurpose: Used cluster linear regression to improve accuracy of predicting the future infections and deaths from the coronavirus from 3/08/2020 - 3/15/2020 based on the dataset from 1/22/2020 - 3/7/2020.\n\nLibraries used\n\nTidyverse - Sort data based on date / days\nGgplot - linear model\nCluster - using cluster algorithms\nFactoextra - visualize the clusters\n\nDataset has 3992 rows and 8 columns.\nMerged data based on the date of reported infections, death and recoveries from 1/22/2020 - 3/07/2020.\nControl\n\nNormal linear regression model for infected and death\nExperimental\nCluster 1: Consist of Day 1 - 22 (1/22/2020 - 2/12/2020) // 32 days away from 3/15\nCluster 2: Consist of Day 23 - 36 (2/13/2020 - 2/26/2020) // 18 days away from 3/15\nCluster 3: Consist of Day 37 - 46 (2/27/2020 - 3/07/2020) // 8 days away from 3/15\n\nResults\n\nNormal linear model: infected(day) = 2582 * day - 7922\nCluster 1: infected(day) = 2582 * day - 7922\nCluster 2: infected(day) = 1468 * day + 39608\nCluster 3: infected(day) = 2636 * day - 6158\n\nPrediction for 03/15/2020\n\nNormal linear model for infections: 135192 predicted infections.\nCluster 1 linear model: 131506 predicted infections.\nCluster 2 linear model: 118880 predicted infections.\nCluster 3 linear model: 136186 predicted infections.\nNormal linear model for deaths: 4427 predicted deaths.\n\nActual\n\nInfected on 03/15/2020: 162774\nDeaths on 03/15/2020: 6460\n\nPercent errors\n\nLinear model infection percent error: 17.0%\nCluster 1 percent error: 19.2%\nCluster 2 percent error: 27.8%\nCluster 3 percent error: 16.33%\nLinear model death percent error: 31.5%\n\n'], 'url_profile': 'https://github.com/jchanunhs', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jun 23, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '12 contributions\n        in the last year', 'description': ['Housing-Price-Index\nLinear Regression Machine learning Model\n'], 'url_profile': 'https://github.com/Shubham8452', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jun 23, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '17 contributions\n        in the last year', 'description': ['Logistic Regression on CPU And GPU\nLogistic Regression on GPU Side\nuse 2class_CPU_new and 2class_GPU_new\nCompile code in ug machine: nvcc -ccbin clang-3.8 -o 2class_CPU 2class_CPU_new.cu -lm\n'], 'url_profile': 'https://github.com/hankimi', 'info_list': ['Cuda', 'Updated Oct 7, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Oct 24, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'Updated Jun 26, 2020', '2', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Jupyter Notebook', 'Updated Feb 1, 2021', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020']}","{'location': 'Bengaluru, Karnataka, India', 'stats_list': [], 'contributions': '369 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/shashank195', 'info_list': ['Cuda', 'Updated Oct 7, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Oct 24, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'Updated Jun 26, 2020', '2', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Jupyter Notebook', 'Updated Feb 1, 2021', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020']}","{'location': 'Rome, Italy', 'stats_list': [], 'contributions': '43 contributions\n        in the last year', 'description': ['Regression Metrics Python\nStatistical estimators used in regression or optimization problems.\nImplemented metrics:\n\nRSS (Residual Sum of Squares):\n\n\n\n\n\nMSE (Mean Squared Error):\n\n\n\n\n\nMSPE (Mean Squared Percentage Error):\n\n\n\n\n\nRMSE (Root-Mean-Square Error):\n\n\n\n\n\nRMSPE (Root-Mean-Square Percentage Error):\n\n\n\n\n\nMAE (Mean Absolute Error):\n\n\n\n\n\nMAPE (Mean Absolute Percentage Error):\n\n\n\n\n\nRSE (Relative Squared Error):\n\n\n\n\n\nRAE (Relative Absolute Error):\n\n\n\n\n\nR2 (Coefficient of determination):\n\n\n\n\nWhere  is the actual value,  is the forecasted value,  and  are the average of the  variable and the number of samples, respectively.\n'], 'url_profile': 'https://github.com/mtortora-ai', 'info_list': ['Cuda', 'Updated Oct 7, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Oct 24, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'Updated Jun 26, 2020', '2', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Jupyter Notebook', 'Updated Feb 1, 2021', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': [""Absenteeism_Prediction_in_Workplace\nIntroduction\nAbsenteeism is the term given when an employee is habitually and frequently absent from work. This excludes paid leave and occasions where an employer has granted an employee time off.\nThis task will address Absenteeism at a company during work time.\nProblem: Business environment nowadays is more competitive than it used to be. This lead to increased pressure in the workplace. Therefore, it is reasonable to expect that unachievable business goals and an elevated risk of unemployment can raise people's stress levels. Often, the continuous presence of such factors becomes detrimental to a person's health. Sometimes this may result in minor illness which of course is not desired. However, it may happen that the employee develops a long-term condition. An example being depression.\nLooking at predicting absenteeism from work.\nWe would like to know whether or not an employee can be expected to be missing for a specific number of hours in a given work day.\nHaving such information in advance can improve our decision-making. How? by re-organizing the work process in a way that will allow us to avoid a lack of productivity and increase the quality of work generated in our firm.\nLogically here come some additional questions based on what information should we predict whether an employee is expected to be absent or not.\nHow would we measure absenteeism?\nShould we rather think about trying to predict excessive absenteeism?\nJust remember that as a whole the purpose of the business task will be to explore whether a person presenting certain characteristics is expected to be away from work at some point in time or not.\nIn other words, we want to know for how many working hours an employee could be away from work based on information such as how far they live from their workplace? How many children and pets they have? Do they have higher education? and so on.\nVisualization and insight\nAge vs Probability\n\nFrom the figure, we can clearly see that employees with age 40 years and below absent from work for more three hours.\nFor instance, there's a 59 percent chance that an employee who is 28 years will be absent from work for more than three hours.\nReason vs Probability\n\nWe can see all reasons contain data for both values 0 and 1 except for reason 2.\nNone of the employees (from our 40 observations) were away from work. For this reason, it is removed from the analysis since it provides less information on our dataset.\nIf a person is supposed to be absent due to a reason from Group 1 as marked by the dots associated with the value of 1 the probability that she will be excessively absent is above 50 percent.\nHence such an individual is expected to be away from work for more than three hours whereas when we look at a Reason 3 we must consider the very few observations of people who had specified this reason for excessive absence as well as the fact that the probabilities have been distributed both in the lower and upper parts of the vertical line.\nThat's why we could say that.\nSimilarly, to reason 2 this class doesn't tell us much about what to expect from individuals being absent because of a reason from Group 3.\nFinally reason 4 leads us to an opposite conclusion compared to reason one.\nThe people who are absent because of reason 4 absence exhibit a probability below 50 percent to be excessively absent.\nAnd now if we want to extend our analysis by adding a qualitative interpretation of the results what should we say for groups 1 and 4? Do our numerical inferences match any business logic and can they have a more intuitive explanation?\nThe reasons included in group 1 without disrespecting all other reasons the ones we have here represent very serious diseases. That's why the numbers tell us that the expected probability of an individual to be excessively absent because of a reason from this class is higher than 50 percent.\nHow about group 4?\nIt represents what we've called less-serious reasons for absence a dental appointment, physiotherapy, a medical consultation and others.\nWhen you think of it is quite probable that none of these could be serious enough to require that a person is absent from their workplace for an entire day. That's why the numbers show that people who have to be absent for such a reason are not expected to be excessively absent as you can see the probability values are all below the mark of 50 percent.\nTransportation Expense and Children\n\nWe would like to see the probability that a person will be excessively absent from work in relation to the transportation expense they must cover each month as well as to the number of children they have.\nAlthough loosely we could say that there is a positive correlation. Perhaps if we were given a data set containing more observations this correlation would have been stronger.\nThen we could say with certainty that the higher the transportation expenses of a person the higher the chance they will be away from work excessively good.\nLooking at the data further, it turns out people with no children don't exhibit a high probability for excessive absence. Also aside from one small exception none of them have high transportation expenses.\nPerhaps there is nothing that would induce these people live further away from their working place.\nWe have a lot more data in this case (1 child) the probability that this group is expected to be excessively absent varies across observations. However, most of the data is clustered around the average transportation expense spending between $220 and $240 a month.\nWhat about people with two children?\nIf we disregard the values clustered around the centre the distribution is similar. Thus we could say that our data is about people who don't generally spend more than $240 on transportation. Only 5 observations lay beyond this cut-off line.\nJust one individual has 3 children. In other words, this category can't really affect the analysis of the 40 observations we have. Therefore, it is excluded from the analysis.\n""], 'url_profile': 'https://github.com/FedoAIworld', 'info_list': ['Cuda', 'Updated Oct 7, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Oct 24, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'Updated Jun 26, 2020', '2', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Jupyter Notebook', 'Updated Feb 1, 2021', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020']}","{'location': 'NSUTA-GHANA', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/aadadzie', 'info_list': ['Cuda', 'Updated Oct 7, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Oct 24, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'Updated Jun 26, 2020', '2', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Jupyter Notebook', 'Updated Feb 1, 2021', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020']}","{'location': 'Ha Noi', 'stats_list': [], 'contributions': '135 contributions\n        in the last year', 'description': ['MNIST-Handwritten-Digit-Recognition\nUsing Softmax Regression, Softmax Regression with shallow neural network and deep neural network\nHow to use\n\n\nOpen MNIST.ipynb to train model and predict your image\n\n\nConvolutional_Model.ipynb - Implement sobel convolutional and rebuild AlexNet, VGG16, VGG11 architecture\n\n\nResnet.ipynb - Rebuild AlexNet, VGG16, VGG11 arch\n\n\n'], 'url_profile': 'https://github.com/ducviet00', 'info_list': ['Cuda', 'Updated Oct 7, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Oct 24, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'Updated Jun 26, 2020', '2', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Jupyter Notebook', 'Updated Feb 1, 2021', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '69 contributions\n        in the last year', 'description': ['Regression-and-Gradient-Descent-Algorithm\nsingle and multivariate regression analysis and application of gradient descent algorithm\n'], 'url_profile': 'https://github.com/AYSE-DUMAN', 'info_list': ['Cuda', 'Updated Oct 7, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Oct 24, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'Updated Jun 26, 2020', '2', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Jupyter Notebook', 'Updated Feb 1, 2021', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '242 contributions\n        in the last year', 'description': ['cell-counting\nDeeply supervised density regression for automatic cell counting in microscopy images\n'], 'url_profile': 'https://github.com/shenghh2015', 'info_list': ['Cuda', 'Updated Oct 7, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Oct 24, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'Updated Jun 26, 2020', '2', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Jupyter Notebook', 'Updated Feb 1, 2021', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020']}","{'location': 'brighton, United Kingdom', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': ['Car-Price-Prediction-Linear-Regression\nProblem Statement\nThis assignment is a programming assignment wherein you have to build a multiple linear regression model for the prediction of car prices. You will need to submit a Jupyter notebook for the same.\nProblem Statement\nA Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts.\nThey have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\nWhich variables are significant in predicting the price of a car\nHow well those variables describe the price of a car\nBased on various market surveys, the consulting firm has gathered a large dataset of different types of cars across the Americal market.\nBusiness Goal\nYou are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market.\n'], 'url_profile': 'https://github.com/VikramMathur3012', 'info_list': ['Cuda', 'Updated Oct 7, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Oct 24, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'Updated Jun 26, 2020', '2', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Jupyter Notebook', 'Updated Feb 1, 2021', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020']}","{'location': 'California', 'stats_list': [], 'contributions': '321 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gladieschanggoodluck', 'info_list': ['Cuda', 'Updated Oct 7, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Oct 24, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'Updated Jun 26, 2020', '2', 'Jupyter Notebook', 'Updated Apr 6, 2020', '2', 'Jupyter Notebook', 'Updated Feb 1, 2021', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['scQRreg\nQuantile regression for single cell data\n'], 'url_profile': 'https://github.com/SMU-medicalgenetics', 'info_list': ['Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', '1', 'Python', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'MATLAB', 'Apache-2.0 license', 'Updated Apr 9, 2020', 'R', 'Updated Apr 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['linear-regression\nCO2 emission prediction using linear regression\n'], 'url_profile': 'https://github.com/Ilisten2soul', 'info_list': ['Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', '1', 'Python', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'MATLAB', 'Apache-2.0 license', 'Updated Apr 9, 2020', 'R', 'Updated Apr 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/9rishabh8', 'info_list': ['Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', '1', 'Python', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'MATLAB', 'Apache-2.0 license', 'Updated Apr 9, 2020', 'R', 'Updated Apr 13, 2020']}","{'location': 'Portland, OR', 'stats_list': [], 'contributions': '78 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/moleculesynth', 'info_list': ['Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', '1', 'Python', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'MATLAB', 'Apache-2.0 license', 'Updated Apr 9, 2020', 'R', 'Updated Apr 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '30 contributions\n        in the last year', 'description': ['Apprentice-Chef-Regression-Analysis\nDeliverables: Predicting revenue for first year users through simple machine learning processes and present 2 insights and 1 actionable recommendation.\nCourse Case: Apprentice Chef\nCase Challenge Part I After three years serving customers across the San Francisco Bay Area, the executives at Apprentice Chef have come to realize that over 90% of their revenue comes from customers that have been ordering meal sets for 12 months or less. Given this information, they would like to better understand how much revenue to expect from each customer within their first year of orders. Thus, they have hired you on a full-time contract to analyze their data, develop your top insights, and build a machine learning model to predict revenue over the first year of each customerâ€™s life cycle.\n'], 'url_profile': 'https://github.com/AbdulBishar', 'info_list': ['Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', '1', 'Python', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'MATLAB', 'Apache-2.0 license', 'Updated Apr 9, 2020', 'R', 'Updated Apr 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '978 contributions\n        in the last year', 'description': ['Kernel-Ridge-Regression\nKernel Ridge Regression from scratch using NumPy\n\n\n'], 'url_profile': 'https://github.com/vee-upatising', 'info_list': ['Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', '1', 'Python', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'MATLAB', 'Apache-2.0 license', 'Updated Apr 9, 2020', 'R', 'Updated Apr 13, 2020']}","{'location': 'Chennai', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['Linear_Regression\nusing numpy develope regression model in python\n'], 'url_profile': 'https://github.com/Janan1527', 'info_list': ['Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', '1', 'Python', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'MATLAB', 'Apache-2.0 license', 'Updated Apr 9, 2020', 'R', 'Updated Apr 13, 2020']}","{'location': 'Noida,india', 'stats_list': [], 'contributions': '35 contributions\n        in the last year', 'description': ['linear_model\nrequired step should follow in linear regression\n'], 'url_profile': 'https://github.com/vedica1011', 'info_list': ['Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', '1', 'Python', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'MATLAB', 'Apache-2.0 license', 'Updated Apr 9, 2020', 'R', 'Updated Apr 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': [""Particle Swarm Optimization (PSO) based Logistic Regression used for Epidemic modelling\n\nRun main.m file in the MATLAB environment. The data used in this project is from COVID19 epidemic in India and is stored in getData.m.\n\nPSO is used alongside MATLAB's inbuilt non linear regression tools to better guess the regression parameters.\n\n\n\n""], 'url_profile': 'https://github.com/n-source', 'info_list': ['Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', '1', 'Python', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'MATLAB', 'Apache-2.0 license', 'Updated Apr 9, 2020', 'R', 'Updated Apr 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '20 contributions\n        in the last year', 'description': ['correlation_and_regression\nHomework for BST 611 - Correlation and Regression\n'], 'url_profile': 'https://github.com/rdalejohnson', 'info_list': ['Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 8, 2020', '1', 'Python', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'MATLAB', 'Apache-2.0 license', 'Updated Apr 9, 2020', 'R', 'Updated Apr 13, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '20 contributions\n        in the last year', 'description': ['correlation_and_regression\nHomework for BST 611 - Correlation and Regression\n'], 'url_profile': 'https://github.com/rdalejohnson', 'info_list': ['R', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Dec 5, 2020', 'Python', 'Updated Apr 29, 2020', 'Python', 'BSD-3-Clause license', 'Updated Oct 4, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 7, 2020', 'R', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 12, 2020', 'Dockerfile', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '138 contributions\n        in the last year', 'description': ['electric-demand-forecast\nLinear Regression Model to Predict Demand, This notebook coded in python run a linear regression in order to forecast the demand load. The source of the data is from cammesa precisely from the province of Corrientes in Argentina between the year 2013 and 2015. click here to see the notebook.\n\n'], 'url_profile': 'https://github.com/martinezger', 'info_list': ['R', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Dec 5, 2020', 'Python', 'Updated Apr 29, 2020', 'Python', 'BSD-3-Clause license', 'Updated Oct 4, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 7, 2020', 'R', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 12, 2020', 'Dockerfile', 'Updated May 12, 2020']}","{'location': 'Italy', 'stats_list': [], 'contributions': '35 contributions\n        in the last year', 'description': ['COVID-19-Trends-IT\nMatplotlib + SciPy regression of the first wave of COVID-19 in Italy\nData sources: https://github.com/pcm-dpc/COVID-19, distributed under a Creative Commons License\nRegression technique: Non-linear least squares\n'], 'url_profile': 'https://github.com/TurtleARM', 'info_list': ['R', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Dec 5, 2020', 'Python', 'Updated Apr 29, 2020', 'Python', 'BSD-3-Clause license', 'Updated Oct 4, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 7, 2020', 'R', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 12, 2020', 'Dockerfile', 'Updated May 12, 2020']}","{'location': 'Seoul, South Korea', 'stats_list': [], 'contributions': '52 contributions\n        in the last year', 'description': ['FeatureSelectionGP\nGaussian process elastic net (GPEN) regression for feature selection\nThis code was used in the following paper :\nJ. Lim, S. Ha and J. Choi, ""Prediction of Reward Functions for Deep Reinforcement Learning via Gaussian Process Regression,"" in IEEE/ASME Transactions on Mechatronics, vol. 25, no. 4, pp. 1739-1746, Aug. 2020, doi: 10.1109/TMECH.2020.2993564.\n\nDependency\n\nNumpy\nScipy\nScikit-learn\n\n'], 'url_profile': 'https://github.com/lim271', 'info_list': ['R', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Dec 5, 2020', 'Python', 'Updated Apr 29, 2020', 'Python', 'BSD-3-Clause license', 'Updated Oct 4, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 7, 2020', 'R', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 12, 2020', 'Dockerfile', 'Updated May 12, 2020']}","{'location': 'Poland', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/maticel', 'info_list': ['R', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Dec 5, 2020', 'Python', 'Updated Apr 29, 2020', 'Python', 'BSD-3-Clause license', 'Updated Oct 4, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 7, 2020', 'R', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 12, 2020', 'Dockerfile', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '169 contributions\n        in the last year', 'description': ['Linear Regression Single Variable House Pricing - Pararius\nIn regression problems we trying to predict continuous valued output.\nLinear regression is used to predict a quantitative response Y from the predictor variable X.\nLinear Regression is made with an assumption that thereâ€™s a linear relationship between X and Y.\nWe know the given eqaution y=mx+b represents a straight line with slope m and the y intercept b.\ny=m*x+b\n""m"" represents the ""slope"" of the line. This is rise/run.\n""b"" represents the ""y-intercept"" of the line. This is where the line cross es the y-axis (the part of the coordinate grid that goes up and down).\n'], 'url_profile': 'https://github.com/edwardmartinsjr', 'info_list': ['R', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Dec 5, 2020', 'Python', 'Updated Apr 29, 2020', 'Python', 'BSD-3-Clause license', 'Updated Oct 4, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 7, 2020', 'R', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 12, 2020', 'Dockerfile', 'Updated May 12, 2020']}","{'location': 'Dublin, Ireland', 'stats_list': [], 'contributions': '29 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/souradip1991', 'info_list': ['R', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Dec 5, 2020', 'Python', 'Updated Apr 29, 2020', 'Python', 'BSD-3-Clause license', 'Updated Oct 4, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 7, 2020', 'R', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 12, 2020', 'Dockerfile', 'Updated May 12, 2020']}","{'location': 'Merul Badda, Anandanagar, Dhaka', 'stats_list': [], 'contributions': '133 contributions\n        in the last year', 'description': ['Water Heating Problem in Winter Season\nArtificial Intelligence Kick-Start Workshop\n'], 'url_profile': 'https://github.com/Sabikrahat', 'info_list': ['R', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Dec 5, 2020', 'Python', 'Updated Apr 29, 2020', 'Python', 'BSD-3-Clause license', 'Updated Oct 4, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 7, 2020', 'R', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 12, 2020', 'Dockerfile', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['linearRegression-LDA\nlinear regression and Linear Discriminant Analysis (LDA)\n'], 'url_profile': 'https://github.com/ecliman', 'info_list': ['R', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Dec 5, 2020', 'Python', 'Updated Apr 29, 2020', 'Python', 'BSD-3-Clause license', 'Updated Oct 4, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 7, 2020', 'R', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 12, 2020', 'Dockerfile', 'Updated May 12, 2020']}","{'location': 'Carrer Dr Aiguader 88 (PRBB Building), Barcelona (Spain)', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/regicor', 'info_list': ['R', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Dec 5, 2020', 'Python', 'Updated Apr 29, 2020', 'Python', 'BSD-3-Clause license', 'Updated Oct 4, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 7, 2020', 'R', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 12, 2020', 'Dockerfile', 'Updated May 12, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '57 contributions\n        in the last year', 'description': ['JS_Linear_Regression_Gradient_Descent\n'], 'url_profile': 'https://github.com/Arowne', 'info_list': ['HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Jun 11, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'BSD-3-Clause license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 10, 2020', 'Java', 'Updated Apr 11, 2020', 'Python', 'Updated Sep 30, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '9 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/nehalsam', 'info_list': ['HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Jun 11, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'BSD-3-Clause license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 10, 2020', 'Java', 'Updated Apr 11, 2020', 'Python', 'Updated Sep 30, 2020']}","{'location': 'Thailand', 'stats_list': [], 'contributions': '89 contributions\n        in the last year', 'description': ['Cancer_Screening_App\nDemo Cancer screening application with Logistic Regression\nhttps://cancer-screening-app-2.herokuapp.com/\ndeployed to Heroku\nheroku logs --tail --cancer-screening-app-2\n'], 'url_profile': 'https://github.com/perlestot', 'info_list': ['HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Jun 11, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'BSD-3-Clause license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 10, 2020', 'Java', 'Updated Apr 11, 2020', 'Python', 'Updated Sep 30, 2020']}","{'location': 'Chennai', 'stats_list': [], 'contributions': '106 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/vairamuthushanmugavel', 'info_list': ['HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Jun 11, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'BSD-3-Clause license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 10, 2020', 'Java', 'Updated Apr 11, 2020', 'Python', 'Updated Sep 30, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '79 contributions\n        in the last year', 'description': ['training_models\nExcersises from the chapter relating to training models\n'], 'url_profile': 'https://github.com/seankelly1994', 'info_list': ['HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Jun 11, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'BSD-3-Clause license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 10, 2020', 'Java', 'Updated Apr 11, 2020', 'Python', 'Updated Sep 30, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': [""Specifying an R environment with a runtime.txt file\nJupyter+R: \nRStudio: \nRShiny: \nBinder supports using R and RStudio, with libraries pinned to a specific\nsnapshot on MRAN.\nYou need to have a runtime.txt file that is formatted like:\nr-<YYYY>-<MM>-<DD>\n\nwhere YYYY-MM-DD is a snapshot at MRAN that will be used for installing\nlibraries. In this line, you can request a specific\nversion of R. To do this list the version between the 'r'\nand the year, as in r-3.6-2019-09-24. Right now the default version of R is 3.6.\nYou also need a Python notebook file such as this one.\nYou can also have an install.R file that will be executed during build, and can be used to install libraries.\nBoth RStudio and IRKernel\nare installed by default, so you can use either the Jupyter notebook interface or\nthe RStudio interface.\nThis repository also contains an example of a Shiny app.\nLast, note that if your Binder URL points to a folder, as in\nhttp://mybinder.org/v2/gh/binder-examples/r/master?urlpath=shiny/bus-dashboard/,\nyou will need (1) to put in the final slash in the URL, and (2) to avoid converted\nspaces-'%20'-in the URL, instead placing a hyphen.\nNote: An alternative is to use the excellent holepunch package for R.\n""], 'url_profile': 'https://github.com/veera-sci', 'info_list': ['HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Jun 11, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'BSD-3-Clause license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 10, 2020', 'Java', 'Updated Apr 11, 2020', 'Python', 'Updated Sep 30, 2020']}","{'location': 'Barcelona', 'stats_list': [], 'contributions': '26 contributions\n        in the last year', 'description': ['House_Prices\nHouse Prices (Kaggle): Advanced Regression Techniques\nhttps://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\nGoal\nIt is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable.\nMetric\nSubmissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)\nSubmission File Format\nThe file should contain a header and have the following format:\n'], 'url_profile': 'https://github.com/PCerralbo', 'info_list': ['HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Jun 11, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'BSD-3-Clause license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 10, 2020', 'Java', 'Updated Apr 11, 2020', 'Python', 'Updated Sep 30, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '278 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/kmiec96', 'info_list': ['HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Jun 11, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'BSD-3-Clause license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 10, 2020', 'Java', 'Updated Apr 11, 2020', 'Python', 'Updated Sep 30, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/abdulrehman03365', 'info_list': ['HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Jun 11, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'BSD-3-Clause license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 10, 2020', 'Java', 'Updated Apr 11, 2020', 'Python', 'Updated Sep 30, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '250 contributions\n        in the last year', 'description': [""Logistic Regression\nThis is a simple instance of logistic regression used to a) make a particular decision, i.e. who does or does not get a discount based on the user spend and b) predict some class based on some input, in this case, the class is gender based on the users' input height and weight.\nThe error analysis is simply the accuracy of the prediction printed out alongside the prediction of the gender.\nRunning this file is trivial and only requires the dataset provides with it (loaded into the same directory). The tutorial for making this script came from a towardsdatascience article by Gustavo Chaves. The URL is at the bottom of this file.\nhttps://towardsdatascience.com/understanding-logistic-regression-step-by-step-704a78be7e0a\n""], 'url_profile': 'https://github.com/MrFlygerian', 'info_list': ['HTML', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Jun 11, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'BSD-3-Clause license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 10, 2020', 'Java', 'Updated Apr 11, 2020', 'Python', 'Updated Sep 30, 2020']}"
"{'location': 'Bandung, Indonesia', 'stats_list': [], 'contributions': '206 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/dimitriirfan', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '2', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 23, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '26 contributions\n        in the last year', 'description': ['Mnist_logistic_regression-\nAnalyzed Mnist dataset with logistic regression\n'], 'url_profile': 'https://github.com/prazwalp007', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '2', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 23, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'Lisbon, Portugal', 'stats_list': [], 'contributions': '52 contributions\n        in the last year', 'description': ['Diamond-Price-Prediction-Model\nWe will be analysing the datasets for Diamond Price Prediction.\nInstallation\nWe will be using the standard inbuilt anaconda package installation. We will use python packages such as NumPy, Pandas, Seaborn,\nmatplotlib and Scikit learn for the mentioned activities.\n** The project is yet to be completed\n'], 'url_profile': 'https://github.com/anoopsp', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '2', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 23, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '8 contributions\n        in the last year', 'description': ['""# linreg1""\n""# This is the first project in a series of three project. Stay tuned for more!""\n'], 'url_profile': 'https://github.com/elmatiso', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '2', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 23, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'BANDUNG, INDONESIA', 'stats_list': [], 'contributions': '83 contributions\n        in the last year', 'description': ['linear-regression\nlinear regression code and module for beginner\n'], 'url_profile': 'https://github.com/Bagja9102Kurniawan', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '2', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 23, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '37 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/concussion20', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '2', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 23, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '61 contributions\n        in the last year', 'description': ['Machine-Learning-Regression-Linear-Regression\n'], 'url_profile': 'https://github.com/Vishali-M', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '2', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 23, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'Sialkot', 'stats_list': [], 'contributions': '179 contributions\n        in the last year', 'description': ['Polynomial-Linear-Regression-CO2-Emission-Prediction\n'], 'url_profile': 'https://github.com/mrqasimasif', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '2', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 23, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'Chennai', 'stats_list': [], 'contributions': '1,824 contributions\n        in the last year', 'description': ['Kaggle House-Price-Prediction-by-Advance-Regression-Techniques\n'], 'url_profile': 'https://github.com/DheerajKumar97', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '2', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 23, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7 contributions\n        in the last year', 'description': ['Linear-Regression-in-python\nThis project is based on Simple regression algorithm here we will try to implement simple linear regression algorithm.\nIn this project we will be making use of juputer notebook.\nThere are many library which will be needed to implement this project:\n\nnumpy\npandas\nmatplotlib\nsklearn\n\n'], 'url_profile': 'https://github.com/vic4603', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '2', 'MIT license', 'Updated Apr 12, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Apr 23, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}"
"{'location': 'Bengaluru', 'stats_list': [], 'contributions': '50 contributions\n        in the last year', 'description': [""Regression Models (Ridge,LASSO and Linear Regression)---Sklearn\nCode Outline -\n1- Linear Regression\n2- LASSO Regression\n3- Ridge Regression\nThis code will help to understand step wise understanding of linear regression/ Ridge Regression/ LASSO Regression model through python.\nIt's include reading data with PANDAS library and doing basic EDA process and again building final model and comparison of final model.\n""], 'url_profile': 'https://github.com/kdmac', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 7, 2020', 'R', 'MIT license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated Dec 23, 2019']}","{'location': 'NONE', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['RegressionSteps\nThe three functions explained below work together to explore and present further actions and possibilities of linear regression models. My goal is to help users experiment with the explanatory variables of a linear regression model. As a result, these experiments will help the user reach conclusions about how the initial dependent variable will change, if one of the explanatory variables is changed as wished.\nThis is part of my coursework in the module GIS and Science in the UCL Centre for Advanced Spatial Analysis (casa.ucl.ac.uk)\nPlease read more on my blog: http://psybercity.co.uk/\nAlso, to understand how the functions work, please read the file ""functiondosumentationexplanation""\nRequirements\nR project (http://www.r-project.org/)\nR packages:\nrms (http://cran.r-project.org/web/packages/rms/index.html)\nggplo2 (http://cran.r-project.org/web/packages/ggplot2/index.html)\nmaptools (http://cran.r-project.org/web/packages/maptools/index.html)\nReferences\ndocumentation that helped me understand linear regression modeling\nhttp://en.wikipedia.org/wiki/Linear_regression (reference number 1)\nDunn (1989) Building regression models: the importance of graphicsFile\nJones (1984) Graphical Methods for exploring relationshipsFile\nhttp://en.wikipedia.org/wiki/Simple_linear_regression\nhttp://en.wikipedia.org/wiki/Linear_model\nin class lectures and notes kept in class\ndocumentation that helped me learn how to make functions in r / helped me improve my coding skills\nhttp://www.rexamples.com/4/Reading%20user%20input\nhttp://geo.maua.sp.gov.br/maua/pacotes/rlib/linux/gtools/html/ask.html\ndocumentation that helped me better understand certain r functions\nhttp://stat.ethz.ch/R-manual/R-patched/library/graphics/html/hist.html\nhttp://docs.ggplot2.org/current/geom_histogram.html\nhttp://stackoverflow.com/questions/3541713/how-to-plot-two-histograms-together-in-r\nhttp://rfunction.com/archives/539\nhttp://spatial.ly/2013/12/introduction-spatial-data-ggplot2/\nalso I had to study the r packages I used\nhttp://cran.r-project.org/web/packages/rms/rms.pdf\nhttp://cran.r-project.org/web/packages/ggplot2/ggplot2.pdf\ndocumentation that helped me understand gcse capped points\nBrief Guide 6: KS4 Capped Points Scores, Lincolnshire School Improvement Service (reference number 3\ndata downloaded from\nhttp://data.london.gov.uk/datastore/package/ward-profiles-and-atlas  (reference number 2)\n'], 'url_profile': 'https://github.com/AnnThanicha', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 7, 2020', 'R', 'MIT license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated Dec 23, 2019']}","{'location': 'USA', 'stats_list': [], 'contributions': '37 contributions\n        in the last year', 'description': ['ABOUT\nThis program is an implementation and test of the regression tree learning algorithm\nProgram was written in R using R native functions\nAnalysis uses the rpart package\nThe following sample datasets are provided with the R package rpart:\n\nkyphosis\nsolder\n\nFor both of these the programs perform the following analysis:\n\nCreate a model using the rpart function\nCreate a regression tree plot\nList the important attributes\nUsing the best pruning paramter, create a prunded tree\nDivide the dataset into an 80/20 training/test split\nBuild a pruned model using just the training data and use it to find the predicion on the test dataset. How much is the accuracy obtained.\nRepeate step 6) but this time use a 90/10 training/test split\n\nCOMPILING, INSTALLATION AND RUNNING\nProgram files are Kyphosis.R and Solder.R\nCompiling:\nNo compiling of R â€¦ its an interpreted language.\nHow to run the code and a genric run command statement.\nAssumes RPart is installed. If not run:\n\ninstall.packages(""rpart"", dependencies=TRUE)\n\nGeneric run command: Rscript Kyphosis.R\nGeneric run command: Rscript Solder.R\nRESULTS\nResults are shown in the Results.pdf file.\nRegression Tree plots are printed to RGraphics and are shown in the Rplots.pdf file.\nAccuracies are printed to the Console.\nLICENSE\nMIT License\n'], 'url_profile': 'https://github.com/shoeloh', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 7, 2020', 'R', 'MIT license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated Dec 23, 2019']}","{'location': 'Bangalore, India', 'stats_list': [], 'contributions': '25 contributions\n        in the last year', 'description': ['Logistic-Regression\nPredicting chronic kidney disease from data using logistic regression classifier\nWe will go through the entire data pipeline from data cleaning, preprocessing, staging and modelling on a relatively small dataset (400 entries). We will compare different machine learning models and try to measure their performance using various metrics.\nSummary\nIt is a binary classification problem\nFeatures include numerical values and categorical values\nThere are missing values within features and need to impute missing numerical and categorical values\nCategorical features need to be converted to numerical using the encoding methods\nFind the correlation between the features\nFind the distribution of numerical features and normalise if required\nModel the prediction with logistic regression classifier\nDisplay the coefficients and form the logistic regression equation.\nEvaluate the model using cross validation methods(k-fold)\nDraw the decision boundary\nVisualise the test results\n'], 'url_profile': 'https://github.com/kannan-rg', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 7, 2020', 'R', 'MIT license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated Dec 23, 2019']}","{'location': 'NONE', 'stats_list': [], 'contributions': '220 contributions\n        in the last year', 'description': [""w5-Sentiment-Classification-By-NLP-Logistic-Regression\nMovie Review's Sentiment Classification by Logistic Regression\n1. Prepare the data\nTrain Data:  https://drive.google.com/open?id=1qfUh29q1BAnIz1AI5jviQZdbRFYM4FTK\nEvaluate Data:  https://drive.google.com/open?id=1loD4WoqQlmV2uGufT1NslmHLoDtlwMk1\n2. Clean our data\nGet the 'review' and 'sentiment' columns for train data.\nDrop duplicate found in data.\nData have no null values.\nStopwords\nUse english stopwords from ntlk library.\nPreprocessor\nUse regular expression to remove HTML markup, non-word characters and move the emoticons to the end of each review.\nStemmer\nUse PorterStemmer to normalize words in reviews.\nUse Vectorizer to transfrom preprocess methods to vectorize method\nCreate Pipeline\nUse Pipeline to apply preprocess methods to data then transfer data to our model\nTest model with list of C parameter to find the max accuracy score\nApply best C parameter to model\n""], 'url_profile': 'https://github.com/natuan310', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 7, 2020', 'R', 'MIT license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated Dec 23, 2019']}","{'location': 'Warsaw', 'stats_list': [], 'contributions': '70 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/rafal-mokrzycki', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 7, 2020', 'R', 'MIT license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated Dec 23, 2019']}","{'location': 'NONE', 'stats_list': [], 'contributions': '65 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/jarvis-666', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 7, 2020', 'R', 'MIT license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated Dec 23, 2019']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '8 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Shreyank1397', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 7, 2020', 'R', 'MIT license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated Dec 23, 2019']}","{'location': 'Long Island, New York', 'stats_list': [], 'contributions': '17 contributions\n        in the last year', 'description': ['covid-19\nview covid-19 data by U.S. state or date and perform a simple linear regression analysis.\nProblem Statement:\nHow effective has each U.S. state been at treating patients diagnosed with the coronavirus? If more people in one state recover from the illness compared to the people living in another state, studying the variables that might have led to this has the potential to increase the nationwide recovery rate. There are many variables that would contribute to state recovery rate, like population density, number of hospitals, number of resources, government funding, geographical features, average diet, average level of physical exercise, and so on. It may be useful to study these factors, however the first step is to study the number of cases and deaths over time.\nObjectives:\xa0\n\nAnalyze the number of COVID-19 cases and deaths by U.S. state over time\nCalculate COVID-19 mortality rate by state\nCreate a tool that will quickly visualize the data using tables and charts\nAllow user to search by either state or date and sort data by columns\nAllow user to plot the data and fit a linear regression model\nCalculate R-squared value\n\nLibraries used:\n\npandas for data preparation\nnumpy for data manipulation\nmatplotlib for data visualization\nsklearn for statistical modeling\n\nR-squared value meaning:\nThe Rsquared value, or correlation of determination, explains how closely correlated the dependent value (cases) is with the independent value (deaths). As the number of cases increases, the number of deaths to the virus should increase as well. It may be useful to study how linear this relationship is.\nDatasource (updated daily):\nhttps://github.com/nytimes/covid-19-data/blob/master/us-states.csv\n'], 'url_profile': 'https://github.com/paulmarinos', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 7, 2020', 'R', 'MIT license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated Dec 23, 2019']}","{'location': 'NONE', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['LinearRegressionModel\nSimple Linear Regression Model using Tensorflow 2.0 in Python\n'], 'url_profile': 'https://github.com/ssubbyun', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 7, 2020', 'R', 'MIT license', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated Dec 23, 2019']}"
"{'location': 'Mumbai', 'stats_list': [], 'contributions': '264 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/FarheenB', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'MATLAB', 'MIT license', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Apr 19, 2020', 'Updated Sep 23, 2020', 'Python', 'Updated Feb 28, 2021', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Aug 9, 2020']}","{'location': 'Hyderabad, India', 'stats_list': [], 'contributions': '48 contributions\n        in the last year', 'description': ['Linear-Regression-Information\nThis repository contains all the concepts involved in Linear Regression\n\n\nA typical lifecycle diagram for a machine learning model\n\n\nWhat is Regression Analysis?\n\n\nWhy to use Regression?\n\n\nIntroduction to Linear Regression.\n\n\nA small example to understand the interpretition taken out from the linear regression data\n\n\nSimple Regression line\n\n\nHow to know whether the fitted line is the best fit?\n\n\nGradient descent - To minimise the error\n\n\nð‘…2  statistics\n\n\nAdjusted  ð‘…2  statistics\n\n\nExplanation to- Is linear regression a low bias/high variance model or a high bias/low variance model?\n\n\nHypothesis Testing and p-values\n\n\nMultiple Linear Regression\n\n\nFeature Selection\n\n\nHandling Categorical Predictors with Two Categories\n\n\nMulti- Collinearity\n\n\nWhy Should We Care About Multi-Collinearity?\n\n\nHow to detect Multi-collinearity?\n\n\nBias Variance trade-off\n\n\nRegularization - Ridge, lasso, ElasticNet\n\n\nA small project including all the concepts of Linear Regression\n\n\nPolynomial Regression.\n\n\n'], 'url_profile': 'https://github.com/vaibhavcodes', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'MATLAB', 'MIT license', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Apr 19, 2020', 'Updated Sep 23, 2020', 'Python', 'Updated Feb 28, 2021', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Aug 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '50 contributions\n        in the last year', 'description': ['JMLR2020\nSuppport code for submission ""Quadratic Regression Under Sparse Noise""\n'], 'url_profile': 'https://github.com/igormolybog', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'MATLAB', 'MIT license', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Apr 19, 2020', 'Updated Sep 23, 2020', 'Python', 'Updated Feb 28, 2021', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Aug 9, 2020']}","{'location': 'Warsaw', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['multiclass-perceptron\n'], 'url_profile': 'https://github.com/Paulos16', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'MATLAB', 'MIT license', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Apr 19, 2020', 'Updated Sep 23, 2020', 'Python', 'Updated Feb 28, 2021', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Aug 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '32 contributions\n        in the last year', 'description': ['Machine-Learning_Python\nRefer this for Data Science/ML where the projects goes through a structured skeleton model which will find and suggest the best ML\nalgorithm for your business use case.Have used pandas,numpy,matplotlib,Scikit-Learn,seaborn libraries,\nHyperparamater tuning,Data Ingestion,Data transformation,Data science,Accuracy,Scores,Feature Importance,Confusion Matrix etc.\nThe link has below 2 projects comprising of above:\n\nClassification Model -- The code is written in python to predict if a person has Heart disease or not using Cleveland medical data from Kaggle.\nRegression Model     -- The code is written in python to predict pricing of a Bulldozer with Time Series using the input product features with data set from Kaggle.\n\nI have written enough comments on each and every line of the code. Hope this helps for your reference.\n'], 'url_profile': 'https://github.com/gopinathdb', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'MATLAB', 'MIT license', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Apr 19, 2020', 'Updated Sep 23, 2020', 'Python', 'Updated Feb 28, 2021', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Aug 9, 2020']}","{'location': 'Bucharest, Romania', 'stats_list': [], 'contributions': '462 contributions\n        in the last year', 'description': [""Housing Prices Advanced Regression Techniques\nKaggle Competition\nThis repository contains my solution to the Housing Prices Advanced Regression Techniques Kaggle Competition.\nThe source code can be found in the following:\n\nHousing Prices Advanced Regression Techniques.ipynb: contains the a notebook with detailed explanations, as well as source code; the recommended file to read, since code-only can be harder to grasp\nmain.py: the main file, containing all the code that was used to generate and solve the problem\ntransformers.py: file containing the transformers (and imputers) used in the data processing pipelines\n\nTechnical Requirements\nIn order to properly run the code provided, one needs the following:\n\nPython 3.8.2 - the version it was developed into; any backwards compatible version will work, as well as some previous versions\nScikit-Learn 0.0 - pip does not want to show the proper version for this package, but any version will work as long as you check for any differences from the code presented\nNumpy 1.18.2\nPandas 1.0.3\nMatplotlib 3.2.1\n\n\nNote: The notebook was made in Kaggle's engine, thus I cannot state any proper version to use. For the Kaggle notebook, please click here.\n\nAuthor\n\nFilip-Ioan Dutescu - @filipdutescu\n\nLicense\nThis project is licensed under the Apache 2.0 License - see the LICENSE.md file for details.\n""], 'url_profile': 'https://github.com/filipdutescu', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'MATLAB', 'MIT license', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Apr 19, 2020', 'Updated Sep 23, 2020', 'Python', 'Updated Feb 28, 2021', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Aug 9, 2020']}","{'location': 'Boulder, CO', 'stats_list': [], 'contributions': '27 contributions\n        in the last year', 'description': ['ecommerce-analysis\nData viz and regression analysis on kaggle data set.\n'], 'url_profile': 'https://github.com/dkeogh1', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'MATLAB', 'MIT license', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Apr 19, 2020', 'Updated Sep 23, 2020', 'Python', 'Updated Feb 28, 2021', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Aug 9, 2020']}","{'location': 'London, UK', 'stats_list': [], 'contributions': '467 contributions\n        in the last year', 'description': ['Quantile and CDF Regression Example\nQuantile regression objective\n$$ J(\\tau) = E\\left(\\rho(\\tau, Y - u(\\tau, X)|X\\right)$$\n\nCDF regression objective\n$$ J(y_c) = E\\left(\\mathbb{1}{Y < y_c} \\log v(y_c, X) + (1 - \\mathbb{1}{Y < yc}) \\log(1 - v(y_x, X)) | X\\right)$$\n\nThe functions $u$, $v$ must be monotonic in $\\tau$ and $y_c$ respectively.\nUnconditional distribution of $Y$\nQuantile regression\n\nCDF estimation via logistic regression with monotone network\n\nConditional distributional of $Y|X$\nQuantile regression\n\nCDF estimation via logistic regression with monotone network\n\nTODO\nDo more quantitative error plots etc.\n'], 'url_profile': 'https://github.com/cottrell', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'MATLAB', 'MIT license', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Apr 19, 2020', 'Updated Sep 23, 2020', 'Python', 'Updated Feb 28, 2021', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Aug 9, 2020']}","{'location': 'tokyo, japan', 'stats_list': [], 'contributions': '76 contributions\n        in the last year', 'description': ['Simple-Linear-Regression\nPracticing Simple linear regression with python and anaconda.\n'], 'url_profile': 'https://github.com/Mayaz9156', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'MATLAB', 'MIT license', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Apr 19, 2020', 'Updated Sep 23, 2020', 'Python', 'Updated Feb 28, 2021', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Aug 9, 2020']}","{'location': 'Toronto, ON', 'stats_list': [], 'contributions': '22 contributions\n        in the last year', 'description': ['Drinking-Age-Mortality-Rates-through-R\nRegression discontinuity study comparing drinking age and death rates\n'], 'url_profile': 'https://github.com/Mustafa-barez', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'MATLAB', 'MIT license', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Apr 19, 2020', 'Updated Sep 23, 2020', 'Python', 'Updated Feb 28, 2021', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Aug 9, 2020']}"
"{'location': 'Mumbai', 'stats_list': [], 'contributions': '264 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/FarheenB', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 6, 2020', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '44 contributions\n        in the last year', 'description': ['Climbing_logbook\n06.04.2020\nJaromir Panas\nA small project with regression analysis of climbers performance.\nThe repository includes a jupyter notebook file with analysis of data from climbers logbook https://www.8a.nu/. The scraped data form the climbers logbook, in format of a SQLite database, is available at https://www.kaggle.com/dcohen21/8anu-climbing-logbook/metadata.\nThe goal of the project is threefold. Firstly, personal: to practice skills with tensorflow, pandas and matplotlib: learn more and understand better their functionality. Secondly, to investigate the data for the factors that affect the climbers performance. Thirdly, to build a predictive model that will estimate the highest grade that a climber will be able to achieve.\n'], 'url_profile': 'https://github.com/jarromi', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 6, 2020', 'Updated Apr 9, 2020']}","{'location': 'Stanford, CA', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': ['Linear_Regression_with_AI\nWe demonstrate a flaw with the Keras/TensorFlow Deep Learning network when input variables take on both negative and positive values\n'], 'url_profile': 'https://github.com/melindazhu', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 6, 2020', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '151 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/conan9191', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 6, 2020', 'Updated Apr 9, 2020']}","{'location': 'Kathmandu, Nepal', 'stats_list': [], 'contributions': '53 contributions\n        in the last year', 'description': ['Linear-Regression-Example\nFind out the Co2 emission using Linear regression ML Technique.\n'], 'url_profile': 'https://github.com/mikalshrestha', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 6, 2020', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '41 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/immoth', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 6, 2020', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Cypher1612', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 6, 2020', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '42 contributions\n        in the last year', 'description': ['SB-Mini-Project-Linear-Regression\nSpringboard mini project on linear regression and modeling with statsmodels\n'], 'url_profile': 'https://github.com/triffidia', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 6, 2020', 'Updated Apr 9, 2020']}","{'location': 'Ahmedabad, India', 'stats_list': [], 'contributions': '39 contributions\n        in the last year', 'description': ['Covid-19_Regression_analysis\nRegression analysis on confirmed cases of the world\n'], 'url_profile': 'https://github.com/Dhruminthkk', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 6, 2020', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['SimpleBeetleAnalysis\nplots data and uses linear regression to predict beetle growth\n'], 'url_profile': 'https://github.com/AntonioOnwu', 'info_list': ['Julia', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 6, 2020', 'Updated Apr 9, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['This is a project on logistic regression.\nA csv file is provided and by using the method we are supposed to predict which customers are most likely to churn given this data.\n'], 'url_profile': 'https://github.com/anshulm2211', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Jun 11, 2020', 'Python', 'Updated Jul 10, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'CC0-1.0 license', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020']}","{'location': 'Zero Kilo Meter -5 , Pokhara, Nepal', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['This is a repositiory for a ML of grade prediction.\nThe program is done in two ways.\n\nUsing the modules.\nWithout using the modules.\nThe dataset used for the program is also given above.\nJust enjoy.\n\n'], 'url_profile': 'https://github.com/suloveghimirey', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Jun 11, 2020', 'Python', 'Updated Jul 10, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'CC0-1.0 license', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020']}","{'location': 'Singapore', 'stats_list': [], 'contributions': '50 contributions\n        in the last year', 'description': ['Hotel-Rating-Predictor\nScraping TripAdvisor and using linear regression to predict hotel ratings.\nNotebooks are organized in the following order:\n\nscrape\nclean\nEDA\nmodel\n\n'], 'url_profile': 'https://github.com/linanpy', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Jun 11, 2020', 'Python', 'Updated Jul 10, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'CC0-1.0 license', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020']}","{'location': 'Magdeburg, Germany', 'stats_list': [], 'contributions': '132 contributions\n        in the last year', 'description': ['Introduction:\nThis implementation is part of an academic programming assignment during Machine Learning Lecture of Gredient Descent.\nImplementation:\nThe task is to write a python program to implement batch linear regression using gradient descent using the standard gradient descent calculation.\nInput data:\nInput data is expected to be a .csv file with last column as target value. It will be provided through terminal while running the program\nOutput:\nExpected output is a .csv file with weights and sse value for each example point. It will be created in the same working directory.\nHow to Run the program?\nUsing the following command:\npython3 linearregression.py --data somedata.csv --learningRate somevalue --threshold somevalue\n\n'], 'url_profile': 'https://github.com/prafulladiwesh', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Jun 11, 2020', 'Python', 'Updated Jul 10, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'CC0-1.0 license', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020']}","{'location': 'Columbus OH', 'stats_list': [], 'contributions': '55 contributions\n        in the last year', 'description': ['advanced-analytics-\nDecision tree, random forest, linear/ logistics regression, clustering\n'], 'url_profile': 'https://github.com/katintalk', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Jun 11, 2020', 'Python', 'Updated Jul 10, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'CC0-1.0 license', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '264 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/FarheenB', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Jun 11, 2020', 'Python', 'Updated Jul 10, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'CC0-1.0 license', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '12 contributions\n        in the last year', 'description': ['Predicting payments in Swedish Motor Insurance\n\nThe experiment is based on Swedish Motor Insurance data set which describes third party automobile insurance claims for the year 1977 in Sweden. The goal here was to analyze the data and to perform simple linear regression for the 2 points of interest in this dataset: number of claims (the frequency) and sum of payments (the severity). In order to do that, we had to split the dataset into training and test set, apply predictions in the test set according to a training and to come up with measures for our predictions.\nBy visualizing our points of interest we get following distribution graphs:\n\nWe can see that graphs are pretty similar, therefore we will try to do linear regression here based on number of claims to predict payments.\nLater, we will measure how good our predictions are\n'], 'url_profile': 'https://github.com/aleksandarsibincic', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Jun 11, 2020', 'Python', 'Updated Jul 10, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'CC0-1.0 license', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020']}","{'location': 'Chicago', 'stats_list': [], 'contributions': '420 contributions\n        in the last year', 'description': ['Twitter Sentimental Analysis using Logistic Regression on TF-IDF\n Steps \n\nRead the data from the CSV file\nTrain Data Cleaning- Removing Punctuations, Stop words and making Lowercase\nTest  Data Cleaning- Removing Punctuations, Stop words and making Lowercase\nFind TF-IDF for cleaned train data\nFind TF-IDF for cleaned test  data\nCreate train and test dataframes from the corresponding TF-IDF data\nTrain the Logistic regression model using the train data\nUsing the model make the predictions on Test data to identify sentiments through Tweets.\n\n'], 'url_profile': 'https://github.com/ankitbvs', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Jun 11, 2020', 'Python', 'Updated Jul 10, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'CC0-1.0 license', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020']}","{'location': 'New York, New York ', 'stats_list': [], 'contributions': '599 contributions\n        in the last year', 'description': [""NLP Analysis with Amazon Reviews Data\n\nGoal:\nBinary Classification\nUsing Amazon data to predict if the review is negative or positive\n\nIf rating <=3  negative review  0\nIf rating >=4  positive review  1\n\nMulti-calss classification\nThis part is to use the users' review to predict the rating scores and the label(target) in this part is the rating score from 1 to 5.\nThis is multi-class classification\nAttribute information\n\nhelpful - helpfulness rating of the review [2,3], e.g. 2/3 ,  2 is numerator , 3 id denominator\nNumerator: Number of readers who found the review is  helpful\nDenominator: Number of readers who indicated whether they found the review helpful or not.\nreview Text - text of the review\noverall - rating of the product\nsummary - summary of the review\nunix Review Time - time of the review (unix time)\n\nEDA\nBigram & World Cloud\n\nBigrams Shows that Top 5 words for positive reviews are all positive, on the other hand top 5 words for negative reviews either neutral or negative.\n\n\n\n\nReview counts\n\nReview counts graph shows that  the numbers of positive reviews and negative reviews are not balanced, therefore oversampling method was applied.\n\n\nReview Length\n\nOn the other hand we can see the mean of length of negative reviews is long than positive reviews. That makes sense, because when a person complains about a product that she/he does like , the person will talk a lot.\n\n\nReview Counts by Time\n\nIn 2013 Amazon sells over 200 million products in the USA, which are categorised into 35 departments and almost 20 million in Sports & Outdoors\n\n\nData cleaning and preprocessing\n\nCombined summary column and review column as â€œcombined_textâ€\nCreated a target column based on rating column\nCreated two columns, one is helpfulness_numerator ,another one is helpfulness_denominator\nTokenization, Punctuation removal , stemming, lemmatization\nAfter step 4.  created a column - review_len which is length of review(text)\nData Resampling (Oversampling Method)\n\nModeling- Binary Classification\nThere are two parts at first level, text data analysis and non_text data analysis. For text data , Naive Bayes Classifier, Neural Network and Logistic Regression were applies and obtained each model's predictions (train data and test data ). For the non_text data, Random Forest , Neural Network and Logistic Regression were applied and generated the predictions. At second level, All six train-data predictions  and six test-data prediction were combined as new features renamed as  new x_train data and new x_text data. XGboost and Neural Network were applied to predict again. The result shows that model stacking gives slightly higher f1 score from 0.9059 to 0.9063. Eventhough model stacking may deliver better result, it is difficult to interpret the result.\n\nModeling- Multi-class Classification\nSimilary, this part contians two parts, in the first modeling part, Naive Bayes Classifier, Neural Network and Random Forest were applied and second part is included model stacking with XGboost model and Neural Network. In the first part, the F1 scores of Naive Bayes Classifier, Neural Network and Random Forest are 0.6067, 0.6085, 0.6186 respectively. Obviously Random Forest perfomed best with f1 score 0.6186. In second part, after model stacking the f1 scores of XGboost and Neural Network are 0.5893 and 0.6189. After model stacking we can see that f1 score slightly increased 0.0003.\n\nPresentation:https://docs.google.com/presentation/d/1pjb43sTBqI7z4jKIwuu9FlcUvjYyJvtK07uPGz71drQ/edit?usp=sharing\nDashboard:https://public.tableau.com/profile/hua.shi#!/vizhome/NLPAnalysiswithAmazonSportsOutdoorReviewData/Dashboard1?publish=yes\n""], 'url_profile': 'https://github.com/melanieshi0120', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Jun 11, 2020', 'Python', 'Updated Jul 10, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'CC0-1.0 license', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020']}","{'location': 'Sialkot', 'stats_list': [], 'contributions': '179 contributions\n        in the last year', 'description': ['Linear-Regression-Co2-Emission-Prediction\nMachine Learning Regression Algorithm. Predicts the CO2 emission for Unknown vehicle based on the engines size of the vehicle.\n'], 'url_profile': 'https://github.com/mrqasimasif', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Jun 11, 2020', 'Python', 'Updated Jul 10, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'CC0-1.0 license', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020']}"
"{'location': 'New York, New York ', 'stats_list': [], 'contributions': '599 contributions\n        in the last year', 'description': [""NLP Analysis with Amazon Reviews Data\n\nGoal:\nBinary Classification\nUsing Amazon data to predict if the review is negative or positive\n\nIf rating <=3  negative review  0\nIf rating >=4  positive review  1\n\nMulti-calss classification\nThis part is to use the users' review to predict the rating scores and the label(target) in this part is the rating score from 1 to 5.\nThis is multi-class classification\nAttribute information\n\nhelpful - helpfulness rating of the review [2,3], e.g. 2/3 ,  2 is numerator , 3 id denominator\nNumerator: Number of readers who found the review is  helpful\nDenominator: Number of readers who indicated whether they found the review helpful or not.\nreview Text - text of the review\noverall - rating of the product\nsummary - summary of the review\nunix Review Time - time of the review (unix time)\n\nEDA\nBigram & World Cloud\n\nBigrams Shows that Top 5 words for positive reviews are all positive, on the other hand top 5 words for negative reviews either neutral or negative.\n\n\n\n\nReview counts\n\nReview counts graph shows that  the numbers of positive reviews and negative reviews are not balanced, therefore oversampling method was applied.\n\n\nReview Length\n\nOn the other hand we can see the mean of length of negative reviews is long than positive reviews. That makes sense, because when a person complains about a product that she/he does like , the person will talk a lot.\n\n\nReview Counts by Time\n\nIn 2013 Amazon sells over 200 million products in the USA, which are categorised into 35 departments and almost 20 million in Sports & Outdoors\n\n\nData cleaning and preprocessing\n\nCombined summary column and review column as â€œcombined_textâ€\nCreated a target column based on rating column\nCreated two columns, one is helpfulness_numerator ,another one is helpfulness_denominator\nTokenization, Punctuation removal , stemming, lemmatization\nAfter step 4.  created a column - review_len which is length of review(text)\nData Resampling (Oversampling Method)\n\nModeling- Binary Classification\nThere are two parts at first level, text data analysis and non_text data analysis. For text data , Naive Bayes Classifier, Neural Network and Logistic Regression were applies and obtained each model's predictions (train data and test data ). For the non_text data, Random Forest , Neural Network and Logistic Regression were applied and generated the predictions. At second level, All six train-data predictions  and six test-data prediction were combined as new features renamed as  new x_train data and new x_text data. XGboost and Neural Network were applied to predict again. The result shows that model stacking gives slightly higher f1 score from 0.9059 to 0.9063. Eventhough model stacking may deliver better result, it is difficult to interpret the result.\n\nModeling- Multi-class Classification\nSimilary, this part contians two parts, in the first modeling part, Naive Bayes Classifier, Neural Network and Random Forest were applied and second part is included model stacking with XGboost model and Neural Network. In the first part, the F1 scores of Naive Bayes Classifier, Neural Network and Random Forest are 0.6067, 0.6085, 0.6186 respectively. Obviously Random Forest perfomed best with f1 score 0.6186. In second part, after model stacking the f1 scores of XGboost and Neural Network are 0.5893 and 0.6189. After model stacking we can see that f1 score slightly increased 0.0003.\n\nPresentation:https://docs.google.com/presentation/d/1pjb43sTBqI7z4jKIwuu9FlcUvjYyJvtK07uPGz71drQ/edit?usp=sharing\nDashboard:https://public.tableau.com/profile/hua.shi#!/vizhome/NLPAnalysiswithAmazonSportsOutdoorReviewData/Dashboard1?publish=yes\n""], 'url_profile': 'https://github.com/melanieshi0120', 'info_list': ['Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Sep 2, 2020', 'JavaScript', 'Updated Oct 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Feb 24, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Sialkot', 'stats_list': [], 'contributions': '179 contributions\n        in the last year', 'description': ['Linear-Regression-Co2-Emission-Prediction\nMachine Learning Regression Algorithm. Predicts the CO2 emission for Unknown vehicle based on the engines size of the vehicle.\n'], 'url_profile': 'https://github.com/mrqasimasif', 'info_list': ['Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Sep 2, 2020', 'JavaScript', 'Updated Oct 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Feb 24, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'MUMBAI', 'stats_list': [], 'contributions': '32 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/saviosimoes', 'info_list': ['Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Sep 2, 2020', 'JavaScript', 'Updated Oct 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Feb 24, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '12 contributions\n        in the last year', 'description': ['OrdBenchmarkDatasets\nBenchmark ordinal regression datasets for the HistGBODT project.\nReferences:\n[1] Chu, Wei & Ghahramani, Zoubin. (2005). Gaussian Processes for Ordinal Regression. Journal of Machine Learning Research. 6. 1019-1041.\n[2] Wei Chu and S. Sathiya Keerthi. 2007. Support Vector Ordinal Regression. Neural Comput. 19, 3 (March 2007), 792â€“815. DOI:https://doi.org/10.1162/neco.2007.19.3.792\n[3] http://www.gatsby.ucl.ac.uk/~chuwei/ordinalregression.html\n[4] https://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html\n'], 'url_profile': 'https://github.com/hrbzkm98', 'info_list': ['Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Sep 2, 2020', 'JavaScript', 'Updated Oct 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Feb 24, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '35 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/conradwhiteley', 'info_list': ['Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Sep 2, 2020', 'JavaScript', 'Updated Oct 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Feb 24, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'China', 'stats_list': [], 'contributions': '143 contributions\n        in the last year', 'description': ['pytorch-examples\n'], 'url_profile': 'https://github.com/scarleatt', 'info_list': ['Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Sep 2, 2020', 'JavaScript', 'Updated Oct 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Feb 24, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Everywhere', 'stats_list': [], 'contributions': '865 contributions\n        in the last year', 'description': ['regression_kriging_site\nA website that makes use of regression kriging\n'], 'url_profile': 'https://github.com/iamr0b0tx', 'info_list': ['Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Sep 2, 2020', 'JavaScript', 'Updated Oct 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Feb 24, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Senegal', 'stats_list': [], 'contributions': '81 contributions\n        in the last year', 'description': ['Linear-regression\nRidge and Lasso Regression: L1 and L2 Regularization\n'], 'url_profile': 'https://github.com/IdrissouSOUNON', 'info_list': ['Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Sep 2, 2020', 'JavaScript', 'Updated Oct 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Feb 24, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Nairobi', 'stats_list': [], 'contributions': '338 contributions\n        in the last year', 'description': ['Simple Python code challenges to create a good foundation for the language\nEverything can be executed in terminal!\nAny recomendations? hit me up\nThis is a work in progress, files may change abruptly as I incorporate more learnings and knowledge\n'], 'url_profile': 'https://github.com/DevShasa', 'info_list': ['Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Sep 2, 2020', 'JavaScript', 'Updated Oct 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Feb 24, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Italy', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['Date created\nThe project was created in 12/04/2020 and README.md was createn in 12/04/2020.\nProject Title\nProject: Linear Regression(Codecademy PRO test)\nDescription\nLinear Regression is when you have a group of points on a graph, and you find a line that approximately resembles that group of points. A good Linear Regression algorithm minimizes the error_, or the distance from each point to the line. A line with the least error is the line that fits the data the best. We call this a line of best fit.\nWe will use loops, lists, and arithmetic to create a function that will find a line of best fit when given a set of data.\nFiles used\nTo make this project i used Jupyter Notebook.\nYou have to use the same IDLE to open it\n'], 'url_profile': 'https://github.com/mircomiglietta', 'info_list': ['Jupyter Notebook', 'Updated Oct 18, 2020', '1', 'Python', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Sep 2, 2020', 'JavaScript', 'Updated Oct 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Feb 24, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '53 contributions\n        in the last year', 'description': ['#Oswaldo David GarcÃ­a RodrÃ­guez, A01206725\nLinear Regression\n'], 'url_profile': 'https://github.com/Oswaldo1002009', 'info_list': ['Python', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Python', 'MIT license', 'Updated Apr 6, 2020', 'R', 'Updated May 9, 2020', 'Updated Aug 24, 2020', '1', 'Python', 'Updated May 8, 2020', 'Python', 'Updated Jul 25, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Julia', 'Updated Apr 6, 2020']}","{'location': 'Italy', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['Date created\nThe project was created in 12/04/2020 and README.md was createn in 12/04/2020.\nProject Title\nProject: Linear Regression(Codecademy PRO test)\nDescription\nLinear Regression is when you have a group of points on a graph, and you find a line that approximately resembles that group of points. A good Linear Regression algorithm minimizes the error_, or the distance from each point to the line. A line with the least error is the line that fits the data the best. We call this a line of best fit.\nWe will use loops, lists, and arithmetic to create a function that will find a line of best fit when given a set of data.\nFiles used\nTo make this project i used Jupyter Notebook.\nYou have to use the same IDLE to open it\n'], 'url_profile': 'https://github.com/mircomiglietta', 'info_list': ['Python', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Python', 'MIT license', 'Updated Apr 6, 2020', 'R', 'Updated May 9, 2020', 'Updated Aug 24, 2020', '1', 'Python', 'Updated May 8, 2020', 'Python', 'Updated Jul 25, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Julia', 'Updated Apr 6, 2020']}","{'location': 'India', 'stats_list': [], 'contributions': '221 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/danish17', 'info_list': ['Python', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Python', 'MIT license', 'Updated Apr 6, 2020', 'R', 'Updated May 9, 2020', 'Updated Aug 24, 2020', '1', 'Python', 'Updated May 8, 2020', 'Python', 'Updated Jul 25, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Julia', 'Updated Apr 6, 2020']}","{'location': 'Bucharest', 'stats_list': [], 'contributions': '241 contributions\n        in the last year', 'description': ['Statistics project\nThe project has 2 parts:\n\nLiniar vs Multiple Liniar Regression\nRandom variables operations\n\nThe documentation for this project is here: https://github.com/AndraRaco/Statistics-project/blob/master/Proiect.pdf.\n\n'], 'url_profile': 'https://github.com/AndraRaco', 'info_list': ['Python', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Python', 'MIT license', 'Updated Apr 6, 2020', 'R', 'Updated May 9, 2020', 'Updated Aug 24, 2020', '1', 'Python', 'Updated May 8, 2020', 'Python', 'Updated Jul 25, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Julia', 'Updated Apr 6, 2020']}","{'location': 'San Francisco', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['Logistic-Regression\nLogistic Regression on the ""mtcars"" dataset in R\n'], 'url_profile': 'https://github.com/Chasesinclair1', 'info_list': ['Python', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Python', 'MIT license', 'Updated Apr 6, 2020', 'R', 'Updated May 9, 2020', 'Updated Aug 24, 2020', '1', 'Python', 'Updated May 8, 2020', 'Python', 'Updated Jul 25, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Julia', 'Updated Apr 6, 2020']}","{'location': 'Toronto, Ontario', 'stats_list': [], 'contributions': '64 contributions\n        in the last year', 'description': ['Stock-Market-Prediction\nThis project deals with predicting the opening BID, ASK and PRICE using daily Apple stock data of 4 years. This data would be useful for traders to determine if a stock should be traded as a future, forward, option or some other derivative as they would be able to see the future trend.\nData Pre-processing and Feature Engineering\n\nCheck for missing values - no missing values\nCheck if categorical data, encoding needed - no categorical data\nCheck Feature Importance - All features had high significance, so not dropping\nSplit data into train, validation and test in the ratio 60:20:20\nFeature Scaling - We are normalizing data between zero and one.\n\nPrediction Models\n\nAutoregressive Integrated Moving Average models (ARIMA)\nLong Short-Term Memory (LSTM)\nGated Recurrent Unit (GRU)\n\nModel Optimization\nBayesian Optimization of GRU and LSTM models.\nAccuracy Measures for Comparison\n\nMean Absolute Error (MAE)\nRoot Mean Squared Error (RMSE)\nMean Forecast Error (MFE)\n\n\nEven the less complex models like ARIMA can show better performance than the complex neural netwrok models on some datasets.\n'], 'url_profile': 'https://github.com/rjagait', 'info_list': ['Python', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Python', 'MIT license', 'Updated Apr 6, 2020', 'R', 'Updated May 9, 2020', 'Updated Aug 24, 2020', '1', 'Python', 'Updated May 8, 2020', 'Python', 'Updated Jul 25, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Julia', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '250 contributions\n        in the last year', 'description': [""Boston House Price Prediction\nThis is regression training using boston house price data from 1978. It's main purpose is to predic the price of a house based on the number of rooms in the house, the relative poverty percentage in the house's neighborhood and the average class size, represented as the pupil-teacher ratio. The regressor used here is a Decision Tree regressor.\nThere is also some data analaysis performed near the beginning of the script, to give a brief overview of the data its distribution and correlations, as well as some information about the nature of the models being used. The Model Learning and Model Complexity graphs are used for model analysis and are generated from functions in the visuals file. They give a description of how the model predictive power changes as a function of kew Decision Tree parameters (in this case the max depth is the parameter being principally examined).\nWhen the Model Learning script is run, some warning will appear. Also, for the Model Learning graphs, there is no traning score for the oth training size. This is purely due to the inability of the regressor to provide score for null traning points, and is nothing to be concerned aboout.\nFor the error analysis, a function from the aforementioned visuals file is used to run the prediction 10 times using variable random states and the variance calculated. This nicely describes the models' sensitivity in both monetary and percentage terms.\nTo run the prediction algorithm simply use import and make sure to have all the dependencies (the data and the visuals file) saved in the same directory. All libraries used here are fairly standard.\nThis algorithm was adapated from a towardsdatascience article by Victor Roman (the URL is available below). The article is rather brief and bereft of detail, and significant research had to be done to figure out why parts of the instructions didn't work. All the relevant material is available in the article links, and apart from some minor design details little revision was required.\nhttps://towardsdatascience.com/machine-learning-project-predicting-boston-house-prices-with-regression-b4e47493633d\n""], 'url_profile': 'https://github.com/MrFlygerian', 'info_list': ['Python', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Python', 'MIT license', 'Updated Apr 6, 2020', 'R', 'Updated May 9, 2020', 'Updated Aug 24, 2020', '1', 'Python', 'Updated May 8, 2020', 'Python', 'Updated Jul 25, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Julia', 'Updated Apr 6, 2020']}","{'location': 'Stanford, CA', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': ['Mixed_Category_Regression_AI\nUsing Keras/TensorFlow Deep Learning Network, we demonstrate how to perform regression when the input data consists of both continuous and categorical variables.\n'], 'url_profile': 'https://github.com/melindazhu', 'info_list': ['Python', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Python', 'MIT license', 'Updated Apr 6, 2020', 'R', 'Updated May 9, 2020', 'Updated Aug 24, 2020', '1', 'Python', 'Updated May 8, 2020', 'Python', 'Updated Jul 25, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Julia', 'Updated Apr 6, 2020']}","{'location': 'Ithaca, NY', 'stats_list': [], 'contributions': '563 contributions\n        in the last year', 'description': ['Project: Regression Modeling with the Boston Housing Dataset\nIntroduction\nIn this lab, you\'ll apply the regression analysis and diagnostics techniques covered in this section to the ""Boston Housing"" dataset. You performed a detailed EDA for this dataset earlier on, and hopefully, you more or less recall how this data is structured! In this lab, you\'ll use some of the features in this dataset to create a linear model to predict the house price!\nObjectives\nYou will be able to:\n\nPerform a linear regression using statsmodels\nDetermine if a particular set of data exhibits the assumptions of linear regression\nEvaluate a linear regression model by using statistical performance metrics pertaining to overall model and specific parameters\nUse the coefficient of determination to determine model performance\nInterpret the parameters of a simple linear regression model in relation to what they signify for specific data\n\nLet\'s get started\nImport necessary libraries and load \'BostonHousing.csv\' as a pandas dataframe\n# Your code here\nThe columns in the Boston housing data represent the dependent and independent variables. The dependent variable here is the median house value MEDV. The description of the other variables is available on KAGGLE.\nInspect the columns of the dataset and comment on type of variables present\n# Your code here\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\ncrim\nzn\nindus\nchas\nnox\nrm\nage\ndis\nrad\ntax\nptratio\nb\nlstat\nmedv\n\n\n\n\n0\n0.00632\n18.0\n2.31\n0\n0.538\n6.575\n65.2\n4.0900\n1\n296\n15.3\n396.90\n4.98\n24.0\n\n\n1\n0.02731\n0.0\n7.07\n0\n0.469\n6.421\n78.9\n4.9671\n2\n242\n17.8\n396.90\n9.14\n21.6\n\n\n2\n0.02729\n0.0\n7.07\n0\n0.469\n7.185\n61.1\n4.9671\n2\n242\n17.8\n392.83\n4.03\n34.7\n\n\n3\n0.03237\n0.0\n2.18\n0\n0.458\n6.998\n45.8\n6.0622\n3\n222\n18.7\n394.63\n2.94\n33.4\n\n\n4\n0.06905\n0.0\n2.18\n0\n0.458\n7.147\n54.2\n6.0622\n3\n222\n18.7\n396.90\n5.33\n36.2\n\n\n\n\n# Record your observations here \nCreate histograms for all variables in the dataset and comment on their shape (uniform or not?)\n# Your code here \n\n# You observations here \nBased on this, we preselected some features  for you which appear to be more \'normal\' than others.\nCreate a new dataset with [\'crim\', \'dis\', \'rm\', \'zn\', \'age\', \'medv\']\n# Your code here\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\ncrim\ndis\nrm\nzn\nage\nmedv\n\n\n\n\n0\n0.00632\n4.0900\n6.575\n18.0\n65.2\n24.0\n\n\n1\n0.02731\n4.9671\n6.421\n0.0\n78.9\n21.6\n\n\n2\n0.02729\n4.9671\n7.185\n0.0\n61.1\n34.7\n\n\n3\n0.03237\n6.0622\n6.998\n0.0\n45.8\n33.4\n\n\n4\n0.06905\n6.0622\n7.147\n0.0\n54.2\n36.2\n\n\n\n\nCheck the linearity assumption for all chosen features with target variable using scatter plots\n# Your code here \n\n\n\n\n\n# Your observations here \nClearly, your data needs a lot of preprocessing to improve the results. This key behind a Kaggle competition is to process the data in such a way that you can identify the relationships and make predictions in the best possible way. For now, we\'ll use the dataset untouched and just move on with the regression. The assumptions are not exactly all fulfilled, but they still hold to a level that we can move on.\nLet\'s do Regression\nNow, let\'s perform a number of simple regression experiments between the chosen independent variables and the dependent variable (price). You\'ll do this in a loop and in every iteration, you should pick one of the independent variables. Perform the following steps:\n\nRun a simple OLS regression between independent and dependent variables\nPlot a regression line on the scatter plots\nPlot the residuals using sm.graphics.plot_regress_exog()\nPlot a Q-Q plot for regression residuals normality test\nStore following values in array for each iteration:\n\nIndependent Variable\nr_squared\'\nintercept\'\n\'slope\'\n\'p-value\'\n\'normality (JB)\'\n\n\nComment on each output\n\n# Your code here\nBoston Housing DataSet - Regression Analysis and Diagnostics for formula: medv~crim\n-------------------------------------------------------------------------------------\n\n\n\n\nPress Enter to continue...\nBoston Housing DataSet - Regression Analysis and Diagnostics for formula: medv~dis\n-------------------------------------------------------------------------------------\n\n\n\n\nPress Enter to continue...\nBoston Housing DataSet - Regression Analysis and Diagnostics for formula: medv~rm\n-------------------------------------------------------------------------------------\n\n\n\n\nPress Enter to continue...\nBoston Housing DataSet - Regression Analysis and Diagnostics for formula: medv~zn\n-------------------------------------------------------------------------------------\n\n\n\n\nPress Enter to continue...\nBoston Housing DataSet - Regression Analysis and Diagnostics for formula: medv~age\n-------------------------------------------------------------------------------------\n\n\n\n\nPress Enter to continue...\n\npd.DataFrame(results)\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\n0\n1\n2\n3\n4\n5\n\n\n\n\n0\nind_var\nr_squared\nintercept\nslope\np-value\nnormality (JB)\n\n\n1\ncrim\n0.15078\n24.0331\n-0.41519\n1.17399e-19\n295.404\n\n\n2\ndis\n0.0624644\n18.3901\n1.09161\n1.20661e-08\n305.104\n\n\n3\nrm\n0.483525\n-34.6706\n9.10211\n2.48723e-74\n612.449\n\n\n4\nzn\n0.129921\n20.9176\n0.14214\n5.71358e-17\n262.387\n\n\n5\nage\n0.142095\n30.9787\n-0.123163\n1.56998e-18\n456.983\n\n\n\n\n#Your observations here \nClearly, the results are not very reliable. The best R-Squared is witnessed with rm, so in this analysis, this is our best predictor.\nHow can you improve these results?\n\nPreprocessing\n\nThis is where the preprocessing of data comes in. Dealing with outliers, normalizing data, scaling values etc. can help regression analysis get more meaningful results from the given data.\n\nAdvanced Analytical Methods\n\nSimple regression is a very basic analysis technique and trying to fit a straight line solution to complex analytical questions may prove to be very inefficient. Later on, you\'ll explore multiple regression where you can use multiple features at once to define a relationship with the outcome. You\'ll also look at some preprocessing and data simplification techniques and revisit the Boston dataset with an improved toolkit.\nLevel up - Optional\nApply some data wrangling skills that you have learned in the previous section to pre-process the set of independent variables we chose above. You can start off with outliers and think of a way to deal with them. See how it affects the goodness of fit.\nSummary\nIn this lab, you applied your skills learned so far on a new data set. You looked at the outcome of your analysis and realized that the data might need some preprocessing to see a clear improvement in the results. You\'ll pick this back up later on, after learning about more preprocessing techniques and advanced modeling techniques.\n'], 'url_profile': 'https://github.com/merb92', 'info_list': ['Python', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Python', 'MIT license', 'Updated Apr 6, 2020', 'R', 'Updated May 9, 2020', 'Updated Aug 24, 2020', '1', 'Python', 'Updated May 8, 2020', 'Python', 'Updated Jul 25, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Julia', 'Updated Apr 6, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '264 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/FarheenB', 'info_list': ['Python', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Python', 'MIT license', 'Updated Apr 6, 2020', 'R', 'Updated May 9, 2020', 'Updated Aug 24, 2020', '1', 'Python', 'Updated May 8, 2020', 'Python', 'Updated Jul 25, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Julia', 'Updated Apr 6, 2020']}"
"{'location': 'Goa , INDIA', 'stats_list': [], 'contributions': '142 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/StephennFernandes', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'HTML', 'Updated Apr 27, 2020', 'Updated Apr 9, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 6, 2020', 'MATLAB', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'Updated Apr 7, 2020']}","{'location': 'Queens, NY', 'stats_list': [], 'contributions': '38 contributions\n        in the last year', 'description': ['Scraper\nWebScraper and Regressions\n'], 'url_profile': 'https://github.com/austinjohnson', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'HTML', 'Updated Apr 27, 2020', 'Updated Apr 9, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 6, 2020', 'MATLAB', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'Updated Apr 7, 2020']}","{'location': 'Delhi, India', 'stats_list': [], 'contributions': '40 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/vm-iiit', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'HTML', 'Updated Apr 27, 2020', 'Updated Apr 9, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 6, 2020', 'MATLAB', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '117 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/rafallewanczyk', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'HTML', 'Updated Apr 27, 2020', 'Updated Apr 9, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 6, 2020', 'MATLAB', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '26 contributions\n        in the last year', 'description': [""Linear-Regression-\nYou just got some contract work with an Ecommerce company based in New York City that sells clothing online but they also have in-store style and clothing advice sessions. Customers come in to the store, have sessions/meetings with a personal stylist, then they can go home and order either on a mobile app or website for the clothes they want.  The company is trying to decide whether to focus their efforts on their mobile app experience or their website. They've hired you on contract to help them figure it out!\n""], 'url_profile': 'https://github.com/monisha98reddy', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'HTML', 'Updated Apr 27, 2020', 'Updated Apr 9, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 6, 2020', 'MATLAB', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/anilganji11', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'HTML', 'Updated Apr 27, 2020', 'Updated Apr 9, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 6, 2020', 'MATLAB', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '22 contributions\n        in the last year', 'description': ['Linear-Regression\n'], 'url_profile': 'https://github.com/russell-lin', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'HTML', 'Updated Apr 27, 2020', 'Updated Apr 9, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 6, 2020', 'MATLAB', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '294 contributions\n        in the last year', 'description': [""Logistic-Regression\nIn this repository you will get a program which deals with a logistic regression problem of machine learning.\nI have built a logistic regression model to predict whether a student gets admitted into a university.\nSuppose that you are the administrator of a university department and you want to determine each applicant's chance of admission based on their results on two exams.\nYou have historical data from previous applicants that you can use as a training set for logistic regression. For each training\nexample, you have the applicant's scores on two exams and the admissions decision.\n""], 'url_profile': 'https://github.com/Ashish-Arya-CS', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'HTML', 'Updated Apr 27, 2020', 'Updated Apr 9, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 6, 2020', 'MATLAB', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '42 contributions\n        in the last year', 'description': ['Linear-Reg\n'], 'url_profile': 'https://github.com/Dinusha-Herath-Mudiyanselage', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'HTML', 'Updated Apr 27, 2020', 'Updated Apr 9, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 6, 2020', 'MATLAB', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'Updated Apr 7, 2020']}","{'location': 'NY/NJ', 'stats_list': [], 'contributions': '35 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/tk33', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'HTML', 'Updated Apr 27, 2020', 'Updated Apr 9, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 6, 2020', 'MATLAB', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'Updated Apr 7, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '72 contributions\n        in the last year', 'description': [""Linear-Regression\nAbstract\nGiven a dataset with no apparent relationship between x-values and y-values, the ability of scipy.optimize.curve_fit to create a best-fit line is evaluated. In linear regression, it is assumed that the data are related by a linear model y=Î²x+e, where Î² is the regression coefficient and e is Gaussian noise. By generating many datasets where there is no relationship between X and Y (Î² = 0) and fitting a line to each simulation, it is possible to estimate the likelihood of seeing the relationship generated by scipy.optimize.curve_fit in the original dataset by chance. The regression coefficient for the given dataset is compared to a distribution of regression coefficients from running many simulations. Two different distributions are created for comparison. The first involves best-fit lines of completely new generated datasets, while the second involves generating new datasets through bootstrapping. The regression coefficient from cipy.optimize.curve_fit is shown to be almost equal to the median regression coefficent from the distribution. Finally, a distribution of residuals from the original best-fit line created by scipy.optimize.curve_fit is created. This distribution is found to somewhat follow a normal distribution.\nMethods\nFirst, scipy.optimize.curve_fit is used to form a best-fit line for the original dataset. The output covariance of the fit is used to determine the 95% confidence interval in the slope of the fitted line. Then, 1000 new datasets with no relationship between X and Y are generated. The values in each dataset are randomly picked between the lower and upper bounds of x- and y-values from the original dataset. A distribution of regression coefficients is created from these new datasets and used to evaluate the probability of obtaining the scipy.optimize.curve_fit result from the original dataset. This process of generating new datasets, fitting a line to each dataset, and comparing the distribution of slopes to the original result is repeated. However, this time the new datasets are generated through bootstrapping. The original data is resampled with replacement to create 1000 new datasets. The 2.5th percentile and 97.5th percentiles of the bootstrapped distribution are calculated, so that 95% of the regression coefficients fall between these two values. This range is used to compare to the 95% confidence interval in the regression coefficient of the original dataset.\nIn addition to regression coefficients, the residuals are also evaluated. The residuals are calculated by subtracting the original data from the scipy.optimize.curve_fit fitted model. The Kolmogorov-Smirnov test is used to determine how well the distribution of residuals follows a normal distribution.\nResults and Discussion\nThe regression coefficient found by scipy.optimize.curve_fit is: 0.0741\nThe 95% confidence interval in the fitted slope of the line is: [0.0457, 0.102]\nThe distribution of regression coefficients from datasets generated randomly indicates that the likelihood of seeing a relationship with slope greater than or equal to the best-fit coefficient of the original dataset is 6.60%. However, bootstrapping is perhaps a better way to assess confidence in the scipy.optimize.curve_fit results. When comparing to the distribution of regression coefficients of bootstrapped datasets, the likelihood of seeing a regression coefficient less than or equal to the best-fit coefficient of the original dataset is 48.30%. These results are shown below in Figure 1.\n\nThe median regression coefficient from the distribution of bootstrapped datasets is: 0.0733\nThe 2.5th percentile is: 0.0234\nThe 97.5th percentile is: 0.122\nFigure 2 shows how these values compare to the scipy.optimize.curve_fit best-fit of the original dataset. As seen below, it appears as though the scipy.optimize.curve_fit best-fit line and the line using the median regression coefficient from the bootstrapped datasets are almost equal. However, the bootstrapped model has a greater confidence interval. This makes sense considering the wide spread of the data.\n\nThe Kolmogorov-Smirnov statistic is: 0.268\nThe probability of observing residuals is: 7.673e-07\nThe Kolmogorov-Smirnov statistic suggests that the normal distribution is an 'okay' though not great fit for the residuals. The probability of observing residuals is extremely low, which may explain the deviation from what is expected.\nFigure 3 shows the distribution of residuals.\n""], 'url_profile': 'https://github.com/shoshireich', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 12, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Feb 3, 2021', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'Lahore, Pakistan', 'stats_list': [], 'contributions': '132 contributions\n        in the last year', 'description': ['Linear-regression\nThis project uses a dummy artificial dataset of Ecommerce customers and sklearn is used to implement linear regression on it. Data is analyzed too.\n'], 'url_profile': 'https://github.com/jawadSajid', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 12, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Feb 3, 2021', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '84 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ycui10', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 12, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Feb 3, 2021', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/vaidehi2203', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 12, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Feb 3, 2021', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Aditya1231', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 12, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Feb 3, 2021', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': ['MultipleRegression\n'], 'url_profile': 'https://github.com/pangbl', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 12, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Feb 3, 2021', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '383 contributions\n        in the last year', 'description': ['Logistic-regression\n'], 'url_profile': 'https://github.com/priyanshu-data', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 12, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Feb 3, 2021', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '157 contributions\n        in the last year', 'description': ['Documentation hosted on Github Pages.\n'], 'url_profile': 'https://github.com/jacekdobrowolski', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 12, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Feb 3, 2021', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'Taipei', 'stats_list': [], 'contributions': '66 contributions\n        in the last year', 'description': ['ML_regression\nThis project refers to the ML course of the NTU professor, Hung-yi Lee.\nAbstract\nThe spirit of linear regression is that we try to draw a line in the graph so that this line can be close to all points.\nIn addition, using Gradient Descent to find and train the parameters is our goal in this project.\nContents\n\nThe project includes:\n\ntrain.csv\ntest.csv\nlinear.ipynb\n\n\n\nRequirement\nThe library you have to install using pip :\npip install pandas\npip install numpy\npip install matplotlib.pyplot\n\nTraining / Testing Data reference\nhttps://www.kaggle.com/andonians/random-linear-regression#train.csv\nCourse reference\nhttp://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html?fbclid=IwAR0RHYT5SaYLmgycLlwL4GvtUr0DXML_mJOB_uFAf2NIMHSNLXNQDi7V6Ck\nAuthors\n\nfindelementbyid - Initial work - https://github.com/findelementbyid\n\n'], 'url_profile': 'https://github.com/findelementbyid', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 12, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Feb 3, 2021', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'Chennai', 'stats_list': [], 'contributions': '32 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/AllegroAB', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 13, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 12, 2020', 'R', 'Updated Apr 9, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Feb 3, 2021', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}"
"{'location': 'Nairobi-Kenya', 'stats_list': [], 'contributions': '554 contributions\n        in the last year', 'description': ['logistic-regressions\n'], 'url_profile': 'https://github.com/abel-keya', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020']}","{'location': 'bengluru', 'stats_list': [], 'contributions': '32 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/santusrk', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020']}","{'location': 'Istanbul, Turkey', 'stats_list': [], 'contributions': '77 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/tugrulhkarabulut', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '169 contributions\n        in the last year', 'description': [""Regression Project - Estimate Home Value\nBackground\n\nWe want to be able to predict the values of single unit properties that the tax district assesses using the property data from  May and June in 2017.\n\nOther notes\n\nFor the first iteration of your model, use only square feet of the home, number of bedrooms, and number of bathrooms to estimate the properties assessed value, 'taxvaluedollarcnt'. You can expand this to other fields after you have completed an mvp (minimally viable product).\nYou will want to read and re-read the requirements given by your stakeholders to be sure you are meeting all of their needs and representing it in your data, report and model.\nYou will want to do some data validation or QA (quality assurance) to be sure the data you gather is what you think it is.\nYou will want to make sure you are using the best fields to represent square feet of home, number of bedrooms and number of bathrooms. best => the most accurate and available information. You will need to do some data investigation in the database and use your domain expertise to make some judgement calls.\n\nSpecification\nGoals\n\nYour customer is the zillow data science team. state your goals as if you were delivering this to zillow. They have asked for something from you and you are basically communicating in a more concise way, and very clearly, the goals as you understand them and as you have taken and acted upon through your research.\n\nDeliverables\n\nWhat should the zillow team expect to receive from you? Again, as you were communicating to them, not to your instructors.\n\n\n\nA report (in the form of a presentation, both verbal and through a slides)\n\nThe report/presentation slides should summarize your findings about the drivers of the Zestimate error. This will come from the analysis you do during the exploration phase of the pipeline. In the report, you will have charts that visually tell the story of what is driving the errors.\n\n\n\nA github repository containing your jupyter notebook that walks through the pipeline along with the .py files necessary to reproduce your model.\n\nmodel must be reproducible by someone with their own env.py file\n\n\n\nThe Pipeline\nPROJECT PLANNING & README\nBrainstorming ideas, hypotheses, related to how variables might impact or relate to each other, both within independent variables and between the independent variables and dependent variable, and also related to any ideas for new features you may have while first looking at the existing variables and challenge ahead of you.\nHave a detailed README.md file for anyone who wants to check out your project. In this file should be a description of what the project is, and any instructions necessary for someone else to clone your project and run the code on their own laptop.\nACQUIRE:\n\n\nGoal: leave this section with a dataframe ready to prepare.\n\n\nThe ad hoc part includes summarizing your data as you read it in and begin to explore, look at the first few rows, data types, summary stats, column names, shape of the data frame, etc.\n\n\nacquire.py: The reproducible part is the gathering data from SQL.\n\n\nPREP:\n\n\nGoal: leave this section with a dataset that is ready to be analyzed. Data types are appropriate, missing values have been addressed, as have any data integrity issues.\n\n\nThe ad hoc part includes plotting the distributions of individual variables and using those plots to identify outliers and if those should be handled (and if so, how), identify unit scales to identify how to best scale the numeric data, as well as finding erroneous or invalid data that may exist in your dataframe.\n\n\nAdd a data dictionary in your notebook that defines all fields used in either your model or your analysis, and answers the question: why did you use the fields you used, e.g. why did you use bedroom_field1 over bedroom_field2, not why did you use number of bedrooms!\n\n\nprep.py: The reproducible part is the handling of missing values, fixing data integrity issues, changing data types, etc.\n\n\nSPLIT & SCALE:\n\n\nGoal: leave this section with 2 dataframes (train & test) and scaled data\n\n\nsplit_scale.py: split data, scale data (create scaler, fit the scaler to train and transform the train and test using that scaler)\n\n\nDATA EXPLORATION\n\n\nGoal: Address each of the questions you posed in your planning and brainstorming and any others you have come up with along the way through visual or statistical analysis.\n\n\nWhen you have completed this step, you will have the findings from your analysis that will be used in your final report, answers to specific questions your customers has asked, and information to move forward toward building a model.\n\n\nRun at least 1 t-test and 1 correlation test (but as many as you need!)\n\n\nVisualize all combinations of variables in some way(s).\n\n\nWhat independent variables are correlated with the dependent? (this is good)\n\n\nWhich independent variables are correlated with other independent variables? (this is not so good and needs to be addressed)\n\n\nSummarize your takeaways and conclusions.\n\n\nFEATURE SELECTION\n\n\nGoal: leave this section with a dataframe with the features to be used to build your model.\n\n\nAre there new features you could create based on existing features that might be helpful?\n\n\nYou could use feature selection techniques to see if there are any that are not adding value to the model.\n\n\nfeature_selection.py: to run whatever functions need to be run to end with a dataframe that contains the features that will be used to model the data.\n\n\nMODELING & EVALUATION\n\n\nGoal: develop a regression model that performs better than a baseline.\n\n\nYou must evaluate a baseline model, and show how the model you end up with performs better than that.\n\n\nmodel.py: will have the functions to fit, predict and evaluate the model\n\n\nYour notebook will contain various algorithms and/or hyperparameters tried, along with the evaluation code and results, before settling on the final algorithm.\n\n\nBe sure and evaluate your model using the standard techniques: plotting the residuals, computing the evaluation metric (SSE, RMSE, and/or MSE), comparing to baseline, plotting y by y_hat\n\n\n\n""], 'url_profile': 'https://github.com/jiangyipeng718', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020']}","{'location': 'INDIA', 'stats_list': [], 'contributions': '26 contributions\n        in the last year', 'description': ['Linear-Regression\n\n\n\nMean Absolute Error: 4.520425289175486 \nMean Squared Error: 32.35216934989533 \nRoot Mean Squared Error: 5.687896742197007\n'], 'url_profile': 'https://github.com/GaneshKumarKhilji', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020']}","{'location': 'NY/NJ', 'stats_list': [], 'contributions': '35 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/tk33', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/SandaruThilakarathne', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020']}","{'location': 'Pune', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/naimesh-s', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020']}","{'location': 'Ä°zmir,Turkey', 'stats_list': [], 'contributions': '81 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/aycaecemgul', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '38 contributions\n        in the last year', 'description': ['Example linear regression using python libraries.\n'], 'url_profile': 'https://github.com/Aaron9174', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '345 contributions\n        in the last year', 'description': ['LOGISTIC-REGRESSION\n'], 'url_profile': 'https://github.com/NarayanaReddy29', 'info_list': ['Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Updated Aug 24, 2020', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'New Delhi', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gaurab2455', 'info_list': ['Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Updated Aug 24, 2020', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/mmthant03', 'info_list': ['Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Updated Aug 24, 2020', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'Nairobi, Kenya', 'stats_list': [], 'contributions': '47 contributions\n        in the last year', 'description': ['Linear-Regression\n'], 'url_profile': 'https://github.com/dihesus', 'info_list': ['Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Updated Aug 24, 2020', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'Milan, Italy', 'stats_list': [], 'contributions': '47 contributions\n        in the last year', 'description': [""What Makes Cities Attractive for People's Moving, Visiting, or Relocating? A Machine Learning Model.\nCan we predict the number of people visiting a certain city by using Machine Learning Techniques? can we predict the reasons behind that decision? According to the world economic forum, the rise in the number of megacities is the most visible evidence of the accelerating global trend towards urbanization. In 1950, cities were home to 751 million people, less than one-third of the global population. Just two (New York and Tokyo) had more than 10 million inhabitants. Today, 55% of us live in urban areas â€“ thatâ€™s 4.2 billion people. In another generation, that proportion is set to grow to 68%, potentially adding another 2.5 billion people to already crowded cities.\nBut what is it the reason that people seek when moving, visiting, or relocating to another city? Is it a good economy? is it the culture? maybe the social rights, or the crime rates, real estate affordability, LGBT+ rights or even average net salary? The fact is that there are a lot and a lot of factors that people can take into consideration when moving to another city for tourism, business or even to study.\nThrough this Article I will try to produce a prediction model using Python to predict and forecast cities demand and finding the causal effect relationship between different variables. I will be building a dataset from scratch and experimenting some ideas with regression models. This dataset includes official data collected from different sources such as Eurostat, Istat, Statista, World Bank, Government platforms, Teleport, OECD, and Numbeo. The data will be exploring a sample of 42 cities ranked by 13 selected variables.\nThe data will be tested for correlation to measure if those variables have a relationship with the number of people visiting a certain city each year, and to also measure if we can predict the numbers of people visiting a city throughout those variables. We will be measuring how those variables are in relationship with each other. A regression analysis will be implemented, both linear simple regression and multiple linear regression, a prediction model will be produced based on the data and evaluated with different methodologies.\nThe variables we selected to compare against the Visitors yearly numbers are as following: Visitors to locals ratio, Employment, GDP, GDP per capita, Population, Foreign Population, Land area (km2), Medium Size City Center Apartment Rent, AVG Net Salary, Air Quality score, Urban Greenery score, Life Expectancy and number of Startups.\nThe selected cities are all from within the European union, they were chosen due to similar regulation, similar polices and easy travel between them. The selected cities are: Paris, London, Milano, Madrid, Munich, Berlin, Barcelona, Stockholm, Hamburg, Frankfurt, Roma, Amsterdam, Stuttgart, Brussel, Vienna, Dublin, Napoli, Budapest, Lisbon, Oslo, Lyon, Copenhagen, Leeds, Rotterdam, ZÃ¼rich, Helsinki, Manchester, Prague, Antwerp, Porto, Utrecht, Bordeaux, Bilbao, Eindhoven, Basel, Liverpool, GenÃ¨ve, Nice, Firenze, Riga, Vilnius, Tallinn.\nLet's get started.\n""], 'url_profile': 'https://github.com/YasserElsedawy', 'info_list': ['Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Updated Aug 24, 2020', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'San Francisco', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['Linear-Regression-\nR Markdown file containing practice problems in Data Visualization focused on Linear Regression\n'], 'url_profile': 'https://github.com/Chasesinclair1', 'info_list': ['Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Updated Aug 24, 2020', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/DhruvDRE', 'info_list': ['Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Updated Aug 24, 2020', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['NONE'], 'url_profile': 'https://github.com/Intelligent-Systems-Phystech', 'info_list': ['Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Updated Aug 24, 2020', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'Nashik', 'stats_list': [], 'contributions': '71 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Nilayy7', 'info_list': ['Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Updated Aug 24, 2020', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'Warsaw', 'stats_list': [], 'contributions': '102 contributions\n        in the last year', 'description': ['Simple script that creates nonlinear regression model, made in around 1h to help my friend at college.\nFunction that I found, which fits given data set, was f(x)= a*(x-b)**2 + c\nso the point was to optimize parameters a, b, c.\n'], 'url_profile': 'https://github.com/mzakonek', 'info_list': ['Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Updated Aug 24, 2020', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 7, 2020']}"
"{'location': 'Bangalore', 'stats_list': [], 'contributions': '237 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/akash-alt', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'Bangalore,India', 'stats_list': [], 'contributions': '49 contributions\n        in the last year', 'description': ['logistic-regression-\nbasic approach to logistic regression with a dataset and challenges which we face with categorical features , Imbalanced data, Feature encoding.\n'], 'url_profile': 'https://github.com/saibharath2', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '62 contributions\n        in the last year', 'description': ['apartment_regression\nI prefer to use cufflinks/plotly for all of the visualizations instead of matplotlib. Because Github does not show these by default, you can all the full visualizations at:\nhttps://nbviewer.jupyter.org/github/suarez96/apartment_regression/blob/master/apartment.ipynb\n'], 'url_profile': 'https://github.com/suarez96', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '60 contributions\n        in the last year', 'description': [""Linear_regression\nBuild the linear regression model using scikit learn in boston data to predict\n'Price' based on other dependent variable.\n""], 'url_profile': 'https://github.com/MrinalSriv', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '45 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/satyamt13', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '190 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/chetansy', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '54 contributions\n        in the last year', 'description': ['Linear-Regression\nBuilt a simple linear model and predicted y for a given x = 25 and given x = 11. THe columns here are represented as x and y.\n'], 'url_profile': 'https://github.com/Sanjana-Ramankandath', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/qiangha', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Nayanakulkarni09', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}","{'location': 'Istanbul, TURKEY', 'stats_list': [], 'contributions': '102 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/tekinadem', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Nayanakulkarni09', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Python', 'Updated May 3, 2020', 'Updated Apr 7, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'Istanbul, TURKEY', 'stats_list': [], 'contributions': '102 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/tekinadem', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Python', 'Updated May 3, 2020', 'Updated Apr 7, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'New Delhi', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gaurab2455', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Python', 'Updated May 3, 2020', 'Updated Apr 7, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/mmthant03', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Python', 'Updated May 3, 2020', 'Updated Apr 7, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'Nairobi, Kenya', 'stats_list': [], 'contributions': '47 contributions\n        in the last year', 'description': ['Linear-Regression\n'], 'url_profile': 'https://github.com/dihesus', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Python', 'Updated May 3, 2020', 'Updated Apr 7, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'Milan, Italy', 'stats_list': [], 'contributions': '47 contributions\n        in the last year', 'description': [""What Makes Cities Attractive for People's Moving, Visiting, or Relocating? A Machine Learning Model.\nCan we predict the number of people visiting a certain city by using Machine Learning Techniques? can we predict the reasons behind that decision? According to the world economic forum, the rise in the number of megacities is the most visible evidence of the accelerating global trend towards urbanization. In 1950, cities were home to 751 million people, less than one-third of the global population. Just two (New York and Tokyo) had more than 10 million inhabitants. Today, 55% of us live in urban areas â€“ thatâ€™s 4.2 billion people. In another generation, that proportion is set to grow to 68%, potentially adding another 2.5 billion people to already crowded cities.\nBut what is it the reason that people seek when moving, visiting, or relocating to another city? Is it a good economy? is it the culture? maybe the social rights, or the crime rates, real estate affordability, LGBT+ rights or even average net salary? The fact is that there are a lot and a lot of factors that people can take into consideration when moving to another city for tourism, business or even to study.\nThrough this Article I will try to produce a prediction model using Python to predict and forecast cities demand and finding the causal effect relationship between different variables. I will be building a dataset from scratch and experimenting some ideas with regression models. This dataset includes official data collected from different sources such as Eurostat, Istat, Statista, World Bank, Government platforms, Teleport, OECD, and Numbeo. The data will be exploring a sample of 42 cities ranked by 13 selected variables.\nThe data will be tested for correlation to measure if those variables have a relationship with the number of people visiting a certain city each year, and to also measure if we can predict the numbers of people visiting a city throughout those variables. We will be measuring how those variables are in relationship with each other. A regression analysis will be implemented, both linear simple regression and multiple linear regression, a prediction model will be produced based on the data and evaluated with different methodologies.\nThe variables we selected to compare against the Visitors yearly numbers are as following: Visitors to locals ratio, Employment, GDP, GDP per capita, Population, Foreign Population, Land area (km2), Medium Size City Center Apartment Rent, AVG Net Salary, Air Quality score, Urban Greenery score, Life Expectancy and number of Startups.\nThe selected cities are all from within the European union, they were chosen due to similar regulation, similar polices and easy travel between them. The selected cities are: Paris, London, Milano, Madrid, Munich, Berlin, Barcelona, Stockholm, Hamburg, Frankfurt, Roma, Amsterdam, Stuttgart, Brussel, Vienna, Dublin, Napoli, Budapest, Lisbon, Oslo, Lyon, Copenhagen, Leeds, Rotterdam, ZÃ¼rich, Helsinki, Manchester, Prague, Antwerp, Porto, Utrecht, Bordeaux, Bilbao, Eindhoven, Basel, Liverpool, GenÃ¨ve, Nice, Firenze, Riga, Vilnius, Tallinn.\nLet's get started.\n""], 'url_profile': 'https://github.com/YasserElsedawy', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Python', 'Updated May 3, 2020', 'Updated Apr 7, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'Greater Noida, UP', 'stats_list': [], 'contributions': '176 contributions\n        in the last year', 'description': ['Linear-Regression\nIn statistics, linear regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression.\n'], 'url_profile': 'https://github.com/monishamandal02', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Python', 'Updated May 3, 2020', 'Updated Apr 7, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/becky00635', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Python', 'Updated May 3, 2020', 'Updated Apr 7, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'Nashik', 'stats_list': [], 'contributions': '71 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Nilayy7', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Python', 'Updated May 3, 2020', 'Updated Apr 7, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'Lahore, Pakistan', 'stats_list': [], 'contributions': '132 contributions\n        in the last year', 'description': ['Logistic-regression\nThis project uses logistic regression to make some simple predictions on provided advertising data.\n'], 'url_profile': 'https://github.com/jawadSajid', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Oct 21, 2020', 'Python', 'Updated May 3, 2020', 'Updated Apr 7, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}"
"{'location': 'SÃ£o Paulo, Brazil', 'stats_list': [], 'contributions': '133 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/GIZELLYPY', 'info_list': ['Jupyter Notebook', 'Updated Jan 6, 2021', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated Jul 15, 2020', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '22 contributions\n        in the last year', 'description': ['KERAS-regression\nhi , this is a regression model based on few independent parameters like Cement,Blast Furnace Slag ,Fly Ash,Water,Superplasticizer,Coarse Aggregate,Fine Aggregate\ni have tried to calculate the strenghth of the concrete . i have traibed it on 70% of data and validated on rest of the data .the mean square errors of all data has been evaluated with diffreent varying hyperaparameters and conditions\ngo through them .\n'], 'url_profile': 'https://github.com/omkar17MM02001', 'info_list': ['Jupyter Notebook', 'Updated Jan 6, 2021', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated Jul 15, 2020', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '17 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Karolina-Bogacka', 'info_list': ['Jupyter Notebook', 'Updated Jan 6, 2021', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated Jul 15, 2020', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '58 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/avishgos', 'info_list': ['Jupyter Notebook', 'Updated Jan 6, 2021', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated Jul 15, 2020', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '386 contributions\n        in the last year', 'description': ['LogisticRegression\n\nEin Binder-Kompatibles Repository mit einer requirements.txt und runtime.txt Datei.\nSie kÃ¶nnen auch unter der folgenden Binder-URL dieses Notebook erzeugen:\nhttps://mybinder.org/v2/gh/Soley02/LogisticRegression/HEAD\nAusfÃ¼hrung:\nFÃ¼r die AufÃ¼hrung durch MyBinder, wurden die hier enthalten Dateien verwendet.\nDie Daten welches in den ML-Beispielen verwendet wurden, sind ebenfalls direkt abrufbar im Code und mÃ¼ssen nicht zusÃ¤tzlich heruntergeladen werden.\n\nSchritt: Auf Badge von MyBinder klicken oder per LINK\nSchritt: Warten bis alle erforderlichen Pakete/Module durch MyBinder hinzugefÃ¼gt sind\nSchritt: MyBinder wurde erfolgreich durchgefÃ¼hrt und Jyupter Notebook (Nbviewer) Ã¶ffnet sich\nSchritt: Beides der Programme konnten ausgefÃ¼hrt werden (Logistische_Regression.ipynb & Logistische_Regression_2.ipynb)\n\nNotes\nDie requirements.txt Datei listet alle Python-Bibliotheken auf, die fÃ¼r dieses Notebook erforderlich sind. Diese werden automatisch installiert:\npip install -r requirements.txt\n\nIn diesem Beispiel enthaltenen Bibliotheken sind:\n\npandas = 1.0.1\nnumpy = 1.18.1\nmatplotlib = 3.1.3\nseaborn = 0.11.1\nscikit-learn = 0.24.1\n\n'], 'url_profile': 'https://github.com/Soley02', 'info_list': ['Jupyter Notebook', 'Updated Jan 6, 2021', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated Jul 15, 2020', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gordongogah', 'info_list': ['Jupyter Notebook', 'Updated Jan 6, 2021', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated Jul 15, 2020', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/indigow', 'info_list': ['Jupyter Notebook', 'Updated Jan 6, 2021', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated Jul 15, 2020', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'Nairobi-Kenya', 'stats_list': [], 'contributions': '554 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/abel-keya', 'info_list': ['Jupyter Notebook', 'Updated Jan 6, 2021', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated Jul 15, 2020', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '144 contributions\n        in the last year', 'description': ['Logistic-Regression\n'], 'url_profile': 'https://github.com/i1idan', 'info_list': ['Jupyter Notebook', 'Updated Jan 6, 2021', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated Jul 15, 2020', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '28 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/samiBEN91', 'info_list': ['Jupyter Notebook', 'Updated Jan 6, 2021', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated Jul 15, 2020', 'Jupyter Notebook', 'Updated Feb 24, 2021', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '28 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/kevin-moe', 'info_list': ['Python', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', 'R', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'R', 'Updated May 11, 2020', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '345 contributions\n        in the last year', 'description': ['LINEAR-REGRESSION\n'], 'url_profile': 'https://github.com/NarayanaReddy29', 'info_list': ['Python', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', 'R', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'R', 'Updated May 11, 2020', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/KimMooGyeong', 'info_list': ['Python', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', 'R', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'R', 'Updated May 11, 2020', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '30 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/mad-farmer', 'info_list': ['Python', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', 'R', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'R', 'Updated May 11, 2020', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '10 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/zxs1900', 'info_list': ['Python', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', 'R', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'R', 'Updated May 11, 2020', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020']}","{'location': 'Portland, OR', 'stats_list': [], 'contributions': '78 contributions\n        in the last year', 'description': ['linear_regression\nsimple js linear regression model, following D Shiffman https://youtu.be/_cXuvTQl090\n'], 'url_profile': 'https://github.com/moleculesynth', 'info_list': ['Python', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', 'R', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'R', 'Updated May 11, 2020', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020']}","{'location': 'Hyderabad', 'stats_list': [], 'contributions': '62 contributions\n        in the last year', 'description': ['Logistic-Regression\nIt is an advertising data wherein the data comprises of the time spent by the customer on particular website, data usage, so on and so forth. It is known whether the particular customer clicks on an add or not is predicted for the best possible outcome.\n'], 'url_profile': 'https://github.com/Sandhya1825', 'info_list': ['Python', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', 'R', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'R', 'Updated May 11, 2020', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '108 contributions\n        in the last year', 'description': ['multilinear-regression\nReal State Price\n'], 'url_profile': 'https://github.com/ADITEYARAJ', 'info_list': ['Python', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', 'R', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'R', 'Updated May 11, 2020', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Niharika2020', 'info_list': ['Python', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', 'R', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'R', 'Updated May 11, 2020', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020']}","{'location': 'New Jersey, USA', 'stats_list': [], 'contributions': '23 contributions\n        in the last year', 'description': ['linearRegression\n'], 'url_profile': 'https://github.com/dagarwal98', 'info_list': ['Python', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 10, 2020', 'R', 'Updated Apr 11, 2020', 'JavaScript', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'R', 'Updated May 11, 2020', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '60 contributions\n        in the last year', 'description': ['Logistic_regression\nI decided to treat this as a classification problem by creating a new binary variable affair (did the woman have at least one affair?)\nand trying to predict the classification for each woman. Dataset The dataset I chose is the affairs dataset that comes with Statsmodels. It was derived from a survey of women in 1974 by Redbook magazine, in which married women were asked about their participation in extramarital affairs. More information about the study is available in a 1978 paper from the Journal of Political Economy.  The dataset contains 6366 observations of 9 variables: rate_marriage: woman\'s rating of her marriage (1 = very poor, 5 = very good) age: woman\'s age yrs_married: number of years married children: number of children religious: woman\'s rating of how religious she is (1 = not religious, 4 = strongly religious) educ: level of education (9 = grade school, 12 = high school, 14 = some college, 16 = college graduate, 17 = some graduate school, 20 = advanced degree)  occupation: woman\'s occupation (1 = student, 2 = farming/semi- skilled/unskilled, 3 = ""white collar"", 4 =  teacher/nurse/writer/technician/skilled, 5 = managerial/business, 6 = professional with advanced degree) occupation_husb: husband\'s occupation (same coding as above) affairs: time spent in extra-marital affairs\n'], 'url_profile': 'https://github.com/MrinalSriv', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Feb 11, 2021', 'Python', 'Updated Apr 7, 2020', '3', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'HTML', 'CC0-1.0 license', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '265 contributions\n        in the last year', 'description': ['What is Linear Regression\nLinear regression is a statistical model that inspects the linear relationships\nbetween a (y) dependent variable and one or more (x1,x2,xN) independent variables.\nPredictive Analysis two things, Predicts variable do a good job in predicting a dependent\nvariable and which variable in particular are significant predictors of the outcome variable? \nFormula\nThe Simpliest form of the regression equation is y = a + b*x \ny = dependent variable \nx = independet varaible \nb = regression cofefficient \na = constant\n \n \nDirections\n\nPlot the data with y as the output and x as the input And Plot \n \nFit a linear regression model to this data. \n \nPredict the value for y when x is 10. \n[8.03] \nPredict the value for y when x is 20. \n[19.96] \nWould you want to use this regession model, when it only has N = 97 dependents or number of data length?\nWhy ore why not? \nNO, 97 is not enough data. \nLinear regression needs a lot of training data so that it can fit the data correctly, \navoiding under-fitting as well as over-fitting\n\n'], 'url_profile': 'https://github.com/TheErrorMaster', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Feb 11, 2021', 'Python', 'Updated Apr 7, 2020', '3', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'HTML', 'CC0-1.0 license', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '42 contributions\n        in the last year', 'description': ['logistic_regression\n'], 'url_profile': 'https://github.com/mahdinezhadasad', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Feb 11, 2021', 'Python', 'Updated Apr 7, 2020', '3', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'HTML', 'CC0-1.0 license', 'Updated Apr 8, 2020']}","{'location': 'Shanghai, China', 'stats_list': [], 'contributions': '112 contributions\n        in the last year', 'description': ['Crack_Regression\n1ã€crackdata.csvåŒ…å«50000ä¸ªé’¢ç­‹æ··å‡åœŸè£‚ç¼è®¡ç®—çš„æ•°æ®ï¼›\n2ã€ä½¿ç”¨Pytorchã€TensorFlowã€MXNetåˆ†åˆ«å¯¹åŒä¸€ä»½æ•°æ®æ–‡ä»¶è¿›è¡Œå›žå½’ï¼›\n3ã€ä½¿ç”¨è‡ªå®šä¹‰çš„ç¥žç»ç½‘ç»œï¼ŒåŒ…æ‹¬æ­£å‘ä¼ æ’­å’Œæ¢¯åº¦åä¼ è¿›è¡Œå›žå½’ï¼›\n4ã€ä½¿ç”¨sklearnçš„PCAå¯¹æ•°æ®è¿›è¡Œé™ç»´åˆ†æžï¼›\n5ã€ä½¿ç”¨sklearnçš„SVMã€LogisticRegressionå¯¹æ•°æ®è¿›è¡Œåˆ†ç±»ï¼›\n'], 'url_profile': 'https://github.com/Qingyan1218', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Feb 11, 2021', 'Python', 'Updated Apr 7, 2020', '3', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'HTML', 'CC0-1.0 license', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/chunshou-Liu', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Feb 11, 2021', 'Python', 'Updated Apr 7, 2020', '3', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'HTML', 'CC0-1.0 license', 'Updated Apr 8, 2020']}","{'location': 'Lokoja, Kogi state', 'stats_list': [], 'contributions': '39 contributions\n        in the last year', 'description': ['A-Logistic-Regression-Model-for-Predicting-the-Propensity-of-Term-Deposit-Purchases-in-a-Bank\n'], 'url_profile': 'https://github.com/Abdulsamod1', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Feb 11, 2021', 'Python', 'Updated Apr 7, 2020', '3', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'HTML', 'CC0-1.0 license', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '61 contributions\n        in the last year', 'description': ['logistic_regression_mini_project\n'], 'url_profile': 'https://github.com/jordanstrassner', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Feb 11, 2021', 'Python', 'Updated Apr 7, 2020', '3', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'HTML', 'CC0-1.0 license', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '28 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/samiBEN91', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Feb 11, 2021', 'Python', 'Updated Apr 7, 2020', '3', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'HTML', 'CC0-1.0 license', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '23 contributions\n        in the last year', 'description': ['SimpleMultilinearRegressionPy\nDockerized simple multilinear regression.\nDependencies:\n\nnumpy\nmatplotlib\n\nRun using docker-compose up, after execution two image files will be generated with the resulting plot.\n'], 'url_profile': 'https://github.com/dgutierrez1', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Feb 11, 2021', 'Python', 'Updated Apr 7, 2020', '3', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'HTML', 'CC0-1.0 license', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['linear-regression-practice\nPractice Session for Data Science Practicum 1 Students (UP FAMNIT)\n'], 'url_profile': 'https://github.com/burnardm', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Feb 11, 2021', 'Python', 'Updated Apr 7, 2020', '3', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'HTML', 'CC0-1.0 license', 'Updated Apr 8, 2020']}"
"{'location': 'India', 'stats_list': [], 'contributions': '208 contributions\n        in the last year', 'description': ['Linear-Regression-project\nThis repository contains my solution of Linear-Regression-project(Provided by Udemy in its course Python for Data Science)\n'], 'url_profile': 'https://github.com/dharma610', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 24, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020']}","{'location': 'Assam', 'stats_list': [], 'contributions': '87 contributions\n        in the last year', 'description': ['Linear-Regression\nIn simple linear regression, we predict scores on one variable from the scores on a second variable. The variable we are predicting is called the criterion variable and is referred to as Y. The variable we are basing our predictions on is called the predictor variable and is referred to as X. When there is only one predictor variable, the prediction method is called simple regression. In simple linear regression, the topic of this section, the predictions of Y when plotted as a function of X form a straight line.\n'], 'url_profile': 'https://github.com/rajansahu713', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 24, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '383 contributions\n        in the last year', 'description': ['Multi-linear-regression\n'], 'url_profile': 'https://github.com/priyanshu-data', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 24, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020']}","{'location': 'Udaipur', 'stats_list': [], 'contributions': '57 contributions\n        in the last year', 'description': ['Machine-Learning-Notes_REgression\nBrief PDF notes of Machine Learning\n'], 'url_profile': 'https://github.com/kaustavmitra26', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 24, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020']}","{'location': 'Lahore, Pakistan', 'stats_list': [], 'contributions': '132 contributions\n        in the last year', 'description': ['PySpark-Linear-Regression\nThis project uses an Ecommerce customers dataset to predict yearly spent amount using linear regression from PySpark MLlib.\n'], 'url_profile': 'https://github.com/jawadSajid', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 24, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020']}","{'location': 'Dhaka, Bangladesh', 'stats_list': [], 'contributions': '156 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/MasumBhuiyan', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 24, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': ['Regression_lineaire_Equipe3\n'], 'url_profile': 'https://github.com/Larko1992', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 24, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['Machine-Learning-Logistic-Regression\nIt consist of basic iplementation of Logistic Regression using sklearn library.\nI have implemented Logistic regression to predict whether a person will buy an insurance policy or not.\n###############\nLogistic Regression - It is a one of the techniques used to solve the classification problems.\nFor example,\nTo predict whether an email is spam (1) or (0)\nWhether the tumor is malignant (1) or not (0)\n'], 'url_profile': 'https://github.com/kishluv782', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 24, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020']}","{'location': 'Thailand', 'stats_list': [], 'contributions': '35 contributions\n        in the last year', 'description': ['Logistics-Regression-Model (Telco case)\n'], 'url_profile': 'https://github.com/Chanon-aumrung', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 24, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020']}","{'location': 'Malabe, Sri Lanka', 'stats_list': [], 'contributions': '136 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/lakmalrupasinghe', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 24, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '40 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/itsme020', 'info_list': ['R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'Porto Alegre/RS', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': ['Linear-Regression-Correlation\nEstudo sobre regressÃ£o linear e correlaÃ§Ã£o utilizando Python\nArquivos:\n20200409-CASOS.xlsx                       - Listagem de casos novos por dia\n20200409-CASOS-RL30dias.xlsx              - Resultado da RegressÃ£o Linear, arquivo base com 28 dias, foi adicionado 2 dias de casos novos\n20200409-CASOSb.xlsx                      - Retirados valores muito baixos, para aumentar a eficiÃªncia do cÃ¡lculo da regressÃ£o\n20200409-OBITOS.xlsx                      - Listagem de obitos novos por dia\nCorrelaÃ§Ã£o Pearson.ipynb                  - Arquivo para fazer correlaÃ§Ãµes\nRL dia 09 COVID19.ipynb                   - Arquivo da regressÃ£o linear (atualizado dia 09/04/2020\nRL COVID19 - Brazil - 20200409.png        - Plotagem da correlaÃ§Ã£o e da linha de linear\nRL COVID19b - Brazil - 20200409.png       - Plotagem da correlaÃ§Ã£o e da linha de linear, arquivo base CASOSb\n'], 'url_profile': 'https://github.com/lucaslimafernandes', 'info_list': ['R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/arjundinakar', 'info_list': ['R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/venkatarajesh59', 'info_list': ['R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': ['Muliple-Linear-Regression\nUsing Backward selection and iteration model\nwe should follow the below fundamental checks for rely on model:\n      1. Everything IN\n      2. Stepwise process:\n        a) Backward Selection\n        b) Forward Selection\n        c)Bi-Direction\n      3. Score Check\n\n\n\nEverything IN:\nIt is like of garbage in garbage out. What are variable you are giving to that project it will give the output like that.\nIf youâ€™re giving an unrelevent data in your project it consume more time and accuracy never good than we are excepted.\n\n\nBackward selection:\nIn this section I going explain of backward selection and their rules.\n      1.\tSet a significance level may 5% or 1%\n      2.\tBuild a model with the all independent variables\n      3.\tCheck your p values and take highest level of p value in your model :\n               If p|>SL \uf0e0 Reject or eliminate that column and iterate start without that variable\n              4.contiune the step 3 until we are satisfy the rule\n\n   Based on the Backward selection we can able to rely on our model, we are going in a right way.\n\n\n\n3.Score :\nFinally check the score, each iteration we can able to see how much of our model tuning and score increasing when eliminate unrelevant variable.\n'], 'url_profile': 'https://github.com/chitra1308', 'info_list': ['R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['Decision-Tree-Regression\n'], 'url_profile': 'https://github.com/Yazdwivedi', 'info_list': ['R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '64 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/kraumar', 'info_list': ['R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'Hyderabad', 'stats_list': [], 'contributions': '86 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/sriramaraju423', 'info_list': ['R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'Vancouver, Canada', 'stats_list': [], 'contributions': '118 contributions\n        in the last year', 'description': ['Bayesian statistics Analysis Projects\nProjects:\n\nSunspot count\nSleep and awake pattern\nUnderstanding of multitonial and Dirichlet project using Zoo visit data\nStudent grades data from UCI ML repository. The objective is to predict the final grade from the student information which makes this a supervised, regression task.\nKaggle Diabetes dataset. Objective: Given a set of eight medical characteristics about a patients, predict whether or not the patient has diabetes. We compared the performance of standard ML algorithms with bayesian statistics.\n\nReports\n\nDetailed report on Frequentist vs Bayesian analsis\n\nScikitlearn pointer\nsklearn.linear_model.LogisticRegression vs sklearn.linear_model.LogisticRegressionCV\nWhile the instance of the first class just trains logistic regression on provided data. The instance of the second class divides the Train dataset into different Train/Validation Set combinations before training and helps test the model is good across different splits of data. The process is called K-Fold Cross Validation (thatâ€™s where CV comes from) and is a very frequently used method in Machine Learning practice.\n'], 'url_profile': 'https://github.com/sidhant-guliani', 'info_list': ['R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '12 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/abhishekbenjamin', 'info_list': ['R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'R', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '186 contributions\n        in the last year', 'description': [""Multiple-Regression---BHBA-NEFA\nBHBA Multiple Regression\nBelow is our first model of multiple regression with all significant predictors associated with BHBA. After running this first model, we used backward step elimination, eliminating the least significant predictor and re-running the model.\nBHBA Multiple Regression - First Model\n Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']\n Family: binomial  ( logit )\n Formula: BS.BHBA.1.2 ~ MS.DIM + CE.Fat.Level + MS.Lactose + MS.Acetone.Log \n + MS.Urea + MS.pH + Cow.Breed + CE.Lame + \n BS.NEFA.0.7 + FPR.1.4 + (1 | CowID) \n Data: sub5_ncf_BHB\n\n AIC      BIC   logLik deviance df.resid \n 450.5    501.4   -213.2    426.5      502 \n\n Scaled residuals: \nMin      1Q  Median      3Q     Max \n -2.4340 -0.0409 -0.0154 -0.0010  9.0011 \n\n Random effects:\n Groups Name        Variance Std.Dev.\n CowID  (Intercept) 72.5     8.515   \n Number of obs: 514, groups:  CowID, 325\n\n Fixed effects:\n                Estimate Std. Error z value Pr(>|z|)    \n (Intercept)     -7.4959     1.2075  -6.208 5.38e-10 ***\n MS.DIM           0.4782     0.3318   1.441   0.1495    \n CE.Fat.Level     0.1830     0.3928   0.466   0.6413    \n MS.Lactose      -0.5264     0.3793  -1.388   0.1652    \n MS.Acetone.Log   2.7647     0.5829   4.743 2.11e-06 ***\n MS.Urea          0.8043     0.4246   1.894   0.0582 .  \n MS.pH            0.7343     0.4849   1.514   0.1299    \n Cow.Breed02      2.7410     1.1801   2.323   0.0202 *  \n CE.Lame1        -0.7902     1.0990  -0.719   0.4721    \n BS.NEFA.0.71     0.3421     0.7559   0.453   0.6508    \n FPR.1.41         0.4604     0.7024   0.655   0.5122    \n ---\n Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nBHBA Multiple Regression - Final Model\n Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']\n Family: binomial  ( logit )\n Formula: BS.BHBA.1.2 ~ MS.Acetone.Log + Cow.Breed + (1 | CowID)\n Data: sub5_ncf_BHB\n\n   AIC      BIC   logLik deviance df.resid \n 455.8    472.8   -223.9    447.8      517 \n\n Scaled residuals: \n   Min      1Q  Median      3Q     Max \n -2.2490 -0.0442 -0.0176 -0.0010  6.0287 \n\n Random effects:\n Groups Name        Variance Std.Dev.\n CowID  (Intercept) 73.23    8.558   \n Number of obs: 521, groups:  CowID, 328\n\n Fixed effects:\n               Estimate Std. Error z value Pr(>|z|)    \n (Intercept)     -7.4096     1.1279  -6.569 5.05e-11 ***\n MS.Acetone.Log   2.7440     0.5014   5.472 4.45e-08 ***\n Cow.Breed02      2.9418     1.1095   2.651  0.00801 ** \n ---\n Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nAfter the addition of Fatty Acids, we found that no Fatty Acids were significant predictors. Therefore, our final model was determined without the addition of Fatty Acids.\nBHBA Odds Ratio's, Confidence Intervals, and Effect Plots\n                     OR        2.5 %       97.5 %\n (Intercept)    1.554846e+01 6.289893e-05 6.431509e-03\n MS.Acetone.Log 1.894910e+01 6.394550e+00 4.633322e+01\n Cow.Breed02    6.054013e-04 2.177258e+00 1.928642e+02\n\n\nNEFA Multiple Regression\nBelow is our first model of multiple regression with all significant predictors associated with NEFA. After running this first model, we used backward step elimination, eliminating the least significant predictor and re-running the model.\nNEFA Multiple Regression - First Model\n Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']\n Family: binomial  ( logit )\n Formula: BS.NEFA.0.7 ~ BS.MS.Date.Difference + MS.DIM + FPR.1.4 + MS.Acetone.Log +  \n CE.Fat.Level + MS.pH + Cow.Breed + BS.Month_warm + CE.Stom.Layering +      \n BS.BHBA.1.2 + CE.Lame + (1 | CowID:Farm.No)\n Data: sub4nc_FA\n\n AIC      BIC   logLik deviance df.resid \n 481.4    536.5   -227.7    455.4      499 \n\n Scaled residuals: \n    Min      1Q  Median      3Q     Max \n -3.0227 -0.3775 -0.2382  0.2557  6.2066 \n\n Random effects:\n Groups        Name        Variance Std.Dev.\n CowID:Farm.No (Intercept) 1.656    1.287   \n Number of obs: 512, groups:  CowID:Farm.No, 325\n\n Fixed effects:\n                  Estimate Std. Error z value Pr(>|z|)    \n (Intercept)           -1.10638    0.72661  -1.523  0.12784    \n BS.MS.Date.Difference -0.18253    0.15177  -1.203  0.22910    \n MS.DIM                -0.23846    0.15037  -1.586  0.11278    \n FPR.1.41               0.97354    0.31976   3.045  0.00233 ** \n MS.Acetone.Log         0.80585    0.21261   3.790  0.00015 ***\n CE.Fat.Level           0.47353    0.16756   2.826  0.00471 ** \n MS.pH                  0.01278    0.15331   0.083  0.93356    \n Cow.Breed02           -0.52252    0.44761  -1.167  0.24307    \n BS.Month_warm1         0.24806    0.31733   0.782  0.43438    \n CE.Stom.Layering1     -1.43661    0.72308  -1.987  0.04695 *  \n BS.BHBA.1.21           0.39613    0.36784   1.077  0.28153    \n CE.Lame1               0.44875    0.42605   1.053  0.29221    \n ---\n Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nNEFA Multiple Regression - Final Model\n Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']\n Family: binomial  ( logit )\n Formula: BS.NEFA.0.7 ~ FPR.1.4 + MS.Acetone.Log + CE.Fat.Level + (1 |CowID:Farm.No)\n Data: sub4nc_FA\n\n  AIC      BIC   logLik deviance df.resid \n 476.8    498.0   -233.4    466.8      509 \n\n Scaled residuals: \n    Min      1Q  Median      3Q     Max \n -2.6028 -0.3849 -0.2465  0.2621  5.4450 \n\n Random effects:\n Groups        Name        Variance Std.Dev.\n CowID:Farm.No (Intercept) 1.764    1.328   \n Number of obs: 514, groups:  CowID:Farm.No, 325\n\n Fixed effects:\n                Estimate Std. Error z value Pr(>|z|)    \n (Intercept)     -2.3067     0.3324  -6.939 3.96e-12 ***\n FPR.1.41         0.9202     0.3060   3.007  0.00264 ** \n MS.Acetone.Log   1.0369     0.2022   5.129 2.92e-07 ***\n CE.Fat.Level     0.5509     0.1648   3.342  0.00083 ***\n ---\n Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nNEFA Multiple Regression - Addition of Fatty Acid\nAfter finding a final model without the addition of fatty acids with NEFA, we added in individual fatty acids to the model and included the fatty acid that produced the best fit, which was Oleic acid. After the addition of Oleic acid, we once again did backward step elimination.\nNEFA Multiple Regression - First Model with Fatty Acid\n Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']\n Family: binomial  ( logit )\n Formula: BS.NEFA.0.7 ~ FPR.1.4 + MS.Acetone.Log + CE.Fat.Level + MS.Oleic +      (1 | CowID:Farm.No)\n Data: sub4nc_FA\n\n  AIC      BIC   logLik deviance df.resid \n 371.5    395.2   -179.7    359.5      379 \n\n Scaled residuals: \n   Min      1Q  Median      3Q     Max \n -3.9578 -0.3920 -0.2446  0.3269  2.4875 \n\n Random effects:\n Groups        Name        Variance Std.Dev.\n CowID:Farm.No (Intercept) 1.713    1.309   \n Number of obs: 385, groups:  CowID:Farm.No, 236\n\n Fixed effects:\n                Estimate Std. Error z value Pr(>|z|)    \n (Intercept)     -1.4907     0.3524  -4.230 2.34e-05 ***\n FPR.1.41        -0.5320     0.4750  -1.120 0.262715    \n MS.Acetone.Log   0.3415     0.2569   1.329 0.183761    \n CE.Fat.Level     0.3785     0.1842   2.054 0.039930 *  \n MS.Oleic         1.3971     0.3634   3.844 0.000121 ***\n ---\n Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nNEFA Multiple Regression - Final Model with Fatty Acid\n Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']\n Family: binomial  ( logit )\n Formula: BS.NEFA.0.7 ~ MS.Acetone.Log + CE.Fat.Level + MS.Oleic + (1 |CowID:Farm.No)\n Data: sub4nc_FA\n\n  AIC      BIC   logLik deviance df.resid \n 370.8    390.5   -180.4    360.8      380 \n\n Scaled residuals: \n   Min      1Q  Median      3Q     Max \n -3.2997 -0.4031 -0.2443  0.3630  2.5982 \n\n Random effects:\n Groups        Name        Variance Std.Dev.\n CowID:Farm.No (Intercept) 1.635    1.279   \n Number of obs: 385, groups:  CowID:Farm.No, 236\n\n Fixed effects:\n           Estimate Std. Error z value Pr(>|z|)    \n (Intercept)     -1.7137     0.3056  -5.608 2.04e-08 ***\n MS.Acetone.Log   0.3827     0.2509   1.525   0.1272    \n CE.Fat.Level     0.3917     0.1822   2.149   0.0316 *  \n MS.Oleic         1.1521     0.2719   4.237 2.26e-05 ***\n ---\n Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n\nNEFA Odds Ratio's, Confidence Intervals, and Effect Plots\n                     OR      2.5 %     97.5 %\n (Intercept)    1.4661651 0.07943635  0.2954894\n MS.Acetone.Log 1.4795185 0.90416028  2.4831767\n CE.Fat.Level   3.1647980 1.04739544  2.1979837\n MS.Oleic       0.1801901 1.96843685  6.0445656\n\n\n""], 'url_profile': 'https://github.com/Alec-Sawalski', 'info_list': ['Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 12, 2020', 'MATLAB', 'Updated Jun 29, 2020', 'JavaScript', 'Updated May 7, 2020', 'Jupyter Notebook', 'Updated Feb 28, 2021', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 12, 2020']}","{'location': 'Bhubaneswar', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': ['Linear Regression With Sales Prediction Project\nVideo Link Of Complete Project https://youtu.be/ZPPiZvvpU6s\nLinear Regression is a machine learning algorithm based on supervised learning. It performs a regression task. Regression models a target prediction value based on independent variables. It is mostly used for finding out the relationship between variables and forecasting.\nIt performs the task to predict a dependent variable value (y) based on a given independent variable (x). So, this regression technique finds out a linear relationship between x (input) and y(output).\nThe simplest form of a simple linear regression equation with one dependent and one independent variable is represented by:\n\nSimilarly for multiple variable\n\n\nProject\n\nLetâ€™s consider a problem statement, a company wants to increase its sells to a certain amount. Now the challenge is to find the amount of investment on advertisement that will result the gain in sells.\nTo solve this problem we have to get the history of the investment and the sales value and prepair our dataset.\nNext we have to create a Logistic Regression model and fit the dataset with the model. After testing if we get that model is working fine then we will save the model for future use.\nFinally we have to integrate the model with a GUI, in this project we will create a tkinter GUI.\nCode Link:\nLinear_regression: simple_and_multiple_linear_regression.ipynb\nGUI Integration : integrating_model_with_gui.ipynb\nHope you have enjoyed learning this, if so share this with others and for more such contents you can connect with me on\nYouTube: https://www.youtube.com/channel/UCmF8qppe02J1ot4Jfwl_lFg\nLinkedIn: https://www.linkedin.com/in/jagwithyou/\nMedium: https://medium.com/@jagwithyou\n'], 'url_profile': 'https://github.com/jagwithyou', 'info_list': ['Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 12, 2020', 'MATLAB', 'Updated Jun 29, 2020', 'JavaScript', 'Updated May 7, 2020', 'Jupyter Notebook', 'Updated Feb 28, 2021', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '49 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/kelvin1338', 'info_list': ['Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 12, 2020', 'MATLAB', 'Updated Jun 29, 2020', 'JavaScript', 'Updated May 7, 2020', 'Jupyter Notebook', 'Updated Feb 28, 2021', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '41 contributions\n        in the last year', 'description': ['Prevendo a nota do ENEM 2016 de matemÃ¡tica - Machine Learning\nCriaÃ§Ã£o de um modelo preditivo de Machine Learnig para prever a nota de matemÃ¡tica do ENEM 2016.\nEsse foi um desafio que participei da Codenation para o programa de acleradev em Data Science no qual obtive um score de 93,2%\n1 - Primeiro passo\nPara elaboraÃ§Ã£o desse modelo foi utilizado algumas bibliotecas, para maior facilidade indico baixar o anaconda no qual jÃ¡ tem todas essas bibliotecas.\n2 - O que foi fornecido  e pedido pela Codenation\n\nfoi fornecido 2 arquivos um train.csv e test.csv\nEste arquivo, e apenas ele, deve ser utilizado para todos os desafios\nNo arquivo test.csv crie um modelo para prever nota da prova de matemÃ¡tica (coluna NU_NOTA_MT) de quem participou do ENEM 2016.\nSalve sua resposta em um arquivo chamado answer.csv com duas colunas: NU_INSCRICAO e NU_NOTA_MT.\n\n'], 'url_profile': 'https://github.com/dannirodrigues', 'info_list': ['Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 12, 2020', 'MATLAB', 'Updated Jun 29, 2020', 'JavaScript', 'Updated May 7, 2020', 'Jupyter Notebook', 'Updated Feb 28, 2021', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 12, 2020']}","{'location': 'Milwaukee', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': [""Regression_Stock_Scan\n(My first Python project) Web scrape stock data and run statistical analysis\nCurrently this project needs to be updated to work with a change in the Yahoo finance website. The code will fail to scrape the financials page from the website and fail.\nI want to describe the project I recently completed. I used Python to web-scrape a great deal of financial data from the stock market to perform a statistical analysis of stocks I will consider adding to my personal investment portfolio. My Python program scans and filters hundreds of thousands of rows of data, assigns a weighted score system, and returns to me with the top 20 stocks. The score system is predominantly a modified linear regression slope of the last 90 days of closing prices. I will briefly describe what I did.\nTo start I scan over 20,000 stocks on GuruFocus.com to gather all stocks between $15 and $100. Because I do not have that much money in my portfolio, I try to diversify as best I can by having low cost stocks.\nI then take each stock to Yahoo Finance and plug the ticker into its server. Many of the securities on GuruFocus are not exactly 'real' and have little to no information on Yahoo Finance, so I remove these from my data frame.\nNext, I take the filtered stocks and I collect price information on each stock from Yahoo Finance. I collect 90 days of open prices, close prices, the daily high, low, and the volume. In total I have over 284,000 rows of stock data in my data frame at this point. I keep my data temporarily stored in a pipe-delimited CSV file as I move from function to function in my Python script. That way if my code stops or has an issue getting a response from a server I can pick back up where I left off after re-starting my code.\nThen I perform another level of screening. Using the data I collected on volumes, I find the mean volume and standard deviation for each of the stocks over the 90 day period. I find the Z-score of every stock and I filter-out any stock with a Z-score below a certain threshold (I keep tweaking it to get the best results).\nNow that I've performed my last filtration I begin a new statistical analysis to assign my scores. At this point I have well over 50,000 stocks to look at. I get the linear regression slope of the last 90 days' closing prices. A relatively 'high' slope will mean the price has been trending upward the last 90 days. I tend to go with short-term trading as my personal investing strategy, so I only look at the recent past, then I will buy a stock with the intention to hold it for a few weeks at a minimum before I sell it.\nI modify the linear regression slope by multiplying it by the r-squared value. The r-squared value is the correlation coefficient squared, which basically tells how well data points fit a regression line. The correlation coefficient and r-squared will help tell if the regression line has any explanatory power. Because the r-squared value has a maximum of one, when I multiply the slope by the r-squared value I effectively discount the slope of any regression lines with little explanatory power (if the r-squared value is miraculously 1 then the slope is maintained after being multiplied by 1). Thus I modify the slope to give lower scores to stocks with data that doesn't trend well.\nMy weighted score system is heavily focused on the modified regression slope. The modified slope is 85% of the score. The remaining 15% is a modified average revenue change over the past four years of the publicly traded company. What I do is get the year to year change in revenue over four years and average the change. I modify this value to smooth out the radical shifts in some companies' revenue and I discount any company that has less than four years of revenue history. Without getting into too much detail, I basically discount any radical upward swings in revenue. If a company's revenue fell by 90% then the absolute number of this change is .9. There are some companies who can more than triple, quadruple, and multiply one years revenue the next year by great numbers. So the maximum fall in revenue is -1, but the rise can be times 10 or even more. This distorts an averaging formula so I take steps to smooth it out.\n""], 'url_profile': 'https://github.com/MillerB20', 'info_list': ['Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 12, 2020', 'MATLAB', 'Updated Jun 29, 2020', 'JavaScript', 'Updated May 7, 2020', 'Jupyter Notebook', 'Updated Feb 28, 2021', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['Regularized Regression Coresets\nThis project contains the code for the experiments performed in the paper ""On Coresets For Regularized Regression"" by Rachit Chhaya, Supratim Shit and Anirban Dasgupta accepted at ICML 2020. Here is the link to the arxiv version: https://arxiv.org/abs/2006.05440.\nThere are 3 files containing matlab code for the experiments.\nRLAD_icml.m contains the code for the Regularized Least Absolute Deviation problem on synthetic data. The modifiedlasso_icml.m contains the code for modified lasso experiments and also for the sparsity checking experiment of the modified lasso. Finally the modified lasso experiments on real data are done usibg the code modlassoreal data.m .\nWe used the following real data:\nhttps://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant .\nAll the files have comments that explain the variables and also what small changes to make to run the codes. We have provided code that will generate new synthetic data at every run. However you should save the data once generated as .mat file and then use it repeatedly.\n'], 'url_profile': 'https://github.com/RachitChhaya', 'info_list': ['Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 12, 2020', 'MATLAB', 'Updated Jun 29, 2020', 'JavaScript', 'Updated May 7, 2020', 'Jupyter Notebook', 'Updated Feb 28, 2021', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 12, 2020']}","{'location': 'Nanjing/Harbin', 'stats_list': [], 'contributions': '159 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/QRXqrx', 'info_list': ['Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 12, 2020', 'MATLAB', 'Updated Jun 29, 2020', 'JavaScript', 'Updated May 7, 2020', 'Jupyter Notebook', 'Updated Feb 28, 2021', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '339 contributions\n        in the last year', 'description': [""Machine_Learning\nStep by step process to learn machine learning in Python.\n    Regression is a machine learning method based on supervised learning. It performs a regression task. Regression models a target prediction value based on independent variables.Linear regression performs the task to predict a dependent variable value (y) based on a given independent variable (x). So, this regression technique finds out a linear relationship between x (input) and y(output). \n     The equation has the form Y= a + bX, where Y is the dependent variable (that's the variable that goes on the Y axis), X is the independent variable (i.e. it is plotted on the X axis), b is the slope of the line and a is the y-intercept.A regression line is a straight line that describes how a response variable y changes as an explanatory variable x changes. We often use a regression line to predict the value of y for a given value of x.\n\n""], 'url_profile': 'https://github.com/DbCurious', 'info_list': ['Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 12, 2020', 'MATLAB', 'Updated Jun 29, 2020', 'JavaScript', 'Updated May 7, 2020', 'Jupyter Notebook', 'Updated Feb 28, 2021', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/michaelsabramson', 'info_list': ['Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 12, 2020', 'MATLAB', 'Updated Jun 29, 2020', 'JavaScript', 'Updated May 7, 2020', 'Jupyter Notebook', 'Updated Feb 28, 2021', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['Coursera_Regression_Models\n'], 'url_profile': 'https://github.com/abarrantesh', 'info_list': ['Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Python', 'Updated Apr 12, 2020', 'MATLAB', 'Updated Jun 29, 2020', 'JavaScript', 'Updated May 7, 2020', 'Jupyter Notebook', 'Updated Feb 28, 2021', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 12, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '220 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/degugj', 'info_list': ['Assembly', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'HTML', 'Updated Apr 13, 2020']}","{'location': 'San Antonio, TX', 'stats_list': [], 'contributions': '787 contributions\n        in the last year', 'description': ['Linear Regression Project\nObjectives:\n\nTo wrangle the data, remove, null values and filter features to meet the brief\'s especifications.\nFind the best key features to predict the tax assessed value of single unit properties that the tax district assessed during the months of May 2017 - June 2017.\nTo generate and evaluate an effective linear regression model using key features to help predict property values.\nTo calculate tax rates and provide a visual distribution of tax rate for all counties that the properties are located in\nPresent the findings in report\n\nProject Brief:\n\nWe want to be able to predict the values of single unit properties that the tax district assesses using the property data from those whose last transaction\nwas during the ""hot months"" (in terms of real estate demand) of May and June in 2017. We also need some additional information outside of the model.\n\n\nZach lost the email that told us where these properties were located. Ugh, Zach :-/. Because property taxes are assessed at the county level,\nwe would like to know what states and counties these are located in.\n\n\nWe\'d also like to know the distribution of tax rates for each county.\n\n\nThe data should have the tax amounts and tax value of the home, so it shouldn\'t be too hard to calculate. Please include in your report to us the\ndistribution of tax rates for each county so that we can see how much they vary within the properties in the county and the rates the bulk of the\nproperties sit around.\n\n\nNote that this is separate from the model you will build, because if you use tax amount in your model, you would be using a future data point to\npredict a future data point, and that is cheating! In other words, for prediction purposes, we won\'t know tax amount until we know tax value.\n\nExecutive Summary:\n\n\nI found that bathroom square footage and total property square footage were two of the most important features when it came to calculating tax assessed home value. The key insight is that the target variable is not ""market house price"" (i.e not what the seller would value their house), but rather what the county values the property as for tax purposes. This means that the focus needs to be on features that tax assessors look for when evaluating properties, and number of bathrooms, as well as bathroom count, are key features because they are a good indicator of the property\'s quality. Number of bedrooms is not always as reliable, because this is a key driver of market value, which leads to many homeowners to create smaller bedrooms to inflate this metric.\n\nA successful model was created using bedroom square feet, bathroom square feet, and total square feet (excluding bathroom and bedroom square footage). These features were engineered using the data and domain knowledge to help reduce the dependency that the original features share, which was leading a skew in the model.\n\n\n\nFurther improvements:\n\nTo improve the model, we would need more features that are important to tax assessors, such as:\n\nLocation: While latitude and longitude is avialable in the data, any useful analysis would require a clustering algorithms to group locations of higher value, and currently this is not possible.\nQuality features: Garage square footage, pool size, number of fireplaces, etc. These are factors that tax assessors are more likely to look at, rather than bedroom count, because they are a better representation of the quality of the property. Unfortunately, the data available has a lot of null values for all of these categories, which makes them unsable for the model.\n\n\n\nRequirements to access report:\n\n\nTo access the full report, the repo needs to be cloned, along with all the .py files.\n\n\nDue to the size of the data, the report pulls the data from a SQL database. In order to get access to the data, and the report, an env.py file will need to be present in the same directory that the files are cloned to, and the file needs to have the following variables:\nuser = username information for the sql database\nhost = host number\npassword = password.\nThe wrangle.py file will look for the env.py file to access the SQL database and pull the data. A new file csv file will then be created and stored in the same directory for future use.\n\n\n'], 'url_profile': 'https://github.com/guedanie', 'info_list': ['Assembly', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'HTML', 'Updated Apr 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '413 contributions\n        in the last year', 'description': ['íšŒê·€ë¶„ì„ í”„ë¡œì íŠ¸\n\nDacon - AIí”„ë Œì¦ˆ ì‹œì¦Œ1 ì˜¨ë„ ì¶”ì • ê²½ì§„ ëŒ€íšŒ\n\n\níŒ€ì›: ì–‘ì¤€, ì˜¤ì§„ê²½, ìœ¤ì˜ˆìŠ¬, ì´í¬ìž¬\n\n\n1. ë°ì´í„° ì„¤ëª…\n\n\n\nëŒ€ì „ì§€ì—­ì—ì„œ ì¸¡ì •í•œ ì‹¤ë‚´ì™¸ 19ê³³ì˜ ì„¼ì„œë°ì´í„°ì™€ ì£¼ë³€ ì§€ì—­ì˜ ê¸°ìƒì²­ ê³µê³µë°ì´í„°ë¥¼ semi-ë¹„ì‹ë³„í™”í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.\n\n\nì„¼ì„œëŠ” ì˜¨ë„ë¥¼ ì¸¡ì •í•˜ì˜€ìŠµë‹ˆë‹¤.\n\n\nëª¨ë“  ë°ì´í„°ëŠ” ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬ ë˜ì–´ ìžˆìœ¼ë©° 10ë¶„ ë‹¨ìœ„ ë°ì´í„° ìž…ë‹ˆë‹¤.\n\n\nì˜ˆì¸¡ ëŒ€ìƒ(target variable)ì€ Y18ìž…ë‹ˆë‹¤.\n\n\ntrain.csv\n\n30ì¼ ê°„ì˜ ê¸°ìƒì²­ ë°ì´í„° (X00 - X39) ë° ì„¼ì„œë°ì´í„° (Y00 - Y17)\nì´í›„ 3ì¼ ê°„ì˜ ê¸°ìƒì²­ ë°ì´í„° (X00 - X39) ë° ì„¼ì„œë°ì´í„° (Y18)\n\n\n\ntest.csv\n\ntrain.csv ê¸°ê°„ ì´í›„ 80ì¼ ê°„ì˜ ê¸°ìƒì²­ ë°ì´í„° (X00 - X39)\n\n\n\n2. ë°ì´í„° ì „ì²˜ë¦¬ & ë¶„ì„ ê³¼ì •\n\n\n3.ê²°ê³¼\n\nMSE 3.94, ìƒìœ„ 11%(ì´ 378ëª… ì°¸ê°€)\n\n4.í”„ë¡œì íŠ¸ ê²°ê³¼ë¬¼\ná„’á…¬á„€á…±á„‡á…®á†«á„‰á…¥á†¨á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³.pdf\n5. ë¶„ì„ì— í•„ìš”í•œ íŒ¨í‚¤ì§€\n\nrequirements.txt\n\n'], 'url_profile': 'https://github.com/DS-Heejae', 'info_list': ['Assembly', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'HTML', 'Updated Apr 13, 2020']}","{'location': 'New Delhi', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gaurab2455', 'info_list': ['Assembly', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'HTML', 'Updated Apr 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '54 contributions\n        in the last year', 'description': ['Linear_And_Logistic_Regression\nIn Titanic dataset , Implement the logistic regression and find aout the Accuracy of model\nImplementing Logistic Regression\nsteps\n1) Collecting data\n2) Analysing Data\n3) Data Wrangling\n4) Train & test\n5) Accuracy check\nAnd in Suv dataset , simply check the accuracy\n'], 'url_profile': 'https://github.com/9717', 'info_list': ['Assembly', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'HTML', 'Updated Apr 13, 2020']}","{'location': 'Germany', 'stats_list': [], 'contributions': '44 contributions\n        in the last year', 'description': ['Bayesian_regression_pyro\nThis repo contains working examples MCMC and SVI models for bayesian regression using the pyro library. Goal is to have flexible easy to use classes with a syntax similar to scikit-learn fit /predict.\n\n\n\nAlgorithm\nDescription\nClass\n\n\n\n\nHMC MCMC with NUTS\nHamilton Monte Carlo Markov Chain Monte Carlo Method with No U-Turn Sample\nbay_reg_mcmc\n\n\nSVI\nStochastic Variational Inference\nbay_reg_svi\n\n\n\nTo do\n\n Implement non linear use case\n Implement non linear use case with previous transformation\n Implement use case for multidimensional input\n\nFile and folder description\n\n\n\nFile/Folder\nDescription\n\n\n\n\nexample.ipynb\nExample use of those two algorithms\n\n\nbayesian_regression_mcmc_svi.py\nbay_reg_mcmc & bay_reg_svi class\n\n\n\nInstallation\npip install -r requirements.txt\nIf you can want to run the file in a new enviroment:\n\nMake sure conda is installed (Best practice, set up with virtualenv is not tested)\nOpen a terminal or a anaconda prompt\nIf desired make new enviroment: conda create -n name_of_enviroment python\nActivate enviroment conda activate: conda create name_of_enviroment\nInstall dependencies: pip install requirements.txt\nIf the new enviroment / kernel is supposed to be used in Jupyter, install kernel:\n\n    python -m ipykernel install --name name_of_enviroment\n\nOpen your Jupyter Notebook it should work now\n\n'], 'url_profile': 'https://github.com/MonNum5', 'info_list': ['Assembly', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'HTML', 'Updated Apr 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Dfd11', 'info_list': ['Assembly', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'HTML', 'Updated Apr 13, 2020']}","{'location': 'Evanston, IL', 'stats_list': [], 'contributions': '1,115 contributions\n        in the last year', 'description': ['MNIST_LogisticRegression\nSimple ML program to learn parameters used in identifying numbers in the MNIST dataset\n'], 'url_profile': 'https://github.com/Ajuogaaz', 'info_list': ['Assembly', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'HTML', 'Updated Apr 13, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '647 contributions\n        in the last year', 'description': ['      \n\n\n\n\n\nPattern Recognition and Neural Networks\n\n    Classifiers and Regression\n    \nExplore the repositoryÂ»\n\n\nView Problem Statement\nView Report\n\n\n\ntags : linear regression, logistic regression, scikit-learn, one vs rest classifier, iris dataset, German data\n\nAbout The Repository\nThis repository holds the python implementation files for Assignment #2 for E1 213 Pattern Recognition and Neural Networks offered at the Indian Institute of Science (IISc), Bangalore. In this assignment we will explore linear models and compare different methods of learning linear classifiers and regression functions. The following methods have been implemented across the problems.\n\nLinear regression\nLogistic regression\nOne vs Rest classification\nOne hot classification\n\nProblem 1 deals with implementing and evaluating linear and logistic regressions with synthetic data drawn from Gamma, Uniform and Normal distributions. Problem 2 deals with classification using the Iris dataset with three 2-class classifiers using â€˜one vs restâ€™ strategy and with a 3-class linear classifier (by taking the target variable as a 3-dimensional one-hot vector). Problems 3 deals with classification using German credit data using linear least squares and logistic regression. Problem 4 deals with an 1D regression with polynomial fitting.\nBuilt With\nThis project was built with\n\npython v3.7\nThe list of libraries used for developing this project is available at requirements.txt.\n\nGetting Started\nClone the repository into a local machine using\ngit clone https://github.com/vineeths96/Linear-classifiers-and-Regression\nPrerequisites\nPlease install required libraries by running the following command (preferably within a virtual environment).\npip install -r requirements.txt\nInstructions to run\nThere are four python files - problem_1.py, problem_2.py, problem_3.py , and problem_4.py - each corresponding to the particular problem in the Problem Statement. Each problem has their corresponding implementation files under a python package with the same name. Each package has python modules and functions to load data, train a model, test it, and write the performance metrics to an output file at ./results with the same file name.\nRunning the program\npython problem_<QUES_NUM>.py\nResults\nView Report for the results and detailed discussions.\nLicense\nDistributed under the MIT License. See LICENSE for more information.\nContact\nVineeth S  - vs96codes@gmail.com\nProject Link: https://github.com/vineeths96/Linear-classifiers-and-Regression\n'], 'url_profile': 'https://github.com/vineeths96', 'info_list': ['Assembly', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'HTML', 'Updated Apr 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '62 contributions\n        in the last year', 'description': ['IntroduceLinearRegression\n'], 'url_profile': 'https://github.com/tanthanh0510', 'info_list': ['Assembly', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'HTML', 'Updated Apr 13, 2020']}"
"{'location': 'New Delhi', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gaurab2455', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'HTML', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '54 contributions\n        in the last year', 'description': ['Linear_And_Logistic_Regression\nIn Titanic dataset , Implement the logistic regression and find aout the Accuracy of model\nImplementing Logistic Regression\nsteps\n1) Collecting data\n2) Analysing Data\n3) Data Wrangling\n4) Train & test\n5) Accuracy check\nAnd in Suv dataset , simply check the accuracy\n'], 'url_profile': 'https://github.com/9717', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'HTML', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020']}","{'location': 'Germany', 'stats_list': [], 'contributions': '44 contributions\n        in the last year', 'description': ['Bayesian_regression_pyro\nThis repo contains working examples MCMC and SVI models for bayesian regression using the pyro library. Goal is to have flexible easy to use classes with a syntax similar to scikit-learn fit /predict.\n\n\n\nAlgorithm\nDescription\nClass\n\n\n\n\nHMC MCMC with NUTS\nHamilton Monte Carlo Markov Chain Monte Carlo Method with No U-Turn Sample\nbay_reg_mcmc\n\n\nSVI\nStochastic Variational Inference\nbay_reg_svi\n\n\n\nTo do\n\n Implement non linear use case\n Implement non linear use case with previous transformation\n Implement use case for multidimensional input\n\nFile and folder description\n\n\n\nFile/Folder\nDescription\n\n\n\n\nexample.ipynb\nExample use of those two algorithms\n\n\nbayesian_regression_mcmc_svi.py\nbay_reg_mcmc & bay_reg_svi class\n\n\n\nInstallation\npip install -r requirements.txt\nIf you can want to run the file in a new enviroment:\n\nMake sure conda is installed (Best practice, set up with virtualenv is not tested)\nOpen a terminal or a anaconda prompt\nIf desired make new enviroment: conda create -n name_of_enviroment python\nActivate enviroment conda activate: conda create name_of_enviroment\nInstall dependencies: pip install requirements.txt\nIf the new enviroment / kernel is supposed to be used in Jupyter, install kernel:\n\n    python -m ipykernel install --name name_of_enviroment\n\nOpen your Jupyter Notebook it should work now\n\n'], 'url_profile': 'https://github.com/MonNum5', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'HTML', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Dfd11', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'HTML', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020']}","{'location': 'Evanston, IL', 'stats_list': [], 'contributions': '1,115 contributions\n        in the last year', 'description': ['MNIST_LogisticRegression\nSimple ML program to learn parameters used in identifying numbers in the MNIST dataset\n'], 'url_profile': 'https://github.com/Ajuogaaz', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'HTML', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '647 contributions\n        in the last year', 'description': ['      \n\n\n\n\n\nPattern Recognition and Neural Networks\n\n    Classifiers and Regression\n    \nExplore the repositoryÂ»\n\n\nView Problem Statement\nView Report\n\n\n\ntags : linear regression, logistic regression, scikit-learn, one vs rest classifier, iris dataset, German data\n\nAbout The Repository\nThis repository holds the python implementation files for Assignment #2 for E1 213 Pattern Recognition and Neural Networks offered at the Indian Institute of Science (IISc), Bangalore. In this assignment we will explore linear models and compare different methods of learning linear classifiers and regression functions. The following methods have been implemented across the problems.\n\nLinear regression\nLogistic regression\nOne vs Rest classification\nOne hot classification\n\nProblem 1 deals with implementing and evaluating linear and logistic regressions with synthetic data drawn from Gamma, Uniform and Normal distributions. Problem 2 deals with classification using the Iris dataset with three 2-class classifiers using â€˜one vs restâ€™ strategy and with a 3-class linear classifier (by taking the target variable as a 3-dimensional one-hot vector). Problems 3 deals with classification using German credit data using linear least squares and logistic regression. Problem 4 deals with an 1D regression with polynomial fitting.\nBuilt With\nThis project was built with\n\npython v3.7\nThe list of libraries used for developing this project is available at requirements.txt.\n\nGetting Started\nClone the repository into a local machine using\ngit clone https://github.com/vineeths96/Linear-classifiers-and-Regression\nPrerequisites\nPlease install required libraries by running the following command (preferably within a virtual environment).\npip install -r requirements.txt\nInstructions to run\nThere are four python files - problem_1.py, problem_2.py, problem_3.py , and problem_4.py - each corresponding to the particular problem in the Problem Statement. Each problem has their corresponding implementation files under a python package with the same name. Each package has python modules and functions to load data, train a model, test it, and write the performance metrics to an output file at ./results with the same file name.\nRunning the program\npython problem_<QUES_NUM>.py\nResults\nView Report for the results and detailed discussions.\nLicense\nDistributed under the MIT License. See LICENSE for more information.\nContact\nVineeth S  - vs96codes@gmail.com\nProject Link: https://github.com/vineeths96/Linear-classifiers-and-Regression\n'], 'url_profile': 'https://github.com/vineeths96', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'HTML', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020']}","{'location': 'Gurgaon', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/VishalKakkar1995', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'HTML', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '73 contributions\n        in the last year', 'description': [""Insurance-Prediction-Linear-Regression\nCreate a model for Insurance Prediction using Linear Regression and for UI used Flask\nTeam Member's:-\n1.Mayur Pawar roll no.= 41 TE/B\n2.Mahesh Pawar roll no.= 40 TE/B\n""], 'url_profile': 'https://github.com/programmerMayur', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'HTML', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '41 contributions\n        in the last year', 'description': ['Regression Final Project\nJoshua Morgan, Will Espinoza\nObjective\nIn this project, we create a risk analysis and cost benefit analysis managers dealing with decision making in COVID-19.\nData\nOur data comes from data is divided into two main components.\nCase Data\nFirst our case datacollected in Hubei china. This data can be seen in the ncov_hubei.csv table. This data was processed, filtered, and outputed into cleaned_covid2.csv.\nLife Table Data\nOur analysis includes the use of life years which are found in the life_table.csv.\nCode\nFiles of interest are the preprocessing file contained in.\nThe modeling was done the Logistic Regression Implementation.ipynb.\nFor a detailed, summary of our findings and methods please see the Final_Report.pdf\n'], 'url_profile': 'https://github.com/jemorgan1000', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'HTML', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020']}","{'location': 'Windsor, Ontario', 'stats_list': [], 'contributions': '153 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Harshal131', 'info_list': ['Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'MIT license', 'Updated Jun 26, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'HTML', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 22, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '105 contributions\n        in the last year', 'description': ['Neural-Network-for-Regression-from-scratch-using-numpy-only\nWe will implement 3-layer neural network for regression. We are using sigmoid as activation function and mean-squared-error as loss.\n'], 'url_profile': 'https://github.com/irfanumar1994', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Jul 14, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '30 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/juamatx', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Jul 14, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 11, 2020']}","{'location': 'France', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['Constrained-linear-regression-Package\nThis is a linear regression model that allows to enforce linear constraints and bounds on the weights.\nGiven Theta1 & Theta2 weight, a linear constraint can be defined as Theta1>p1*Theta2 where p1 is a scalar.\nMoreover, each weight of the model can be limited to specified bounds by complying with the following criteria: Theta-bound>0\nThe Mean Squared Error of the model is optimized with Batch Gradient Descent.\nThese constraints are implemented by adding to the loss function a convex penalty term P:\nP=Sum(f(-Constraint)), where f can be a Relu, Squared Relu or an Exponential function.\n'], 'url_profile': 'https://github.com/Lucadel', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Jul 14, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '83 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/atulcoin', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Jul 14, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/urvashi-tuteja', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Jul 14, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 11, 2020']}","{'location': 'Patna', 'stats_list': [], 'contributions': '156 contributions\n        in the last year', 'description': ['Support-vector-regression-model\n'], 'url_profile': 'https://github.com/Sonalikhasyap15', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Jul 14, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 11, 2020']}","{'location': 'Patna', 'stats_list': [], 'contributions': '156 contributions\n        in the last year', 'description': ['Random-forest-regression-model\n'], 'url_profile': 'https://github.com/Sonalikhasyap15', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Jul 14, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '146 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/NeginSal', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Jul 14, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['MachineLearningMultipleRegression\n'], 'url_profile': 'https://github.com/cat19977', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Jul 14, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 11, 2020']}","{'location': 'Pune, India', 'stats_list': [], 'contributions': '694 contributions\n        in the last year', 'description': ['ML-Linear-Regression-Interactive-\nImplementation of Linear Regression Machine Learning algorithm using Gradient Descent. Made in p5.js\nTry it out on:\nhttps://editor.p5js.org/sainivaibhav19/sketches/EodjoFuU\nPreview:\n\n'], 'url_profile': 'https://github.com/VaibhavSaini19', 'info_list': ['Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 13, 2020', 'Python', 'Updated Jul 14, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 6, 2020', 'HTML', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 11, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['data-science-\n'], 'url_profile': 'https://github.com/mohit180796', 'info_list': ['1', 'Jupyter Notebook', 'Updated Aug 5, 2020', 'R', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 18, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 25, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'R', 'Updated Apr 8, 2020']}","{'location': 'Nashik', 'stats_list': [], 'contributions': '71 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Nilayy7', 'info_list': ['1', 'Jupyter Notebook', 'Updated Aug 5, 2020', 'R', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 18, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 25, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'R', 'Updated Apr 8, 2020']}","{'location': 'Gujrat, Punjab, Pakistan', 'stats_list': [], 'contributions': '7 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/adeel085', 'info_list': ['1', 'Jupyter Notebook', 'Updated Aug 5, 2020', 'R', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 18, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 25, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'R', 'Updated Apr 8, 2020']}","{'location': 'delhi', 'stats_list': [], 'contributions': '460 contributions\n        in the last year', 'description': ['ml-04-linear-regression\n'], 'url_profile': 'https://github.com/mistertandon', 'info_list': ['1', 'Jupyter Notebook', 'Updated Aug 5, 2020', 'R', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 18, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 25, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'R', 'Updated Apr 8, 2020']}","{'location': 'Tbilisi , Georgia', 'stats_list': [], 'contributions': '506 contributions\n        in the last year', 'description': ['.\nâ”œâ”€â”€ figures\nâ”‚\xa0\xa0 â”œâ”€â”€ Figure_1.png\nâ”‚\xa0\xa0 â”œâ”€â”€ Figure_2.png\nâ”‚\xa0\xa0 â”œâ”€â”€ Figure_3.png\nâ”‚\xa0\xa0 â””â”€â”€ Figure_4.png\nâ”œâ”€â”€ README.md\nâ”œâ”€â”€ run.py\nâ”œâ”€â”€ utils\nâ”‚\xa0\xa0 â”œâ”€â”€ data.py\nâ”‚\xa0\xa0 â”œâ”€â”€ __init__.py\nâ”‚\xa0\xa0 â”œâ”€â”€ model.py\nâ”‚\xa0\xa0 â””â”€â”€ plot.py\nâ””â”€â”€ weights\n    â””â”€â”€ LogReg-6a82p.pkl\n3 directories, 11 files\n\n\nusage: run.py [-h] [--load LOAD]\n\noptional arguments:\n  -h, --help   show this help message and exit\n  --load LOAD  True: Load trained model False: Train model default: True\nMSE 3.766020984227096\nR^2 value: 0.8833333333333333\nb_0: 1.6609947334733783 \nb_1: -6.564698790751537\nDo you want to save the model weight? yes\nModel saved at weights/LogReg-6a82p.pkl\n\nTrain the model\npython run.py\npython run.py --load 0\nLoad the weight model\npython run.py --load 1\nTraining process\nusage: run.py [-h] [--load LOAD]\n\noptional arguments:\n  -h, --help   show this help message and exit\n  --load LOAD  True: Load trained model False: Train model default: True\nMSE 3.766020984227096\nR^2 value: 0.8833333333333333\nb_0: 1.6609947334733783 \nb_1: -6.564698790751537\nDo you want to save the model weight? yes\nModel saved at weights/LogReg-6a82p.pkl\n\n\n\n\n\n\nDocker for Logistic Regression\nBuild Docker image\nYou can build Docker image by following:\ndocker-compose build\nRun Docker container\nYou can launch a container from the Docker image by following:\ndocker-compose up\n'], 'url_profile': 'https://github.com/mysterio42', 'info_list': ['1', 'Jupyter Notebook', 'Updated Aug 5, 2020', 'R', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 18, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 25, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'R', 'Updated Apr 8, 2020']}","{'location': 'Karachi,Pakistan', 'stats_list': [], 'contributions': '81 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/khawar512', 'info_list': ['1', 'Jupyter Notebook', 'Updated Aug 5, 2020', 'R', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 18, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 25, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'R', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/liorhirsch', 'info_list': ['1', 'Jupyter Notebook', 'Updated Aug 5, 2020', 'R', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 18, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 25, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'R', 'Updated Apr 8, 2020']}","{'location': 'India', 'stats_list': [], 'contributions': '908 contributions\n        in the last year', 'description': ['Logistic-Regression-Classifier-Template\nThis is a template I made while building a Deep Learning project.\n'], 'url_profile': 'https://github.com/KushalBhanot', 'info_list': ['1', 'Jupyter Notebook', 'Updated Aug 5, 2020', 'R', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 18, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 25, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'R', 'Updated Apr 8, 2020']}","{'location': 'Montreal, Canada', 'stats_list': [], 'contributions': '38 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/amfei', 'info_list': ['1', 'Jupyter Notebook', 'Updated Aug 5, 2020', 'R', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 18, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 25, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'R', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '383 contributions\n        in the last year', 'description': ['simple-linear-regression\n'], 'url_profile': 'https://github.com/priyanshu-data', 'info_list': ['1', 'Jupyter Notebook', 'Updated Aug 5, 2020', 'R', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 18, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 25, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'R', 'Updated Apr 8, 2020']}"
"{'location': 'India', 'stats_list': [], 'contributions': '908 contributions\n        in the last year', 'description': ['Logistic-Regression-Classifier-Template\nThis is a template I made while building a Deep Learning project.\n'], 'url_profile': 'https://github.com/KushalBhanot', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020', 'HTML', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'Montreal, Canada', 'stats_list': [], 'contributions': '38 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/amfei', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020', 'HTML', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '345 contributions\n        in the last year', 'description': ['MULTIPLE-LINEAR-REGRESSION\n'], 'url_profile': 'https://github.com/NarayanaReddy29', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020', 'HTML', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['Linear-regression-model\n'], 'url_profile': 'https://github.com/xinyanma', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020', 'HTML', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '47 contributions\n        in the last year', 'description': ['Logistic-Regression-Python-\nUsing Sklearn\nProject on employee absenteeism. Data includes reasons for previous absence, distance from work, education level etc.\n'], 'url_profile': 'https://github.com/bokedara', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020', 'HTML', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'Alverca do Ribatejo', 'stats_list': [], 'contributions': '49 contributions\n        in the last year', 'description': ['ANN_keras_regression\nANN_keras_regression_prediting_house_prices\n'], 'url_profile': 'https://github.com/RFJC21', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020', 'HTML', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '42 contributions\n        in the last year', 'description': ['Lasso-and-Ridge-Regression\nimplementation of Lasso and Ridge Dataset using GridSearch CV\n'], 'url_profile': 'https://github.com/prady1999', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020', 'HTML', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '108 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ADITEYARAJ', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020', 'HTML', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '61 contributions\n        in the last year', 'description': ['linear_regression_mini_project\n'], 'url_profile': 'https://github.com/jordanstrassner', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020', 'HTML', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'Dhaka, Bangladesh', 'stats_list': [], 'contributions': '156 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/MasumBhuiyan', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 10, 2020', 'Updated Apr 10, 2020', 'HTML', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}"
"{'location': 'mumbai', 'stats_list': [], 'contributions': '44 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gowthamthenarasu', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'HTML', 'Updated May 28, 2020', 'C#', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'MIT license', 'Updated Apr 15, 2020']}","{'location': 'Los Angeles', 'stats_list': [], 'contributions': '65 contributions\n        in the last year', 'description': ['Cat Classifier - Logical Regression\nBuilt a simple image-recognition algorithm that can correctly classify pictures as cat or non-cat using numpy.\n'], 'url_profile': 'https://github.com/Kripakaran', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'HTML', 'Updated May 28, 2020', 'C#', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'MIT license', 'Updated Apr 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['Regression-Modeling-For-Debt-Collection\nAfter a debt has been legally declared ""uncollectable"" by a bank, the account is considered to be ""charged-off."" But that doesn\'t mean\nthe bank simply walks away from the debt. They still want to collect some of the money they are owed. In this project, we will look at a\nsituation where a bank assigned delinquent customers to different recovery strategies based on the expected amount the bank believed it\nwould recover from the customer. The goal for the data scientist is to determine in this non-random assignment whether the incremental\namount the bank earns exceeded the additional cost of assigning customers to a higher recovery strategy.\n'], 'url_profile': 'https://github.com/Kshitiz14', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'HTML', 'Updated May 28, 2020', 'C#', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'MIT license', 'Updated Apr 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '42 contributions\n        in the last year', 'description': ['linear-regression-with-flask\na simple linear regression web application that I made with the flask framework\nhttps://regression-with-flask.herokuapp.com/\n'], 'url_profile': 'https://github.com/thehybrid18', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'HTML', 'Updated May 28, 2020', 'C#', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'MIT license', 'Updated Apr 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '75 contributions\n        in the last year', 'description': ['TestAppRegression\nTesting of apps\n'], 'url_profile': 'https://github.com/test1teams', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'HTML', 'Updated May 28, 2020', 'C#', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'MIT license', 'Updated Apr 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '32 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/goabishek', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'HTML', 'Updated May 28, 2020', 'C#', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'MIT license', 'Updated Apr 15, 2020']}","{'location': 'San Francisco ', 'stats_list': [], 'contributions': '38 contributions\n        in the last year', 'description': ['Regression-Model-Movies-Dataset\n'], 'url_profile': 'https://github.com/Sheethal-crypto', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'HTML', 'Updated May 28, 2020', 'C#', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'MIT license', 'Updated Apr 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '117 contributions\n        in the last year', 'description': ['Regression-Models-Course-Project\nYou work for Motor Trend, a magazine about the automobile industry. Looking at a data set of a collection of cars, they are interested in exploring the relationship between a set of variables and miles per gallon (MPG) (outcome). They are particularly interested in the following two questions:  â€œIs an automatic or manual transmission better for MPGâ€ ""Quantify the MPG difference between automatic and manual transmissions""\n'], 'url_profile': 'https://github.com/endri81', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'HTML', 'Updated May 28, 2020', 'C#', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'MIT license', 'Updated Apr 15, 2020']}","{'location': 'San Antonio, TX', 'stats_list': [], 'contributions': '277 contributions\n        in the last year', 'description': ['Zillow Regression Project\nIn a deluge of data, which drop(s) are driving single-unit property values for Zillow.com?\nUsing the property data from those whose last transaction was between 1May and 30Jun of 2017 (the \'Hot Months\'), I attempt to predict the value of single-unit properties based on tax district assessments.\nAlso, because property taxes are assessed at the county level, I need to know where (state and county) the sample pools are located, as well as the distribution of the tax rates for each county.\nObjectives:\n\n\nPlanning, acquiring, preparing, and exploring the data in the provided Zillow MySQL database to gain an understanding of which variables are independent from each other and which are not.\n\n\nModel trial-and-error: modeling all these variables against and with each other to determine which factors have the heaviest weights in determining single-unit property values.  Being that there are multiple features and a single target (home value), multiple univariate regression modeling will be the focus of this portion.\n\n\nFrom these efforts, create a Google Slide presentation of 3-5 slides clearly laying out the results of my findings to an audience of Data Scientists working for Zillow.\n\n\nBacking up a bit:\nI had originally done my whiteborading for the cached project, determining error drivers in the Zillow \'Zestimate\' algorithm.\nWhen I realized the project paradigm had changed, I became a little detached; a \'woe is me\' moment, for sure.\nBUT hope was not lost: in my initial exploration of the Zestimate algorithm, I noticed a couple of things that seemed problematic and were almost certainly drivers of error.\nOne, the algorithm relies heavily on customer feedback and input.  That type of reliance seems to be rich with Type I and Type II errors.  The majority of people only go to Zillow for sales-related activities: ""How much do I sell my home for / how much is that home \'really\' worth?""  Motivation is a key factor in losing one\'s objectivity, so it would seem the feedback they receive would be fraught with \'he said / she said\' data and customer complaints.  It\'s easy to envision a trend where the more feedback they got, the further buyer and seller data would diverge from each other.\nSecondly, foreclosures are not factored into the algorithm, whereas variables like \'area home sale price\' are.  Anyone who has driven through neighborhoods with a foreclosed property(properties) knows that property values surrounding those foreclosures are diminished, at least from a buyer\'s perspective.  Their reasoning for not including foreclosures is that they are outliers.  While that may be true under normal conditions, Zillow was founded in 2006 - two years before the tremendously non-normal condition of the 2008 housing crash.   An increase in foreclosures (say, for the city of Detroit) would push outliers closer to - and possibly within - the normal distribution curve.\nOnce my Minimum Viable Product is satisfactory, I would like to explore possible feature engineering that includes these and other factors I discovered while looking into the cached project deliverables.\nFull disclosure on my process:\nNaturally, the data science pipeline / workflow is implemented, but I\'m a bit \'old-school\' and need to touch and feel my information.  I have printed out the necessary modules for my own reference, as well as whiteboarded all objectives, complete with Post-It notes of various colors to physically keep track of my progress.\nMost of the dataframe coding and visualizations have been done using Jupyter Notebooks, an awesome and easy-to-use development environment, especially for people like me who tend to think out loud.  In the notebooks are comments that range from snippet to tome - the decision to keep them in there is to show my thinking process throughout each phase of the project.\nImports and this README file are rooted in VSCode.  Previous python-ing had been performed in PyCharm in preparation for this course and Jupyter Notebooks during this course, so when perusing my code in VS, one may find some noob-like stylings.\nBut, hey: as long as the functions work, right?\nMinimum Viable Product\nAt the very least, we are to use our modeling to predict single-unit property values using only three factors: the number of bedrooms, the number of bathrooms, and the overall square footage.  From this spec, I will attempt to reject the following three null-hypotheses:\nNumber of Bedrooms\n\n\n$H_0$ - The number of bedrooms is not a driver of single-unit property values.\n\n\n($H_a$ - The number of bedrooms IS a driver of single-unit property values)\n\n\nNumber of Bathrooms\n\n\n$H_0$ - The number of bathrooms is not a driver of single-unit property values\n\n\n($H_a$ - The number of bathrooms IS a driver of single_unit properties)\n\n\nSquare Footage\n\n\n$H_0$ - Square footage does not drive single-unit property values\n\n\n($H_a$ - Square footage DOES INDEED drive singe-unit property values)\n\n\nTending to null values in the dataset\nInitial exploration of the data revealed some null values in the features \'square_feet\' and \'tax_amount.\'  It is not believed that these 25 values will have any significant affect on the projection of the remaining non-null variables (totaling 15,011), so these rows will be dropped altogether from our analysis.\nGlossary of Terms\nSeveral features in the provided data needed some clarification for me.  While not exhaustive, this is the segment in which I hope to keep track of their definitions:\nfips number / code\n\nshort for Federal Information Processing Standard\nit\'s a unique identifier for US counties / county equivalents\ncomposed of five numbers: first two are the state code, and the last three digits are the county code\nour database lists them as four-number codes; this is due to the first number being the placeholder zero(0)\n(Source: https://en.wikipedia.org/wiki/FIPS_county_code)\n\nRecursive Feature Elimination\nA method of removing features of low importance to reduce model complexity and overfitting.  Not every feature (independent variable, or X value) is as important to the model as the next, and this method of \'feature herd thinning\' iterates through the model, selecting the attributes that best predict the target variable (the y, or \'home_value\', in this case).\n'], 'url_profile': 'https://github.com/nickjoseph210', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'HTML', 'Updated May 28, 2020', 'C#', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'MIT license', 'Updated Apr 15, 2020']}","{'location': 'Minnesota', 'stats_list': [], 'contributions': '430 contributions\n        in the last year', 'description': ['Applied Regression Analysis\n\nTOC\n{:toc}\n\nRead in csv files\n\nSet working directory that contains the interested csv file\ndat<-read.csv(""test.csv"")\n\nBasics of dataframe\nA dataframe can be created from vectors, each containing a particular feature for all examples.\nx<-c(1, 2, 3)  # feature x of all 3 examples\ny<-c(5.5, 6.1, 231)  # feature y of all 3 examples\nz<-c(4, 7, 8)  # feature z of all 3 examples\n\ndf<-data.frame(x, y, z)  # create a dataframe\n\ndf$x  # access the vector (col) ""x"" of the dataframe ""df""\ndf$x<-c(2, 3, 4)  # edit the content of a vector inside a dataframe\nggplot2\nInstall ggplot2\ninstall.packages(""ggplot2"")\nBring ggplot2 to current session\nlibrary(ggplot2)\nPlot a single point (4, 9) using geom_point\nx<-4\ny<-9\ndat<-data.frame(x, y)\nggplot()+geom_point(data=dat, aes(x=x, y=y), size=10, color=""red"")\nMore info on geom_point:\nggplot()+geom_point(data=dat, aes(x=x, y=y), size=10, color=""red"")\n\ngeom_point: geometry for plotting points\n\ndata: dataframe that contains data\naes\n\nx=x: x values come from the x vector\ny=y: y values come from the y vector\n\n\nsize: size of each point on plot\ncolor: color of each point on plot\n\nhttp://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf\n\n\nshape: shape of each point on plot, given by integers\n\nhttp://sape.inf.usi.ch/quick-reference/ggplot2/shape\n\n\n\n\n\nControl axis limits\nggplot()+\n\tgeom_point(data=dat, aes(x=x, y=y), size=10, color=""red"")+\n\tscale_x_continuous(limits=c(-10, 30))+\n\tscale_y_continuous(limits=c(-20, 80))\nPlot multiple points\nPlot point (2, 6), (5, 4) and (1, 9):\nx<-c(2, 5, 1)\ny<-c(6, 4, 9)\ndat<-data.frame(x, y)\nggplot()+geom_point(data=dat, aes(x=x, y=y), size=10, color=""red"")\nGraph line from endpoints\nPlot line from (1, 3) to (8, 10); plot line from (-2, 13) to (7, -5).\nx<-c(1, 8)\nx<-c(3, 10)\ndat<-data.frame(x, y)\nggplot()+geom_line(data=dat, ase(x=x, y=y))\nGraph line from equation\nGraph $y=3x+1$ where $x\\in[0, 10]$:\nx<-c(0, 10)\nx<-3*x+1\ndat<-data.frame(x, y)\nggplot()+geom_line(data=dat, ase(x=x, y=y))\nSampling from populations\nRandom integer\nsample(1:10, 100, replace=TRUE)  \n# 1st arg: sample from 1 to 10 inclusive\n# 2nd arg: sample 100 points\n# replace: whether to sample with replacement\nNormal populations\nrnorm(100, 50, 10)\n# 1st arg: number of points to sample\n# 2nd arg: mean\n# 3rd arg: standard deviation\nPlot a vertical sample\nx<-rep(1, 100)  # repeat 1 100 times\ny<-rnorm(100, 50, 10)\ndat<-data.frame(x, y)\n\nx<-1\ny<-50\nmean<-data.frame(x, y)\n\nggplot()\n\t+geom_point(data=dat, aes(x=x, y=y))\n\t+geom_point(data=mean, aes(x=x, y=y), size=7, color=""red"")\nPlot several vertical samples\nTask: plot three distinct vertical samples of 100 points each.\n\nSample 1: x=1, mean=50, std=10\nSample 2: x=9, mean=30, std=10\nSample 3: x=15, mean=78, std=10\n\nx<-rep(1, 100)\nx<-c(x, rep(9, 100))\nx<-c(x, rep(15, 100))\n\ny<-rnorm(100, 50, 10)\ny<-c(y, rnorm(100, 30, 10))\ny<-c(y, rnorm(100, 78, 10))\n\ndat<-data.frame(x, y)\n\nx<-c(1, 9, 15)\ny<-c(50, 30, 78)\nmeans<-data.frame(x, y)\n\nggplot()+\n\tgeom_point(data=dat, aes(x=x, y=y))+\n  geom_point(data=means, aes(x=x, y=y), color=""red"")\nSamples along a line\nCreate four vertical samples of 100 points each. Means must lie on the line $y=3x+1$. Locations of x are 1, 9, 15, 22.\n# generate data for line\nx<-c(0, 25)\ny<-3*x+1\nline<-data.frame(x, y)\n\n# generate means\nx<-c(1, 9, 15, 22)\ny<-3*x+1\nmeans<-data.frame(x, y)\n\n# generate samples\nx<-c(rep(1, 100), rep(9, 100), rep(15, 100), rep(22, 100))\ny<-c(rnorm(100, means[1], 10), rnorm(100, means[2], 10), rnorm(100, means[3], 10), rnorm(100, means[4], 10))\nsamples<-data.frame(x, y)\n\nggplot()+\n\tgeom_line(data=line, aes(x=x, y=y))+\n  geom_point(data=means, aes(x=x, y=y), size=7, color=""red"")+\n\tgeom_point(data=samples, aes(x=x, y=y))\nsapply\nx<-c(2, 4, 9, 15)\n\n# these two are equivalent\nsqrt(x)\nsapply(x, function(x) sqrt(x))\nCloud of points\nProblem:\n\nGenerate 100 data points.\nThe x-coordinates are drawn from a normal population of mean 10 and standard deviation 5.\nFor each x-value, one y-value is drawn from a normal population with mean 3x+1 and standard deviation 10.\n\nx<-rnorm(100, 10, 5)\ny<-3*x+1\nmeans<-data.frame(x, y)\n\n# generate one y value for each x value\ny<-sapply(x, function(x) rnorm(1, 3*x+1, 10))\nsamples<-data.frame(x, y)\n          \nggplot()+\n    geom_point(data=means, aes(x=x, y=y), color=""red"")+\n    geom_point(data=samples, aes(x=x, y=y))\n\nSimple linear regression in R\nFather and son heights\nlibrary(UsingR)\nhead(father.son)  # view the first few rows\n\nx<-c(60, 75)\ny<-c(63, 78)\nline<-data.frame(x, y)\n\n# plot data, and add a line\nggplot()+\n\tgeom_point(data=father.son, aes(x=fheight, y=sheight))+\n\tgeom_line(data=lie, aes(x=x, y=y))\nResidual visualization\nx<-father.son$fheight\ny<-father.son$sheight\n\ngroup<-1:1078\ndat<-data.frame(x, y, group)\n\n# create endpoints for plotting the line\nx<-c(0, 100)\ny<-x+3\nline<-data.frame(x, y)\n\n# for each data point in the dataset, get a point with the same x value but is on the line\ny<-x+3  # the values of y predicted by the model\nmeans<-data.frame(x, y, group)\n\n# similar to np.vstack\nd<-rbind(dat, means)\n\nggplot()+\n\tgeom_point(data=dat, aes=(x=x, y=y))+\n\tgeom_line(data=line, aes=(x=x, y=y))+\n\tgeom_point(data=means, aes=(x=x, y=y), color=""red"")+\n\tgeom_point(data=d, aes=(x=x, y=y, group=group))\n# for each group, the ""group"" argument plots one line for points in that group\nSum of squared residuals\nSquare each residual and then add them all up.\nresiduals<-means$y-dat$y\nsquared_residuals<-residuals^2\nsum_of_squared_residuals<-sum(squared_residuals)\nThe least-squares line\nlm(y~x, data=dat)\n\n# read from the output of the command above\nslope<-0.5141\nintercept<-33.8866\nx<-c(57, 78)\ny<-slope*x+intercept\nline<-data.frame(x, y)\n\nx<-means$x\nx<-slope*x+intercept\nmeans<-data.frame(x,y,group)\n\nd=rbind(dat, means)\n\nggplot()+\n\tgeom_point(data=dat, aes=(x=x, y=y))+\n\tgeom_line(data=line, aes=(x=x, y=y))+\n\tgeom_point(data=means, aes=(x=x, y=y), color=""red"")+\n\tgeom_point(data=d, aes=(x=x, y=y, group=group))\nPrediction\npred<-slope*input+intercept\n'], 'url_profile': 'https://github.com/zhihanyang2022', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'HTML', 'Updated May 28, 2020', 'C#', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'MIT license', 'Updated Apr 15, 2020']}"
"{'location': 'brighton, United Kingdom', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': ['House-Price-Prediction\nBuild a regression model using regularisation in order to predict the actual value of the prospective properties and decide whether to invest in them or not.\nA US-based housing company named Surprise Housing has decided to enter the Australian market. The company uses data analytics to purchase houses at a price below their actual values and flip them at a higher price. For the same purpose, the company has collected a data set from the sale of houses in Australia. The data is provided in the CSV file below.\nThe company is looking at prospective properties to buy to enter the market.\nYou are required to build a regression model using regularisation in order to predict the actual value of the prospective properties and decide whether to invest in them or not.\nThe company wants to know:\nWhich variables are significant in predicting the price of a house, and\nHow well those variables describe the price of a house.\nAlso, determine the optimal value of lambda for ridge and lasso regression.\nBusiness Goal\nYou are required to model the price of houses with the available independent variables. This model will then be used by the management to understand how exactly the prices vary with the variables. They can accordingly manipulate the strategy of the firm and concentrate on areas that will yield high returns. Further, the model will be a good way for the management to understand the pricing dynamics of a new market.\n'], 'url_profile': 'https://github.com/VikramMathur3012', 'info_list': ['2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '1', 'Python', 'Updated May 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated May 31, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/abdulrehman03365', 'info_list': ['2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '1', 'Python', 'Updated May 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated May 31, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['muli-linear-regression-ML-Stephen-Curry-Shoting\nMulti-Linear Regression on Stephen Curry Regular Season Shooting, 3point percentage.\nMake sure to have anconda installed and run this juypter notebook when downloading\nDownload the csv file and place them in the same file together (same directory)\nThis predicts Currys 3 point percentage based on specific independent variables such as, min, season, all star team mates playing along side, total points and finally age.\nHave fun and see if the predictions are true!\nDeveloper: S.Singh\n'], 'url_profile': 'https://github.com/sumerCS', 'info_list': ['2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '1', 'Python', 'Updated May 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated May 31, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020']}","{'location': 'San Francisco, CA', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['Machine_Learning_Project\nRegression-based models with Apprentice Chef, Inc. dataset to make revenue prediction.\n-Overview-\nThe executives of Apprentice Chef, Inc. have come to realize that over 90% of revenue comes from customers that have been ordering for 12 months or less, and they want to understand how much revenue to expect from each customer within their first year of order by using a regression-based model to predict revenue.\nThis is my first individual supervised learning project in the Machine Learning course at Hult International Business School.\n'], 'url_profile': 'https://github.com/yurikatokoro', 'info_list': ['2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '1', 'Python', 'Updated May 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated May 31, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '68 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/priyadarshi0007', 'info_list': ['2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '1', 'Python', 'Updated May 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated May 31, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020']}","{'location': 'Winnipeg, Manitoba', 'stats_list': [], 'contributions': '688 contributions\n        in the last year', 'description': ['Customer Churn Detection\nThe dataset includes different information about customers. The objective is to predict customer churn from the data. The input data is highly imbalanced consisting 150 churn (i.e., churn = 1) and 750 no churn (i.e., churn = 0) customers. Check the customer_churn.csv dataset for details.\nâ€¢ MLlib and PySpark is used to build the model. \nâ€¢ Feature vectorization is performed to convert the categorical features.\nâ€¢ Random undersampling is performed to the majority class (i.e., No Churn) and random oversampling is performed to the minority class (i.e., Churn) to balance the class distribution.\nâ€¢ Logistic regression, Random Forest and Gradient Boosting Tree are applied to the balanced data.\nâ€¢ The best performance is achieved for the Gradient Boosting Tree with AUC (Area Under Curve) = 0.92.\n\nInitial Distribution of the Class (i.e., Churn):\n\nDistribution after sampling:\n\nArea Under Curve (AUC):\n\n'], 'url_profile': 'https://github.com/ShahedSabab', 'info_list': ['2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '1', 'Python', 'Updated May 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated May 31, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '95 contributions\n        in the last year', 'description': ['Reverse Principal Component Analysis for Multi-output Regression\n\n\nThis repository stores relevant material for the paper titled ""Reverse Principal Component Analysis for Multi-output Regression"" by Akshit Bhalla (1RV16IM007), final year student at R.V. College of Engineering, Bengaluru, submitted to ACCTHPA\'20 (ADVANCED COMPUTING AND COMMUNICATION TECHNIQUES FOR HIGH PERFORMANCE APPLICATIONS (ACCTHPA))\n\n\nThe ""datasets"" folder contains the datasets used in the paper, namely:\na. edm\nb. end\nc. scm1d\nd. slump\n\n\nThe file ""Multi-output Regression.ipynb"" contains the code for the methodology proposed. In the code, on setting ""name"" to any one of the datasets mentioned in 2.a., 2.b., 2.c. or 2.d., produces a pickle file containing the entire analysis for the dataset. Produce all 4 pickle files. One may change values such as ""threshold"" and experiment as desired.\n\n\nThe file ""Analysis.ipynb"" takes the 4 pickle files and generates visualizations for the study.\n\n\nNote: All coding performed using Python 3.7.\n'], 'url_profile': 'https://github.com/akshitbhalla2', 'info_list': ['2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '1', 'Python', 'Updated May 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated May 31, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020']}","{'location': 'Mumbai,Maharashtra', 'stats_list': [], 'contributions': '303 contributions\n        in the last year', 'description': ['DWM_mini_project\nData Warehouse and Mining Project to show the dataset analysis using Regression Alogrithm in Machine Learning\nSteps:\n\nOpen the main.py file in the final_codes_needed folder\nDownload the required python libraries\nUpload any .csv dataset, just make sure that the variable to be predicted is the last column of the dataset\nUpload the file in the UI\nThe result will give the data anaysis of the dataset, its accuracy, and the result graphs.\n\n'], 'url_profile': 'https://github.com/surya8barca', 'info_list': ['2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '1', 'Python', 'Updated May 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated May 31, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020']}","{'location': 'Nairobi', 'stats_list': [], 'contributions': '52 contributions\n        in the last year', 'description': ['Heart-Disease-prediction-using-Random-Forest-and-Logistic-Regression\nPredicting whether one has heart disease or not using Random Forest and Logistic Regression Models\n'], 'url_profile': 'https://github.com/KimaniKibuthu', 'info_list': ['2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '1', 'Python', 'Updated May 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated May 31, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '194 contributions\n        in the last year', 'description': ['bayesian_ames\nUsing PyMC3 to do a hierarchical regression on the Ames Housing dataset\n'], 'url_profile': 'https://github.com/Bmcgarry194', 'info_list': ['2', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '1', 'Python', 'Updated May 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated May 31, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 26, 2020']}"
"{'location': 'Uganda', 'stats_list': [], 'contributions': '105 contributions\n        in the last year', 'description': [""Predicting House Prices_Kaggle_InClass Competition\nHouse Prices: Advanced Regression Techniques Predict sales prices and practice feature engineering, RFs, and gradient boosting\nAsk a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\nModels used: Lasso, Ridge, Elasticnet, XGBoost, LightGradientBoosting, and StackingCVRegressor\n""], 'url_profile': 'https://github.com/eddUG', 'info_list': ['Jupyter Notebook', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Python', 'Updated Jul 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 6, 2020', 'R', 'Updated Apr 9, 2020', 'R', 'Updated May 5, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020']}","{'location': 'Ontario, Canada', 'stats_list': [], 'contributions': '74 contributions\n        in the last year', 'description': ['This project was undertaken as a part of Post Graduate Diploma from upGrad IIIT-B\nMultiple Linear Regression to Predict factors affecting Price of a car\nA Chinese automobile company wants to understand the factors on which the pricing of cars depends.\nSpecifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\n\nWhich variables are significant in predicting the price of a car\nHow well those variables describe the price of a car\n\nA consulting firm has gathered a large dataset of different types of cars across the Americal market.\nBusiness Goal\nYou are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market.\nSolution Overview to perform a Multiple Linear Regression Model\nStep 1: Reading, Understanding and cleaning the Data\n\n1.1 Reading and understanding\n1.2 Cleaning data\n\nStep 2: EDA and Visualizing the data\n\n2.1 Visualizing categorical variables\n2.2 Visualizing numerical variables\n\nStep 3. Data Preparation\n\n3.1 Adding Derived variables\n3.2 Creating dummy variables\n\nStep 4. Creating Training and Testing Sets and scaling the features\n\n4.1 Dividing the data into train and test set\n4.2 Scaling numeric variables\n\nStep 5. Building the linear model\n\n5.1 Using RFE to select initial 10 features\n5.2 Building linear model using statsmodel\n5.3 Dropping columns and re-evaluating the model\n\nStep 6. Residual Analysis of train data\nStep 7. Predictions on the Test Set\nStep 8. Model Evaluation and Inference\n'], 'url_profile': 'https://github.com/kanika1101', 'info_list': ['Jupyter Notebook', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Python', 'Updated Jul 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 6, 2020', 'R', 'Updated Apr 9, 2020', 'R', 'Updated May 5, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020']}","{'location': 'Pilar, Buenos Aires', 'stats_list': [], 'contributions': '1,618 contributions\n        in the last year', 'description': ['House Appraiser\nMachine Learning Model\nLinear regression developed with sklearn to predict the value of a property based on certain features.\nUsage\nRun the application using:\n$ export FLASK_APP=main.py\n$ flask run\nAPI\nPredict price\nMethod: POST\nURL: http://127.0.0.1:5000/predict\nPayload:\n{\n    ""total_surface"": 400,\n    ""covered_surface"": 200,\n    ""rooms"": 6,\n    ""bathrooms"": 2,\n    ""garages"": 0,\n    ""bedrooms"": 2,\n    ""toilettes"": 2,\n    ""antiquity"": 0,\n    ""zone"": ""Pilar""\n}\nResponse example:\n{\n  ""price"": 500000\n}\nGet all zones\nMethod: GET\nURL: http://127.0.0.1:5000/zones\nResponse example:\n[\n  ""Pilar"",\n  ""Nordelta"",\n  ""San Isidro""\n]\nGet price in function of the total or covered surface\nMethod: GET\nURL: http://127.0.0.1:5000/prices\nParams:\n\nsurface: [\'covered\', \'total\']\n\nResponse example:\n[\n  {\n\t""total_surface"": 400,\n\t""average_price"": 500000\n  },\n  {\n\t""total_surface"": 500,\n\t""average_price"": 600000\n  }\n]\nGet amount of houses by zone\nMethod: GET\nURL: http://127.0.0.1:5000/houses\nResponse example:\n[\n  {\n\t""zone"": ""Pilar"",\n\t""amount"": 328\n  },\n  {\n\t""zone"": ""Nordelta"",\n\t""amount"": 200\n  }\n]\n\nAverage price by zone\nMethod: GET\nURL: http://127.0.0.1:5000/prices/by-zone/average\nParams:\n\nrange: [\'asc\', \'desc\']\ntop: number\n\nResponse example:\n[\n  {\n    ""zone"": ""Pilar"",\n\t""average_price"": 150000\n  },\n  {\n    ""zone"": ""Nordelta"",\n\t""average_price"": 300000\n  }\n]\nAverage price by bathrooms amount\nMethod: GET\nURL: http://127.0.0.1:5000/prices/by-bathrooms\nResponse example:\n[\n  {\n    ""bathrooms"": 1,\n\t""average_price"": 150000\n  },\n  {\n    ""zone"": 3,\n\t""average_price"": 300000\n  }\n]\nPrices by zone\nMethod: GET\nURL: http://127.0.0.1:5000/prices/by-zone/average\nResponse example:\n[\n    {\n        ""amount"": 22,\n        ""class"": 0,\n        ""zone"": ""Almirante Brown""\n    },\n    {\n        ""amount"": 23,\n        ""class"": 1,\n        ""zone"": ""Almirante Brown""\n    }\n]\n'], 'url_profile': 'https://github.com/brianfroschauer', 'info_list': ['Jupyter Notebook', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Python', 'Updated Jul 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 6, 2020', 'R', 'Updated Apr 9, 2020', 'R', 'Updated May 5, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': ['ImageClassification\nMulti-class logistic regression on CIFAR-10 dataset using the cross entropy loss\n'], 'url_profile': 'https://github.com/aasthagoyal46', 'info_list': ['Jupyter Notebook', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Python', 'Updated Jul 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 6, 2020', 'R', 'Updated Apr 9, 2020', 'R', 'Updated May 5, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020']}","{'location': 'Bengaluru', 'stats_list': [], 'contributions': '50 contributions\n        in the last year', 'description': ['Suport-Vector-Regression--scikit--learn\nThis code help to understand step wise SVM algo for regression model.\n'], 'url_profile': 'https://github.com/kdmac', 'info_list': ['Jupyter Notebook', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Python', 'Updated Jul 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 6, 2020', 'R', 'Updated Apr 9, 2020', 'R', 'Updated May 5, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '80 contributions\n        in the last year', 'description': ['MINST-DATA\nClassification of digits[MINST-DATA] using logistic regression and naive bayes\n'], 'url_profile': 'https://github.com/asrini56', 'info_list': ['Jupyter Notebook', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Python', 'Updated Jul 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 6, 2020', 'R', 'Updated Apr 9, 2020', 'R', 'Updated May 5, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020']}","{'location': 'Nancy', 'stats_list': [], 'contributions': '127 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ulookme', 'info_list': ['Jupyter Notebook', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Python', 'Updated Jul 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 6, 2020', 'R', 'Updated Apr 9, 2020', 'R', 'Updated May 5, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Robust Mixture Regression\nr package\nr package link [https://cran.r-project.org/web/packages/RobMixReg/index.html]\nmanual document [https://cran.r-project.org/web/packages/RobMixReg/RobMixReg.pdf]\n\nLicense: \nDownload: \n\nRobust Mixture Regression Plot (with outliers)\n\nAdd Regresseion Line\n\nInstall from CRAN\ninstall.packages(""RobMixReg)\nlibrary(""RobMixReg"")\n\nInstall from github for most updated package.\nPlease report the bug as the description in the Question&Problem.\nlibrary(""devtools"")\ndevtools::install_github(""changwn/RobMixReg"")\n\nExample\nlibrary(RobMixReg)\n#library(robust)\nlibrary(flexmix)\nlibrary(robustbase)\nlibrary(MASS)\nlibrary(gtools)\n\n# gaussData\nx=(gaussData$x);y=as.numeric(gaussData$y);\nformula01=as.formula(""y~x"")\nexample_data01=data.frame(x,y)\n\nres_rmr = rmr(lr.method=\'flexmix\', formula=formula01, data=example_data01)\nres_rmr = rmr(lr.method=\'TLE\', formula=formula01, data=example_data01)\nres_rmr = rmr(lr.method=\'CTLE\', formula=formula01, data=example_data01)\nres_rmr = rmr(lr.method=\'mixbi\', formula=formula01, data=example_data01)\nres_rmr = rmr(lr.method=\'mixLp\', formula=formula01, data=example_data01)\n\n# simuData\nexample_data02 <- simuData[,1:3]\nformula02=as.formula(""y~X1+X2"")\n\nres_rmr = rmr(lr.method=\'flexmix\', formula=formula01, data=example_data01, nc=3)\nres_rmr = rmr(lr.method=\'TLE\', formula=formula01, data=example_data01, nc=3,tRatio=0.05)\nres_rmr = rmr(lr.method=\'CTLE\', formula=formula01, data=example_data01, nc=3)\nres_rmr = rmr(lr.method=\'mixbi\', formula=formula01, data=example_data01, nc=3)\nres_rmr = rmr(lr.method=\'mixLp\', formula=formula01, data=example_data01, nc=3)\n\n\nQuestions & Problems\nIf you have any questions or problems, please feel free to open a new issue here. We will fix the new issue ASAP.  You can also email the maintainers and authors below.\n\nWennan Chang\n(wnchang@iu.edu)\n\nPhD candidate at BDR group, Indiana University School of Medicine\n\nSha Cao\n(shacao@iu.edu)\n\nAssistant Professor\nDepartment of Biostatistics, Indiana University School of Medicine\n'], 'url_profile': 'https://github.com/zcslab', 'info_list': ['Jupyter Notebook', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Python', 'Updated Jul 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 6, 2020', 'R', 'Updated Apr 9, 2020', 'R', 'Updated May 5, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '45 contributions\n        in the last year', 'description': ['House_Prices__Prediction\nR project - Predicting house sale prices of Aimes, Iowa. Kaggle competition - House Prices: Advanced Regression Techniques\n'], 'url_profile': 'https://github.com/andresoliverac', 'info_list': ['Jupyter Notebook', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Python', 'Updated Jul 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 6, 2020', 'R', 'Updated Apr 9, 2020', 'R', 'Updated May 5, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '76 contributions\n        in the last year', 'description': ['ML - SVM, GMM, Linear Regression & K-Means Clustering\nIn this part we implemented 6 questions based on SVM, GMM, Linear Regression & K-Means Clustering.\n'], 'url_profile': 'https://github.com/Sagnik07', 'info_list': ['Jupyter Notebook', 'Updated Apr 20, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Python', 'Updated Jul 26, 2020', 'Jupyter Notebook', 'Updated Apr 14, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 6, 2020', 'R', 'Updated Apr 9, 2020', 'R', 'Updated May 5, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '47 contributions\n        in the last year', 'description': ['LinearRegression-with-BackwardElimination\nPredicting Housing price using Linear regression and improving the model by performing backward elimination\n'], 'url_profile': 'https://github.com/Shreyas670', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Jul 3, 2020', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'C++', 'Updated Apr 9, 2020', 'C', 'MIT license', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Oct 17, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '264 contributions\n        in the last year', 'description': ['Flight Delay Prediction by Logistic Regression\nFollowing the dataset provided, developed a system that would analyze the flight delays for the airport authorities. This would assist them in revamping their operations for better services.\nModel accuracy of 81%\n'], 'url_profile': 'https://github.com/FarheenB', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Jul 3, 2020', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'C++', 'Updated Apr 9, 2020', 'C', 'MIT license', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Oct 17, 2020']}","{'location': 'Rio de Janeiro', 'stats_list': [], 'contributions': '29 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/g-dant', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Jul 3, 2020', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'C++', 'Updated Apr 9, 2020', 'C', 'MIT license', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Oct 17, 2020']}","{'location': 'Surat, Gujarat, India', 'stats_list': [], 'contributions': '127 contributions\n        in the last year', 'description': ['Sentiment-Analysis-with-scikit-learn-and-nltk\nUses voting from NaiveBayes, LinearSVC, MultinomialBinary, BernoulliNB, Logistic Regression for final result\nAbout the training dataset\n\nThe dataset is a collection of some ~10000 postive and negative reviews.\n\nExternal Python Dependencies\n\npython7.7.7\nScikit Learn@0.22.2\nnltk@3.5b1\n\nInstalling\n\nRun the jupter notebook Sentiment_Analysis_Notebook.ipynb. It will fill the pickled_files directory with saved models.\nOnce done you can import sentiment_analysis.py module\n\nExample Usage\n\nWhile inside the directory containing the sentiment_analysis.py file and the pickled_files folder\n\nimport sentiment_analysis as s\n\nprint(s.sentiment(""The movies was very bad. They acting was horrible. Very bad experience! 0/10!""))\n'], 'url_profile': 'https://github.com/zed1025', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Jul 3, 2020', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'C++', 'Updated Apr 9, 2020', 'C', 'MIT license', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Oct 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['QPADMslack\nR package for nonconvex penalized quantile regression in distributed big data based on ADMM.\nIt can be used to reproduce the simulation studies in the following paper:\nYe Fan, Nan Lin and Xianjun Yin. Penalized Quantile Regression for Distributed Big Data Using the Slack Variable Representation.\nTwo main functions are included: QPADMslack( ) and paraQPADMslack( ), designed for the distributed and the non-distributed computation, repectively.\n'], 'url_profile': 'https://github.com/nanlin999', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Jul 3, 2020', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'C++', 'Updated Apr 9, 2020', 'C', 'MIT license', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Oct 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': [""\nR package SBLF\n\n\nOverview\nThis R package provides a user-friendly interface for fitting spatial\nBayesian latent factor models. Uncover the latent brain image structure\nusing image on image regression.\nInstallation\nThe package is currently only runnable on Linux. Windows or Mac users\ncan run a virtual Linux distribution on their machine or use a cluster.\nTo install, open R and run:\nIf the devtools package is not yet installed, install it first:\ninstall.packages('devtools')\nlibrary(devtools)\n# install SBLF from Github:\ninstall_github('umich-biostatistics/SBLF') \nlibrary(SBLF)\nExample usage\nQuick example:\n?SBLF\nmod = SBLF(xtrain, xtest, ztrain, ztest, voxel_loc, seed = 1234, burnin = 250, iter = 500)\n""], 'url_profile': 'https://github.com/umich-biostatistics', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Jul 3, 2020', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'C++', 'Updated Apr 9, 2020', 'C', 'MIT license', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Oct 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['Titanic Survival Guide\nAnalyzing Titanic passengers in order to create a logistic regression to predict passenger survival probability.\n'], 'url_profile': 'https://github.com/Dasheikh', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Jul 3, 2020', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'C++', 'Updated Apr 9, 2020', 'C', 'MIT license', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Oct 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/abdulrehman03365', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Jul 3, 2020', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'C++', 'Updated Apr 9, 2020', 'C', 'MIT license', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Oct 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '109 contributions\n        in the last year', 'description': ['salary_app\nPredicts the salary of the new employees from the trained ML model using Linear Regression\n\ncontains the dataset used and the python file used to train the model\nthe python file used to use the developed model that can be used as an application\nuse the program in the command prompt or the python compiler\nrun the second file directly which will bw using the pretrained model\n\n'], 'url_profile': 'https://github.com/Vaibhav-Mehta-19', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Jul 3, 2020', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'C++', 'Updated Apr 9, 2020', 'C', 'MIT license', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Oct 17, 2020']}","{'location': 'Edinburgh, United Kingdom', 'stats_list': [], 'contributions': '68 contributions\n        in the last year', 'description': ['Introductory Applied Machine Learning\nExploration on various datasets using regression and classification models on SKLearn.\n'], 'url_profile': 'https://github.com/RaresTudorache', 'info_list': ['Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Jul 3, 2020', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'C++', 'Updated Apr 9, 2020', 'C', 'MIT license', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Oct 17, 2020']}"
"{'location': 'Los Angeles', 'stats_list': [], 'contributions': '65 contributions\n        in the last year', 'description': ['Deep NN for Binary Classification\nImproved accuracy and performance over traditional logistic regression model by careful construction of deep NN\n'], 'url_profile': 'https://github.com/Kripakaran', 'info_list': ['Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 17, 2020', '1', 'Python', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Jul 20, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Jun 9, 2020', 'R', 'Updated Dec 29, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['all-about-linear-regression-with-python\nThis tutorial here will explain all about linear regression. Well, not all, but all what you need to know!\nTopics Covered\n\nIntroduction\nPre Modelling Assumptions\nExploratory Data Analysis\nModelling\nPost Modelling Assumptions\nHypertuning\nEvaluation\nConclusion\n\nIntroduction\n'], 'url_profile': 'https://github.com/data-science-and-stuff', 'info_list': ['Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 17, 2020', '1', 'Python', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Jul 20, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Jun 9, 2020', 'R', 'Updated Dec 29, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Belo Horizonte', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['Corona-virus\nForecast of corona virus in next two days using polinomial regression in python\nThis script code 2 make some forecast about the incidence of corona virus in Brazil for the next two months\nTo run, the file covid_19_data and the script code 2 must be in the some directory. This algorith uses polinomial regression.\n'], 'url_profile': 'https://github.com/lucasarielrc', 'info_list': ['Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 17, 2020', '1', 'Python', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Jul 20, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Jun 9, 2020', 'R', 'Updated Dec 29, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '45 contributions\n        in the last year', 'description': ['Description\nDo regression analysis for number of followers and favorites of some tweets related to specific topics for acquiring popular tweets and make the list of them on website from the result.\nCurrently, the topic is Splatoon!\nbuzzclip\nThe name of Django project. It contains settings.py.\nMainapp\nDjango application that handles data and passes it to React through API.\nIt also contain the analysis script named ""analyzer.py"" that works like referred to in description.\nfrontend\nReact application. in App.js, React takes data of tweets from API and embed them.\nanalysis method\nCode shown as below is performed under analyzer.py\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv(\'tweet_data.csv\') # a data list from twitter API contains number of followers and favorites.\ndf = df[df[""followers""] != 0].sort_values(""followers"")\n\nx = df[""followers""]\ny = df[""fav""]\n\nplt.plot(x, y, ""o"")\n\ndef reg1dim(x, y):\n    n = len(x)\n    a = ((np.dot(x, y)- y.sum() * x.sum()/n)/\n        ((x ** 2).sum() - x.sum()**2 / n))\n    b = (y.sum() - a * x.sum())/n\n    return a, b\n\na, b = reg1dim(x, y)\n\nprint(a)\nprint(b)\n\nplt.plot(x, a * x + b)\n\nplt.xscale(\'log\')\nplt.yscale(\'log\')\nplt.xlabel(\'follower\')\nplt.ylabel(\'favorite\')\nplt.grid(which=\'both\')\n\n\nbuz_factors = [] \n# Popularity Index. introduced by calculating the ratio of the number of favorites of each tweet to avarage number of it.\n\nfor i in range(len(df)):\n    factor = y.values[i] / (a * x.values[i] + b)\n    buz_factors.append(factor)\n\ndf[""buz_factors""] = buz_factors\n\nx = df[""followers""]\ny = df[""buz_factors""]\n\nplt.plot(x, y, ""o"")\n\nplt.xscale(\'log\')\nplt.yscale(\'log\')\nplt.xlabel(\'followers\')\nplt.ylabel(\'popularity\')\nplt.grid(which=\'both\')\n\n\nIf popularity is 10^2, that tweet has 100 times as many favorites as avarage.\ndf.to_csv(\'mediaanalyzed.csv\')\n\n'], 'url_profile': 'https://github.com/ryu38', 'info_list': ['Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 17, 2020', '1', 'Python', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Jul 20, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Jun 9, 2020', 'R', 'Updated Dec 29, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'New Braunfels, Texas', 'stats_list': [], 'contributions': '401 contributions\n        in the last year', 'description': ['Creating a Model\nthat can be used to predict property value using zillow data\nHypothesis:\n\n$H_0$: Number of bathrooms and bedrooms in home, as well as square footage will not be leading factors in predicting property value\n$H_a$: Number of bathrooms, bedrooms and square footage will have a strong reciprocy for predicting property value.\n$H_a$: Using recursive feature elimination from SK.learn will proove a different variation of features that will predict features mentioned above but not discluding other possible features included in the dataset\n\nData Dictionary\n\n\n\nUnit-Title\nDescription\n\n\n\n\nid\nprimary-key / index\n\n\nbathroomcnt\nNumber of restrooms in unit (including half-baths and quarter-baths)\n\n\nbedroomcnt\nNumber of bedrooms in unit\n\n\ncalculatedfinishedsquarefeet\nSquare footage of the property\n\n\nroomcnt\nNumber of rooms in unit\n\n\nstructuretaxvaluedollarcnt\nproperty value\n\n\ntaxamount\nThe amount the homeowner was taxed\n\n\ntransactiondate\nThe date of the last transaction\n\n\n\nDeliverables\n\nLink for google presentation HERE.\nGitHub repository above\n\nTo Reproduce My Results\n\nenv.py file is required with log-in credentials to the database used\nMy SQL query is in the zillow_wrangle.py file in the repository above\nrandom state used in the split my data function is 830\n\n'], 'url_profile': 'https://github.com/jivemachine', 'info_list': ['Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 17, 2020', '1', 'Python', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Jul 20, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Jun 9, 2020', 'R', 'Updated Dec 29, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Ahmedabad, Gujarat, India', 'stats_list': [], 'contributions': '40 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Vishvam17', 'info_list': ['Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 17, 2020', '1', 'Python', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Jul 20, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Jun 9, 2020', 'R', 'Updated Dec 29, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '10 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/AegorDemov', 'info_list': ['Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 17, 2020', '1', 'Python', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Jul 20, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Jun 9, 2020', 'R', 'Updated Dec 29, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Portugal', 'stats_list': [], 'contributions': '34 contributions\n        in the last year', 'description': [""Gaussian Regression via Monte Carlo Sampling\nGaussian Regression via Monte Carlo Sampling.  A different method for extracting values of a gaussian distribution.\nProblem\nThis problem arose from a need to calculate the width of a laser spectrum after it passes through an interference filter multiple\ntimes.\nI needed to calculate whether it's width would be shortened after multiple passes. Through simple graphical analysics I could not\nsee if it was happening or not. To overcome this problem I needed to find a regression. Once I had the regression and\nthe equation of the curve, I would be able to access whether it's width was shorterened or not.\nTo find the regression I decided to use pseudo random numbers to extract the equation of a normal distribution that fits the lab\ndata and also gives me full control over the precision of the fit curve.\nMethod\nBenefits of this method\n\nEasy to implement;\nFast to calculate;\nFully controlled precision;\nGives the precision of the method.\n\nProcedure\nThis method consists of 7 steps:\n\nImport excel data into python readable data;\nTransform data into probabilistic data using normalization;\nDraw m samples, each of size n, of the probabilistic data;\nFor each sample calculate its average and standard deviation;\nStore these values in a list of average values and in a list of stadard deviations;\nNow that we can apply Central Limit Theorem, calculate the average value of each of the previously mentioned lsits;\nFor each case, calculate the confidence interval.\n\nThe code itself is well documented and explains every step, as well as the mathematical explanation.\n""], 'url_profile': 'https://github.com/MShumskiy', 'info_list': ['Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 17, 2020', '1', 'Python', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Jul 20, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Jun 9, 2020', 'R', 'Updated Dec 29, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7 contributions\n        in the last year', 'description': ['2Stage-Sparse-IVR\nThe R codes for learning sparse instrumental variable regression with 2 stage methods\n'], 'url_profile': 'https://github.com/mortamini', 'info_list': ['Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 17, 2020', '1', 'Python', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Jul 20, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Jun 9, 2020', 'R', 'Updated Dec 29, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Dallas', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ktgrandhi', 'info_list': ['Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 17, 2020', '1', 'Python', 'Updated Apr 9, 2020', 'JavaScript', 'Updated Jul 20, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Jun 9, 2020', 'R', 'Updated Dec 29, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}"
"{'location': 'Germany', 'stats_list': [], 'contributions': '44 contributions\n        in the last year', 'description': ['Probabilistc Machine Learning Models\nIntroduction\nThis Repository contains various probabilistic Machine Learning models and with their libraries for regression tasks. A short summary is given in the following table. Goal of this is to collect possible algorithms and compare them. All the algorithms have a similar object oriented structure and use pytorch as main library\n\n\n\nAlgorithm\nDescription\nFile\n\n\n\n\nBayesian Neural Network\nBayesian neural network using the Pyro library\nbnn_pyro\n\n\nBootstrap Neural Network\nBootstrap neural network with cuda option\nbootstrap_net_pytorch_cuda\n\n\nMonte Carlo Dropout Neural Network\nMonte Carlo dropout neural network with cuda option\nmc_net_pytorch_cuda\n\n\nMonte Carlo LSTM Neural Network\nMonte Carlo Long Short Term Memory neural network\nmc_lstm_pytorch\n\n\nDeep Ensemble Monte Carlo Droupout Neural Network\nDeep Ensemble dropout neural network\npytorch_mc_deep_ensemble\n\n\nQuantile Regression Neural Network\nQuantile Regression Neural Network\nquantile_reg_nn\n\n\nGaussian Process\nGaussian Process using Pyro library\ngaussian_process_pyro\n\n\nGaussian Process\nGaussian Process using GPytorch library\nGPR_gpytorch_pyro\n\n\nSparse Gaussian Process\nGaussian Process using Pyro library\nsparse_gaussian_process_pytro\n\n\nSparse Gaussian Process\nGaussian Process using GPytorch library\nsparse_gpytorch\n\n\n\nTo do\n\n Implement Bayesian Neural Network in comparison\n Implement Monte Carlo LSTM in comparison\n Implement Deep Ensemble Monte Carlo Droupout in comparison\n Implement Pyro Gaussian Process  in comparison\n Implement Pyro sparse Gaussian Process  in comparison\n Implement Gpytorch Gaussian Process  in comparison\n Implement Gpytorch sparse Gaussian Process  in comparison\n\nFile and folder description\n\n\n\nFile/Folder\nDescription\n\n\n\n\ncomparison.ipynb\nJupyter notebook with the comparison of the algorithm\n\n\nmoedels\nFolder containing the compared models\n\n\n\nInstallation\npip install -r requirements.txt\nIf you can want to run the file in a new enviroment:\n\nMake sure conda is installed (Best practice, set up with virtualenv is not tested)\nOpen a terminal or a anaconda prompt\nIf desired make new enviroment: conda create -n name_of_enviroment python\nActivate enviroment conda activate: conda create name_of_enviroment\nInstall dependencies: pip install requirements.txt\nIf the new enviroment / kernel is supposed to be used in Jupyter, install kernel:\npython -m ipykernel install --name name_of_enviroment\nOpen your Jupyter Notebook it should work now\n\n'], 'url_profile': 'https://github.com/MonNum5', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'HTML', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 1, 2020', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'Raleigh', 'stats_list': [], 'contributions': '180 contributions\n        in the last year', 'description': ['SGD-for-Linear-Regression-with-L2-Regularization\nCode for Stochastic Gradient Descent for Linear Regression with L2 Regularization in Python 3.\nReferences:\n\nhttps://machinelearningmastery.com/implement-linear-regression-stochastic-gradient-descent-scratch-python/\nhttps://machinelearningmastery.com/implement-simple-linear-regression-scratch-python/\nhttps://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b\n'], 'url_profile': 'https://github.com/rohanpillai20', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'HTML', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 1, 2020', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': [""Multiple-linear-regression-python-sklearn\nIt's a multiple linear regression  algorithm to predict the price of used car .\n""], 'url_profile': 'https://github.com/Aminouad', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'HTML', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 1, 2020', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'Latvia', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/pilots7', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'HTML', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 1, 2020', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': [""Singapore Property Prices\nThis project aims to build a regression model to predict property prices in Singapore.\nCurrent Status\nRegression model has been built and is being refined for HDB resale prices using the HDB resale price data available at data.gov.sg here: https://data.gov.sg/dataset/resale-flat-prices. The current model achieves an R-squared of 0.89 in predicting resale flat prices.\nSome features that have been engineered, with the help of Geocoding and Google's distance matrix APIs, include:\n\nDistance to nearest MRT/LRT station\nDistance to shopping malls\nTravel time from nearest station to CBD\n\nA web-scraping bot implemented in scrapy has also been built to scrape listing data from 99co.\nInitial model accuracy for the HDB data from 99co is low, at an R-squared of 0.47. However, this may be because 99co reflects the listed price and not the actual resale price.\nWork in progress\n\nRefine model for 99co listings\nBuilt an automated tool to detect under-priced 99co listings and send alert via email\n\n""], 'url_profile': 'https://github.com/justinwyq', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'HTML', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 1, 2020', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'Boston', 'stats_list': [], 'contributions': '37 contributions\n        in the last year', 'description': ['Character-Recognition\nBuilt a Logistic Regression algorithm from scratch, to recognise a character given an image.\nThere are 2 files with 28 *28 grayscale images. Each image is encoded as a row of 784 integer values between 0 and 255 indicating the brightness of each pixel.\nThe label associated with each image is encoded as an integer value between 0 and 9. The dataset is an MNIST dataset.\nResults-\nThe model has an accuracy of 0.9175. The maximum number of misclassifications is for the digit 5, while, the minimum number of misclassifications is for the digit 0.\n'], 'url_profile': 'https://github.com/manpreetkaurassi', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'HTML', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 1, 2020', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'Atlanta, GA', 'stats_list': [], 'contributions': '102 contributions\n        in the last year', 'description': ['COVID19_Cases_Prediction\nPolynomial regression to capture trend changes for confirmed cases predictions per day\nYoutube video:\nhttps://youtu.be/oWgofKBK9VQ\n'], 'url_profile': 'https://github.com/GreenMouth', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'HTML', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 1, 2020', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['test\n'], 'url_profile': 'https://github.com/oracc', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'HTML', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 1, 2020', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['ITC6003finalproject\nITC 6003 course project for Deree MSc Data Science. Machine learning, classification, regression, clustering\nIt consistists of 4 parts that are the 4 tasks we were asked to perform:\n\n\nClassification: Predicting arrhythmia type (20%)\nSource data & description: http://archive.ics.uci.edu/ml/datasets/Arrhythmia\nThe aim is to distinguish between the presence and absence of cardiac arrhythmia and to classify it in\none of the 16 groups.\n\n\nClustering: Market Segmentation: Unsupervised learning (20%)\nSource data & description: https://archive.ics.uci.edu/ml/datasets/Wholesale+customers\nDiscover clusters, evaluate and characterize them.\n\n\nRegression (20%)\nIt is up to you to choose regression task, but you should inform the instructor and get approval for it.\nIndicative data sources: Kaggle.com , https://www.analyticsvidhya.com/ ,\nhttps://github.com/awesomedata/awesome-public-datasets , https://www.openml.org/ .\n\n\nScaling-up: Predicting buys (20%)\nSource data & description: https://2015.recsyschallenge.com/challenge.html Your task is to predict\nwhether a user will buy a product or not based on his/her online behavior, and in particular his/her\nclicks during a session. There are two files:\nyoochoose-clicks.dat - Click events. Each record/line in the file has the following fields:\nâ€¢ Session ID â€“ the id of the session. In one session there are one or many clicks.\nâ€¢ Timestamp â€“ the time when the click occurred.\nâ€¢ Item ID â€“ the unique identifier of the item.\nâ€¢ Category â€“ the category of the item.\nyoochoose-buys.dat - Buy events. Each record/line in the file has the following fields:\nâ€¢ Session ID - the id of the session. In one session there are one or many buying events.\nâ€¢ Timestamp - the time when the buy occurred.\nâ€¢ Item ID â€“ the unique identifier of item.\nâ€¢ Price â€“ the price of the item.\nâ€¢ Quantity â€“ how many of this item were bought.\nThe Session ID in yoochoose-buys.dat will always exist in the yoochoose-clicks.dat file â€“ the records with\nthe same Session ID together form the sequence of click events of a certain user during the session. The\nsession could be short (few minutes) or very long (few hours), it could have one click or hundreds of\nclicks. All depends on the activity of the user.\n\n\nTasks to perform\n\nBuild a data set that can be used in classifier to decide whether someone will buy or not.\nPreprocess the data & perform classification\n\n'], 'url_profile': 'https://github.com/apostolisken', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'HTML', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 1, 2020', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020']}","{'location': 'Hyderabad', 'stats_list': [], 'contributions': '255 contributions\n        in the last year', 'description': ['Simple_Classifier_Model:\n\nSimple Classifier Model for sentiment analysis of movie reviews using Logistic regression\nIn this case, I have used simple regression techniwue to achieve 85% accuracy for classifying movies reviews taken from\nhttps://www.kaggle.com/utathya/sentiment-analysis-of-imdb-reviews.\n\n'], 'url_profile': 'https://github.com/Kausthub8', 'info_list': ['1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'HTML', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 1, 2020', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 7, 2020']}"
"{'location': 'France', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['Scipy-Optimize-with-constraints\nAn example of a constrained optimization problem dealt with Scipy\n'], 'url_profile': 'https://github.com/Lucadel', 'info_list': ['Jupyter Notebook', 'Updated Jul 14, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', '1', 'Python', 'Updated Jun 27, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Jan 23, 2021', 'Jupyter Notebook', 'Updated Apr 13, 2020']}","{'location': 'Ä°stanbul', 'stats_list': [], 'contributions': '9 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Rhavutcu', 'info_list': ['Jupyter Notebook', 'Updated Jul 14, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', '1', 'Python', 'Updated Jun 27, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Jan 23, 2021', 'Jupyter Notebook', 'Updated Apr 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '42 contributions\n        in the last year', 'description': [""Cancer-data-OLS-regression-challange\nData is from the following source and was used for my personal education uses only.\nhttps://data.world/nrippner/ols-regression-challenge\ndata read me paseted below.\nData Dictionary\nTARGET_deathRate: Dependent variable. Mean per capita (100,000) cancer mortalities(a)\navgAnnCount: Mean number of reported cases of cancer diagnosed annually(a)\navgDeathsPerYear: Mean number of reported mortalities due to cancer(a)\nincidenceRate: Mean per capita (100,000) cancer diagoses(a)\nmedianIncome: Median income per county (b)\npopEst2015: Population of county (b)\npovertyPercent: Percent of populace in poverty (b)\nstudyPerCap: Per capita number of cancer-related clinical trials per county (a)\nbinnedInc: Median income per capita binned by decile (b)\nMedianAge: Median age of county residents (b)\nMedianAgeMale: Median age of male county residents (b)\nMedianAgeFemale: Median age of female county residents (b)\nGeography: County name (b)\nAvgHouseholdSize: Mean household size of county (b)\nPercentMarried: Percent of county residents who are married (b)\nPctNoHS18_24: Percent of county residents ages 18-24 highest education attained: less than high school (b)\nPctHS18_24: Percent of county residents ages 18-24 highest education attained: high school diploma (b)\nPctSomeCol18_24: Percent of county residents ages 18-24 highest education attained: some college (b)\nPctBachDeg18_24: Percent of county residents ages 18-24 highest education attained: bachelor's degree (b)\nPctHS25_Over: Percent of county residents ages 25 and over highest education attained: high school diploma (b)\nPctBachDeg25_Over: Percent of county residents ages 25 and over highest education attained: bachelor's degree (b)\nPctEmployed16_Over: Percent of county residents ages 16 and over employed (b)\nPctUnemployed16_Over: Percent of county residents ages 16 and over unemployed (b)\nPctPrivateCoverage: Percent of county residents with private health coverage (b)\nPctPrivateCoverageAlone: Percent of county residents with private health coverage alone (no public assistance) (b)\nPctEmpPrivCoverage: Percent of county residents with employee-provided private health coverage (b)\nPctPublicCoverage: Percent of county residents with government-provided health coverage (b)\nPctPubliceCoverageAlone: Percent of county residents with government-provided health coverage alone (b)\nPctWhite: Percent of county residents who identify as White (b)\nPctBlack: Percent of county residents who identify as Black (b)\nPctAsian: Percent of county residents who identify as Asian (b)\nPctOtherRace: Percent of county residents who identify in a category which is not White, Black, or Asian (b)\nPctMarriedHouseholds: Percent of married households (b)\nBirthRate: Number of live births relative to number of women in county (b)\n(a): years 2010-2016\n(b): 2013 Census Estimates\n""], 'url_profile': 'https://github.com/JohnRMcK', 'info_list': ['Jupyter Notebook', 'Updated Jul 14, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', '1', 'Python', 'Updated Jun 27, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Jan 23, 2021', 'Jupyter Notebook', 'Updated Apr 13, 2020']}","{'location': 'Canada', 'stats_list': [], 'contributions': '69 contributions\n        in the last year', 'description': ['COVID-19-linear-regression-model\n'], 'url_profile': 'https://github.com/nikunjdnp', 'info_list': ['Jupyter Notebook', 'Updated Jul 14, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', '1', 'Python', 'Updated Jun 27, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Jan 23, 2021', 'Jupyter Notebook', 'Updated Apr 13, 2020']}","{'location': 'Columbus, OH', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['Classification-and-Regression-Tree-CART-\nA machine learning predictive model to classify individuals based on behavior or segment health customers\n'], 'url_profile': 'https://github.com/TarikuJBeyene', 'info_list': ['Jupyter Notebook', 'Updated Jul 14, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', '1', 'Python', 'Updated Jun 27, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Jan 23, 2021', 'Jupyter Notebook', 'Updated Apr 13, 2020']}","{'location': 'Buffalo,New York', 'stats_list': [], 'contributions': '17 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/rgadalay', 'info_list': ['Jupyter Notebook', 'Updated Jul 14, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', '1', 'Python', 'Updated Jun 27, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Jan 23, 2021', 'Jupyter Notebook', 'Updated Apr 13, 2020']}","{'location': 'Quebec,Canada', 'stats_list': [], 'contributions': '130 contributions\n        in the last year', 'description': [""PrÃ©diction-prix-maison-rÃ©gression-linÃ©aire\nCe repository se compose d'un cahier python qui explique le processus de prÃ©diction des prix des logements Ã  l'aide de modÃ¨les d'apprentissage automatique et de visualisations de donnÃ©es Ã  l'aide de python. Le code est disponible avec la language de python.\n""], 'url_profile': 'https://github.com/tristandanle', 'info_list': ['Jupyter Notebook', 'Updated Jul 14, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', '1', 'Python', 'Updated Jun 27, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Jan 23, 2021', 'Jupyter Notebook', 'Updated Apr 13, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '73 contributions\n        in the last year', 'description': ['breast-cancer-detection-logistic-regression\nWe use Logistic model for detecting breast cancer\n'], 'url_profile': 'https://github.com/programmerMayur', 'info_list': ['Jupyter Notebook', 'Updated Jul 14, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', '1', 'Python', 'Updated Jun 27, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Jan 23, 2021', 'Jupyter Notebook', 'Updated Apr 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/hmjung-cpu', 'info_list': ['Jupyter Notebook', 'Updated Jul 14, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', '1', 'Python', 'Updated Jun 27, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Jan 23, 2021', 'Jupyter Notebook', 'Updated Apr 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '216 contributions\n        in the last year', 'description': ['Movie-review-with-Logistic-Regression\nUsing TF- IDF and Logistic Regression to train model.\nUse Pinline to connect all things together.\n'], 'url_profile': 'https://github.com/trantntran', 'info_list': ['Jupyter Notebook', 'Updated Jul 14, 2020', 'Python', 'Updated Apr 6, 2020', 'Updated Apr 6, 2020', '1', 'Python', 'Updated Jun 27, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Jan 23, 2021', 'Jupyter Notebook', 'Updated Apr 13, 2020']}"
"{'location': 'India', 'stats_list': [], 'contributions': '69 contributions\n        in the last year', 'description': ['Logistic-Regression-Without-any-library-\nA simple classification problem of 2 sets of points red and blue, which are classified with logistic regression.\nUsed functions are:\n\nError Funtion     : Cross Entropy\nOptimizing Funtion: Gradient Descent\nActivation Funtion: Sigmoid\n\nScreenshot\n\n'], 'url_profile': 'https://github.com/dark-jay', 'info_list': ['Python', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 7, 2020', 'Python', 'Updated Apr 18, 2020']}","{'location': 'Bhubaneswar', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': ['Logistic Regression with example : Diabetes Detection\nLogistic Regression is a Machine Learning algorithm which is used for the classification problems, it is a predictive analysis algorithm and based on the concept of probability.\n\nAs shown in the picture if you are trying to figure out the test will pass or fail; that is known as Logistic regression. Lets see some real world example\n\nTo predict whether an email is spam (1) or (0)\nWhether the tumour is malignant (1) or not (0)\nIf you are diabetic  (1) or not (0)\n\nConsider a scenario where we need to classify whether an email is spam or not. If we use linear regression for this problem, there is a need for setting up a threshold based on which classification can be done. Say if the actual class is malignant, predicted continuous value 0.4 and the threshold value is 0.5, the data point will be classified as not malignant which can lead to serious consequence in real time.\nFrom this example, it can be inferred that linear regression is not suitable for classification problem. Linear regression is unbounded, and this brings logistic regression into picture. Their value strictly ranges from 0 to 1.\nProject:\nTo make the learning project easier and productive, we are going to learn Logistic Regression by an example of creating a logistic regression model to predict a user is Diabetic or not.\nFirst we are going to collect the dataset and clean it. Then we will create a Logistic regression model with fitting the dataset.\nFileName: diabetic_analysis_logistic_regression.ipynb\nFinally after a successive training itâ€™s our main goal to integrate our machine learning model with the GUIs. You can use tkinter for making a desktop application like we did in Linear Regression example, but here we are going to integrate it with a web framework i.e Flask, to create a website that will take the input parameters from the user and predict if they are Diabetic or not.\nCommand to run the script: python flask_integration\\app.py\n\nHope you have enjoyed learning this, if so share this with others and for more such contents you can connect with me on\nYouTube: https://www.youtube.com/channel/UCmF8qppe02J1ot4Jfwl_lFg\nLinkedIn: https://www.linkedin.com/in/jagwithyou/\nMedium: https://medium.com/@jagwithyou\n'], 'url_profile': 'https://github.com/jagwithyou', 'info_list': ['Python', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 7, 2020', 'Python', 'Updated Apr 18, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '54 contributions\n        in the last year', 'description': ['Polynomial_Linear_regression_Positiion_salary\n'], 'url_profile': 'https://github.com/aishwarya123mathpati', 'info_list': ['Python', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 7, 2020', 'Python', 'Updated Apr 18, 2020']}","{'location': 'Pune', 'stats_list': [], 'contributions': '95 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/nimbhorkarnishant', 'info_list': ['Python', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 7, 2020', 'Python', 'Updated Apr 18, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '216 contributions\n        in the last year', 'description': ['Movie-review-with-Logistic-Regression\nUsing TF- IDF and Logistic Regression to train model.\nUse Pinline to connect all things together.\n'], 'url_profile': 'https://github.com/trantntran', 'info_list': ['Python', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 7, 2020', 'Python', 'Updated Apr 18, 2020']}","{'location': 'India', 'stats_list': [], 'contributions': '48 contributions\n        in the last year', 'description': ['Car-Price-Prediction-LinearRegression\nA Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts.\nThey have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\nWhich variables are significant in predicting the price of a car\nHow well those variables describe the price of a car\nBased on various market surveys, the consulting firm has gathered a large dataset of different types of cars across the Americal market.\nBusiness Goal\nYou are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market.\n'], 'url_profile': 'https://github.com/adasgupta', 'info_list': ['Python', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 7, 2020', 'Python', 'Updated Apr 18, 2020']}","{'location': 'London, UK', 'stats_list': [], 'contributions': '708 contributions\n        in the last year', 'description': ['Project: Regression Modeling with the Boston Housing Dataset\nIntroduction\nIn this lab, you\'ll apply the regression analysis and diagnostics techniques covered in this section to the ""Boston Housing"" dataset. You performed a detailed EDA for this dataset earlier on, and hopefully, you more or less recall how this data is structured! In this lab, you\'ll use some of the features in this dataset to create a linear model to predict the house price!\nObjectives\nYou will be able to:\n\nPerform a linear regression using statsmodels\nDetermine if a particular set of data exhibits the assumptions of linear regression\nEvaluate a linear regression model by using statistical performance metrics pertaining to overall model and specific parameters\nUse the coefficient of determination to determine model performance\nInterpret the parameters of a simple linear regression model in relation to what they signify for specific data\n\nLet\'s get started\nImport necessary libraries and load \'BostonHousing.csv\' as a pandas dataframe\n# Your code here\nThe columns in the Boston housing data represent the dependent and independent variables. The dependent variable here is the median house value MEDV. The description of the other variables is available on KAGGLE.\nInspect the columns of the dataset and comment on type of variables present\n# Your code here\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\ncrim\nzn\nindus\nchas\nnox\nrm\nage\ndis\nrad\ntax\nptratio\nb\nlstat\nmedv\n\n\n\n\n0\n0.00632\n18.0\n2.31\n0\n0.538\n6.575\n65.2\n4.0900\n1\n296\n15.3\n396.90\n4.98\n24.0\n\n\n1\n0.02731\n0.0\n7.07\n0\n0.469\n6.421\n78.9\n4.9671\n2\n242\n17.8\n396.90\n9.14\n21.6\n\n\n2\n0.02729\n0.0\n7.07\n0\n0.469\n7.185\n61.1\n4.9671\n2\n242\n17.8\n392.83\n4.03\n34.7\n\n\n3\n0.03237\n0.0\n2.18\n0\n0.458\n6.998\n45.8\n6.0622\n3\n222\n18.7\n394.63\n2.94\n33.4\n\n\n4\n0.06905\n0.0\n2.18\n0\n0.458\n7.147\n54.2\n6.0622\n3\n222\n18.7\n396.90\n5.33\n36.2\n\n\n\n\n# Record your observations here \nCreate histograms for all variables in the dataset and comment on their shape (uniform or not?)\n# Your code here \n\n# You observations here \nBased on this, we preselected some features  for you which appear to be more \'normal\' than others.\nCreate a new dataset with [\'crim\', \'dis\', \'rm\', \'zn\', \'age\', \'medv\']\n# Your code here\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\ncrim\ndis\nrm\nzn\nage\nmedv\n\n\n\n\n0\n0.00632\n4.0900\n6.575\n18.0\n65.2\n24.0\n\n\n1\n0.02731\n4.9671\n6.421\n0.0\n78.9\n21.6\n\n\n2\n0.02729\n4.9671\n7.185\n0.0\n61.1\n34.7\n\n\n3\n0.03237\n6.0622\n6.998\n0.0\n45.8\n33.4\n\n\n4\n0.06905\n6.0622\n7.147\n0.0\n54.2\n36.2\n\n\n\n\nCheck the linearity assumption for all chosen features with target variable using scatter plots\n# Your code here \n\n\n\n\n\n# Your observations here \nClearly, your data needs a lot of preprocessing to improve the results. This key behind a Kaggle competition is to process the data in such a way that you can identify the relationships and make predictions in the best possible way. For now, we\'ll use the dataset untouched and just move on with the regression. The assumptions are not exactly all fulfilled, but they still hold to a level that we can move on.\nLet\'s do Regression\nNow, let\'s perform a number of simple regression experiments between the chosen independent variables and the dependent variable (price). You\'ll do this in a loop and in every iteration, you should pick one of the independent variables. Perform the following steps:\n\nRun a simple OLS regression between independent and dependent variables\nPlot a regression line on the scatter plots\nPlot the residuals using sm.graphics.plot_regress_exog()\nPlot a Q-Q plot for regression residuals normality test\nStore following values in array for each iteration:\n\nIndependent Variable\nr_squared\'\nintercept\'\n\'slope\'\n\'p-value\'\n\'normality (JB)\'\n\n\nComment on each output\n\n# Your code here\nBoston Housing DataSet - Regression Analysis and Diagnostics for formula: medv~crim\n-------------------------------------------------------------------------------------\n\n\n\n\nPress Enter to continue...\nBoston Housing DataSet - Regression Analysis and Diagnostics for formula: medv~dis\n-------------------------------------------------------------------------------------\n\n\n\n\nPress Enter to continue...\nBoston Housing DataSet - Regression Analysis and Diagnostics for formula: medv~rm\n-------------------------------------------------------------------------------------\n\n\n\n\nPress Enter to continue...\nBoston Housing DataSet - Regression Analysis and Diagnostics for formula: medv~zn\n-------------------------------------------------------------------------------------\n\n\n\n\nPress Enter to continue...\nBoston Housing DataSet - Regression Analysis and Diagnostics for formula: medv~age\n-------------------------------------------------------------------------------------\n\n\n\n\nPress Enter to continue...\n\npd.DataFrame(results)\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\n0\n1\n2\n3\n4\n5\n\n\n\n\n0\nind_var\nr_squared\nintercept\nslope\np-value\nnormality (JB)\n\n\n1\ncrim\n0.15078\n24.0331\n-0.41519\n1.17399e-19\n295.404\n\n\n2\ndis\n0.0624644\n18.3901\n1.09161\n1.20661e-08\n305.104\n\n\n3\nrm\n0.483525\n-34.6706\n9.10211\n2.48723e-74\n612.449\n\n\n4\nzn\n0.129921\n20.9176\n0.14214\n5.71358e-17\n262.387\n\n\n5\nage\n0.142095\n30.9787\n-0.123163\n1.56998e-18\n456.983\n\n\n\n\n#Your observations here \nClearly, the results are not very reliable. The best R-Squared is witnessed with rm, so in this analysis, this is our best predictor.\nHow can you improve these results?\n\nPreprocessing\n\nThis is where the preprocessing of data comes in. Dealing with outliers, normalizing data, scaling values etc. can help regression analysis get more meaningful results from the given data.\n\nAdvanced Analytical Methods\n\nSimple regression is a very basic analysis technique and trying to fit a straight line solution to complex analytical questions may prove to be very inefficient. Later on, you\'ll explore multiple regression where you can use multiple features at once to define a relationship with the outcome. You\'ll also look at some preprocessing and data simplification techniques and revisit the Boston dataset with an improved toolkit.\nLevel up - Optional\nApply some data wrangling skills that you have learned in the previous section to pre-process the set of independent variables we chose above. You can start off with outliers and think of a way to deal with them. See how it affects the goodness of fit.\nSummary\nIn this lab, you applied your skills learned so far on a new data set. You looked at the outcome of your analysis and realized that the data might need some preprocessing to see a clear improvement in the results. You\'ll pick this back up later on, after learning about more preprocessing techniques and advanced modeling techniques.\n'], 'url_profile': 'https://github.com/nadinezab', 'info_list': ['Python', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 7, 2020', 'Python', 'Updated Apr 18, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gulshanroy', 'info_list': ['Python', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 7, 2020', 'Python', 'Updated Apr 18, 2020']}","{'location': 'Nasik', 'stats_list': [], 'contributions': '139 contributions\n        in the last year', 'description': ['Car-price-prediction-using-Regression\nProject made while learning ""Data Analysis using Python"" provided by IBM.\nIn this project we are going to do Data analysis and predict the price of a used car using information about it like brand,mileage,engine_type,etc.\nLibraries Used\n\nNumpy\nPandas\nMatplotlib\nScikit-Learn\n\nProgramming Language used:\n\nPython 3.6\n\n'], 'url_profile': 'https://github.com/Prince326', 'info_list': ['Python', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 7, 2020', 'Python', 'Updated Apr 18, 2020']}","{'location': 'Poland', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['Logistic Regression vs Naive Bayes Classifier\nComparison of discriminative and generative classifiers on example of\nLogistic Regression and Naive Bayes Classifier. Classifiers were trained\non this dataset to classify breast cancer as benign or malignant.\nTraining\n\nTraining samples: 2/3 of all samples.\nTest samples: 1/3 of all samples.\nLogistic Regression:\n\ndata is scaled\nactivation function: sigmoid\ntheta initialization: uniform [0, 1]\nalpha parameter: 0.1\nregularization: L2 with lambda=0.0005\n\n\nNaive Bayes Classifier:\n\nLaplace smoothing\nxj|y=c are treated as variables from multinomial distribution\n\n\n\nResults\nUncertainty and error rate of both classifiers on test samples averaged from 1000 trainings.\n\n\nConclusions\nNaive Bayes Classifier achieved its asymptotic error slightly faster,\nbut both classifiers end up with quite the same performance. According to this\npaper,\nasymptotic error of Logistic Regression should be lower than\nNaive Bayes one, thus we can expect Logistic Regression to outperform\nNaive Bayes given more data samples.\n'], 'url_profile': 'https://github.com/panpiort8', 'info_list': ['Python', 'MIT license', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated May 7, 2020', 'Python', 'Updated Apr 18, 2020']}"
"{'location': 'Montreal, Canada', 'stats_list': [], 'contributions': '51 contributions\n        in the last year', 'description': ['simple-linear-regression-from-scratch\nThis is just a quick, almost barebones implementation of a linear regression model using nothing but numpy.\nNothing to see here. Â¯\\(ãƒ„)/Â¯\n'], 'url_profile': 'https://github.com/sebastienvezina', 'info_list': ['Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 10, 2020', '1', 'JavaScript', 'Updated May 19, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '73 contributions\n        in the last year', 'description': ['ML-Knn-classifier-and-regression\nPredictions on basic knn machine learning algorithm.\n'], 'url_profile': 'https://github.com/MehdiHmidi523', 'info_list': ['Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 10, 2020', '1', 'JavaScript', 'Updated May 19, 2020']}","{'location': 'san francisco', 'stats_list': [], 'contributions': '30 contributions\n        in the last year', 'description': ['ML_Apprentice_Chef_Logistic_Regression\n'], 'url_profile': 'https://github.com/skanska1', 'info_list': ['Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 10, 2020', '1', 'JavaScript', 'Updated May 19, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '345 contributions\n        in the last year', 'description': ['VISUALISATION-FOR-MULTIPLE-LINEAR-REGRESSION\n'], 'url_profile': 'https://github.com/NarayanaReddy29', 'info_list': ['Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 10, 2020', '1', 'JavaScript', 'Updated May 19, 2020']}","{'location': 'London, UK', 'stats_list': [], 'contributions': '708 contributions\n        in the last year', 'description': ['Complete Regression - Lab\nIntroduction\nBy now, you have created all the necessary functions to calculate the slope, intercept, best-fit line, prediction, and visualizations. In this lab you will put them all together to run a regression experiment and calculate the model loss.\nObjectives\nYou will be able to:\n\nPerform a linear regression using self-constructed functions\nCalculate the coefficient of determination using self-constructed functions\nUse the coefficient of determination to determine model performance\n\nThe formulas\nSlope:\n$\\hat m = \\dfrac{\\overline{x}*\\overline{y}-\\overline{xy}}{(\\overline{x})^2-\\overline{x^2}}$\nIntercept: $ \\hat c = \\bar{y} - \\hat m\\bar{x}$\nPrediction: $\\hat{y} = \\hat mx + \\hat c$\nR-Squared:\n$ R^2 = 1- \\dfrac{SS_{RES}}{SS_{TOT}} = 1 - \\dfrac{\\sum_i(y_i - \\hat y_i)^2}{\\sum_i(y_i - \\overline y_i)^2} $\nUse the Python functions created earlier to implement these formulas to run a regression analysis using x and y as input variables.\n# Combine all the functions created so far to run a complete regression experiment. \n# Produce an output similar to the one shown below. \n\nX = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=np.float64)\nY = np.array([7, 7, 8, 9, 9, 10, 10, 11, 11, 12], dtype=np.float64)\n# Basic Regression Diagnostics\n# ----------------------------\n# Slope: 0.56\n# Y-Intercept: 6.33\n# R-Squared: 0.97\n# ----------------------------\n# Model: Y = 0.56 * X + 6.33\nBasic Regression Diagnostics\n----------------------------\nSlope: 0.56\nY-Intercept: 6.33\nR-Squared: 0.97\n----------------------------\nModel: Y = 0.56 * X + 6.33\n\n\nMake Predictions\nPredict and plot the value of y using regression line above for a new value of $x = 4.5$.\n# Make prediction for x = 4.5 and visualize on the scatter plot\n\nLevel up - Optional\nLoad the ""heightweight.csv"" dataset. Use the height as an independent and weight as a dependent variable and draw a regression line to data using your code above. Calculate your R-Squared value for the model and try to predict new values of y.\nSummary\nIn this lab, we ran a complete simple regression analysis experiment using functions created so far. Next up, you\'ll learn how you can use Python\'s built-in modules to perform similar analyses with a much higher level of sophistication.\n'], 'url_profile': 'https://github.com/nadinezab', 'info_list': ['Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 10, 2020', '1', 'JavaScript', 'Updated May 19, 2020']}","{'location': 'Singapore', 'stats_list': [], 'contributions': '83 contributions\n        in the last year', 'description': ['House-Prices-Advanced-Regression-Techniques\n'], 'url_profile': 'https://github.com/sudhirnpathak', 'info_list': ['Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 10, 2020', '1', 'JavaScript', 'Updated May 19, 2020']}","{'location': 'Lucknow, India', 'stats_list': [], 'contributions': '681 contributions\n        in the last year', 'description': ['Linear-Regression-BMI-Life-Expectancy\nSckit_Learn Basic curve fitting use LinearRegression model\n'], 'url_profile': 'https://github.com/sudhanshu456', 'info_list': ['Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 10, 2020', '1', 'JavaScript', 'Updated May 19, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7,850 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/NumtraCG', 'info_list': ['Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 10, 2020', '1', 'JavaScript', 'Updated May 19, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['happy-builder\nbuild happy from LTSs 3 and 9, with stack version 1.9.3 and 2.1.3\n'], 'url_profile': 'https://github.com/phlummox-bugs', 'info_list': ['Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 10, 2020', '1', 'JavaScript', 'Updated May 19, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '69 contributions\n        in the last year', 'description': ['An Approach to Explore Logistic Regression Models\nThis tool applies the potential of Attribute-RadViz in identifying correlations levels of attributes to explore LR models. We focus on reducing the limitations of using those models in multidimensional data contexts.\nThe tool includes the following aspects:\n\nfeature selection,\nregression model construction,\nevaluation of binary and multinomial regression, and\nconstruction of a panorama for queries over the model.\n\nAuthors:\n\nErasmo Artur (USP)\nRosane Minghim (UCC)\n\nInstalling and running\n\nDownload this project and unzip in a local directory\nOpen the HTML file in a browser (tested in Chrome, Firefox, and Edge)\n\nGetting started\n\nRendering the first view:\n\nGo to Left panel->CSV File->Choose file to pick a CSV file.\nThen choose a target attribute from Left panel->Target Attribute.\n\n\nGeneration of logistic regression models:\n\nSelect attributes clicking over them and click over the dimensional anchor of the desired label.\n\n\n\nThe interface\n\n\n(a) File opener\n(b) Target attribute selection\n(c) Adjust the size of the elements\n(d) Adjust the opacity of the elements\n(e) Adjust the strength of RadViz links\n(f) Adjust the repelling force of the elements (to avoid overlapping)\n(g) Enable/disable visual widgets of the tool (can increase performance)\n\nInformation bars: Hide/Show all informations bars\nBorders of nodes: Hide/Show the borders of the mapped elements\nLinks lines: Hide/Show between DAs and mapped elements\nWord cloud:  Hide/Show a word cloud when hovering DAs\nCorrelation between attributes: Dynamically changes sizes of elements according to the correlation to the hovered one.\n\n\n(h) Choose the evaluation mode in the second view\n(i) Plot some attribute of the data set directly to the ROC\n(j) Choose the discretization of the ROC curve\n(k) Choose the confindence of the LR model\n(l) Choose the attribute used in to identify mapped items by the tooltip\n(m) Define the sample size for the view\n(n) Define the opacity of the elements\n(o) Adjust the repelling force of the elements (to avoid overlapping)\n\n'], 'url_profile': 'https://github.com/erasmoartur', 'info_list': ['Python', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated May 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Updated Apr 8, 2020', 'Updated Apr 10, 2020', '1', 'JavaScript', 'Updated May 19, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '10 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/cxuanyi', 'info_list': ['1', 'JavaScript', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 9, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Jun 1, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'San Francisco ', 'stats_list': [], 'contributions': '38 contributions\n        in the last year', 'description': ['Supervised-Learning-using-Scikit-learning-Regression\n'], 'url_profile': 'https://github.com/Sheethal-crypto', 'info_list': ['1', 'JavaScript', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 9, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Jun 1, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'Boston', 'stats_list': [], 'contributions': '226 contributions\n        in the last year', 'description': ['Boston-911-Analysis-Logistic-Regression-Decision-Tree-\nPredicting 911 based on Bostin 911 calls data using Logistic Regression and Decison Tree.\nIn this project we are going to work on Boston 911 calls data set from Analyze Boston website.Crime incident reports are provided by Boston Police Department (BPD) to document the initial details surrounding an incident to which BPD officers respond. This is a dataset containing records from the new crime incident report system, which includes a reduced set of fields focused on capturing the type of incident as well as when and where it occurred. Records in the new system begin in June of 2015.\nThis dataset contains records of crime incident reports using the new system starting in June of 2015 till last week.\nDataset link https://data.boston.gov/dataset/crime-incident-reports-august-2015-to-date-source-new-system\n'], 'url_profile': 'https://github.com/ashish-kumarsingh', 'info_list': ['1', 'JavaScript', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 9, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Jun 1, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '76 contributions\n        in the last year', 'description': ['ML - ML_PCA-Logistic-Regression-MLP-CNN-SVM\nIn this part we implemented 4 questions based on PCA, Logistic Regression, Multi Layer Perceptron model, Convolutional Neural Network & SVM.\n'], 'url_profile': 'https://github.com/Sagnik07', 'info_list': ['1', 'JavaScript', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 9, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Jun 1, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '85 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/collins-emasi', 'info_list': ['1', 'JavaScript', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 9, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Jun 1, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'Canada', 'stats_list': [], 'contributions': '74 contributions\n        in the last year', 'description': ['Regression-Discontinuity-Design-with-Education-Data\n'], 'url_profile': 'https://github.com/liyongh1', 'info_list': ['1', 'JavaScript', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 9, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Jun 1, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '100 contributions\n        in the last year', 'description': ['End2End_Housing_Price_Regression_Project\nEnd to end housing price regressiong project, fomr ""Hands-on Machine Learning with scikit-learn, keras and TensorFlow"" 2nd Edition.\n'], 'url_profile': 'https://github.com/Y2Data', 'info_list': ['1', 'JavaScript', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 9, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Jun 1, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '73 contributions\n        in the last year', 'description': ['Car-Power-factor-Prediction-Linear-regression\nLinear model to predict Car Power_perf_factor\n'], 'url_profile': 'https://github.com/programmerMayur', 'info_list': ['1', 'JavaScript', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 9, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Jun 1, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'Tampa', 'stats_list': [], 'contributions': '34 contributions\n        in the last year', 'description': ['House-Sales_in_King_Count_US_Regression\n'], 'url_profile': 'https://github.com/shivam-gupta20', 'info_list': ['1', 'JavaScript', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 9, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Jun 1, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}","{'location': 'London, UK', 'stats_list': [], 'contributions': '708 contributions\n        in the last year', 'description': [""Simple Linear Regression - Lab\nIntroduction\nIn this lab, you'll get some hand-on practice developing a simple linear regression model. You'll also use your model to make a prediction about new data!\nObjectives\nYou will be able to:\n\nPerform a linear regression using self-constructed functions\nInterpret the parameters of a simple linear regression model in relation to what they signify for specific data\n\nLet's get started\nThe best-fit line's slope $\\hat m$ can be calculated as:\n$$\\hat m = \\rho \\frac{S_Y}{S_X}$$\nWith $\\rho$ being the correlation coefficient and ${S_Y}$ and ${S_X}$ being the standard deviation of $x$ and $y$, respectively. It can be shown that this is also equal to:\n$$\\hat m = \\dfrac{\\overline{x}*\\overline{y}-\\overline{xy}}{(\\overline{x})^2-\\overline{x^2}}$$\nYou'll use the latter formula in this lab. First, break down the formula into its parts. To do this, you'll import the required libraries and define some data points to work with. Next, you'll use some pre-created toy data in NumPy arrays. Let's do this for you to give you a head start.\n# import necessary libraries\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nstyle.use('ggplot')\n%matplotlib inline\n\n# Initialize arrays X and Y with given values\n# X = Independent Variable\nX = np.array([1,2,3,4,5,6,8,8,9,10], dtype=np.float64)\n# Y = Dependent Variable\nY = np.array([7,7,8,9,9,10,10,11,11,12], dtype=np.float64)\nCreate a scatter plot of X and Y and comment on the output\n# Scatter plot\n# Your observations about the relationship between X and Y \n\n\n\n#\nWrite a function calc_slope()\nWrite a function calc_slope() that takes in X and Y and calculates the slope using the formula shown above.\n# Write the function to calculate slope as: \n# (mean(x) * mean(y) â€“ mean(x*y)) / ( mean (x)^2 â€“ mean( x^2))\ndef calc_slope(xs,ys):\n    \n    pass\n\ncalc_slope(X,Y)\n\n# 0.5393518518518512\nGreat, so we have our slope. Next we calculate the intercept.\nAs a reminder, the calculation for the best-fit line's y-intercept is:\n$$\\hat c = \\overline y - \\hat m \\overline x $$\nWrite a function best_fit()\nWrite a function best_fit() that takes in X and Y, calculates the slope and intercept using the formula. The function should return slope and intercept values.\n# use the slope function with intercept formula to return calculate slope and intercept from data points\n\ndef best_fit(xs,ys):\n    \n    pass\n\n# Uncomment below to test your function\n\n#m, c = best_fit(X,Y)\n#m, c\n\n# (0.5393518518518512, 6.379629629629633)\nWe now have a working model with m and c as model parameters. We can create a line for the data points using the calculated slope and intercept:\n\nRecall that $y = mx + c$. We can now use slope and intercept values along with X data points (features) to calculate the Y data points (labels) of the regression line.\n\nWrite a function reg_line()\nWrite a function reg_line() that takes in slope, intercept and X vector and calculates the regression line using $y= mx + c$ for each point in X\ndef reg_line (m, c, xs):\n    \n    pass\n\n# Uncomment below\n#regression_line = reg_line(m,c,X)\nPlot the (x,y) data points and draw the calculated regression line for visual inspection\n# Plot data and regression line\nSo there we have it, our least squares regression line. This is the best fit line and does describe the data pretty well (still not perfect though).\nDescribe your Model Mathematically and in Words\n# Your answer here\n\n\nPredicting new data\nSo, how might you go about actually making a prediction based on this model you just made?\nNow that we have a working model with m and b as model parameters. We can fill in a value of x with these parameters to identify a corresponding value of $\\hat y$ according to our model. Recall the formula:\n$$\\hat y = \\hat mx + \\hat c$$\nLet's try to find a y prediction for a new value of $x = 7$, and plot the new prediction with existing data\nx_new = 7\ny_predicted = None\ny_predicted\n\n# 10.155092592592592\nPlot the prediction with the rest of the data\n# Plot as above and show the predicted value\nYou now know how to create your own models, which is great! Next, you'll find out how to determine the accuracy of your model!\nSummary\nIn this lesson, you learned how to perform linear regression for data that are linearly related. You first calculated the slope and intercept parameters of the regression line that best fit the data. You then used the regression line parameters to predict the value ($\\hat y$-value) of a previously unseen feature ($x$-value).\n""], 'url_profile': 'https://github.com/nadinezab', 'info_list': ['1', 'JavaScript', 'Updated Apr 19, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 9, 2020', '1', 'Jupyter Notebook', 'Updated May 8, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Jun 1, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '35 contributions\n        in the last year', 'description': ['HW5-1-1-Linear-Regression\nRobotics homework practice linear regression\n'], 'url_profile': 'https://github.com/leeandy0822', 'info_list': ['Python', 'Updated Apr 12, 2020', 'HTML', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Raleigh', 'stats_list': [], 'contributions': '327 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/rajshrivastava', 'info_list': ['Python', 'Updated Apr 12, 2020', 'HTML', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '73 contributions\n        in the last year', 'description': ['Car-Power-factor-Prediction-Linear-regression\nLinear model to predict Car Power_perf_factor\n'], 'url_profile': 'https://github.com/programmerMayur', 'info_list': ['Python', 'Updated Apr 12, 2020', 'HTML', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Tampa', 'stats_list': [], 'contributions': '34 contributions\n        in the last year', 'description': ['House-Sales_in_King_Count_US_Regression\n'], 'url_profile': 'https://github.com/shivam-gupta20', 'info_list': ['Python', 'Updated Apr 12, 2020', 'HTML', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '92 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gagan8287', 'info_list': ['Python', 'Updated Apr 12, 2020', 'HTML', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '92 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gagan8287', 'info_list': ['Python', 'Updated Apr 12, 2020', 'HTML', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Karachi', 'stats_list': [], 'contributions': '142 contributions\n        in the last year', 'description': ['COVID-19-Prediction-Using-Logistic-Regression\nThis is randomly generated dataset.\n'], 'url_profile': 'https://github.com/syedkashifaliquadri', 'info_list': ['Python', 'Updated Apr 12, 2020', 'HTML', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '186 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Alec-Sawalski', 'info_list': ['Python', 'Updated Apr 12, 2020', 'HTML', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Hyderabad, India', 'stats_list': [], 'contributions': '48 contributions\n        in the last year', 'description': ['Admission-Prediction-project-using-Linear-Regression-model\nBased on a candidate IELTS score, GRE score, SOP(Statement of Purpose), LOR(Letter of Recommendation), CGPA, TOEFL score, University ranking in which candidate wants the admission into, if any Research done by the candidate, the model will predict his/her chances to get the admission into that particular ranked university\n'], 'url_profile': 'https://github.com/vaibhavcodes', 'info_list': ['Python', 'Updated Apr 12, 2020', 'HTML', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/abidek', 'info_list': ['Python', 'Updated Apr 12, 2020', 'HTML', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}"
"{'location': 'Bengaluru', 'stats_list': [], 'contributions': '83 contributions\n        in the last year', 'description': ['Heart risk prediction using artificial neural networks,random forest classifier and logistic regression algorithms.\nA website built using Flask framework to predict if a person has a risk of heart disease occurrence using scientific parameters.Various machine learning algorithms have been used including Logistic Regression,Random Forest classifier and Artificial Neural Networks.\n'], 'url_profile': 'https://github.com/Sachinvh12', 'info_list': ['Jupyter Notebook', 'Updated Oct 3, 2020', '1', 'Jupyter Notebook', 'Updated Apr 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Shell', 'MIT license', 'Updated Apr 8, 2020', 'Vue', 'Apache-2.0 license', 'Updated Oct 6, 2020', 'R', 'Updated Jul 2, 2020', 'Jupyter Notebook', 'Updated Jul 20, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Boston', 'stats_list': [], 'contributions': '39 contributions\n        in the last year', 'description': ['This Project is based on Prediction of Interest Rates of Loans from the Lending Club Loan Data.\nCLAAT Document Link: https://codelabs-preview.appspot.com/?file_id=1rYZCIi7hOFTiRhG1IEAnrO7JBcLSmFqHaxtiy4rvMDk#0\nSteps to Regenerate the Project:\n\nClone the Project into any directory of your choice\nCreate a sub-folder called ""Mice Data"" inside the Data folder\nDownload the Data from https://www.kaggle.com/wendykan/lending-club-loan-data and place it inside the ""Original Data"" in the Data folder\nCheck Folders Under the Code Folder\nUnderstanding the Data: Notebook to Understand the Data more prominently\nCleansing, Preprocessing and EDA: Notebooks to Cleanse and Preprocess Data.\n, Notebook to impute Missing Values using MICE\n, Notebook to Normalize the Data\nFeature Selection: Notebook to Implement Feature Tools\n, Notebook to Select Features using LassoCV\nModels: This Folder Contains Sub-Folders with Notebooks to implement Linear Regression, Random Forests, Neural Networks\nand also implement AutoML using AutoSKLearm, H20.ai and Tpot\n\n'], 'url_profile': 'https://github.com/akashmdubey', 'info_list': ['Jupyter Notebook', 'Updated Oct 3, 2020', '1', 'Jupyter Notebook', 'Updated Apr 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Shell', 'MIT license', 'Updated Apr 8, 2020', 'Vue', 'Apache-2.0 license', 'Updated Oct 6, 2020', 'R', 'Updated Jul 2, 2020', 'Jupyter Notebook', 'Updated Jul 20, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Sydney, Australia', 'stats_list': [], 'contributions': '50 contributions\n        in the last year', 'description': ['Absenteeism-Prediction-in-Python-MySQL-and-Tableau\nThe dataset used for the analysis has 12 columns.\n\nID\nReason for Absence\nDate\nTransportation Expense\nDistance to Work\nAge\nDaily Work Load Average\nBody Mass Index\nEducation\nChildren\nPets\nAbsenteeism Time in Hours.\n\nThe flow of jupyter notebooks is as followed:\n1 - Preprocessing using Python (https://github.com/IQisFisco/Absenteeism-Prediction-in-Python-MySQL-and-Tableau/blob/master/Data_Preprocessing.ipynb)\n2 - Machine Learning with Logistic Regression and creating a module using Python (https://github.com/IQisFisco/Absenteeism-Prediction-in-Python-MySQL-and-Tableau/blob/master/Machine_Learning.ipynb)\n3 - Integration with MySQL (https://github.com/IQisFisco/Absenteeism-Prediction-in-Python-MySQL-and-Tableau/blob/master/Integration.ipynb)\n4 - Querying MySQL and exporting to CSV (https://github.com/IQisFisco/Absenteeism-Prediction-in-Python-MySQL-and-Tableau/blob/master/Querying_MySQL.ipynb)\n5 - The Tableau Public dashboard (https://public.tableau.com/profile/faisal3380#!/vizhome/AbsenteeismPredictionExercise/AbsenteeismoftheEmployees?publish=yes)\n'], 'url_profile': 'https://github.com/IQisFisco', 'info_list': ['Jupyter Notebook', 'Updated Oct 3, 2020', '1', 'Jupyter Notebook', 'Updated Apr 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Shell', 'MIT license', 'Updated Apr 8, 2020', 'Vue', 'Apache-2.0 license', 'Updated Oct 6, 2020', 'R', 'Updated Jul 2, 2020', 'Jupyter Notebook', 'Updated Jul 20, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'East Lansing, Michigan', 'stats_list': [], 'contributions': '316 contributions\n        in the last year', 'description': ['ldscore-baseline-pipeline\nHelper scripts automating a complete pipeline from arbitrary genomic baseline to ldscore regression for arbitrary gwas features\n'], 'url_profile': 'https://github.com/JorySchossau', 'info_list': ['Jupyter Notebook', 'Updated Oct 3, 2020', '1', 'Jupyter Notebook', 'Updated Apr 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Shell', 'MIT license', 'Updated Apr 8, 2020', 'Vue', 'Apache-2.0 license', 'Updated Oct 6, 2020', 'R', 'Updated Jul 2, 2020', 'Jupyter Notebook', 'Updated Jul 20, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '367 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/sanfernoronha', 'info_list': ['Jupyter Notebook', 'Updated Oct 3, 2020', '1', 'Jupyter Notebook', 'Updated Apr 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Shell', 'MIT license', 'Updated Apr 8, 2020', 'Vue', 'Apache-2.0 license', 'Updated Oct 6, 2020', 'R', 'Updated Jul 2, 2020', 'Jupyter Notebook', 'Updated Jul 20, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['NONE'], 'url_profile': 'https://github.com/cran', 'info_list': ['Jupyter Notebook', 'Updated Oct 3, 2020', '1', 'Jupyter Notebook', 'Updated Apr 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Shell', 'MIT license', 'Updated Apr 8, 2020', 'Vue', 'Apache-2.0 license', 'Updated Oct 6, 2020', 'R', 'Updated Jul 2, 2020', 'Jupyter Notebook', 'Updated Jul 20, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Singapore', 'stats_list': [], 'contributions': '224 contributions\n        in the last year', 'description': ['IJCNN2020_music_emotion\nsource code for the paper publised in IJCNN 2020 ""Regression-based Music Emotion Prediction using Triplet Neural Networks""\nDependencies\nnatsort==7.0.1\ntensorflow-GPU==1.13.1\nkeras==2.3.1\nseaborn==0.10.0\nscikit-learn==0.19.2\npydub==0.23.1\nmatplotlib==3.0.2\ntqdm\nInstruction\nThe train the model, please refer to Training.ipynb. The model is trained on DEAM dataset, which can be downloaded here. The data processing steps can be found in DEAM/Data_Processing.ipynb.\nTo use your trained model to predict music emotion, please refer to Demonstration.ipynb.\nDemonstration\nIn each of the region, we picked one song, and the predicted song can be found in /Demo/*\n\nLow\nUpperLow\nMiddle\nLowerHigh\nHigh\n'], 'url_profile': 'https://github.com/KinWaiCheuk', 'info_list': ['Jupyter Notebook', 'Updated Oct 3, 2020', '1', 'Jupyter Notebook', 'Updated Apr 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Shell', 'MIT license', 'Updated Apr 8, 2020', 'Vue', 'Apache-2.0 license', 'Updated Oct 6, 2020', 'R', 'Updated Jul 2, 2020', 'Jupyter Notebook', 'Updated Jul 20, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Dallas', 'stats_list': [], 'contributions': '34 contributions\n        in the last year', 'description': ['Churn data from a telecom company to understand what factors are good predictors of churn using logistic regression\n'], 'url_profile': 'https://github.com/taniyadhar', 'info_list': ['Jupyter Notebook', 'Updated Oct 3, 2020', '1', 'Jupyter Notebook', 'Updated Apr 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Shell', 'MIT license', 'Updated Apr 8, 2020', 'Vue', 'Apache-2.0 license', 'Updated Oct 6, 2020', 'R', 'Updated Jul 2, 2020', 'Jupyter Notebook', 'Updated Jul 20, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '17 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/swedha19', 'info_list': ['Jupyter Notebook', 'Updated Oct 3, 2020', '1', 'Jupyter Notebook', 'Updated Apr 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Shell', 'MIT license', 'Updated Apr 8, 2020', 'Vue', 'Apache-2.0 license', 'Updated Oct 6, 2020', 'R', 'Updated Jul 2, 2020', 'Jupyter Notebook', 'Updated Jul 20, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Bengaluru', 'stats_list': [], 'contributions': '448 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ckmonish2000', 'info_list': ['Jupyter Notebook', 'Updated Oct 3, 2020', '1', 'Jupyter Notebook', 'Updated Apr 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Shell', 'MIT license', 'Updated Apr 8, 2020', 'Vue', 'Apache-2.0 license', 'Updated Oct 6, 2020', 'R', 'Updated Jul 2, 2020', 'Jupyter Notebook', 'Updated Jul 20, 2020', 'Updated Apr 7, 2020', 'Python', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020']}"
"{'location': 'Vellore', 'stats_list': [], 'contributions': '25 contributions\n        in the last year', 'description': ['Car-resale-value\nA polynomial regression model to predict the resale value of a used car with an score of  87%\n'], 'url_profile': 'https://github.com/Muralidharan-ds', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 10, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 14, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 12, 2020', '1', 'Python', 'Updated Feb 11, 2021']}","{'location': 'NONE', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['Fraud-Credit-Card-Detection\nForecasted fraudulent transactions from given data sets using R and applied SMOTE ,Logistic Regression and Random Forest\nTechniques: Imputation,Principal Component Analysis,Clustering, SMOTE algorithm, Logistic Regression, Decision Trees, Random Forest\n'], 'url_profile': 'https://github.com/sayeekrish96', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 10, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 14, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 12, 2020', '1', 'Python', 'Updated Feb 11, 2021']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['NONE'], 'url_profile': 'https://github.com/cran', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 10, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 14, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 12, 2020', '1', 'Python', 'Updated Feb 11, 2021']}","{'location': 'ZÃ¼rich, Switzerland', 'stats_list': [], 'contributions': '79 contributions\n        in the last year', 'description': ['Finance Tracker\nThe purpose of this repository is have script which follow data from stock markets.\nFurthermore, the aim is to inmplement some machine learning models for prediciton.\nInstallation Instructions\nYou can download this repository with this command\n$ git clone https://github.com/fanconic/finance_tracker\n\nThen you can initialize a virtual environment\n$ pip install virtualenv\n$ virtualenv venv\n$ source venv/bin/activate\n\nInstall all the prerequesites\n$ pip install -r requirements.txt\n\nIf you want to run a Jupyter Notebook\n$ pip install ipykernel\n$ ipython kernel install --user --name=venv\n$ jupyter notebook\n\nHave Fun!\n'], 'url_profile': 'https://github.com/fanconic', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 10, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 14, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 12, 2020', '1', 'Python', 'Updated Feb 11, 2021']}","{'location': 'New York, NY', 'stats_list': [], 'contributions': '278 contributions\n        in the last year', 'description': ['DS_proj3\nThis is a project to apply and practice Logistic Regression, Discriminant Analysis (LDA, GDA, NB) and KNN\n'], 'url_profile': 'https://github.com/Akbarnejadhn', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 10, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 14, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 12, 2020', '1', 'Python', 'Updated Feb 11, 2021']}","{'location': 'NONE', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['RobustTailIndex\nThese R codes are to accompany the research paper on: ""Robust Estimation of Pareto-Type Tail Index through an Exponential Regression Model"".\nThe first file, ERM_M Estimator, computes the proposed ERM_M estimator of the tail index and plots them along the number of top order statistics for two values of the robustness tuning parameter, alpha.\nThe second file IF_function computes the influence function of the parameters of interest i.e. the tail index, and the second-order parameters b_{n,k} and rho.\nThe third file, Sensitivity, computes the sensitivity measure of the tail index\n'], 'url_profile': 'https://github.com/rminkah', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 10, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 14, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 12, 2020', '1', 'Python', 'Updated Feb 11, 2021']}","{'location': 'Greensboro, NC', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['PCA is a dimensionality reduction technique, and is used in high dimensionality data to find patterns.\nAn excellent resource to understand PCA, eigenvector, eigenvalues: https://pathmind.com/wiki/eigenvector\nSteps in PCA:\n\nGet data X (n*p dimension)\nGet covariance matrix (p*p dimension)\nDo eigendecomposition that would give pair of eigenvalues (p dimension vector) and eigenvectors (p*p dimension vector)\nWe can sort eigenpairs by descending order of eigenvalues\nCollect the two eigenvectors (or more) that correspond to the two largest eigenvalues, to capture about most of the variance in this dataset. Get more eigenvectors to capture more variance.\nThis would create a n*2-dimensional projection matrix W from the top two eigenvectors.\nUsing the projection matrix, we can now transform entire training dataset onto the PCA subspace (the principal components one and two) obtaining xâ€², now a two-dimensional sample vector consisting of two new features by calculating dot product of projection matrix W and dataset X. This transformed dataset would be n*2 dimensional dataset.\n\n'], 'url_profile': 'https://github.com/rishabhmohan', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 10, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 14, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 12, 2020', '1', 'Python', 'Updated Feb 11, 2021']}","{'location': 'Delhi Technological University', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gunagya', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 10, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 14, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 12, 2020', '1', 'Python', 'Updated Feb 11, 2021']}","{'location': 'New Delhi, India ', 'stats_list': [], 'contributions': '29 contributions\n        in the last year', 'description': ['Ensemble-learning-from-scratch\nImplemented Decision Tree, Bagged Decision Tree and Random Forests algorithms for Classification and Regression from scratch in Python.\nFor Instructions on how to run the program, open ""Instructions.txt""\n'], 'url_profile': 'https://github.com/nishant3101', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 10, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 14, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 12, 2020', '1', 'Python', 'Updated Feb 11, 2021']}","{'location': 'Lacey, WA', 'stats_list': [], 'contributions': '117 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/finbarr91', 'info_list': ['Jupyter Notebook', 'Updated Apr 7, 2020', 'Updated Apr 10, 2020', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 22, 2020', 'HTML', 'Updated Apr 14, 2020', 'R', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 12, 2020', '1', 'Python', 'Updated Feb 11, 2021']}"
"{'location': 'Sao Paulo, Brasil', 'stats_list': [], 'contributions': '68 contributions\n        in the last year', 'description': ['Predicting House Prices in Sao Paulo, Brazil\nUsed the data provided by https://www.kaggle.com/argonalyst/sao-paulo-real-estate-sale-rent-april-2019 to predict the rent prices using a simple regression.\n'], 'url_profile': 'https://github.com/marciohssilveira', 'info_list': ['Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated Feb 13, 2021', 'Updated Dec 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'Recife-PE', 'stats_list': [], 'contributions': '605 contributions\n        in the last year', 'description': ['Desafio Codenation\nEsse projeto refere-se a uma tarefa que tive que realizar no desafio da Codenation, para poder participar da AceleraÃ§Ã£o de Data Science da mesma. No desafio deverÃ­amos usar as notas de alunos (ciÃªncias da natureza, linguagens e cÃ³digos, ciÃªncias humanas e redaÃ§Ã£o) e informaÃ§Ãµes sociais dos alunos (do ano de 2016) que estavam em dois arquivo : train.csv e test.csv.\nO arquivo train.csv tinha todas as features e com esse arquivo irÃ­amos, apÃ³s ser tratado, treinar um modelo de Machine Learning do tipo regressÃ£o.\nJÃ¡ no arquivo test.csv constava todas as features com exceÃ§Ã£o da feature NU_NOTA_MT. Ou seja, apÃ³s treinarmos o modelo usarÃ­amos as features do arquivo de teste para prever as notas de matemÃ¡tica dos alunos.\nApÃ³s gerarmos as previsÃµes com o modelo de machine learning criarÃ­amos um arquivo com apenas duas colunas que seriam NU_INSCRICAO e NU_NOTA_MT criamos o arquivo csv e para submissÃ£o.\nObjetivo do desafio\nUsar um ou mais modelos de machine learning do tipo regressÃ£o para previsÃ£o de notas de matemÃ¡tica do ENEM do ano de 2016.\nEtapas\n\n\nImportaÃ§Ã£o das bibliotecas;\n\n\nImportaÃ§Ã£o das bases de dados;\n\n\nVerificaÃ§Ã£o das variÃ¡veis;\n\n\nSeleÃ§Ã£o das variÃ¡veis por meio da correlaÃ§Ã£o;\n\n\nTratamento dos valores faltantes;\n\n\nAplicaÃ§Ã£o preliminar dos modelos (previsÃµes e anÃ¡lise das previsÃµes);\n\n\nAplicaÃ§Ã£o dos modelos ao Desafio Codenation;\n\n\nComparaÃ§Ã£o dos resultados dos modelos.\n\n\nBibliotecas usadas\nMatplotlib, Pandas, Seaborn e Scikit-learn, Statsmodels e XGBoost\nDados\nArquivos com dados de treino (train.csv) e teste (test.csv) fornecidos pela Codenation.\nModelos usados e resultados\nForam usados vÃ¡rios modelos de ML do tipo RegressÃ£o (11 ao todo) e podem ser observados no script desse repositÃ³rio. O modelo que obteve o melhor resultado foi a RegressÃ£o Gradient Boosting com o resultado de 93.64%.\n'], 'url_profile': 'https://github.com/IvanildoBatista', 'info_list': ['Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated Feb 13, 2021', 'Updated Dec 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '400 contributions\n        in the last year', 'description': ['Econometrics\nRegression Paper / Prompt\n\nAims to show which features of a college correlate to the largest post-graduation salary. Itâ€™s written in Stata and incorporates hypothesis testing, and regression and statistical analysis\nPrompt: Develop and estimate a model that attempts to explain the variation in mobility rates across colleges. how do post-college earnings vary as a function of tuition, expenditures per pupil, major, quality-of-student body as measured by performance on a standardized test, etc.  You may find a need to combine two or more data sets (e.g., you may want to combine information from the data sets. This can be done in Stata.\n\n\nCourse Objectives:\n\nLearn how to define and estimate an economic model\nInterpret your estimation results by identifying what are statistically and economically significant variables\nBe able to critically evaluate economic models\n\nIncorporated Topics:\n\nMultiple simple linear regression techniques\nAnalyzing data sets using ordinary least squares, inference, and statistical software (Stata) to estimate economic models\n\n\n'], 'url_profile': 'https://github.com/eng-jonathan', 'info_list': ['Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated Feb 13, 2021', 'Updated Dec 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'Gurgaon, India', 'stats_list': [], 'contributions': '71 contributions\n        in the last year', 'description': ['Machine-Learning\nRegressions - Clusters - Classifications - LSTM - GAN - ANN - CNN - RNN - Dimensional Reduction\n'], 'url_profile': 'https://github.com/rveerag567', 'info_list': ['Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated Feb 13, 2021', 'Updated Dec 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '37 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/concussion20', 'info_list': ['Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated Feb 13, 2021', 'Updated Dec 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'Ukraine', 'stats_list': [], 'contributions': '332 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Metadorius', 'info_list': ['Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated Feb 13, 2021', 'Updated Dec 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['gu_math504hw\nNumerical methods homework: optimizations, decompositions, regressions, and more\n'], 'url_profile': 'https://github.com/hyeehauser', 'info_list': ['Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated Feb 13, 2021', 'Updated Dec 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'kolkata', 'stats_list': [], 'contributions': '60 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/kishandotpandey1352', 'info_list': ['Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated Feb 13, 2021', 'Updated Dec 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'Montreal, Canada', 'stats_list': [], 'contributions': '38 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/amfei', 'info_list': ['Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated Feb 13, 2021', 'Updated Dec 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': [""Regression with CART Trees - Lab\nIntroduction\nIn this lab, we'll make use of what we learned in the previous lesson to build a model for the Petrol Consumption Dataset from Kaggle. This model will be used to predict gasoline consumption for a bunch of examples, based on features about the drivers.\nObjectives\nIn this lab you will:\n\nFit a decision tree regression model with scikit-learn\n\nImport necessary libraries\n#\xa0Import libraries \nimport pandas as pd  \nimport numpy as np  \nfrom sklearn.model_selection import train_test_split \nThe dataset\n\nImport the 'petrol_consumption.csv' dataset\nPrint the first five rows of the data\nPrint the dimensions of the data\n\n# Import the dataset\ndataset = None\n# Print the first five rows\n# Print the dimensions of the data\n\nPrint the summary statistics of all columns in the data:\n\n#\xa0Describe the dataset\nCreate training and test sets\n\nAssign the target column 'Petrol_Consumption' to y\nAssign the remaining independent variables to X\nSplit the data into training and test sets using a 80/20 split\nSet the random state to 42\n\n# Split the data into training and test sets\nX = None\ny = None\nX_train, X_test, y_train, y_test = None\nCreate an instance of CART regressor and fit the data to the model\nAs mentioned earlier, for a regression task we'll use a different sklearn class than we did for the classification task. The class we'll be using here is the DecisionTreeRegressor class, as opposed to the DecisionTreeClassifier from before.\n# Import the DecisionTreeRegressor class \n\n\n# Instantiate and fit a regression tree model to training data \nregressor = None\nMake predictions and calculate the MAE, MSE, and RMSE\nUse the above model to generate predictions on the test set.\nJust as with decision trees for classification, there are several commonly used metrics for evaluating the performance of our model. The most common metrics are:\n\nMean Absolute Error (MAE)\nMean Squared Error (MSE)\nRoot Mean Squared Error (RMSE)\n\nIf these look familiar, it's likely because you have already seen them before -- they are common evaluation metrics for any sort of regression model, and as we can see, regressions performed with decision tree models are no exception!\nSince these are common evaluation metrics, sklearn has functions for each of them that we can use to make our job easier. You'll find these functions inside the metrics module. In the cell below, calculate each of the three evaluation metrics.\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# Make predictions on the test set\ny_pred = None\n\n# Evaluate these predictions\nprint('Mean Absolute Error:', None)  \nprint('Mean Squared Error:', None)  \nprint('Root Mean Squared Error:', None)\nLevel Up (Optional)\n\n\nLook at the hyperparameters used in the regression tree, check their value ranges in official doc and try running some optimization by growing a number of trees in a loop\n\n\nUse a dataset that you are familiar with and run tree regression to see if you can interpret the results\n\n\nCheck for outliers, try normalization and see the impact on the output\n\n\nSummary\nIn this lesson, you implemented the architecture to train a tree regressor and predict values for unseen data. You saw that with a vanilla approach, the results were not so great, and thus we must further tune the model (what we described as hyperparameter optimization and pruning, in the case of trees).\n""], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated Feb 13, 2021', 'Updated Dec 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Python', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'R', 'Updated Apr 8, 2020', '1', 'Jupyter Notebook', 'Updated Apr 11, 2020', 'Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '8 contributions\n        in the last year', 'description': [""COVID19-patient-outcome-forecast---Neural-Network-vs-Logistic-Regression\nIt contains the code concerning the cleaning and adaptation of the nature ScientificData COVID19 database according to the patients' symptomatology and chronic diseases. In addition, it contains a neural network and a logistic regression experiments that intend to forecast the patient outcome. Both codes are in R. Nevertheless, the csv database that I cleaned and adapted is attached.\n""], 'url_profile': 'https://github.com/IsaSerrato', 'info_list': ['Updated Apr 20, 2020', '1', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 16, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020']}","{'location': 'New Delhi', 'stats_list': [], 'contributions': '170 contributions\n        in the last year', 'description': ['Stock-Market-Dataset-Analysis-using-R\nFirst we will begin examining some numerical and graphical summaries of the Smarket data, which is part of the ISLR library.\nThis data set consists of percentage return for the S&P 500 stock index over 1,250 days, from the beginning of 2001 until the end of 2005.\nFor each date, we have recorded the percentage returns for each of the five previous trading days, Lag1 through Lag5.\nWe have also recorded Volume (the number of shares traded on the previous day), Today (the percentage return on the date in question) and Direction (whether the market was Up or Down on that date).\nOur aim is to forecast whether the rate will go Up or Down.\nMethods Used:\nLogistic Regression\nLDA\nQDA\n'], 'url_profile': 'https://github.com/raman77768', 'info_list': ['Updated Apr 20, 2020', '1', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 16, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020']}","{'location': 'Melbourne', 'stats_list': [], 'contributions': '100 contributions\n        in the last year', 'description': ['Regression-Algorithms-using-L1-and-L2-regularization\nSo the basic purpose of this project was to apply linear and polynomial regression along with standardisation and  Regularisation to come up with a model that could give us best mean absolute value for the output variable (life expectency)\n'], 'url_profile': 'https://github.com/HaiderSS', 'info_list': ['Updated Apr 20, 2020', '1', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 16, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Regression with CART Trees\nIntroduction\nAs we\'ve learned, a decision tree is a supervised machine learning model that can be used both for classification and regression tasks. We have seen that a decision tree uses a tree structure to predict an output class for a given input example in a classification task. For regression analysis, each path in the tree from the root node to a leaf node represents a decision path that ends in a predicted value. In this lesson, we shall see how regression is performed in using a decision tree regressor using a simple example.\nNote: Kindly visit the official documentation for the regressor tree function used in this lesson.\nObjectives\nYou will be able to:\n\nExplain recursive partitioning\nFit a decision tree regression model with scikit-learn\n\nRecursive partitioning\nLinear regression is considered a global model as there is a single model holding over the entire sample space. For data containing complex features with complicated and nonlinear relations, assembling such a single global model can be a very difficult and computationally expensive task.\nAnother way to handle nonlinear regressions is to partition the sample space into smaller regions, as we have already seen in previous lessons with classification trees. This isn\'t much different in regression. Our goal is partition down to increasingly smaller, simpler subsets until we can fit simple regression models to them. Since each subset is a partition of a smaller subset that is itself a subset, this makes it a textbook example of Recursive Partioning.\nRecall that in classification trees, the leaf nodes (the deepest nodes, or the ones at the end of each particular path) are the ones that contain the purest subsets of the data. Regression trees work a bit differently, but the general idea is still the same. With regression trees, each leaf node of the tree represents a cell of the partition. These cells are the smallest unit where a simple regression can be fit to the data accurately. Splitting the data still works the same way as we saw in previous lessons for classification -- we use our tree model to continuously subset down to smaller, more specific subsets until we reach a level where we can build the simplest regression model to the most specific subset in our data. For example, a regression tree may recursively partition the model down further and further until it gets all customers over the age of 50 residing in Florida with an income over $60k/year, and then fit a simple regression model to only the data points that fit within this specific subset.\nSimple local models\nOne point worth noting is that the simple regression models for each partition aren\'t being used as regressions in real-time. Instead, they take the sample mean of the dependent variable for that partition. Whenever the model makes a prediction, it uses this sample mean rather than calculating the actual regression model. In practice, this works quite well, and has some distinct advantages. Models are easier to interpret, and faster to use for inference (making predictions) since they are just retrieving the stored mean value rather than calculating the actual output of the regression.\nThis is more easily understood when visualized. Consider the regression tree below, which predicts the price of cars based on wheelbase and horsepower:\n\nOnce we have created a decision tree, we can visualize the decision boundaries of that tree (assuming that the dimensionality is small enough for visualization). Notice that all the dividing lines are parallel to the axes because each internal node checks whether a single variable is above or below a given value. In simpler terms, all decision boundaries with decision trees will always be horizontal or vertical if visualized -- there are no diagonal, wavy, or curvy lines, because of the nature of the boolean (true/false) logic used by decision trees to determine the splits!\n\nThe tree correctly represents the interaction between Horsepower and Wheelbase, i.e. when Horsepower > 0.6, Wheelbase no longer matters. When both are equally important, the tree switches between them.\nOnce we train the tree, the local models are completely understood,  so all the effort should go into finding a good partitioning of the data.\nCART training algorithm\nIn this lab, we will focus on the CART algorithm (Classification and Regression Trees) for regression.\n\nThe CART algorithm builds a binary tree in which every non-leaf node has exactly two children (corresponding to a yes/no answer).\n\nGiven a set of training examples and their labels, the algorithm repeatedly splits the training examples $D$ into two subsets $D_{left}, D_{right}$ using some feature set $f$ and feature threshold $t_f$ such that samples with the same label are grouped together.\nAt each node, the algorithm selects the split $\\theta = (f, t_f)$ that produces the smallest mean squared error (MSE) (alternatively, we could use the mean absolute error).\nSo at each step, the algorithm selects the parameters $\\theta$ that minimizes the following cost function:\n\\begin{equation}\nJ(D, \\theta) = \\frac{n_{left}}{n_{total}} MSE_{left} + \\frac{n_{right}}{n_{total}} MSE_{right}\n\\end{equation}\n\n$D$: remaining training examples\n$n_{total}$ : number of remaining training examples\n$\\theta = (f, t_f)$: feature and feature threshold\n$n_{left}/n_{right}$: number of samples in the left/right subset\n$MSE_{left}/MSE_{right}$: MSE of the left/right subset\n\nThis step is repeated recursively until the maximum allowable depth is reached or the current number of samples $n_{total}$ drops below some minimum number. The original equations can be found here.\nAfter building the tree, new examples can be classified by navigating through the tree, testing at each node the corresponding feature until a leaf node/prediction is reached.\nMean Squared Error (MSE)\nWhen performing regression with CART trees (i.e. the target values are continuous) we can evaluate a split using its MSE. The MSE of node $m$ is computed as follows:\n\\begin{equation}\n\\hat{y}m = \\frac{1}{n{m}} \\sum_{i \\in D_m} y_i\n\\end{equation}\n\\begin{equation}\nMSE_m = \\frac{1}{n_{m}} \\sum_{i \\in D_m} (y_i - \\hat{y}_m)^2\n\\end{equation}\n\n$D_m$: training examples in node $m$\n$n_{m}$ : total number of training examples in node $m$\n$y_i$: target value of $i-$th example\n\nLet\'s see the above in action with a simple experiment. We shall generate some non-linear synthetic data for our X and y attributes and fit it to a regression tree. So let\'s move ahead with this. In order to have a visual understanding of how this works, we shall deal with a simple regression problem between two variables X and y, where y is a simple function of X that we want to learn. Let\'s see this below:\nGenarate data\nRun the cell below to generate the data we will be using in this lesson:\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nplt.style.use(\'seaborn\')\nnp.random.seed(124)\n\n# Generate 100 examples of X and y (a simple cubic function of X) \nX = np.linspace(-3, 3, 100)\ny = X ** 3 + np.random.randn(100)\n\n# Plot the data \nplt.figure(figsize=(15,6))\nplt.scatter(X, y)\nplt.title(""Simple quadratic dataset with noise"")\nplt.xlabel(""Feature values"")\nplt.ylabel(""Target values"")\nplt.show()\n\nLet\'s now create our features and labels, and also perform a 75/25 split for the training and test sets:\nX = X.reshape(-1, 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\n# Print the data dimensions\nprint(\'Shape X_train:\', X_train.shape)\nprint(\'Shape y_train:\', y_train.shape)\nprint(\'Shape X_test:\', X_test.shape)\nprint(\'Shape y_test:\', y_test.shape)\nShape X_train: (75, 1)\nShape y_train: (75,)\nShape X_test: (25, 1)\nShape y_test: (25,)\n\nFit a Regression tree\nYou can use DecisionTreeRegressor() to fit a decision tree regressor in Scikit-learn. Let\'s create an instance of this class just like the classification tasks and fit it to data. For now, we\'ll set the max depth parameter to 3, as we now know that increasing this could lead to overfitting. We can experiment with different depths later.\nfrom sklearn.tree import DecisionTreeRegressor\nregressor = DecisionTreeRegressor(random_state=42, max_depth=3)\nregressor.fit(X_train, y_train)\nDecisionTreeRegressor(criterion=\'mse\', max_depth=3, max_features=None,\n                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n                      min_impurity_split=None, min_samples_leaf=1,\n                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n                      presort=False, random_state=42, splitter=\'best\')\n\nPrediction and evaluation\nThe output of the cell above shows us the default values for most hyperparameters. You are encouraged to check the official documentation for this class for details on options available to you for growing regression trees!\nWe can now predict labels with previously unseen data and calculate MSE. As an extra measure, we can also look at calculating the R-squared value to inspect the goodness of fit for our model.\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import r2_score\n\n# Make predictions and evaluate \ny_pred = regressor.predict(X_test)\nprint(\'MSE score:\', mse(y_test, y_pred))\nprint(\'R-sq score:\', r2_score(y_test,y_pred))\nMSE score: 7.651234359344747\nR-sq score: 0.9134119360857194\n\nVisualize the model fit\nOur R-squared score tells us that this appears to be a very good fit (remember $r^2$ ranges from 0 (poor) to 1 (best)). Let\'s visualize the learned function below with our scatter plot from earlier and see how well it fits.\nX_grid = np.arange(min(X), max(X), 0.01)\nX_grid = X_grid.reshape((len(X_grid), 1))\nplt.figure(figsize=(15,6))\nplt.scatter(X, y, color = \'red\', label=\'data\')\nplt.plot(X_grid, regressor.predict(X_grid), color = \'green\', label=\'Regression function\')\nplt.title(\'Decision Tree Regression\')\nplt.xlabel(\'Features\')\nplt.ylabel(\'Target\')\nplt.legend()\nplt.show()\n\nWe found this regression line without using any complex non-linear functions, in a fraction of time. This is the key benefit of regression trees over other regression techniques that we have seen earlier.\nSome observations\n\nThe function is not continuous\nHorizontal lines are averages of all data points in sections created\nThese horizontal lines represent sections. Predictions are averages of data points in these sections. So prediction for all values from the same section will be the same\n\nTry changing the max_depth parameter in the model and grow the tree again. The resulting visualization will clearly show you the impact of tree depth on overfitting.\nCaveats\nWithout regularization, decision trees are likely to overfit the training examples. This can be prevented using techniques like pruning or by providing a maximum allowed tree depth and/or a minimum number of samples required to split a node further as we saw with classification.\nAdditional resources\n\nAn Introduction to Recursive Partitioning: Rationale, Application and Characteristics of Classification and Regression Trees, Bagging and Random Forests\nCART: Classification And Regression Trees for Machine Learning\nPopular Decision Tree: Classification and Regression Trees (C&RT)\nYoutube: CART trees\n\nSummary\nIn this lesson, you learned about CART trees for regression. You looked at how the CART algorithm works, along with MSE as a loss measure which is used as a learning mechanism. You saw a simple experiment with some synthetic data where we used a tree regressor to learn a non-linear function.\n'], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['Updated Apr 20, 2020', '1', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 16, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '56 contributions\n        in the last year', 'description': ['Impact-of-PCA-on-SVM-and-Logistic-regression\nThe main aim was to test the impact of dimensionality reduction(PCA) on the accuracy of binary classifiers SVM and logistic regression which predict if cancer is benign or malignant\nObservation:\nFor lower values of K, accuracies were similar but for higher values of K, SVM performed better with considerable difference in the accuracy observed at K=30 where K is the number of principal components\n'], 'url_profile': 'https://github.com/sg1304', 'info_list': ['Updated Apr 20, 2020', '1', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 16, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020']}","{'location': 'Chennai,India', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Adhi15', 'info_list': ['Updated Apr 20, 2020', '1', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 16, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020']}","{'location': 'Montreal, Canada', 'stats_list': [], 'contributions': '38 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/amfei', 'info_list': ['Updated Apr 20, 2020', '1', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 16, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020']}","{'location': 'Cincinnati', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/menonsn', 'info_list': ['Updated Apr 20, 2020', '1', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 16, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '12 contributions\n        in the last year', 'description': ['Hotels reviews\nHotel reviews using data analysis, statistics of data, preprocessing and applying logistic regression  to predict wether review is good or not\nGroup members TE-IT-B\nChaitali Patil-34\nKajol Pawar-39\nShraddha Sasane-46\n'], 'url_profile': 'https://github.com/shraddhasasane', 'info_list': ['Updated Apr 20, 2020', '1', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 16, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '35 contributions\n        in the last year', 'description': ['SpamVsHam-classifier-using-Logistic-Regresion\nSpam vs Ham Classifier that classifies whether a message is spam or ham using Logistic Regression, Which is implemented from scratch.\nSETTING UP THE ENVIRONMENT\nFor running the classifier, I shall recommend installing anaconda for python 3.7. This ensures all the basic dependencies. Moreover, you may create a virtual environment using the environment.yml file uploaded in the repository. The command to create the virtual environment with the environment.yml file is:\nconda env create -f environment.yml\nThe first line of .yml file sets the name of the environment\nconda activate {env_name}\nThis .yml file shall take care of all the important dependencies required for Machine Learning and Deep Learning.\nfor installing any package package_name\npip install package_name\nSTEPS TO CREATE THE FILTER\n1. DATA PREPROCESSING:\nIn this step, we imported the important python libraries for linear algebra, data preprocessing and Natural Language Processing.\nThe Libraries imported are:\n\nnumpy\npandas\nstring\nscikitlearn\nNatural Language toolkit (NLTK)\npyplot\nscipy\n\nThe dataset was imported and was processed as per following sequence:\n\nCleaning the data by removing punctuations and stopwords\nStemming : reducing the words to roots\nTfIdf vectorization : creating a proper matrix of words appearing, with proper weightage given to each word\n\n2. LOGISTIC REGRESSION CLASSIFIER\nThe steps to code the logistic regression classifier from scratch are:\n\nDefine the logistic funtion, more popularly known as sigmoid function\nDefine the logistic cost function\nDefine the gradient descent algorithm to get optimum parameters\nInitialise the matrix of parameters, the learning rate, the number of iterations\nsplit the data into training set and test set, and make predictions on the test set.\n\nIn this classifier, I have used learning rate = 0.01 and 10,000 iterations. This resulted in an accuracy of 86.54%. Feel free to play around with these two hyper parameters to get better results.\n'], 'url_profile': 'https://github.com/captSteveRogers', 'info_list': ['Updated Apr 20, 2020', '1', 'R', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Python', 'Updated Apr 16, 2020', 'R', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 9, 2020', 'Python', 'Updated Apr 8, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '35 contributions\n        in the last year', 'description': ['SpamVsHam-classifier-using-Logistic-Regresion\nSpam vs Ham Classifier that classifies whether a message is spam or ham using Logistic Regression, Which is implemented from scratch.\nSETTING UP THE ENVIRONMENT\nFor running the classifier, I shall recommend installing anaconda for python 3.7. This ensures all the basic dependencies. Moreover, you may create a virtual environment using the environment.yml file uploaded in the repository. The command to create the virtual environment with the environment.yml file is:\nconda env create -f environment.yml\nThe first line of .yml file sets the name of the environment\nconda activate {env_name}\nThis .yml file shall take care of all the important dependencies required for Machine Learning and Deep Learning.\nfor installing any package package_name\npip install package_name\nSTEPS TO CREATE THE FILTER\n1. DATA PREPROCESSING:\nIn this step, we imported the important python libraries for linear algebra, data preprocessing and Natural Language Processing.\nThe Libraries imported are:\n\nnumpy\npandas\nstring\nscikitlearn\nNatural Language toolkit (NLTK)\npyplot\nscipy\n\nThe dataset was imported and was processed as per following sequence:\n\nCleaning the data by removing punctuations and stopwords\nStemming : reducing the words to roots\nTfIdf vectorization : creating a proper matrix of words appearing, with proper weightage given to each word\n\n2. LOGISTIC REGRESSION CLASSIFIER\nThe steps to code the logistic regression classifier from scratch are:\n\nDefine the logistic funtion, more popularly known as sigmoid function\nDefine the logistic cost function\nDefine the gradient descent algorithm to get optimum parameters\nInitialise the matrix of parameters, the learning rate, the number of iterations\nsplit the data into training set and test set, and make predictions on the test set.\n\nIn this classifier, I have used learning rate = 0.01 and 10,000 iterations. This resulted in an accuracy of 86.54%. Feel free to play around with these two hyper parameters to get better results.\n'], 'url_profile': 'https://github.com/captSteveRogers', 'info_list': ['Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'HTML', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Sep 6, 2019', 'Jupyter Notebook', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '22 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ujjaltech', 'info_list': ['Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'HTML', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Sep 6, 2019', 'Jupyter Notebook', 'Updated Apr 8, 2020']}","{'location': 'Amsterdam', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['Bank-loan-Marketing-Prediction\nIdentified potential loan customers for Thera Bank using classification techniques. Compared models built with Logistic Regression and KNN algorithm in order to select the best performing one.\n'], 'url_profile': 'https://github.com/stochasticquant', 'info_list': ['Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'HTML', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Sep 6, 2019', 'Jupyter Notebook', 'Updated Apr 8, 2020']}","{'location': 'SÃ£o Paulo, Brazil', 'stats_list': [], 'contributions': '146 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/polaroidz', 'info_list': ['Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'HTML', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Sep 6, 2019', 'Jupyter Notebook', 'Updated Apr 8, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['Pattern-and-Predictive-Analysis-of-Data-using-Machine-Learning-Algorithms\nPattern and Predictive analysis of Iris data using Logistic Regression and KNN Algorithm with the help of Train and Test and K-Fold Cross Validation\n'], 'url_profile': 'https://github.com/swatikswaroop', 'info_list': ['Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'HTML', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Sep 6, 2019', 'Jupyter Notebook', 'Updated Apr 8, 2020']}","{'location': 'Puducherry', 'stats_list': [], 'contributions': '62 contributions\n        in the last year', 'description': [""Covid-19-Prediction\nCovid-19 Detector which gives the probability of a patient being infected from covid-19 virus using Logistic regression model in Machine learning based on the symptoms.\nVisit website below to use the webapp:\nhttp://covidprediction.pythonanywhere.com\nPrerequisites\nYou must have Scikit Learn, Pandas, numpy (for Machine Leraning Model) and Flask, ninja2 (for API) installed.\nInstall requirements using : pip install -r requirements.txt\nProject Structure\nThis project has three major parts :\n\ntraining.py - This contains code for our Machine Learning model to predict the probability of a patient having COVID-19 infection based on training data in 'data.csv' file and updates 'model.pkl'.\napp.py - This contains Flask APIs that receives patient's symptoms details through GUI or API calls, computes the precited value based on our model and returns it.\ntemplates - This folder contains the HTML templates to allow user to enter patient sympyoms and displays the predicted infection probability. Templates in this project are : index.html, result.html, contact.html and about.html.\n\nRunning the project\n\n\nEnsure that you are in the project home directory. Create the machine learning model by running the command below  -\n  python training.py\n\nThis would create a serialized version of our model into a file model.pkl\n\n\nRun app.py using below command to start Flask API\n  python app.py\n\nflask will run on port 8000.\n\n\nNavigate to URL http://localhost:8000\nYou should be able to view the homepage as below :\n\n\n\nEnter valid values, select options in all the input boxes and hit Submit. (as shown above)\nIf everything goes well, you should be able to see the predcited probability in terms of percentage(multiplied by 100) vaule on the 'result.html' page!\n\n\n\n""], 'url_profile': 'https://github.com/rituraj97', 'info_list': ['Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'HTML', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Sep 6, 2019', 'Jupyter Notebook', 'Updated Apr 8, 2020']}","{'location': 'Punjab', 'stats_list': [], 'contributions': '230 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/siddhhu', 'info_list': ['Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'HTML', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Sep 6, 2019', 'Jupyter Notebook', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/chunshou-Liu', 'info_list': ['Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'HTML', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Sep 6, 2019', 'Jupyter Notebook', 'Updated Apr 8, 2020']}","{'location': 'Bengaluru', 'stats_list': [], 'contributions': '71 contributions\n        in the last year', 'description': ['Applying Data Science to Healthcare Industry\nBusiness Problem: To predict the Hospital cost based on Past Data.\nBusiness Solution: Build a Machine Learning Model using Multiple Linear Regression Algorithm.\n'], 'url_profile': 'https://github.com/Ramadas-Kamat', 'info_list': ['Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'HTML', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Sep 6, 2019', 'Jupyter Notebook', 'Updated Apr 8, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '8 contributions\n        in the last year', 'description': ['Classification-Model-HEART-DISEASE-\nit consist of the classification model about someone having heart disease or not using numpy, scikit learn, Logestic Regression classifier and Cross validation\n'], 'url_profile': 'https://github.com/VIPULJAIN5632', 'info_list': ['Python', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', '1', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'HTML', 'Updated Apr 13, 2020', '1', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Python', 'Updated Apr 7, 2020', 'R', 'Updated Sep 6, 2019', 'Jupyter Notebook', 'Updated Apr 8, 2020']}"
"{'location': 'Bangalore', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/siddhant68', 'info_list': ['Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Nov 7, 2020', 'R', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 15, 2020', 'HTML', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jan 22, 2021']}","{'location': 'India', 'stats_list': [], 'contributions': '74 contributions\n        in the last year', 'description': ['ML Classifiers\nThe pre-processing steps are worth looking at, for the beginners. In the world full of data, Machine Learning has become a to-go field for the ones looking to start off their career. This project shows basic operations performed on the dataset which is widely known as pre-processing. Once the data is ready, 4 main classifier algorithms are applied to find out the Jaccard similarity, F1-score and Accuracy which are the few important parameters one should look at while analysing a model.\nK-Nearest Neighbours:\nKNN can be used for both classification and regression predictive problems. However, it is more widely used in classification problems in the industry. To evaluate any technique we generally look at 3 important aspects:\n\nEase to interpret output\nCalculation time\nPredictive Power\n\n\nPros and Cons associated with KNN\nPros:\n1. No assumptions about data\u200aâ€”\u200auseful, for example, for nonlinear data\n2. Simple algorithm\u200aâ€”\u200ato explain and understand/interpret\n3. High accuracy (relatively)\u200aâ€”\u200ait is pretty high but not competitive in comparison to better supervised learning models\nVersatile\u200aâ€”\u200auseful for classification or regression\n\nCons:\n1. Computationally expensive\u200aâ€”\u200abecause the algorithm stores all of the training data\n2. High memory requirement\n3. Stores all (or almost all) of the training data\n4. Prediction stage might be slow (with big N)\n5. Sensitive to irrelevant features and the scale of the data\n\nSupport Vector Machine:\nSVM is a supervised machine learning algorithm which can be used for classification or regression problems. It uses a technique called the kernel trick to transform your data and then based on these transformations it finds an optimal boundary between the possible outputs.\n\nPros and Cons associated with SVM\nPros:\n    1. It works really well with a clear margin of separation\n    2. It is effective in high dimensional spaces.\n    3. It is effective in cases where the number of dimensions is greater than the number of samples.\n    4. It uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n\nCons:\n    1. It doesnâ€™t perform well when we have large data set because the required training time is higher\n    2. It also doesnâ€™t perform very well, when the data set has more noise i.e. target classes are overlapping\n    3. SVM doesnâ€™t directly provide probability estimates, these are calculated using an expensive five-fold cross-validation. It is included in the related SVC method of Python scikit-learn library.\n\nLogistic Regression:\nLogistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression).\n\nPros and Cons associated with LR\nPros:\n1. Logistic Regression performs well when the dataset is linearly separable.\n2. Logistic regression is less prone to over-fitting but it can overfit in high dimensional datasets. You should consider Regularization (L1 and L2) techniques to avoid over-fitting in these scenarios.\n3. Logistic Regression not only gives a measure of how relevant a predictor (coefficient size) is, but also its direction of association (positive or negative).\n4. Logistic regression is easier to implement, interpret and very efficient to train. \n\nCons:\n1. Main limitation of Logistic Regression is the assumption of linearity between the dependent variable and the independent variables. In the real world, the data is rarely linearly separable. Most of the time data would be a jumbled mess.\n2. If the number of observations are lesser than the number of features, Logistic Regression should not be used, otherwise it may lead to overfit.\n3. Logistic Regression can only be used to predict discrete functions. Therefore, the dependent variable of Logistic Regression is restricted to the discrete number set. This restriction itself is problematic, as it is prohibitive to the prediction of continuous data.\n\nDecision Trees:\nDecision Tree Classifier is a simple and widely used classification technique. It applies a straitforward idea to solve the classification problem. Decision Tree Classifier poses a series of carefully crafted questions about the attributes of the test record. Each time time it receive an answer, a follow-up question is asked until a conclusion about the calss label of the record is reached.\n\nPros and Cons associated with DT\nPros:\n1. Compared to other algorithms decision trees requires less effort for data preparation during pre-processing.\n2. A decision tree does not require normalization of data.\n3. A decision tree does not require scaling of data as well.\n4. Missing values in the data also does NOT affect the process of building decision tree to any considerable extent.\n5. A Decision trees model is very intuitive and easy to explain to technical teams as well as stakeholders.\n\nCons:\n1. A small change in the data can cause a large change in the structure of the decision tree causing instability.\n2. For a Decision tree sometimes calculation can go far more complex compared to other algorithms.\n3. Decision tree often involves higher time to train the model.\n4. Decision tree training is relatively expensive as complexity and time taken is more.\n5. Decision Tree algorithm is inadequate for applying regression and predicting continuous values.\n\nThank you!\n'], 'url_profile': 'https://github.com/Saadia-Hassan', 'info_list': ['Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Nov 7, 2020', 'R', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 15, 2020', 'HTML', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jan 22, 2021']}","{'location': 'Cracow', 'stats_list': [], 'contributions': '21 contributions\n        in the last year', 'description': ['Divorce-Prediction\nDivorce prediction using logistic regression, kNN and artificial neural network performed on data from https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set.\n'], 'url_profile': 'https://github.com/aleksandra197', 'info_list': ['Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Nov 7, 2020', 'R', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 15, 2020', 'HTML', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jan 22, 2021']}","{'location': 'NONE', 'stats_list': [], 'contributions': '148 contributions\n        in the last year', 'description': ['Hurricane Trajectories\nYear-wise Hurricane Type prediction\nHurricanes  follow  a  generalized  life  cycle  based  on  wind  speed(wind-speed  minimum  119km/h).The â€Saffir-Simpson Hurricane Wind Scaleâ€ is a 1 to 5 rating based on a hurricaneâ€™ssustained wind speed.  This scale estimates potential property damage.  Hurricanes havingcategory 3 and higher are considered major hurricanes because of their potential for significantloss of life and damage.  Category 1 and 2 hurricanes are still dangerous, however, and requirepreventative measures. Therefore here the main goal is to predict the number of the hurricanesof the particular category that are expected to take place in given inputted year.This can beutilized to make skillful forecasts so with that precautions can be taken to protect from the damage.\nDimenasionality reduction on hurricane trejectory prediction\nPrincipal  Component  Analysis  (PCA)  is  an  unsupervised,  non-parametric  statisticaltechnique primarily used for dimentionality reduction in machine learning.High dimen-tionality means that the dataset has a large number of features.  The primary problemassociated with high-dimensionality in the machine learning field is computation com-plexity.  Also dimentionality reduction helps in proper data visualisation.  In our caseprediction is the time sensitive.  As quick as possible knowing the trajectories of the hur-ricane can save many precious lives.  So for getting the quick response of the hurricane we used PCA.\nReference\n\n\nB. I. Miller, ""Characteristics of hurricanes: Analyses and calculations made from measurements by aircraft result in a fairly complete description,"" Science, vol. 157, no. 3795, pp. 1389{1399, 1967.\n\n\ndataset: https://www.nhc.noaa.gov/\n\n\nS. Alemany, J. Beltran, A. Perez, and S. Ganzfried, â€œPredicting hurricane trajectories using a recurrentneural network,â€Proceedings of the AAAI Conference on Artificial Intelligence, vol. 33, 02 2018.\n\n\n'], 'url_profile': 'https://github.com/arpitpatel1501', 'info_list': ['Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Nov 7, 2020', 'R', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 15, 2020', 'HTML', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jan 22, 2021']}","{'location': 'Juiz de Fora, Brazil', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['SSMN-CR\nLinear censored regression models with skew scale mixtures of normal distributions;\nAuthors: Daniel C. F. Guzm\\Ã¡n, ClÃ©cio S. Ferreira and Camila B. Zeller\nIn this paper, we propose to examine the censorship problem in context of the class of asymmetric, i.e., we have proposed a linear\nregression model with censored responses based on skew scale mixtures of normal distributions (SSMN). We develop a Monte Carlo EM\n(MCEM) algorithm to perform maximum likelihood inference of the parameters in the proposed linear censored regression models with\nSSMN distributions. The MCEM algorithm has been discussed with an emphasis on the skew-normal, skew Student-t-normal, skew-slash\nand skew-contaminated normal distributions.\nThe file Applications.R allows simulate and to fit SSMN-CR to real data.\n'], 'url_profile': 'https://github.com/ClecioFerreira', 'info_list': ['Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Nov 7, 2020', 'R', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 15, 2020', 'HTML', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jan 22, 2021']}","{'location': 'NONE', 'stats_list': [], 'contributions': '103 contributions\n        in the last year', 'description': [""LumberjackNet\nThis network uses the audio collected during the harvesting of pine trees to estimate the diameter of trunk. This is specially useful to model the volume of the tree which is important in the yield evaluation.\nTo reproduce this results, clone this repository, enter the project folder,create a Python 3.x virtual environment and run:\npip install -r requirements.txt\nTo download the dataset run the file download_dataset.sh. You may have to give execution permission on the file chmod +x download_dataset.sh. Run the file:\n./download_dataset.sh\nThere is some housekeeping necessary to make the data processing easier in training time. To do that, execute the following line:\npython prep_dataset.py\nYou should now see the train_split.json and test_split.json files in the main folder.\nTo start training your network you can must open the lumberjack_net.py and modify the parameters in the main() function.\nWhen you are ready to run, you can execute:\npython lumberjack_net.py\nThe results of your training and validation will be found in the folder expXX under the folder logs.\nI would like to thank the authors of the reference paper for providing a comprehensive explanation of the dataset and for making the dataset open so that this work could exist.\nPan, Pengmin & Mcdonald, Timothy. (2019). Computers and Electronics in Agriculture Tree size estimation from a feller-buncher's cutting sound. Computers and Electronics in Agriculture. 159. 50-58. 10.1016/j.compag.2019.02.021.\n""], 'url_profile': 'https://github.com/rafaelbidese', 'info_list': ['Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Nov 7, 2020', 'R', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 15, 2020', 'HTML', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jan 22, 2021']}","{'location': 'Cracow', 'stats_list': [], 'contributions': '21 contributions\n        in the last year', 'description': ['Titanic-Survival-Prediction\nStatistical Learning project in RMarkdown for academic course. Prediction methods used in this project are kNN, random forest, logistic regression and SVM.\n'], 'url_profile': 'https://github.com/aleksandra197', 'info_list': ['Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Nov 7, 2020', 'R', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 15, 2020', 'HTML', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jan 22, 2021']}","{'location': 'New Delhi', 'stats_list': [], 'contributions': '66 contributions\n        in the last year', 'description': ['House-Price-Predictor\nUsing a machine learning regression model, I made a web application that gets you the predicted price for the property with dependent attributes\nSteps for working of the project\nRun the server.py file present in server directory with\npython server.py\nOpen the index.html file in client directory with a browser and fill the form present there and submit it.\n'], 'url_profile': 'https://github.com/aakashkumarjee', 'info_list': ['Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Nov 7, 2020', 'R', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 15, 2020', 'HTML', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jan 22, 2021']}","{'location': 'India', 'stats_list': [], 'contributions': '186 contributions\n        in the last year', 'description': ['Heart-Disease-Classification\nPredicting presence of Heart Diseases using Machine Learning\nContents\nHD_Prediction1\n\nData Visualisation (sns & matplotlib)\nLinear Regression\nLogistic Regression\n\nHD_Prediction2\n\nParameter tuning with K-Nearest Neighbors (KNN)\n\nHD_Prediction3\n\nSVM\nKernel SVM\nNaive Bayes\n\nHD_Prediction4\n\nDecision Tree Classification\nRandom Forest Classification\n\nHD_Prediction5\n\nFeature Selection using Backward Elimination\n\nHD_Prediction6\nDimensionality Reduction using:\n\nPCA\nLDA\nKernel PCA\n\n'], 'url_profile': 'https://github.com/devi777', 'info_list': ['Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Nov 7, 2020', 'R', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 15, 2020', 'HTML', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jan 22, 2021']}","{'location': 'Recife-PE', 'stats_list': [], 'contributions': '605 contributions\n        in the last year', 'description': ['Data-science\nNesse repositÃ³rio constam projetos de data science com algoritmos de machine learning de aprendizado supervisionado (regressÃ£o e classificaÃ§Ã£o) e de aprendizado nÃ£o supervisionado (clustering). TambÃ©m projetos de deep learning, onde aplico redes neurais para problemas de classificaÃ§Ã£o, regressÃ£o e sÃ©ries temporais.\nProjetos\nProjeto 1 - AnÃ¡lise de regressÃ£o linear\nAplicaÃ§Ã£o da biblioteca MLR para geraÃ§Ã£o de modelos de regressÃ£o linear para explicar a variaÃ§Ã£o do peso de pescados. Foram gerados trÃªs modelos, dois quais o melhor foi o Ãºltimo que apresentou mÃ©tricas de melhor desempenho e comportamento dos resÃ­duos prÃ³ximos de uma distribuiÃ§Ã£o normal.\nProjeto 2 - AutoML para classificaÃ§Ã£o\nAplicaÃ§Ã£o da biblioteca de AutoML TPOT para classificaÃ§Ã£o de preÃ§os de celulares. Com o uso dessa biblioteca foi gerado um modelo com uma acurÃ¡cia de 97.4%.\nProjeto 3 - AutoML para regressÃ£o\nUtilizaÃ§Ã£o da biblioteca TPOT para modelagem de problema de regressÃ£o da competiÃ§Ã£o Kaggle de previsÃ£o do preÃ§os de casas. ApÃ³s aplicar vÃ¡rias geraÃ§Ãµes, aplicamos os dados de teste ao modelo e obtivemos, na competiÃ§Ã£o, um RMSE (raiz quadrada do erro mÃ©dia quadrado) de 0.15742;\nProjeto 4 - Clustering de aÃ§Ãµes\nUsando dados de indicadores fundamentalistas extraÃ­dos do site Fundamentus agrupei aÃ§Ãµes de empresas listadas na Bovespa. Geramos com o modelo Mini Batch Kmeans 5 grupos de aÃ§Ãµes similares;\nProjeto 5 - CompetiÃ§Ã£o Titanic\nUsando modelos de machine learning para prever a sobrevivÃªncia de passageiros do Titanic. Foram usados 21 modelos de classificaÃ§Ã£o, desses, o de melhor desempenho na competiÃ§Ã£o da Kaggle, foi o MPL Classifier (uma rede neural da biblioteca Scikit-Learn) com 80.32% de  acurÃ¡cia;\nProjeto 6 - ProjetoCampanha\nUsando o modelo Gradient Boosting para classificar clientes de uma campanha bancÃ¡ria, o modelo teve um desempenho superior Ã  baseline (50.32%), tendo uma acurÃ¡cia mÃ©dia de 82% e AUC de 0.9 (considerado um resultado considerado satisfatÃ³rio);\nProjeto 7 - ProjetoCancer\nAplicando um algoritmo de Ã¡rvore de decisÃ£o (Decision Tree) para identificaÃ§Ã£o de tipos de tumores. O modelo obteve uma precisÃ£o de 97% para a classe de tumores beningnos e de 93% de precisÃ£o para a classe de tumores malignos. TambÃ©m foi gerado um modelo com apenas as features mais importantes, mas o desem penho foi um pouco inferior ao primeiro modelo;\nProjeto 8 - ProjetoCenso\nAplicaÃ§Ã£o de modelos de machine learning para classificaÃ§Ã£o de renda de indivÃ­duos com base nas caracterÃ­sticas do censo. Foram utilizados 11 modelos de classificaÃ§Ã£o e, desses modelos, o de melhor desempenho foi o XGBoost Classifier que obteve uma acurÃ¡cia de 88.77% e um AUC de 0.96 (desempenho alto);\nProjeto 9 - ProjetoDiabetes\nClassificando ocorrÃªncia de diabetes. Foram usados 8 modelos de classificaÃ§Ã£o (sendo 6 do tipo Ã¡rvore) e destes modelos o que apresentou melhor desempenho na classificaÃ§Ã£o da doenÃ§a de diabetes foi a Extra Tree com uma acurÃ¡cia de 85% e uma AUC de 88%;\nProjeto 10 - ProjetoInsurance\nUsando regressÃ£o linear para prever/calcular o valor do sinistro pago por clientes de planos de saÃºde a partir das caracterÃ­sticas dos mesmos. Foram aplicadas ao modelo features que possuiam maior correlaÃ§Ã£o, alÃ©m de aplicarmos features polinomiais ao modelo o que reduziu o erro do modelo e aumentou o poder explicativo do mesmo;\nProjeto 11 - ProjetoVinho\nA partir das caracterÃ­sticas de vÃ¡rios tipos de vinho e aplicando mÃ©todos de seleÃ§Ã£o de clusters (elbow method e silhouette score), utilizamos o algoritmos de clusterizaÃ§Ã£o KMeans e identificamos 4 clusters de vinhos;\nProjeto 12 - Rede Neural para ClassificaÃ§Ã£o\nAplicaÃ§Ã£o de redes neurais artificais para identificaÃ§Ã£o de clientes que sejam propensos a contratar o emprÃ©stimo pessoal oferecido pelo banco. Como resultado foram geradas trÃªs redes neurais com acurÃ¡cia acima de 98%.\nProjeto 13 - Regras de AssociaÃ§Ã£o\nAplicando o algoritmo Apriori em uma base de cestas de compras foram identificadas regras e padrÃµes de compras, como por exemplo :\n\n\nquem compra butter, other vegetables e whipped/sour cream tambÃ©m compra whole milk com uma confianÃ§a de 0.723404\te um lift de 3.2527;\n\n\nquem compra butter, other vegetables e yogurt tambÃ©m compra whole milk com uma confianÃ§a de 0.73469 e um lift 3.3035;\n\n\nquem compra citrus fruit, root vegetables e tropical fruit tambÃ©m compra other vegetables com uma confianÃ§a de 0.8 e um lift\tde 4.7819.\n\n\n'], 'url_profile': 'https://github.com/IvanildoBatista', 'info_list': ['Python', 'Updated Apr 16, 2020', 'Jupyter Notebook', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Nov 7, 2020', 'R', 'Updated Apr 11, 2020', '1', 'Python', 'Updated Apr 15, 2020', 'HTML', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 8, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jan 22, 2021']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '162 contributions\n        in the last year', 'description': ['Sentiment Analysis: Predicting Overall Ratings of Products using Customer Reviews\nDataSet Used\nWe used a 5-core Amazon review dataset provided by (Ni, 2018). The chosen dataset contains product\nreviews of Cell phones and Accessories purchased from Amazon.com.\nNi, J. (2018). Amazon review data (2018): https://nijianmo.github.io/amazon/index.html. \nDataSet direct download link :  http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Cell_Phones_and_Accessories_5.json.gz\nAnalysis and Implementation\nAnalysis and Code available in JupyterNotebook - ReviewAnalysis.ipynb\nMinutes of meetings\nMinutes of meetings can be found in the file - Minutes of meetings-Group14-TA-CS7IS4\n'], 'url_profile': 'https://github.com/BAGLAT', 'info_list': ['Jupyter Notebook', 'Updated May 29, 2020', 'Updated Apr 7, 2020', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Feb 11, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'AGPL-3.0 license', 'Updated Dec 1, 2020', 'Jupyter Notebook', 'Updated Apr 16, 2020', '5', 'Jupyter Notebook', 'MIT license', 'Updated Aug 26, 2020', 'Jupyter Notebook', 'Updated Aug 25, 2020', '1', 'R', 'GPL-3.0 license', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7,850 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/NumtraCG', 'info_list': ['Jupyter Notebook', 'Updated May 29, 2020', 'Updated Apr 7, 2020', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Feb 11, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'AGPL-3.0 license', 'Updated Dec 1, 2020', 'Jupyter Notebook', 'Updated Apr 16, 2020', '5', 'Jupyter Notebook', 'MIT license', 'Updated Aug 26, 2020', 'Jupyter Notebook', 'Updated Aug 25, 2020', '1', 'R', 'GPL-3.0 license', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '40 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/EktaGambhir', 'info_list': ['Jupyter Notebook', 'Updated May 29, 2020', 'Updated Apr 7, 2020', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Feb 11, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'AGPL-3.0 license', 'Updated Dec 1, 2020', 'Jupyter Notebook', 'Updated Apr 16, 2020', '5', 'Jupyter Notebook', 'MIT license', 'Updated Aug 26, 2020', 'Jupyter Notebook', 'Updated Aug 25, 2020', '1', 'R', 'GPL-3.0 license', 'Updated Apr 6, 2020']}","{'location': 'TURKEY, istanbul', 'stats_list': [], 'contributions': '80 contributions\n        in the last year', 'description': ['Machine Learning Tutorial\nData of all models are find ""Data"" folder.\n'], 'url_profile': 'https://github.com/yigitsener', 'info_list': ['Jupyter Notebook', 'Updated May 29, 2020', 'Updated Apr 7, 2020', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Feb 11, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'AGPL-3.0 license', 'Updated Dec 1, 2020', 'Jupyter Notebook', 'Updated Apr 16, 2020', '5', 'Jupyter Notebook', 'MIT license', 'Updated Aug 26, 2020', 'Jupyter Notebook', 'Updated Aug 25, 2020', '1', 'R', 'GPL-3.0 license', 'Updated Apr 6, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '127 contributions\n        in the last year', 'description': [""Consumer-Complaint-Classification\n\nProblem: Each week the Consumer Financial Protection Bureau sends thousands of consumerâ€™s complaints about financial product and services to company for a response. Classify those consumer complaints into the product category it belongs to using the description of the complaint.\nSolution: The goal of this project is to classify the complaint into a specific product category. Since it has multiple categories, it becomes a multiclass classification that can be solved through many of the machine learning algorithms.\nOnce the algorithm is in place, whenever there is a new complaint, we can easily categorize it nad can then be redirected to the concerned person. This will save a lot of time because we are minimizing the human interventions to decide whom this complaint should go to.\n\nDataset\nwe're going to be using some real banking and finance consumer complaint data Samples.\nGo to the link and download the data: here\nSteps to run project:\n\nHit the green button and clone this repo.\nSee Notebook: ConsumerComplaintClassification.ipynb is used to build multiclass classfication model for categorize complaint_narrative of customers to there product category based on which will be further communicated to the concern issue resolving team.\n\n""], 'url_profile': 'https://github.com/shubhamchouksey', 'info_list': ['Jupyter Notebook', 'Updated May 29, 2020', 'Updated Apr 7, 2020', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Feb 11, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'AGPL-3.0 license', 'Updated Dec 1, 2020', 'Jupyter Notebook', 'Updated Apr 16, 2020', '5', 'Jupyter Notebook', 'MIT license', 'Updated Aug 26, 2020', 'Jupyter Notebook', 'Updated Aug 25, 2020', '1', 'R', 'GPL-3.0 license', 'Updated Apr 6, 2020']}","{'location': 'Madison, Wisconsin, USA', 'stats_list': [], 'contributions': '22 contributions\n        in the last year', 'description': ['manyRegressors\nR package for inference in models with heteroskedasticity and many regressors.\nTo install the package, run the following code in R\ninstall.packages(""devtools"") # Only needed if you do not have devtools already\ndevtools::install_github(""mikkelsoelvsten/manyRegressors"")\n\nIncluded functions\nLOFtest Test a hypothesis that imposes many restrictions in a linear regression with many regressors and heteroskedasticity.\nLOvcov Variance-covariance estimator that is robust to heteroskedasticity and many regressors.\nReferences\nKline, Saggio, and SÃ¸lvsten (2019). Leave-out estimation of variance components. https://arxiv.org/abs/1806.01494\nAnatolyev and SÃ¸lvsten (2020). Testing Many Restrictions Under Heteroskedasticity. https://arxiv.org/abs/2003.07320\n'], 'url_profile': 'https://github.com/mikkelsoelvsten', 'info_list': ['Jupyter Notebook', 'Updated May 29, 2020', 'Updated Apr 7, 2020', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Feb 11, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'AGPL-3.0 license', 'Updated Dec 1, 2020', 'Jupyter Notebook', 'Updated Apr 16, 2020', '5', 'Jupyter Notebook', 'MIT license', 'Updated Aug 26, 2020', 'Jupyter Notebook', 'Updated Aug 25, 2020', '1', 'R', 'GPL-3.0 license', 'Updated Apr 6, 2020']}","{'location': 'Aligarh', 'stats_list': [], 'contributions': '90 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/mrperfectpandit', 'info_list': ['Jupyter Notebook', 'Updated May 29, 2020', 'Updated Apr 7, 2020', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Feb 11, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'AGPL-3.0 license', 'Updated Dec 1, 2020', 'Jupyter Notebook', 'Updated Apr 16, 2020', '5', 'Jupyter Notebook', 'MIT license', 'Updated Aug 26, 2020', 'Jupyter Notebook', 'Updated Aug 25, 2020', '1', 'R', 'GPL-3.0 license', 'Updated Apr 6, 2020']}","{'location': '32.621921, 51.647334', 'stats_list': [], 'contributions': '637 contributions\n        in the last year', 'description': ['Wine Quality Data Set from UCI Machine Learning Lab\nThere are two datasets that provide information on samples of red and white variants of the Portuguese ""Vinho Verde"" wine. Each sample of wine was rated for quality by wine experts and examined with physicochemical tests. Due to privacy and logistic issues, only data on these physicochemical properties  and quality ratings are available (e.g. there is no data about grape types, wine brand,wine selling price, etc . )(Source)\n\nAttributes in Each Dataset:\nPhysicochemical Properties\n\nFixed Acidity\nVolatile Acidity\nCitric Acid\nResidual Sugar\nChlorides\nFree Sulfur Dioxide\nTotal Sulfur Dioxide\nDensity\npH\nSulphates\nAlcohol\n\nQuality Rating\n\nQuality - Score between 0 and 10 (median of at least 3 evaluations made by wine experts)\n\nWriters\n\n\nSoursh Ghaderi ( âœï¸ )\n\n\nBahram Jannesar ( âœï¸ )\n\n\nLicense\nSee full license on this , Under MIT License\n'], 'url_profile': 'https://github.com/BahramJannesar', 'info_list': ['Jupyter Notebook', 'Updated May 29, 2020', 'Updated Apr 7, 2020', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Feb 11, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'AGPL-3.0 license', 'Updated Dec 1, 2020', 'Jupyter Notebook', 'Updated Apr 16, 2020', '5', 'Jupyter Notebook', 'MIT license', 'Updated Aug 26, 2020', 'Jupyter Notebook', 'Updated Aug 25, 2020', '1', 'R', 'GPL-3.0 license', 'Updated Apr 6, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '125 contributions\n        in the last year', 'description': ['Statics-Basics\nA general understanding of Statistics Basics, Different tests with Python Libraries.\n'], 'url_profile': 'https://github.com/Revanthshalon', 'info_list': ['Jupyter Notebook', 'Updated May 29, 2020', 'Updated Apr 7, 2020', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Feb 11, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'AGPL-3.0 license', 'Updated Dec 1, 2020', 'Jupyter Notebook', 'Updated Apr 16, 2020', '5', 'Jupyter Notebook', 'MIT license', 'Updated Aug 26, 2020', 'Jupyter Notebook', 'Updated Aug 25, 2020', '1', 'R', 'GPL-3.0 license', 'Updated Apr 6, 2020']}","{'location': 'Lagos, Nigeria', 'stats_list': [], 'contributions': '32 contributions\n        in the last year', 'description': ['Zindi SA Hack\n6th Place Solution\n'], 'url_profile': 'https://github.com/horlar1', 'info_list': ['Jupyter Notebook', 'Updated May 29, 2020', 'Updated Apr 7, 2020', 'Updated Apr 6, 2020', '2', 'Python', 'MIT license', 'Updated Feb 11, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'AGPL-3.0 license', 'Updated Dec 1, 2020', 'Jupyter Notebook', 'Updated Apr 16, 2020', '5', 'Jupyter Notebook', 'MIT license', 'Updated Aug 26, 2020', 'Jupyter Notebook', 'Updated Aug 25, 2020', '1', 'R', 'GPL-3.0 license', 'Updated Apr 6, 2020']}"
"{'location': 'Mumbai, India.', 'stats_list': [], 'contributions': '426 contributions\n        in the last year', 'description': ['Depression-Analysis-NLP\nSteps followed-\n\nScrape data from Reddit.\nClean the data.\nPreprocess the data for EDA.\nEDA (Histograms, WordClouds).\nBuild and analyze ML models.\nPrepare data for BERT model.\nBuild, train and test the BERT model.\n\n\nRefer to the PDF for report and output analysis.  \nRepeat the confusion matrix building step (cell) for all the models.\n'], 'url_profile': 'https://github.com/rishikesh1419', 'info_list': ['Jupyter Notebook', 'MIT license', 'Updated Jan 11, 2021', 'Python', 'Updated Dec 2, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', '1', 'HTML', 'Updated Aug 15, 2020', 'Python', 'MIT license', 'Updated Jun 18, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Nov 27, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'San Francisco', 'stats_list': [], 'contributions': '83 contributions\n        in the last year', 'description': ['Linear_regression\nLinear Regression is when you have a group of points on a graph, and you find a line that approximately resembles that group of points. A good Linear Regression algorithm minimizes the error_, or the distance from each point to the line. A line with the least error is the line that fits the data the best. We call this a line of _best fit.\n'], 'url_profile': 'https://github.com/cindykhris', 'info_list': ['Jupyter Notebook', 'MIT license', 'Updated Jan 11, 2021', 'Python', 'Updated Dec 2, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', '1', 'HTML', 'Updated Aug 15, 2020', 'Python', 'MIT license', 'Updated Jun 18, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Nov 27, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Hong Kong', 'stats_list': [], 'contributions': '10 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/tanoymajumdar', 'info_list': ['Jupyter Notebook', 'MIT license', 'Updated Jan 11, 2021', 'Python', 'Updated Dec 2, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', '1', 'HTML', 'Updated Aug 15, 2020', 'Python', 'MIT license', 'Updated Jun 18, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Nov 27, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Kolkata,West Bengal,India', 'stats_list': [], 'contributions': '76 contributions\n        in the last year', 'description': ['Breast-Cancer-Prediction\nBreastCancerPrediction (WISCONSIN MEDICAL DATASET)is done using7classiï¬cationalgorithm: Logistic Regression,SupportVectorMachine(linearkernel),SupportVector Machine(polynomialkernel),EnsembleLearningMethodofDecision Tree,RandomForest,AdaboostClassiï¬er,andlastlyvotingalgorithmbasedon LogisticRegression,SupportVectorMachine(polynomial kernel)andDecision tree.  This project was represented by a python GUI using tkinter.\n'], 'url_profile': 'https://github.com/hheavyduty', 'info_list': ['Jupyter Notebook', 'MIT license', 'Updated Jan 11, 2021', 'Python', 'Updated Dec 2, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', '1', 'HTML', 'Updated Aug 15, 2020', 'Python', 'MIT license', 'Updated Jun 18, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Nov 27, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'New Delhi, India', 'stats_list': [], 'contributions': '188 contributions\n        in the last year', 'description': ['Web App Flask for Time Series Deployment in Production\nParticulate Matter 2.5 Predictor\nProject description:\nTime Series Forecasting and regression analysis web app to predict and forecast PM 2.5 values and other Air pollution metrics 3 hours ahead.\nThis project uses the Facebooks Prophet algorithm to forecast the PM 2.5 values 3 Hours ahead.\nImplementation\n\n'], 'url_profile': 'https://github.com/adityakaushal', 'info_list': ['Jupyter Notebook', 'MIT license', 'Updated Jan 11, 2021', 'Python', 'Updated Dec 2, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', '1', 'HTML', 'Updated Aug 15, 2020', 'Python', 'MIT license', 'Updated Jun 18, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Nov 27, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Hong Kong', 'stats_list': [], 'contributions': '459 contributions\n        in the last year', 'description': ['Regression Pipeline: Bike Sharing Demand Forecast\nThis repo contains a scikit-learn based machine learning pipeline for regression with tree-based ensemble learning algorithms, Random Forest and XGBoost in specific. It is applied on a Kaggle playground prediction competition, Bike Sharing Demand.\nThe pipeline features customized preprocessing transformers that take a pandas DataFrame and as input and return the encoded and scaled feature matrix and feature names. It also contains SHAP plots that explains how and to what extent each feature contributes to the prediction to enhance the interpretability of the algorithms we employ.\n\nData\nThe datasets listed below can be downloaded on the competition webpage linked here. Users would need to create a Kaggle account and join the competition to download the datasets.\nâ”‚  sampleSubmission.csv\nâ”‚  test.csv\nâ”‚  train.csv\n\nThe training set contains 10.9K hourly observations of bike sharing demand in Washington, D.C. on the first 20 days of each month in 2011 and 2012. It has 12 features, 9 of which are available in the test set. Refer to the data dictionary for feature definitions.\nNote that count is not available at prediction time as it is the target. Likewise, casual and registered are decomposition of count and will not be available at prediction time as well.\nThere are 6493 observations and 10 features in the test set, accounting for hourly measurements on the last days of each month in 2011 and 2012.\nSince we are working on predicting bike sharing demand in Washington, D.C., information on whether Congress and Senate were in session can be helpful. We manually scraped Congress website for past days in session data for the year 2011 and 2012 and put them in house_sessions_1112.csv and senate_sessions_1112.csv. We would join them with our feature matrices by datetime in the feature engineering stage.\n\nInstallation\nPlease refer to reg-pipe.yml for package dependencies. To install the package, users would need to have Python and Anaconda installed beforehand. Users can prepare the virtual environment for the package, named reg-pipe by default, by running the following:\nconda env create -f reg-pipe.yml\n\n\nUsage\nTo run the pipeline, users would need to download the datasets as described above and unzip the file under the directory ./data. They also need to install the dependencies as described above. Then run the following:\nconda activate reg-pipe\ncd codes\npython train.py\n\n\nPipeline Overview\n\nLicense\nThe package is released under the MIT License.\n'], 'url_profile': 'https://github.com/KunyuHe', 'info_list': ['Jupyter Notebook', 'MIT license', 'Updated Jan 11, 2021', 'Python', 'Updated Dec 2, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', '1', 'HTML', 'Updated Aug 15, 2020', 'Python', 'MIT license', 'Updated Jun 18, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Nov 27, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '9 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/arnavgupta829', 'info_list': ['Jupyter Notebook', 'MIT license', 'Updated Jan 11, 2021', 'Python', 'Updated Dec 2, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', '1', 'HTML', 'Updated Aug 15, 2020', 'Python', 'MIT license', 'Updated Jun 18, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Nov 27, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Kolkata', 'stats_list': [], 'contributions': '55 contributions\n        in the last year', 'description': ['Credit-Card-Fraud-Detection\nThe aim of this R project is to build a classifier that can detect credit card fraudulent transactions. I used Logistic Regression, Decision Tree, Naive Bayes, Random Forest and Gradient Boosting Machine.\n'], 'url_profile': 'https://github.com/som21-star', 'info_list': ['Jupyter Notebook', 'MIT license', 'Updated Jan 11, 2021', 'Python', 'Updated Dec 2, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', '1', 'HTML', 'Updated Aug 15, 2020', 'Python', 'MIT license', 'Updated Jun 18, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Nov 27, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '38 contributions\n        in the last year', 'description': ['Logistic Regression\nLogistic regression is based on the logistic function or the sigmoid function. It is a type of linear model, which transforms the probabilities into discrete values using sigmoid function. So, unlike linear regression, this model can be used to map a set of values to two or more classes.\nThe following links have a very good explanation on logistic regression:\nhttps://machinelearningmastery.com/logistic-regression-for-machine-learning/\nhttps://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc\nThis project is just about experimenting logistic regression on two datasets. Both the datasets differ in number of rows and the values in risk column. In built python libraries have been used to carry out logistic regression.\n'], 'url_profile': 'https://github.com/e-aditi', 'info_list': ['Jupyter Notebook', 'MIT license', 'Updated Jan 11, 2021', 'Python', 'Updated Dec 2, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', '1', 'HTML', 'Updated Aug 15, 2020', 'Python', 'MIT license', 'Updated Jun 18, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Nov 27, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '80 contributions\n        in the last year', 'description': ['Data-Visualization-with-Python\nLINE PLOTS, AREA PLOTS, HISTOGRAM , BAR CHARTS , PIE CHART, BOX PLOT ,  SCATTER PLOT, BUBBLE PLOT , WAFFLE CHART , WORD CLOUDS ,  SEABORN AND REGRESSION PLOTS, INTRO TO FOLIUM , MAPS WITH MARKERS , CHLOROPETH MAPS\n'], 'url_profile': 'https://github.com/Preethinaidu14', 'info_list': ['Jupyter Notebook', 'MIT license', 'Updated Jan 11, 2021', 'Python', 'Updated Dec 2, 2020', 'Python', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', '1', 'HTML', 'Updated Aug 15, 2020', 'Python', 'MIT license', 'Updated Jun 18, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Nov 27, 2020', '1', 'Jupyter Notebook', 'Updated Apr 12, 2020']}"
"{'location': 'Armenia', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['\n'], 'url_profile': 'https://github.com/hakobian4', 'info_list': ['HTML', 'Updated Jun 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 17, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jul 11, 2020', '2', 'Python', 'MIT license', 'Updated Jul 11, 2020', 'Updated Apr 6, 2020']}","{'location': 'India', 'stats_list': [], 'contributions': '445 contributions\n        in the last year', 'description': ['COVID-19-ML-Forecasting\nThis is a ML forecasting model which forecast what the next confirmed cases will be in coming days globally. It shows implementation using Linear Regression and SVM (Support Vector Machine).\nDataset is updated till 9th April cases.\n'], 'url_profile': 'https://github.com/v1zh3d', 'info_list': ['HTML', 'Updated Jun 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 17, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jul 11, 2020', '2', 'Python', 'MIT license', 'Updated Jul 11, 2020', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7,850 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/NumtraCG', 'info_list': ['HTML', 'Updated Jun 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 17, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jul 11, 2020', '2', 'Python', 'MIT license', 'Updated Jul 11, 2020', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7,850 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/NumtraCG', 'info_list': ['HTML', 'Updated Jun 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 17, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jul 11, 2020', '2', 'Python', 'MIT license', 'Updated Jul 11, 2020', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7,850 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/NumtraCG', 'info_list': ['HTML', 'Updated Jun 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 17, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jul 11, 2020', '2', 'Python', 'MIT license', 'Updated Jul 11, 2020', 'Updated Apr 6, 2020']}","{'location': 'brighton, United Kingdom', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': ['Lead-Scoring\nBuild a logistic regression model to assign a lead score between 0 and 100 to each of the leads which can be used by the company to target potential leads. A higher score would mean that the lead is hot, i.e. is most likely to convert whereas a lower score would mean that the lead is cold and will mostly not get converted.\nAn education company named X Education sells online courses to industry professionals. On any given day, many professionals who are interested in the courses land on their website and browse for courses.\nThe company markets its courses on several websites and search engines like Google. Once these people land on the website, they might browse the courses or fill up a form for the course or watch some videos. When these people fill up a form providing their email address or phone number, they are classified to be a lead. Moreover, the company also gets leads through past referrals. Once these leads are acquired, employees from the sales team start making calls, writing emails, etc. Through this process, some of the leads get converted while most do not. The typical lead conversion rate at X education is around 30%.\nNow, although X Education gets a lot of leads, its lead conversion rate is very poor. For example, if, say, they acquire 100 leads in a day, only about 30 of them are converted. To make this process more efficient, the company wishes to identify the most potential leads, also known as â€˜Hot Leadsâ€™. If they successfully identify this set of leads, the lead conversion rate should go up as the sales team will now be focusing more on communicating with the potential leads rather than making calls to everyone.\nAs you can see, there are a lot of leads generated in the initial stage (top) but only a few of them come out as paying customers from the bottom. In the middle stage, you need to nurture the potential leads well (i.e. educating the leads about the product, constantly communicating etc. ) in order to get a higher lead conversion.\nX Education has appointed you to help them select the most promising leads, i.e. the leads that are most likely to convert into paying customers. The company requires you to build a model wherein you need to assign a lead score to each of the leads such that the customers with higher lead score have a higher conversion chance and the customers with lower lead score have a lower conversion chance. The CEO, in particular, has given a ballpark of the target lead conversion rate to be around 80%.\n'], 'url_profile': 'https://github.com/VikramMathur3012', 'info_list': ['HTML', 'Updated Jun 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 17, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jul 11, 2020', '2', 'Python', 'MIT license', 'Updated Jul 11, 2020', 'Updated Apr 6, 2020']}","{'location': 'brighton, United Kingdom', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': [""Credit-Card-Fraud\nPredict fraudulent credit card transactions with the help of machine learning models. Analyse customer-level data which has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group.\nThe dataset is taken from the Kaggle website and it has a total of 2,84,807 transactions, out of which 492 are fraudulent.\nBusiness Problem Overview\nFor many banks, retaining high profitable customers is the number one business goal. Banking fraud, however, poses a significant threat to this goal for different banks. In terms of substantial financial losses, trust and credibility, this is a concerning issue to both banks and customers alike.\nIt has been estimated by Nilson report that by 2020 the banking frauds would account to $30 billion worldwide. With the rise in digital payment channels, the number of fraudulent transactions is also increasing with new and different ways.\nIn the banking industry, credit card fraud detection using machine learning is not just a trend but a necessity for them to put proactive monitoring and fraud prevention mechanisms in place. Machine learning is helping these institutions to reduce time-consuming manual reviews, costly chargebacks and fees, and denials of legitimate transactions.\nUnderstanding and Defining Fraud\nCredit card fraud is any dishonest act and behaviour to obtain information without the proper authorization from the account holder for financial gain. Among different ways of frauds, Skimming is the most common one, which is the way of duplicating of information located on the magnetic strip of the card.  Apart from this, the other ways are:\nManipulation/alteration of genuine cards\nCreation of counterfeit cards\nStolen/lost credit cards\nFraudulent telemarketing\nData Dictionary\nThe data set includes credit card transactions made by European cardholders over a period of two days in September 2013. Out of a total of 2,84,807 transactions, 492 were fraudulent. This data set is highly unbalanced, with the positive class (frauds) accounting for 0.172% of the total transactions. The data set has also been modified with Principal Component Analysis (PCA) to maintain confidentiality. Apart from â€˜timeâ€™ and â€˜amountâ€™, all the other features (V1, V2, V3, up to V28) are the principal components obtained using PCA. The feature 'time' contains the seconds elapsed between the first transaction in the data set and the subsequent transactions. The feature 'amount' is the transaction amount. The feature 'class' represents class labelling, and it takes the value 1 in cases of fraud and 0 in others.\nProject Pipeline\nThe project pipeline can be briefly summarized in the following four steps:\nData Understanding: Here, you need to load the data and understand the features present in it. This would help you choose the features that you will need for your final model.\nExploratory data analytics (EDA): Normally, in this step, you need to perform univariate and bivariate analyses of the data, followed by feature transformations, if necessary. For the current data set, because Gaussian variables are used, you do not need to perform Z-scaling. However, you can check if there is any skewness in the data and try to mitigate it, as it might cause problems during the model-building phase.\nTrain/Test Split: Now you are familiar with the train/test split, which you can perform in order to check the performance of your models with unseen data. Here, for validation, you can use the k-fold cross-validation method. You need to choose an appropriate k value so that the minority class is correctly represented in the test folds.\nModel-Building/Hyperparameter Tuning: This is the final step at which you can try different models and fine-tune their hyperparameters until you get the desired level of performance on the given dataset. You should try and see if you get a better model by the various sampling techniques.\nModel Evaluation: Evaluate the models using appropriate evaluation metrics. Note that since the data is imbalanced it is is more important to identify which are fraudulent transactions accurately than the non-fraudulent. Choose an appropriate evaluation metric which reflects this business goal.\nCost-Benefit Analysis\nAfter finding the best evaluation score on the test data, you have to find how much cost you are saving from the final predictive model.\n""], 'url_profile': 'https://github.com/VikramMathur3012', 'info_list': ['HTML', 'Updated Jun 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 17, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jul 11, 2020', '2', 'Python', 'MIT license', 'Updated Jul 11, 2020', 'Updated Apr 6, 2020']}","{'location': 'Spain', 'stats_list': [], 'contributions': '719 contributions\n        in the last year', 'description': ['\nAcerca de este repositorio.\nEste repositorio contiene los ejercicios realizados para\nla asignatura IA2 en los estudios en la UCM.\nÂ¿CÃ³mo estÃ¡ organizado?\nEste repositorio esta organizado una carpeta por cada\nprÃ¡ctica de laboratorio realizada.\nPrÃ¡ctica 1.\nEn esta carpeta encontrarÃ¡ tres ficheros .ipynb junto a una carpeta de datos los cuales describiremos a continuaciÃ³n:\n\n\nCarpeta Datos: Contiene los dos ficheros utilizados en los diferentes notebooks para poder realizar las tareas correspondientes.\n\n\nFichero Practica_1_1.ipynb: Este fichero contiene tÃ©cnicas de Agrupamiento o Clustering.\n\n\nFichero Practica_1_2.ipynb: Este fichero contiene tÃ©cnicas de ClasificaciÃ³n.\n\n\nFichero Practica_1_3.ipynb: Este fichero contiene tÃ©cnicas de RegresiÃ³n.\n\n\nPuede leer el PDF tÃ­tulado Practica1.pdf para conocer el enunciado suministrado para realizar esta prÃ¡ctica.\nPrÃ¡ctica 2.\nEn esta carpeta encontrarÃ¡ dos ficheros .ipynb junto a una carpeta de datos los cuales describiremos a continuaciÃ³n:\n\n\nCarpeta Datos: Contiene el fichero utilizado en el notebook de Analisis de sentimientos.\n\n\nFichero Practica_2_1.ipynb: Este fichero contiene tÃ©cnicas de AnÃ¡lisis de Sentimientos.\n\n\nFichero Practica_2_2.ipynb: Este fichero contiene tÃ©cnicas de RecuperaciÃ³n de InformaciÃ³n.\n\n\nPuede leer el PDF tÃ­tulado Practica2.pdf para conocer el enunciado suministrado para realizar esta prÃ¡ctica.\nPrÃ¡ctica 3.\nEn esta carpeta encontrarÃ¡ un fichero .ipynb en el cual se encuentran diferentes consultas con sparql.\nPuede leer el PDF tÃ­tulado Practica3.pdf para conocer el enunciado suministrado para realizar esta prÃ¡ctica.\nPrÃ¡ctica 4.\nEn esta carpeta encontrarÃ¡ un fichero .ipynb junto a otros para relizar la practica que se describe en el PDF tÃ­tulado Practica4.pdf, el cual contiene el enunciado suministrado para realizar esta prÃ¡ctica.\nAutores.\n\nFrederick Ernesto Borges Noronha \xa0 \nVictor Manuel Cavero Gracia \xa0 \n\nLicencia.\nEl codigo presente en este repositio se encuentra bajo\nuna Licencia MIT - Puede ver LICENSE para mÃ¡s\ndetalles.\n'], 'url_profile': 'https://github.com/FrederickBor', 'info_list': ['HTML', 'Updated Jun 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 17, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jul 11, 2020', '2', 'Python', 'MIT license', 'Updated Jul 11, 2020', 'Updated Apr 6, 2020']}","{'location': 'Guwahati, Assam, India', 'stats_list': [], 'contributions': '2,595 contributions\n        in the last year', 'description': ['Machine-Learning\nContains my Glossary for Machine Learning related Stuffs using Python\nFor Reference & Datasets - https://www.superdatascience.com/machine-learning\n'], 'url_profile': 'https://github.com/rahulbordoloi', 'info_list': ['HTML', 'Updated Jun 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 17, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jul 11, 2020', '2', 'Python', 'MIT license', 'Updated Jul 11, 2020', 'Updated Apr 6, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['ConsReg\nConsReg is my first R package that I decide to give to the R community. It is a compilation of functions that I have used in my day-to-day developing models.\nConsReg allows the estimation of GLM models with restrictions to parameters: both of limits (upper and lower) and between parameters (e.g. coef1 > coef2). This package is very easy to use and is ideal for situations where the logic of the model is more important than the error itself.\nConsReg has two main functions:\n\nConsReg\nConsRegArima\n\nThe first one, *ConsReg, as I said is a wrapper of glm function, while ConsRegArima allows to estimate regression models with Arima errors.\n'], 'url_profile': 'https://github.com/cran', 'info_list': ['HTML', 'Updated Jun 21, 2020', '1', 'Jupyter Notebook', 'Updated Apr 23, 2020', 'Updated Apr 8, 2020', 'Python', 'Updated Apr 9, 2020', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 8, 2020', '2', 'Jupyter Notebook', 'Updated Apr 17, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jul 11, 2020', '2', 'Python', 'MIT license', 'Updated Jul 11, 2020', 'Updated Apr 6, 2020']}"
"{'location': 'Lacey, WA', 'stats_list': [], 'contributions': '117 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/finbarr91', 'info_list': ['1', 'Python', 'Updated Feb 3, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Jul 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '34 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/karthicksundar95', 'info_list': ['1', 'Python', 'Updated Feb 3, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Jul 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '30 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/AbdulBishar', 'info_list': ['1', 'Python', 'Updated Feb 3, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Jul 14, 2020']}","{'location': 'Dallas ,TX', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': ['PCA_PrincipalComponentAnalysis\nIn this notebook, we will pick a dataset with 6 independent variables and do principal component analysis on the independent variables. Using the PCA results, we will reduce the dimensionality of the data set. Finally we will construct simple linear regression models with the original independent variables and contrast it against a model with the new reduced set of variables constructed using PCA\n'], 'url_profile': 'https://github.com/SindhujaJayakumar', 'info_list': ['1', 'Python', 'Updated Feb 3, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Jul 14, 2020']}","{'location': 'Urbana, Illinois', 'stats_list': [], 'contributions': '190 contributions\n        in the last year', 'description': ['Ames-Housing-XGBoost\nDataset with ~20% empty cells for numeric and categorical features. Performed XGBoost regression with best_params_ that were obtained by 4-fold cross-validated GridSearch. Training RMSE = 25667. The predictions for 1459 houses included separately in pred.csv. (Credits: Dean de Cock on Kaggle.com)\n'], 'url_profile': 'https://github.com/TheKivs', 'info_list': ['1', 'Python', 'Updated Feb 3, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Jul 14, 2020']}","{'location': 'Seattle, WA', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': [""King County, WA Housing Affordability Study\n\nProblem Statement\nFrom 2000 to 2020, the median home value in King County, WA increased by approximately 190%.\nData Gathering\nI gathered my data from the US Census, Zillow, and King County Trend of Housing Costs in Relation to Income.\nMethods\nI gathered 19 years of data for median home value, median household income, population, and housing units available. After uploading the dataframe and minor cleaning, I checked out two multiple line graphs: one with the raw data and one that was based on each year's percent change from base year 2000. From there I moved to modeling.\nModeling\nI first created X and y variables, with X equal to median household income, population, and housing units; y was equal to median home value.  Next I created X_train, y_train, X_test, and y_test, and performed a train_test_split. I ran two different models: linear regression and random forest. I scaled the data before running the models as each variable had significantly different scales.  Then I ran a simple linear regression model and checked some scatter plots for the model predicted values vs actual values.  I also did this for each individual variable just to see what they looked like.  Next I ran the random forest model through a gridsearch, which determined the best estimator was n_estimators = 60.\nResults\nI initially had my test size set to .2, which resulted in train/test scores of .9 for my linear regression. My random forest model got train/test scores of .96 and .56, respectively.  This seemed weird, and I realized because I have such a small dataset (19 rows), my X_test was only a sample size of 3 or 4.  This is not sufficient.  So I changed my test size to .33, which is still only about 6, but it's a little better.  My linear regression model returned scores of .95 and .83, and random forest scores were .98 and .7.  This is still a bit odd, but more in line what would be considered realistic.\nConclusion\nI donâ€™t feel terrible about a model predicting .83 accuracy, but not super great either. I think the reality is that going further back in time with the data would be very helpful; 19 rows is very limiting. I only have 6 points of data in my test set, which is better than nothing but itâ€™s not a lot to test on. Unfortunately, collecting data was probably my most time-consuming part of this project and obtaining more was not possible with the time constraints.\nThe project wasnâ€™t a bust, though. In coordination with population growth generally, the trend did show that increasing incomes coordinated more with home values. I recommended that the county continue to increase housing supply to get ahead of the demand and help reduce home values. I also recommended more research to include rental rates, and a comparison of proportion of housing units for ownership vs for rental throughout the county.\nData Dictionary\n\n\n\nFeature\nType\nDataset\nDescription\n\n\n\n\nindex\nint\ndf\nnumbered index of the rows\n\n\nyear\nint\ndf\nyear the data is from\n\n\nhousing_units\nint\ndf\nnumber of housing units available to live in (single fam. houses, apartments, condos, etc)\n\n\nmed_home_val\nint\ndf\nmedian home value\n\n\npopulation\nint\ndf\npopulation\n\n\nmed_income\nint\ndf\nmedian household income\n\n\n\n""], 'url_profile': 'https://github.com/stephenschott', 'info_list': ['1', 'Python', 'Updated Feb 3, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Jul 14, 2020']}","{'location': 'Seattle, WA', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['Ames, Iowa Correlations in Housing Data\n\nProblem Statement\nWhat can a homeowner or house flipper can do to maximize a house value prior to selling?\nData Gathering\nThis project was based on datasets available on kaggle.com.\nMethods\nThe data is fairly complete but definitely had some issues. I found that 21 of the 80 columns contained null values. I intended to use up to seven variables in my model to show correlation, so I looked at the top ten or so variables to see if there were any issues that jumped out at me. There werenâ€™t significant issues with the top ten or so variables except that many rows in â€œgarage areaâ€ contained nulls. I deleted those as they amounted to approximately 5% of the data, which is not insignificant but in order to accurately create my models based on current information, I needed to be able to utilize this column. I also saw no way to be able to make any kind of educated guess to fill any of these nulls in, and time didnâ€™t allow for that kind of research anyway. I also created a column that subtracted the year the house was built from the year the data was collected in order to get the house age. The seven variables I used were: overall quality, ground floor living area, garage area, garage cars, total basement square footage, first floor square footage, and house age.\nModeling\nFor model 0, I set my features to be overall quality, ground floor living area, and garage area. I set my X and y variables, and then created X_train, y_train, X_test, and y_test for train_test_split. Next I instantiated my linear regression model, and fit it with my training data. I essentially repeated this process six times. For models 1 through 3, I scaled data first, and then used the top three, five, and seven variables in linear regression models. For models 4 through 6, I used scaled data and used the top three, five, and seven variables in Ridge and Lasso models. Being my first project, I didnâ€™t realize I actually created two models each for models 4, 5, and 6, one Ridge and one Lasso. They all got roughly the same scores so it is a moot point, but it was an early lesson for me.\nResults\nModel 0: train: .75 test: .77 \nModel 1: train: .74 test: .8\nModel 2: train: .76 test: .82\nModel 3: train: .76 test: .82\nModel 4: train: .75 test: .78\nModel 5: train: .76 test: .82\nModel 6: train: .77 test: .83\nConclusion\nThis was a big learning experience for me, being my first project.  All of my results had slight bias, meaning I could have added more variables for a better model. The results were  not terrible though.  I concluded that the best way to increase your home value on average is to improve the overall quality of the house (i.e. kitchen, house fixtures, etc), and open up the ground living area if possible. Having a garage and/or basement also correlated well to higher values, but those are either impossible or too expensive to install, so any increased value for the seller would be offset by the cost to build.\nThis was an interesting project for me as I went in thinking kitchens and bathrooms would be the biggest value gain for homeowners, but those were down the list. There wasnâ€™t a category for kitchen or bathroom quality, which may have made a difference. Regardless, it was an important lesson that as a data scientist you have to go in open minded on every project, while at the same time you must use your knowledge of a field to identify things that may not make sense or could be errors, either on our part or the dataset. Overall, I liked this project and would love working in the real-estate industry to find more information like this.\nData Dictionary\n\n\n\nFeature\nType\nDataset\nDescription\n\n\n\n\nId\nint\ntrain\nhouse sale id\n\n\npid\nint\ntrain\nparcel identification number  - can be used with city web site for parcel review\n\n\nms_subclass\nint\ntrain\nidentifies the type of dwelling involved in the sale\n\n\nms_zoning\nobject\nfloat\ntrain\n\n\nlot_frontage\nint\ntrain\narea along street in linear feet\n\n\nlot_area\nobject\ntrain\nlot area is square feet\n\n\nstreet\nobject\ntrain\ntype of road access to property\n\n\nalley\nobject\ntrain\ntype of alley access to property\n\n\nlot_shape\nobject\ntrain\ngeneral shape of the property\n\n\nland_contour\nobject\ntrain\nflatness of the property\n\n\nutilities\nobject\ntrain\ntype of utilities available\n\n\nlot_config\nobject\ntrain\nlot configuration\n\n\nland_slope\nobject\ntrain\nslope of property\n\n\nneighborhood\nobject\ntrain\nphysical locations within Ames city limits\n\n\ncondition_1\nobject\ntrain\nproximity to various conditions\n\n\ncondition_2bldg_type\nobject\ntrain\nproximity to various conditions (if more than one is present)\n\n\nhouse_style\nobject\ntrain\nstyle of dwelling\n\n\noverall_qual\nint\ntrain\nrates the overall material and finish of the house\n\n\noverall_cond\nint\ntrain\nrates the overall condition of the house\n\n\nyear_built\nint\ntrain\noriginal construction date\n\n\nyear_remod/add\nint\ntrain\nremodel date (same as construction date if no remodeling or additions)\n\n\nroof_style\nobject\ntrain\ntype of roof\n\n\nroof_matl\nobject\ntrain\nroof material\n\n\nexterior_1st\nobject\ntrain\nexterior covering on house\n\n\nexterior_2nd\nobject\ntrain\nexterior covering on house (if more than one material)\n\n\nmas_vnr_type\nobject\ntrain\nmosonry veneer type\n\n\nmas_vnr_area\nfloat\ntrain\nmasonry veneer area in square feet\n\n\nexter_qual\nobject\ntrain\nevaluates the quality of the material on the exterior\n\n\nexter_cond\nobject\ntrain\nevaluates the present condition of the material on the exterior\n\n\nfoundation\nobject\ntrain\nfoundation type\n\n\nbsmt_qual\nobject\ntrain\nbasement height\n\n\nbsmt_cond\nobject\ntrain\nevaluates the condition of the basement\n\n\nbsmt_exposure\nobject\ntrain\nRefers to walkout or garden level walls\n\n\nbsmtfin_type_1\nobject\ntrain\nrating of basement type 1\n\n\nbsmtfin_sf_1\nfloat\ntrain\ntype 1 basement square feet\n\n\nbsmtfin_type_2\nobject\ntrain\nrating of basement type 2 (if multiple areas)\n\n\nbsmtfin_sf_2\nfloat\ntrain\ntype 2 basement square feet\n\n\nbsmt_unf_sf\nfloat\ntrain\nunfinished square feet in basement\n\n\ntotal_bsmt_sf\nfloat\ntrain\nbasement square feet\n\n\nheating\nobject\ntrain\ntype of heating\n\n\nheating_qc\nobject\ntrain\nheating quality and condition\n\n\ncentral_air\nobject\ntrain\ncentral air conditioning\n\n\nelectrical\nobject\ntrain\nelectrical type\n\n\n1st_flr_sf\nint\ntrain\nfirst floor square feet\n\n\n2nd_flr_sf\nint\ntrain\nsecond floor square feet\n\n\nlow_qual_fin_sf\nint\ntrain\nlow quality finished square feet (all floors)\n\n\ngr_liv_area\nint\ntrain\nabove ground living area\n\n\nbsmt_full_bath\nfloat\ntrain\nfull baths in basement\n\n\nbsmt_half_bath\nfloat\ntrain\nhalf baths in basement\n\n\nfull_bath\nint\ntrain\nfull baths above grade\n\n\nhalf_bath\nint\ntrain\nhalf baths above grade\n\n\nbedroom_abvgr\nint\ntrain\nbedrooms above grade\n\n\nkitchen_abvgr\nint\ntrain\nkitchens above grade\n\n\nkitchen_qual\nobject\ntrain\nkitchen quality\n\n\ntotrms_abvgrd\nint\ntrain\ntotal room above ground (excpet baths)\n\n\nfunctional\nobject\ntrain\nhome functionality (Assume typical unless deductions are warranted)\n\n\nfireplaces\nint\ntrain\nnumber of fireplaces\n\n\nfireplace_qu\nobject\ntrain\nquality of fireplaces\n\n\ngarage_type\nobject\ntrain\ngarage location\n\n\ngarage_yr_blt\nobject\nfloat\ntrain\n\n\ngarage_finish\nobject\ntrain\nfinish inside the garage\n\n\ngarage_cars\nfloat\ntrain\nhow many cars garage can fit\n\n\ngarage_area\nfloat\ntrain\ngarage area in square feet\n\n\ngarage_qual\nobject\ntrain\ngarage quality\n\n\ngarage_cond\nobject\ntrain\ngarage condition\n\n\npaved_drive\nobject\ntrain\npaved driveway - y, n, p (partial paved)\n\n\nwood_deck_sf\nint\ntrain\nwood deck area in square feet\n\n\nopen_porch_sf\nint\ntrain\nopen porch area in square feet\n\n\nenclosed_porch\nint\ntrain\nenclosed porch area in square feet\n\n\n3ssn_porch\nint\ntrain\nthree season porch area in square feet\n\n\nscreen_porch\nint\ntrain\nscreened porch area in square feet\n\n\npool_area\nint\ntrain\npool area in square feet\n\n\npool_qc\nobject\ntrain\npool quality\n\n\nfence\nobject\ntrain\nfence quality\n\n\nmisc_feature\nobject\ntrain\nmiscellanous features not covered in other categories\n\n\nmisc_val\nint\ntrain\nvalue of miscellaneous features\n\n\nmo_sold\nint\ntrain\nmonth sold (MM)\n\n\nyr_sold\nint\ntrain\nyear sold (YYYY)\n\n\nsale_type\nobject\ntrain\nType of sale\n\n\nsaleprice\nint\ntrain\nsale price of the house\n\n\nyear_2010\nint\ntrain\n2010\n\n\nhouse_age_2010\nint\ntrain\nhouse age in 2010 (year_2010 column minus year_built column)\n\n\n\n'], 'url_profile': 'https://github.com/stephenschott', 'info_list': ['1', 'Python', 'Updated Feb 3, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Jul 14, 2020']}","{'location': 'Kolkata', 'stats_list': [], 'contributions': '55 contributions\n        in the last year', 'description': ['NYC-Taxi-Fare-Prediction\nIn this project, I got to work with the data from a large number of taxi journeys in New York from 2013. I used regression trees and random forests to predict the value of fares and tips, based on location, date and time.\n'], 'url_profile': 'https://github.com/som21-star', 'info_list': ['1', 'Python', 'Updated Feb 3, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Jul 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['Titanic_Analisys_And_MachineLeanrning\nI analyzed the Titanic dataset and edited outliers and missing values. And I still brought it ready for machine learning. I tried and analyzed Decision Tree, SVM, Random Forest, KNN, Logistic Regression algorithms which are among the Machine Learning Algorithms. As a result, the best results of these algorithms are Decision Tree. and Random Forest.\n'], 'url_profile': 'https://github.com/eminaydinalp', 'info_list': ['1', 'Python', 'Updated Feb 3, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Jul 14, 2020']}","{'location': 'France', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': [""Bias-mitigation-with-a-Keras-Embedding\nThis project aims at finding an approach that allows\nto handle truncated targeted features in a linear regression problem.\nLet's say we know that there is a linear relation between some features and a target variable.\nIs it possible to compute the exact weights given truncated target variables?\n""], 'url_profile': 'https://github.com/Lucadel', 'info_list': ['1', 'Python', 'Updated Feb 3, 2021', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'R', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020', 'Python', 'MIT license', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Jul 14, 2020']}"
"{'location': 'Kolkata', 'stats_list': [], 'contributions': '55 contributions\n        in the last year', 'description': ['Kidney-Stones-and-Simson-s-Paradox-\nIn this project, I worked with medical data published in 1986 in ""The British Medical Journal"" where the effectiveness of two types of kidney stone removal treatments (A - open surgery and B - percutaneous nephrolithotomy) were compared. I used multiple logistic regression and visualize model output to help the doctors determine if there is a difference between the two treatments.\n'], 'url_profile': 'https://github.com/som21-star', 'info_list': ['R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'MIT license', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Sep 19, 2020', '1', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 21, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'Seattle, WA', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': [""Correlations and Differences Between Lesbians and Gay Men on Reddit\n\nProblem Statement\nLesbians have twice the divorce rate of gay men.  What correlations on Reddit can we use to identify causes and solutions?\nData Gathering\nI gathered all of my data from two reddit groups. There are GayMen (https://www.reddit.com/r/GayMen/) and actuallesbians (https://www.reddit.com/r/actuallesbians/). I obtained all my data with the Pushshift API, which involved two batches of 500 for each reddit group.\nMethods\nCleaning was fairly minimal to maintain as many words as possible. I converted the data from json to dataframes, and combined the dataframes.  I changed the subreddit column so that GayMen = 1 and actuallesbian = 0. I combined the selftext (the text in the post) and title (text in the title of the post) columns into a new column called text. This allowed me to have one X to compare with my one y variable. I used sklearn's stopwords and removed roughly 15 of their words that could be important in this study, primarily pronouns.\nModeling\nI set X equal to the text column, and y to the subreddit column. I set up X_train, y_train, X_test, y_test and made my test size .33, stratified y, and created a random state of 42. For model 1, I created a â€˜pipeâ€™ with cvec and lr, for CountVectorizer() and LogisticRegression() respectively. The â€˜pipe parametersâ€™ included my stopwords, max_features of 500, 750, and 1000, min_df of 3, 5, and 9, and ngram_range of (1,1) and (1,2). And lastly, I created a GridSearchCV, which included the pipe, pipe parameters, and cv of 5. I repeated this process for my second model, the only difference being that my pipe used TfidfVectorizer(tvec) instead of cvec. My third model ran through the same pipe, with the exception of utilizing MultinomialNB (naive bayes) instead of logistic regression.\nResults\nModel 1: I fit my X_train and y_train to my gridsearch and found the best estimator to be max_features=750, min_df=9, ngram_range=(1, 1). My train and test accuracy scores were .95 and .82, respectively.\nModel 2: max_features = 1000, min_df = 3, and ngram_range = (1,1). The train and test scores came back .9 each\nModel 3: best estimator was max_features = 1000, min_df= 3, and ngram_range = (1,1). The train score was .89 while the test score came back .81\nConclusion\nWe can find significant differences in gay/lesbian subreddit text, but this study did not compare the exact words that were different between the two subreddits. Ultimately, comparing gay and lesbian Reddit language is perhaps useful for differentiating gay men from lesbians, but not the best way to diagnose problems within the lesbian community. A better method would be to conduct surveys with lesbians in marriages that have ended and lesbians in marriages that have lasted over x years and find trends.\nData Dictionary\n\n\n\nFeature\nType\nDataset\nDescription\n\n\n\n\nsubreddit\nint\ndf\n1 = GayMen subreddit, 0 = actuallesbians subreddit\n\n\nselftext\nobj\ndf\nbody text of the reddit submission\n\n\ntitle\nobj\ndf\ntitle text of the reddit submission\n\n\ntext\nobj\ndf\ncombined body and title text of the reddit submission\n\n\n\n""], 'url_profile': 'https://github.com/stephenschott', 'info_list': ['R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'MIT license', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Sep 19, 2020', '1', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 21, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'Dallas ,TX', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/SindhujaJayakumar', 'info_list': ['R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'MIT license', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Sep 19, 2020', '1', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 21, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '69 contributions\n        in the last year', 'description': ['Coursera-The_Best_Classifier_Project\nk-Nearest Neighbour, Decision Tree, Support Vector Machine and Logistic Regression classification algorithms on the given data. The results is reported as the accuracy of each classifier, using the following metrics when these are applicable:  Jaccard index, F1-score and LogLoass\n'], 'url_profile': 'https://github.com/Emharsh', 'info_list': ['R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'MIT license', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Sep 19, 2020', '1', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 21, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'India', 'stats_list': [], 'contributions': '8,265 contributions\n        in the last year', 'description': [""100DaysOfMachineLearning\n\nMy learning log of these 100 days are here.\nYou are always welcome to optimize or improve any resource in this repository by following these instructions.\nPython Package:\n\n\nNumpy: allowing us to work with multidimensional array\n\n\nPandas: to organize data in tabular form and to attach descriptive labels to rows and columns\n\n\nMatplotlib: 2D plotting library designed for visualization of numpy computations\n\n\nScipy: tools for mathematics, ML, others\n\n\nSeaborn: high-level interface for drawing attractive statistical graphics\n\n\nStatsmodels: built on top of numpy and scipy, which integrates with pandas, SM provides good summaries\n\n\nScikit-learn or sklearn: used ML library for below example\n\n\nHow to Save and Load ML Models:\nWHAT On various instances, while working on developing a Machine Learning Model,\nWe'll need to save our prediction models to file, and then restore them in order to reuse our previous work to.\nWHY We need to save and restore/reload later our ML Model , so as to -\n\n\ntest our model on/with new data,\n\n\ncompare multiple models,\n\n\nor anything else.\n\n\nObject serialization: This process / procedure of saving a ML Model is also known as object serialization -\nrepresenting an object with a stream of bytes, in order to store it on disk, \nsend it over a network or save to a database.\n\nDeserialization: While the restoring/reloading of ML Model procedure is known as deserialization.\nExample\nfrom sklearn.externals import joblib\njoblib.dump(model, 'filename.pk1')                    #Save in file  \nmodel = joblib.load('filename.pk1')                   #Load from file\n\nRegression\nRegression is basically a statistical approach to find the relationship between variables.\nIn machine learning, this is used to predict the outcome of an event based on the relationship between variables obtained from the data-set.\nRegression is a task when model attempts to predict continuous values and its evaluation can be done this way.\nLinear\n\n\nSimple linear regression\n\nHow to do simple linear regression\nSalary Prediction using Simple linear Regression\n\n\n\nMultiple linear regression\n\n\nLogistic\n* Simple logistic regression\n* Multiple logistic regression\n\nFeature Engineering\n\nCardinality\nCategorical Encoding\nNo Co-linearity\nNormality\nRare Labels\nOne-Hot-Encoding\nHomoscedasticity\nMonotonic\n\nFeature Selection\n""], 'url_profile': 'https://github.com/Aman9026', 'info_list': ['R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'MIT license', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Sep 19, 2020', '1', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 21, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'Bangladesh', 'stats_list': [], 'contributions': '78 contributions\n        in the last year', 'description': ['Machine Learning with Python\nThis repository contains the implementation of python of the following machine learning algorithms:\n\nRegression (Linear, Non-Linear)\nClassification (KNN, Decision Tree, Logistic Regression, SVM)\nClustering (K-Means, DBSCAN, Hierarchical)\n\nContains the notebooks of the  following projects:\n\nPrediction of CO2 Emission using Simple Linear Regression\nCancer Cell Classification using SVM\nPredict the Telecommunication Customer Group using K-Nearest Neighbors\nPredicting Customer Churn using Logistic Regression\nPredicting Drug for a Future Patient with the Same Illness using Decision Tree Classifier.\nCustomer Segmentation with K-Means\nWeather Station Clustering using DBSCAN & scikit-learn\n\n'], 'url_profile': 'https://github.com/habiburrahman-mu', 'info_list': ['R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'MIT license', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Sep 19, 2020', '1', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 21, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'Hyderabad', 'stats_list': [], 'contributions': '115 contributions\n        in the last year', 'description': [""MachineLearning_-DataSets_solution\nLearner's Guide for Machine Learning.\nThis Repositoryy contains solutions to various datasets available at Kaggle , datacamp and other popular sources. If you are new to data science, these project  notebooks would help to improve your understanding and get experience to various models.\nThe important point in ML models is to understand the Data and attributes. Based on that Algorithms must be selected which would be effective.\nThe first few projects are basic and easy to understand. these are focused on one particular topic. Followed by advanced problems.\n""], 'url_profile': 'https://github.com/uknwho', 'info_list': ['R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'MIT license', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Sep 19, 2020', '1', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 21, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'Nirmal', 'stats_list': [], 'contributions': '737 contributions\n        in the last year', 'description': ['Machine Learning in Finance\n'], 'url_profile': 'https://github.com/AnuragAnalog', 'info_list': ['R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'MIT license', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Sep 19, 2020', '1', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 21, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'Bangalore,India', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': ['ML_Normal_Equation\nNormal Equation is an analytical approach to Linear Regression with a Least Square Cost Function. We can directly find out the value of Î¸ without using Gradient Descent. Following this approach is an effective and a time-saving option when are working with a dataset with small features.\nNormal Equation is a follows :\n\nIn the above equation,\n\nÎ¸ : hypothesis parameters that define it the best.\nX : Input feature value of each instance.\nY : Output value of each instance.\n\n'], 'url_profile': 'https://github.com/AMIYAMAITY', 'info_list': ['R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'MIT license', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Sep 19, 2020', '1', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 21, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['DB_Project\nThe project is based on prediction of Diabetes. There are actually two types of diabetes, namely Type1 and Type2 . The type 2 diabetes are normally called as diabetes mallitus. We consider the Mallitus here. Here, in this project we have used Logistic Regression algorithm. By using the data of the peoplewith and without diabetes, a dataset has been build. We use that dataset to classify the people who are in the risk of getting diabetes.\n'], 'url_profile': 'https://github.com/Pooja2807', 'info_list': ['R', 'Updated Apr 7, 2020', 'Jupyter Notebook', 'Updated Apr 15, 2020', 'Updated Apr 6, 2020', 'Jupyter Notebook', 'Updated Apr 10, 2020', '2', 'MIT license', 'Updated Apr 28, 2020', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Sep 19, 2020', '1', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated Apr 21, 2020', 'Python', 'Updated Apr 9, 2020', 'Jupyter Notebook', 'Updated Apr 7, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '7 contributions\n        in the last year', 'description': [""Bike-sharing-system\nHello everyone,  In this project I was trying to predict the number of users of bike-sharing system, I'm not sure I did it right, so I was hoping if someone with more knowledge than me would give it look and tell me how can I improve this. Overall, this is my first ML project (I'm currenltly covering Linear Regression model) so I hope for constructive feedback.\n""], 'url_profile': 'https://github.com/lakrau', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Python', 'MIT license', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated Feb 12, 2021', '1', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Dec 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['Corona_Analys\nI created a machine learning model with the corona virus data in March. And I made predictions and visualized in April. The algorithms I use are support vector machine and polynomial linear regressors.\n'], 'url_profile': 'https://github.com/eminaydinalp', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Python', 'MIT license', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated Feb 12, 2021', '1', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Dec 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'India, Earth!', 'stats_list': [], 'contributions': '866 contributions\n        in the last year', 'description': ['Nvidia DLI: Getting Started With AI on Jetson Nano\nThe jetson nano course notebooks!\nThe technologies used in the whole course\n\nJupyter Notebooks\nPyTorch\nJetson Nano Development Board\n\nThe free course can be taken at: https://nvidia.com/en-us/deep-learning-ai/education/\nDue to time constraints I wont be able to update the course content here.\nLAST UPDATED: 7-8 months back!\n'], 'url_profile': 'https://github.com/AJV009', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Python', 'MIT license', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated Feb 12, 2021', '1', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Dec 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'Delhi, India', 'stats_list': [], 'contributions': '538 contributions\n        in the last year', 'description': ['Machine Learning Models\n'], 'url_profile': 'https://github.com/Ravjot03', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Python', 'MIT license', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated Feb 12, 2021', '1', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Dec 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'kolkata', 'stats_list': [], 'contributions': '516 contributions\n        in the last year', 'description': ['UCI Machine Learning Repository\n\n\n\nThis is my repository where I practice techniques of Machine Learning by downloading datasets from UCI Machine Learning Repository.\n'], 'url_profile': 'https://github.com/Ankit152', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Python', 'MIT license', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated Feb 12, 2021', '1', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Dec 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'remote', 'stats_list': [], 'contributions': '98 contributions\n        in the last year', 'description': ['Deep Learning\nYou can use the editor on GitHub to maintain and preview the content for your website in Markdown files.\nWhenever you commit to this repository, GitHub Pages will run Jekyll to rebuild the pages in your site, from the content in your Markdown files.\nMarkdown\nMarkdown is a lightweight and easy-to-use syntax for styling your writing. It includes conventions for\nSyntax highlighted code block\n\n# Header 1\n## Header 2\n### Header 3\n\n- Bulleted\n- List\n\n1. Numbered\n2. List\n\n**Bold** and _Italic_ and `Code` text\n\n[Link](url) and ![Image](src)\nFor more details see GitHub Flavored Markdown.\nJekyll Themes\nYour Pages site will use the layout and styles from the Jekyll theme you have selected in your repository settings. The name of this theme is saved in the Jekyll _config.yml configuration file.\nSupport or Contact\nHaving trouble with Pages? Check out our documentation or contact support and weâ€™ll help you sort it out.\n'], 'url_profile': 'https://github.com/Meharab', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Python', 'MIT license', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated Feb 12, 2021', '1', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Dec 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'Boston', 'stats_list': [], 'contributions': '21 contributions\n        in the last year', 'description': ['What-makes-a-successful-Kickstarter-project-Predictive-Analysis-\nIdentified key characteristics of a successful project by analysing Kickstarter crowdfunding data from 2009-2008 and performed analysis with dplyr & tidyverse libraries in R studio to identify correlations between entities using Exploratory Data Analysis.\nProposed a linear model using linear regression and k-fold cross-validation to predict the success of a kickstarter project using backers and fundraising goal as the main variables having an impact on the model.\nCreated word clouds withtext mining approach using tokenizers and tidytext libraries to extract keywords (uni-grams and bi-grams) from project tile which contribute to the success of the project.\nIn this repository, the Project EDA file has all the Exploratory Data Analysis scripts which are mainly done using ggplot.\nThe Project Modelling file includes all the predictive analysis which is done using linear regression, logistic regression and text mining.\n'], 'url_profile': 'https://github.com/abhiD96', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Python', 'MIT license', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated Feb 12, 2021', '1', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Dec 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/parmeshwalunj', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Python', 'MIT license', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated Feb 12, 2021', '1', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Dec 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '17 contributions\n        in the last year', 'description': ['housing-price\nThis is the end-to-end data science project that has been completed by group of three. The project is broken down into two parts.\nThe first part is using a regression analysis to predict the value of houses. The dependent variable for this analysis is the price of the house and the independent variables are many different characteristics of the home, such as size, location, bedrooms, bathrooms, etc.\nThe second part is using a classification analysis to determine what zip-code a house is likely located in based upon its features. The attributes used in this classification analysis consist of different characteristics of the home, such as size, location, bedrooms, and price.\n'], 'url_profile': 'https://github.com/kayakyamak', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Python', 'MIT license', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated Feb 12, 2021', '1', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Dec 7, 2020', 'Python', 'Updated Apr 10, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7 contributions\n        in the last year', 'description': [""kaggle_dataset_grade_prediction\nThe goal here is to predict the final grades of each student based on the features given. So, initially I read the dataset by using pandas and dropped the unimportant features based on the feature importance calculation. Then I coverted the categorical dataset to numerical, by label encoding. And here I used three classifiers primiraly,based on the dataset that are decisiontree,support vector machine and logistic regression.The accuracy rate for each of the classifier is calculated individually. And finally based on the accuracy rate calculated 'decisiontree classifier' has higher accuracy rate ,than the rest of the two in predicting the student's final grade.\n""], 'url_profile': 'https://github.com/soundarya-alagesan', 'info_list': ['Jupyter Notebook', 'Updated Apr 11, 2020', '1', 'Python', 'MIT license', 'Updated Apr 12, 2020', '1', 'Jupyter Notebook', 'Updated Apr 13, 2020', 'Jupyter Notebook', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated Feb 12, 2021', '1', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'R', 'Updated Apr 11, 2020', 'Jupyter Notebook', 'Updated Apr 12, 2020', 'Jupyter Notebook', 'Updated Dec 7, 2020', 'Python', 'Updated Apr 10, 2020']}"
"{'location': 'Planet Earth', 'stats_list': [], 'contributions': '32 contributions\n        in the last year', 'description': ['Wheelchair-control-via-Eye-movement\nThe purpose of this project is to design a prototype of a wheelchair which can help differently abled individuals move independently. The motion of the wheelchair is controlled via the subjectâ€™s eye movement using IR sensors. The eye tracking-based technology employs the use of Infrared (IR) sensor modules, that are mounted on an eye frame to trace the movement of the iris. Since, IR sensors detect only white objects a unique sequence of digital bits is generated corresponding to each eye movement. These signals are then processed via a micro controller to control the motors of the wheelchair. The potential and efficiency of previously developed rehabilitation systems that use head motion, chin control, sip-n-puff control, voice recognition, and EEG signals variedly have also been explored in detail. They were found to be inconvenient as they served either limited usability or non-affordability. After multiple regression analyses, the proposed design was developed as a cost-effective, flexible and stream-lined alternative for people who have trouble adopting conventional assistive technologies.\n'], 'url_profile': 'https://github.com/Ananya-B', 'info_list': ['Updated Apr 6, 2020', 'HTML', 'Updated Apr 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '12 contributions\n        in the last year', 'description': ['Virusc\nRequirements - python interpreter (3.6 & above) ,\nInstall Python Packages - numpy , pandas , flask , newspaper3k , sklearn , flask_mysqldb , matplotlib .\nfollow this steps before running the code:-\n\nInstall xampp\nDownload Apache and Mysql in Xampp\nLaunch the control panel and start Apache and Mysql\nClick on admin corresponding to Mysql\nGo to SQL and paste corona sql text file and run it ,\nNow we are ready to run the main.py file\n\n'], 'url_profile': 'https://github.com/SuyogAhuja', 'info_list': ['Updated Apr 6, 2020', 'HTML', 'Updated Apr 12, 2020']}",,,,,,,,
