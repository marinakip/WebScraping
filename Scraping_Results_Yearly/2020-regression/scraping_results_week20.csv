"{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['AccessibilitySnapshot\n\n\n\n\nAccessibilitySnapshots makes it simple to add regression tests for accessibility in UIKit.\nGetting Started\nBy default, AccessibilitySnapshot uses SnapshotTesting to record snapshots and perform comparisons. The framework also includes support for using iOSSnapshotTestCase as the snapshotting engine instead. Before setting up accessibility snapshot tests, make sure your project is set up for standard snapshot testing. Accessibility snapshot tests require that the test target has a host application. See the Extensions section below for a list of other available snapshotting options.\nCocoaPods\nInstall with CocoaPods by adding the following to your Podfile:\npod \'AccessibilitySnapshot\'\nTo use only the core accessibility parser, add a dependency on the Core subspec alone:\npod \'AccessibilitySnapshot/Core\'\nAlternatively, if you wish to use iOSSnapshotTestCase to perform image comparisons, you can add a dependency on the iOSSnapshotTestCase subspec instead (or in addition - you can use both in the same project):\npod \'AccessibilitySnapshot/iOSSnapshotTestCase\'\nSwift Package Manager\nInstall with Swift Package Manager by adding the following to your Package.swift:\ndependencies: [\n    .package(name: ""AccessibilitySnapshot"", url: ""https://github.com/cashapp/AccessibilitySnapshot.git"", from: ""0.4.1""),\n]\nNext, add AccessibilitySnapshot as a dependency to your test target:\ntargets: [\n    .target(name: ""MyApp""),\n    .testTarget(name: ""MyAppTests"", dependencies: [""MyApp"", ""AccessibilitySnapshot""])\n]\nTo use only the core accessibility parser, add a dependency on the Core library alone:\ntargets: [\n    .target(name: ""MyApp""),\n    .testTarget(name: ""MyAppTests"", dependencies: [""MyApp"", ""AccessibilitySnapshotCore""])\n]\nWe do not currently support AccessibilitySnapshot and iOSSnapshotTestCase through Swift Package Manager.\nUsage\nAccessibilitySnapshot builds on top of existing snapshot frameworks to add support for snapshotting your app\'s accessibility. By default it uses the SnapshotTesting framework for snapshotting, but can be switched over to iOSSnapshotTestCase as well.\nGetting Started with SnapshotTesting\nAccessibilitySnapshot provides an .accessibilityImage snapshotting strategy that can be used with SnapshotTesting\'s snapshot assertions.\nfunc testAccessibility() {\n    let view = MyView()\n    // Configure the view...\n\n    assertSnapshot(matching: view, as: .accessibilityImage)\n}\nSnapshots can also be customized in a few ways, for example controlling when to include indicators for the accessibility activation point of each element. By default, these indicators are shown when the activation point is different than the default activation point for that view. You can override this behavior for each snapshot:\nfunc testAccessibility() {\n    let view = MyView()\n    // Configure the view...\n\n    // Show indicators for every element.\n    assertSnapshot(matching: view, as: .accessibilityImage(showActivationPoints: .always))\n\n    // Don\'t show any indicators.\n    assertSnapshot(matching: view, as: .accessibilityImage(showActivationPoints: .never))\n}\nGetting Started with iOSSnapshotTestCase\nTo run a snapshot test, simply call the SnapshotVerifyAccessibility method:\nfunc testAccessibility() {\n    let view = MyView()\n    // Configure the view...\n\n    SnapshotVerifyAccessibility(view)\n}\nSince AccessibilitySnapshot is built on top of iOSSnapshotTestCase, it uses the same mechanism to record snapshots (setting the self.recordMode property) and supports many of the same features like device agnostic file names and specifying identifiers for each snapshot:\nfunc testAccessibility() {\n    let view = MyView()\n    // Configure the view...\n\n    SnapshotVerifyAccessibility(view, identifier: ""identifier"")\n}\nSnapshots can also optionally include indicators for the accessibility activation point of each element. By default, these indicators are shown when the activation point is different than the default activation point for that view. You can override this behavior for each snapshot:\nfunc testAccessibility() {\n    let view = MyView()\n    // Configure the view...\n\n    // Show indicators for every element.\n    SnapshotVerifyAccessibility(view, showActivationPoints: .always)\n\n    // Don\'t show any indicators.\n    SnapshotVerifyAccessibility(view, showActivationPoints: .never)\n}\nYou can also run accessibility snapshot tests from Objective-C:\n- (void)testAccessibility;\n{\n    UIView *view = [UIView new];\n    // Configure the view...\n\n    SnapshotVerifyAccessibility(view, @""identifier"");\n}\nContributing\nWe love our\ncontributors!\nPlease read our contributing guidelines prior to submitting\na pull request.\nExtensions\nHave you written your own extension? Add it here and submit a pull request!\n\nPlaybookAccessibilitySnapshot brings accessibility snapshot testing support to Playbook.\n\nLicense\nCopyright 2020 Square Inc.\n\nLicensed under the Apache License, Version 2.0 (the ""License"");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an ""AS IS"" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n'], 'url_profile': 'https://github.com/cashapp', 'info_list': ['232', 'Swift', 'Apache-2.0 license', 'Updated Jan 17, 2021', '45', 'C++', 'Updated Mar 1, 2021', '5', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'Jupyter Notebook', 'Updated Jul 16, 2020', '2', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '16', 'Python', 'GPL-3.0 license', 'Updated Jun 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '4', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '20 contributions\n        in the last year', 'description': [""regenie is a C++ program for whole genome regression modelling of large genome-wide association studies.\nIt is developed and supported by a team of scientists at the Regeneron Genetics Center.\nThe method has the following properties\n\nIt works on quantitative and binary traits, including binary traits with unbalanced case-control ratios\nIt can process multiple phenotypes at once\nIt is fast and memory efficient 🔥\nFor binary traits it supports Firth logistic regression and an SPA test\nIt can perform gene/region-based burden tests\nIt supports the BGEN, PLINK bed/bim/fam and PLINK2 pgen/pvar/psam genetic data formats\nIt is ideally suited for implementation in Apache Spark (see GLOW)\nIt can be installed with Conda \n\nFull documentation for the regenie can be found here.\nCitation\nJoelle Mbatchou, Leland Barnard, Joshua Backman, Anthony Marcketta, Jack A. Kosmicki, Andrey Ziyatdinov, Christian Benner, Colm O'Dushlaine, Mathew Barber, Boris Boutkov, Lukas Habegger, Manuel Ferreira, Aris Baras, Jeffrey Reid, Goncalo Abecasis, Evan Maxwell, Jonathan Marchini. (2020) Computationally efficient whole genome regression for quantitative and binary traits [BioRxiv pre-print]\nLicense\nregenie is distributed under an MIT license.\nContact\nIf you have any questions about regenie please contact\n\njonathan.marchini@regeneron.com\njoelle.mbatchou@regeneron.com\n\nIf you want to submit a issue concerning the software please do so\nusing the regenie Github repository.\nVersion history\nVersion 2.0.1 (New option --catCovList to specify categorical covariates; Enabled parameter expansion when specifying select phenotypes/covariates to analyze [e.g. 'PC{1:10}'])\nVersion 2.0 (Added burden testing functionality for region or gene-based tests [see website for details]; added sample size column in summary stats output).\nFor past releases, see here.\n""], 'url_profile': 'https://github.com/rgcgithub', 'info_list': ['232', 'Swift', 'Apache-2.0 license', 'Updated Jan 17, 2021', '45', 'C++', 'Updated Mar 1, 2021', '5', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'Jupyter Notebook', 'Updated Jul 16, 2020', '2', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '16', 'Python', 'GPL-3.0 license', 'Updated Jun 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '4', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Hyderabad', 'stats_list': [], 'contributions': '39 contributions\n        in the last year', 'description': ['Machine-Learning-Foundation\nMachine Learning Foundation\n'], 'url_profile': 'https://github.com/SkillsSquad', 'info_list': ['232', 'Swift', 'Apache-2.0 license', 'Updated Jan 17, 2021', '45', 'C++', 'Updated Mar 1, 2021', '5', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'Jupyter Notebook', 'Updated Jul 16, 2020', '2', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '16', 'Python', 'GPL-3.0 license', 'Updated Jun 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '4', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': [""MLE and Logistic Regression\nIntroduction\nIn this lesson, you'll further investigate the connections between maximum likelihood estimation and logistic regression. This is a common perspective for logistic regression and will be the underlying intuition for upcoming lessons where you'll code the algorithm from the ground up using NumPy.\nObjectives\nYou will be able to:\n\nDetermine how MLE is tied into logistic regression\n\nMLE formulation\nAs discussed, maximum likelihood estimation finds the underlying parameters of an assumed distribution to maximize the likelihood of the observations. Logistic regression expands upon this by investigating the conditional probabilities associated with the various features, treating them as independent probabilities and calculating the respective total probability.\nFor example, when predicting an individual's risk for heart disease, you might consider various factors such as their family history, weight, diet, exercise routines, blood pressure, and cholesterol. When looked at individually, each of these has an associated conditional probability that the individual has heart disease based on each of these factors. Mathematically, you can write each of these probabilities for each factor $X$ as:\n$\\pi_i = Pr(Y_i = 1|X_i = x_i)=\\dfrac{\\text{exp}(\\beta_0 + \\beta_1 x_i)}{1 + \\text{exp}(\\beta_0 + \\beta_1 x_i)}$\nThis is the standard linear regression model ($\\beta_0+\\beta_1 x_i$) you have seen previously, modified to have a range of 0 to 1. The range is modified and constrained by applying the sigmoid function since you're predicting probabilities.\nThen, combining these conditional probabilities from multiple features, you maximize the likelihood function of each of those independent conditional probabilities, giving you:\n$ L(\\beta_0,\\beta_1)=\\prod\\limits_{i=1}^N \\pi_i^{y_i}(1-\\pi_i)^{n_i-y_i}=\\prod\\limits_{i=1}^N \\dfrac{\\text{exp}{y_i(\\beta_0+\\beta_1 x_i)}}{1+\\text{exp}(\\beta_0+\\beta_1 x_i)}$\nNotes on mathematical symbols\nRecall that the $\\prod$ sign stands for a product of each of these individual probabilities. (Similar to how $\\sum$ stands for the sum of a series.) Since this is a monotonically increasing function, its maximum will be the same as the logarithm of the function, which is typically used in practice in order to decompose this product of probabilities into a sum of log probabilities for easier calculation of the derivative. In future sections, you'll investigate the derivative of this function and then use that in order to code up our own function for logistic regression.\nAlgorithm bias and ethical concerns\nIt should also be noted that while this is mathematically sound and a powerful tool, the model will simply reflect the data that is fed in. For example, logistic regression and other algorithms are used to inform a wide range of decisions including whether to provide someone with a loan, the degree of criminal sentencing, or whether to hire an individual for a job. In all of these scenarios, it is again important to remember that the algorithm is simply reflective of the underlying data itself. If an algorithm is trained on a dataset where African Americans have had disproportionate criminal prosecution, the algorithm will continue to perpetuate these racial injustices. Similarly, algorithms trained on data that reflect a gender pay-gap will also continue to promote this bias unless adequately accounted for through careful preprocessing and normalization. With this, substantial thought and analysis regarding problem set up and the resulting model is incredibly important. While future lessons and labs in this section return to underlying mathematical theory and how to implement logistic regression on your own, it is worthwhile to investigate some of the current problems regarding some of these algorithms, and how naive implementations can perpetuate unjust biases.\nAdditional resources\nBelow are a handful of resources providing further information regarding some of the topics discussed here. Be sure to check out some of the news articles describing how poor safeguards and problem formulation surrounding algorithms such as logistic regression can lead to unjust biases:\nAlgorithm bias and ethical concerns\n\n\nMachine Bias\n\n\nAmazon’s Gender-Biased Algorithm Is Not Alone\n\n\nThe software that runs our lives can be bigoted and unfair. But we can fix it\n\n\nWhy artificial intelligence is far too human\n\n\nCan Computers Be Racist? The Human-Like Bias Of Algorithms\n\n\nAdditional mathematical resources\nFor a more in-depth discussion of the mathematical ideas, check out Penn State's lecture here\nIf you want to really go down the math rabbit-hole, check out section 4.4 on Logistic Regression from the Elements of Statistical Learning which can be found here: https://web.stanford.edu/~hastie/ElemStatLearn//.\nSummary\nIn this lesson, you further analyzed logistic regression from the perspective of maximum likelihood estimation. Additionally, there was a brief pause to consider the setup and interpretation of algorithms such as logistic regression. In particular, remember that issues regarding racial and gender bias that can be perpetuated by these algorithms. Always try to ensure your models are ethically sound. In the proceeding labs and lessons, you will continue to formalize your knowledge of logistic regression, implementing gradient descent and then a full logistic regression algorithm using Python packages in order to give you a deeper understanding of how logistic regression works.\n""], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['232', 'Swift', 'Apache-2.0 license', 'Updated Jan 17, 2021', '45', 'C++', 'Updated Mar 1, 2021', '5', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'Jupyter Notebook', 'Updated Jul 16, 2020', '2', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '16', 'Python', 'GPL-3.0 license', 'Updated Jun 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '4', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Nigeria', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['HFT_Test\nRegression Testing HFT system\nFind the regression test part at Test/test_sample.py\n'], 'url_profile': 'https://github.com/achuga200', 'info_list': ['232', 'Swift', 'Apache-2.0 license', 'Updated Jan 17, 2021', '45', 'C++', 'Updated Mar 1, 2021', '5', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'Jupyter Notebook', 'Updated Jul 16, 2020', '2', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '16', 'Python', 'GPL-3.0 license', 'Updated Jun 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '4', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'United States', 'stats_list': [], 'contributions': '122 contributions\n        in the last year', 'description': ['ResBaz_JAGS_tutorial\nThis repository provides a basic introduction to running a JAGS bayesian model in R/Rstudio for the 2020 Research Bazaar workshop at University of Arizona.\nBefore the workshop:\nIf you want to run the code yourself, please make sure you have JAGS installed, R & Rstudio, and have the ""rjags"",""coda"", and ""ggplot2"" r libraries installed.\nInstructions for installing JAGS are here: http://mcmc-jags.sourceforge.net/\nDuring the workshop, feel free to follow along and run the code using the R markdown file.\n'], 'url_profile': 'https://github.com/Kah5', 'info_list': ['232', 'Swift', 'Apache-2.0 license', 'Updated Jan 17, 2021', '45', 'C++', 'Updated Mar 1, 2021', '5', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'Jupyter Notebook', 'Updated Jul 16, 2020', '2', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '16', 'Python', 'GPL-3.0 license', 'Updated Jun 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '4', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '9 contributions\n        in the last year', 'description': [""Regression Model for Sendy Data\nSendyRegressionModel is a Python notebook that cleans a dataset and runs the columns through various regression models.\nThe notebook functions to select the regression model with the most accurate prediction set of values, compared using each model's respective Root Mean Squared Error (RMSE).\nThe notebook functions to clean new data and the appropriate variables in preparation to being fit into the selected model.\nThe predicted variable of this new test data is then created into a DataFrame with the appropriate order number as an index.\nThis dataframe is then saved locally as a csv file named 'submission.csv'\nAuthors and Acknowledgement\nKgaogelo Mamadi\nmrrmamadi@outlook.com\nThabo Ntsekhe\nntsekhethabo@gmail.com\nOmphile Louw\nomphilelouw@gmail.com\nNondumiso Magudulela\nndumi.magd119@gmail.com\nLucas Sithole\nlucas317sithole@gmail.com\n""], 'url_profile': 'https://github.com/mrmamadi', 'info_list': ['232', 'Swift', 'Apache-2.0 license', 'Updated Jan 17, 2021', '45', 'C++', 'Updated Mar 1, 2021', '5', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'Jupyter Notebook', 'Updated Jul 16, 2020', '2', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '16', 'Python', 'GPL-3.0 license', 'Updated Jun 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '4', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'China', 'stats_list': [], 'contributions': '121 contributions\n        in the last year', 'description': ['rotatable yolov3\nIntroduction\nA rotatable yolov3 model which can regress the angle of the bounding box\nFeatures\n\nAdvanced neural network models\nFlexible and efficient toolkit(See woodsgao/pytorch_modules)\nOnline data augmenting(By imgaug)\nMixed precision training(If you have already installed apex)\nEfficient distributed training(0.8x faster when using two 2080ti)\nAdd a script to convert to caffe model(By woodsgao/pytorch2caffe)\n\nInstallation\ngit clone https://github.com/woodsgao/rotatable_yolov3\ncd rotatable_yolov3\npip install -r requirements.txt\n\nTutorials\nCreate custom data\nPlease organize your data in coco format(by default):\ndata/\n    <custom>/\n        images/\n        coco.json\n        train.json\n        val.json\n\nYou can use split_coco_json.py from woodsgao/cv_utils\nto split your coco.json file into train.json and val.json\nTraining\npython3 train.py data/<custom>\n\nDistributed Training\npython3 -m torch.distributed.launch --nproc_per_node=<nproc> train.py data/<custom>\n\nTesting\npython3 test.py data/<custom>/val.json --weights weights.pth\n\nInference\npython3 inference.py data/samples outputs --weights weights.pth\n\nExport to caffe model\npython3 export2caffe.py weights/best.pt -nc 21 -s 416 416\n\n'], 'url_profile': 'https://github.com/woodsgao', 'info_list': ['232', 'Swift', 'Apache-2.0 license', 'Updated Jan 17, 2021', '45', 'C++', 'Updated Mar 1, 2021', '5', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'Jupyter Notebook', 'Updated Jul 16, 2020', '2', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '16', 'Python', 'GPL-3.0 license', 'Updated Jun 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '4', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Johannesburg', 'stats_list': [], 'contributions': '117 contributions\n        in the last year', 'description': ['Sendy Logistics Challenge - Regression Sprint JHB Team 9\nWelcome to the Regression Predict Repository\nInstructions:\nFork this repo to your own account before cloning it into your local machine.\nMake sure to create the necessary branches where you will be contributing to the notebook.\nBefore creating any Pull Request make sure you modified the latest version of the notebook to avoid any conflicts.\nGo team and good luck 😁😁😁\n'], 'url_profile': 'https://github.com/explore-thulani', 'info_list': ['232', 'Swift', 'Apache-2.0 license', 'Updated Jan 17, 2021', '45', 'C++', 'Updated Mar 1, 2021', '5', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'Jupyter Notebook', 'Updated Jul 16, 2020', '2', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '16', 'Python', 'GPL-3.0 license', 'Updated Jun 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '4', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '8 contributions\n        in the last year', 'description': ['Petrophysical_Interpretation_Random_Forest_Regression-\nThe goal of this article is to follow a recommended machine learning workflow on how to perform a petrophysical interpretation using an ensemble technique (Supervised Learning model), which is widely known as Random Forest Regression.\n'], 'url_profile': 'https://github.com/Chrisaranguren', 'info_list': ['232', 'Swift', 'Apache-2.0 license', 'Updated Jan 17, 2021', '45', 'C++', 'Updated Mar 1, 2021', '5', 'Jupyter Notebook', 'Updated Oct 12, 2020', 'Jupyter Notebook', 'Updated Jul 16, 2020', '2', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '16', 'Python', 'GPL-3.0 license', 'Updated Jun 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '4', 'Jupyter Notebook', 'Updated May 14, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '280 contributions\n        in the last year', 'description': ['Scikit-physlearn\n\n\n\nDocumentation |\nBase boosting\nScikit-physlearn is a machine learning library designed to amalgamate\nScikit-learn,\nLightGBM,\nXGBoost,\nCatBoost,\nand Mlxtend\nregressors into a flexible framework that:\n\nFollows the Scikit-learn API.\nProcesses pandas data representations.\nSolves single-target and multi-target regression tasks.\nInterprets regressors with SHAP.\n\nAdditionally, the library contains the official implementation of\nbase boosting, which is an algorithmic\nparadigm for building additive expansions based upon the output of any\nbase-level regressor. The implementation:\n\nSupplants the statistical initialization in gradient boosting\nwith the output of any base-level regressor.\nBoosts arbitrary basis functions, i.e., it is not limited to boosting\ndecision trees.\nEfficiently learns in the low data regime.\n\nThe library was started by Alex Wozniakowski during his graduate studies at Nanyang Technological\nUniversity.\nInstallation\nScikit-physlearn can be installed from PyPI:\npip install scikit-physlearn\n\nTo build from source, follow the installation guide.\nCitation\nIf you use this library, please consider adding the corresponding citation:\n@article{wozniakowski_2020_boosting,\n  title={Boosting on the shoulders of giants in quantum device calibration},\n  author={Wozniakowski, Alex and Thompson, Jayne and Gu, Mile and Binder, Felix C.},\n  journal={arXiv preprint arXiv:2005.06194},\n  year={2020}\n}\n\n\n'], 'url_profile': 'https://github.com/a-wozniakowski', 'info_list': ['1', 'Python', 'MIT license', 'Updated Oct 11, 2020', '3', 'Perl', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated Jul 3, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['NONE'], 'url_profile': 'https://github.com/giellalt', 'info_list': ['1', 'Python', 'MIT license', 'Updated Oct 11, 2020', '3', 'Perl', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated Jul 3, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '8 contributions\n        in the last year', 'description': ['regression_predict\n'], 'url_profile': 'https://github.com/Phiwe-Mabanga', 'info_list': ['1', 'Python', 'MIT license', 'Updated Oct 11, 2020', '3', 'Perl', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated Jul 3, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/hiddenidandname', 'info_list': ['1', 'Python', 'MIT license', 'Updated Oct 11, 2020', '3', 'Perl', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated Jul 3, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'Russia', 'stats_list': [], 'contributions': '9 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/vshilkin', 'info_list': ['1', 'Python', 'MIT license', 'Updated Oct 11, 2020', '3', 'Perl', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated Jul 3, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '226 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Trishnabar98', 'info_list': ['1', 'Python', 'MIT license', 'Updated Oct 11, 2020', '3', 'Perl', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated Jul 3, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Yanchoglov', 'info_list': ['1', 'Python', 'MIT license', 'Updated Oct 11, 2020', '3', 'Perl', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated Jul 3, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '65 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/austinsimpson', 'info_list': ['1', 'Python', 'MIT license', 'Updated Oct 11, 2020', '3', 'Perl', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated Jul 3, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '32 contributions\n        in the last year', 'description': ['Regression\n'], 'url_profile': 'https://github.com/spider2510', 'info_list': ['1', 'Python', 'MIT license', 'Updated Oct 11, 2020', '3', 'Perl', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated Jul 3, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/shrujanp', 'info_list': ['1', 'Python', 'MIT license', 'Updated Oct 11, 2020', '3', 'Perl', 'Updated Mar 3, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated Jul 3, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 14, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '17 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/sevimozinan', 'info_list': ['Updated Jan 7, 2021', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Jun 7, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 29, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Python', 'Updated May 16, 2020']}","{'location': 'San Francisco, CA', 'stats_list': [], 'contributions': '162 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/jmr7755', 'info_list': ['Updated Jan 7, 2021', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Jun 7, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 29, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '23 contributions\n        in the last year', 'description': ['Regression\nThis repository contains assignments using R with the following techniques:\n\nSimple and multiple linear regression\nAnalysis of variance (ANOVA)\nTransformations\nVariable and model selection\nStepwise regression\nGeneralized linear modeling\n\n'], 'url_profile': 'https://github.com/tislam3', 'info_list': ['Updated Jan 7, 2021', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Jun 7, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 29, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['regression\n'], 'url_profile': 'https://github.com/mohamedmakram', 'info_list': ['Updated Jan 7, 2021', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Jun 7, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 29, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Python', 'Updated May 16, 2020']}","{'location': 'United Kingdom', 'stats_list': [], 'contributions': '224 contributions\n        in the last year', 'description': ['regression.py\nBackground\n\n  A python script which takes line segments of 20dps and classifies them to a linear, sinusoidal or cubic fit. This script makes extensive use of matplotlib and numpy.\n\n\n  Multiple line segments can be provided in one CSV. Some test datasets are provided in the repo.\n  Use: python lsr.py  [--plot]\n  Plot flag enbles visual representation of fit using matplotlib.\n\nCode\n\n  To produce the best model does NOT always directly equate to having the lowest loss function. Therefore, to preserve generality I have multiplied more complex functions by larger coefficients (similar to the L2 normalisation scheme for multiple epoch regression). I did attempt to implement a cross validation system however the datasets were so small that segmenting enough data to cross validate either ersulted in woeful overfitting or a crazy output function.\n\nReflection\n\n  This script is bleoted, ineficient and overfits pretty badly. It can however give rough estimates of funtions and their coefficients. I probably would try and run it on a big set of line segments though.\n  To optomise I would probably use pytorch. A library engineered and optimised for regression is always going to be more efficient and accurate than my code.\n\n'], 'url_profile': 'https://github.com/mastamysta', 'info_list': ['Updated Jan 7, 2021', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Jun 7, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 29, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '52 contributions\n        in the last year', 'description': ['Regression\n'], 'url_profile': 'https://github.com/Sanatan321', 'info_list': ['Updated Jan 7, 2021', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Jun 7, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 29, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['regression2\nRegression\n'], 'url_profile': 'https://github.com/hiddenidandname', 'info_list': ['Updated Jan 7, 2021', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Jun 7, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 29, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '30 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Hemalatha-0526', 'info_list': ['Updated Jan 7, 2021', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Jun 7, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 29, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7 contributions\n        in the last year', 'description': ['REGRESSION\nREGRESSION\n'], 'url_profile': 'https://github.com/BileOara', 'info_list': ['Updated Jan 7, 2021', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Jun 7, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 29, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['About-Manifold-Gaussian-Process\nUse Manifold Gaussian Process for Regression and also Classificaion\n'], 'url_profile': 'https://github.com/GGgrey', 'info_list': ['Updated Jan 7, 2021', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Jun 7, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 29, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Python', 'Updated May 16, 2020']}"
"{'location': 'Pretoria, South Africa', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/simbakowo', 'info_list': ['2', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '63 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/rohadhik', 'info_list': ['2', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '158 contributions\n        in the last year', 'description': ['Gender-voice-Prediction-Logistic-Regression\nIn this repository we will see what is this Gender voice (male or female) prediction problem parameters/variable values and try to fit this values in a Logistic regression.\n\nTo run the code follow the below steps:\n1.Install python(3.6+) and need packages.\npip install numpy\n\npip instll pandas\n\npip install matplotlib\n\npip install -U scikit-learn\n\n2.Clone this repository .\nhttps://github.com/karthikeyanthanigai/Gender-voice-Prediction-Logistic-Regression.git\n\n3.Open command line and set the directory to the cloned repository.\ncd Gender-voice-Prediction-Logistic-Regression\n\n4.Enter the command.\npython log.py\n\nif you got any error in install the packages then refer Stackoverflow.\n'], 'url_profile': 'https://github.com/karthikeyanthanigai', 'info_list': ['2', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 17, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/pavan379', 'info_list': ['2', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/vuks01', 'info_list': ['2', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '8 contributions\n        in the last year', 'description': ['Project-on-titanic-ship\nLogistic Regression\n'], 'url_profile': 'https://github.com/Gurleen-Makkar', 'info_list': ['2', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/keenbm', 'info_list': ['2', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['attrition\nlogistic regression\n'], 'url_profile': 'https://github.com/asutoshkumargupta', 'info_list': ['2', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 17, 2020']}","{'location': 'Saharsa, Bihar, India', 'stats_list': [], 'contributions': '336 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/RiyaAgrawal17', 'info_list': ['2', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/HarshitJha', 'info_list': ['2', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 17, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/alitrhn', 'info_list': ['Updated May 17, 2020', 'MIT license', 'Updated May 13, 2020', '2', 'Python', 'Updated May 17, 2020', 'Updated May 16, 2020', '2', 'JavaScript', 'MIT license', 'Updated Feb 17, 2021', 'MATLAB', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Updated May 22, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '10 contributions\n        in the last year', 'description': ['Team12Test12\nRegression collaboration\n'], 'url_profile': 'https://github.com/RhulaniC', 'info_list': ['Updated May 17, 2020', 'MIT license', 'Updated May 13, 2020', '2', 'Python', 'Updated May 17, 2020', 'Updated May 16, 2020', '2', 'JavaScript', 'MIT license', 'Updated Feb 17, 2021', 'MATLAB', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Updated May 22, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '22 contributions\n        in the last year', 'description': ['Regression-Modelling\nRegrerssion(multiple regression) modelling done on 50 Hyderabad based startup companies.\n'], 'url_profile': 'https://github.com/D-AG', 'info_list': ['Updated May 17, 2020', 'MIT license', 'Updated May 13, 2020', '2', 'Python', 'Updated May 17, 2020', 'Updated May 16, 2020', '2', 'JavaScript', 'MIT license', 'Updated Feb 17, 2021', 'MATLAB', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Updated May 22, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Kochi Kerala', 'stats_list': [], 'contributions': '67 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/SauravSuresh', 'info_list': ['Updated May 17, 2020', 'MIT license', 'Updated May 13, 2020', '2', 'Python', 'Updated May 17, 2020', 'Updated May 16, 2020', '2', 'JavaScript', 'MIT license', 'Updated Feb 17, 2021', 'MATLAB', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Updated May 22, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '333 contributions\n        in the last year', 'description': ['polynomial-regression\nModel generator based on the method of least squares.\nUsage\nThere is a unique entry-point, the createModel method.\nOnce we have created our model we can fit it by feeding it with data and specifying the desired degree/s of our resulting model/s.\nThe API is designed in a way that allows creating different models based on each degree at the same time. Instead of having a fixed estimation function, we have an internal object where we are going to store the corresponding coefficients for each degree. This way we can easily compare which degree suits best our problem by calling the estimate function specifying the different degrees.\nLet\'s illustrate its usage with a simple example.\nWe are given these data points.\nWe have them stored as an array of [x,y] values:\nconst data = [ [ 1, 2.4 ],  [ 1.5, 2.6 ], [ 2, 3 ], [ 2.5, 3.2 ] ... ];\n\nWe want to find a model that allows us to interpolate or estimate unknown values according to this information.\nIn this example, we are going to use a low degree (3) and a higher one (20).\nThe code would look as follows:\nconst { createModel } = require(\'polynomial-regression\');\nconst { data } = require(\'./example_dataset\');\n\nconst model = createModel();\n\nmodel.fit(data, [3,20]);\n\nmodel.estimate(3,unknownXValue);\nmodel.estimate(20,unknownXValue);\n\nmodel.saveExpressions(\'./expressionsForGraphs.json\');\nThe file saved looks like this:\n{\n  ""3"": ""+1.5062596662599177*x^0+1.425302045761659*x^1 ... ""\n  ""20"": ""+66.40442892021944*x^0-204.3486735913864*x^1 ... ""\n}\nAnd we can easily copy&paste those strings and plot the corresponding functions.\n\nAPI Reference\n\n\n\nMethod\nDescription\nArguments to be passed\n\n\n\n\nfit\nCalculates coefficients for each degree provided and stores them internally\nData <Array<[x,y]>>, Degrees <Array<Number>>\n\n\nestimate\nReturns the estimated value\nDegree <Number>, xValue <Number>\n\n\nloadParams\nLoads precalculated coefficients merging them into the current model internal store\nPath <string>\n\n\nsaveParams\nSave the current model coefficients in a JSON file\nPath <string>\n\n\nsaveExpressions\nTurn the current model coefficients into reusable expressions and save them in a JSON file\nPath <string>\n\n\nexpressions\nTurn the current model coefficients into reusable expressions and return them as a variable\nNone\n\n\n\n'], 'url_profile': 'https://github.com/danielherrerohernando', 'info_list': ['Updated May 17, 2020', 'MIT license', 'Updated May 13, 2020', '2', 'Python', 'Updated May 17, 2020', 'Updated May 16, 2020', '2', 'JavaScript', 'MIT license', 'Updated Feb 17, 2021', 'MATLAB', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Updated May 22, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '104 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Nabapadma-sarker', 'info_list': ['Updated May 17, 2020', 'MIT license', 'Updated May 13, 2020', '2', 'Python', 'Updated May 17, 2020', 'Updated May 16, 2020', '2', 'JavaScript', 'MIT license', 'Updated Feb 17, 2021', 'MATLAB', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Updated May 22, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '91 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/rkoramtin', 'info_list': ['Updated May 17, 2020', 'MIT license', 'Updated May 13, 2020', '2', 'Python', 'Updated May 17, 2020', 'Updated May 16, 2020', '2', 'JavaScript', 'MIT license', 'Updated Feb 17, 2021', 'MATLAB', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Updated May 22, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['linear-regression\nsimple linear regression\n'], 'url_profile': 'https://github.com/Pranav97Tyagi', 'info_list': ['Updated May 17, 2020', 'MIT license', 'Updated May 13, 2020', '2', 'Python', 'Updated May 17, 2020', 'Updated May 16, 2020', '2', 'JavaScript', 'MIT license', 'Updated Feb 17, 2021', 'MATLAB', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Updated May 22, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/manishkushwah1', 'info_list': ['Updated May 17, 2020', 'MIT license', 'Updated May 13, 2020', '2', 'Python', 'Updated May 17, 2020', 'Updated May 16, 2020', '2', 'JavaScript', 'MIT license', 'Updated Feb 17, 2021', 'MATLAB', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Updated May 22, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Lagos, Nigeria', 'stats_list': [], 'contributions': '71 contributions\n        in the last year', 'description': ['Facial-Recognition-Project\nUsing Logistic Regression\n'], 'url_profile': 'https://github.com/ire-mide1', 'info_list': ['Updated May 17, 2020', 'MIT license', 'Updated May 13, 2020', '2', 'Python', 'Updated May 17, 2020', 'Updated May 16, 2020', '2', 'JavaScript', 'MIT license', 'Updated Feb 17, 2021', 'MATLAB', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Updated May 22, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}"
"{'location': 'Bangalore', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/manishkushwah1', 'info_list': ['Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Oct 24, 2020', 'Python', 'Updated May 12, 2020', 'MATLAB', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'R', 'Updated Oct 17, 2020']}","{'location': 'Helsinki', 'stats_list': [], 'contributions': '47 contributions\n        in the last year', 'description': ['NN-test\nRegression testing in colaboratory\n'], 'url_profile': 'https://github.com/errai-', 'info_list': ['Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Oct 24, 2020', 'Python', 'Updated May 12, 2020', 'MATLAB', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'R', 'Updated Oct 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['Simple-Linear-Regression\nSimple Linear Regression\n'], 'url_profile': 'https://github.com/PrakashRaoM', 'info_list': ['Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Oct 24, 2020', 'Python', 'Updated May 12, 2020', 'MATLAB', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'R', 'Updated Oct 17, 2020']}","{'location': 'melbourne', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['machine-learning-\nmultiple linear regression\nggvcvc\ncommit 5\n'], 'url_profile': 'https://github.com/john-cena-orton', 'info_list': ['Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Oct 24, 2020', 'Python', 'Updated May 12, 2020', 'MATLAB', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'R', 'Updated Oct 17, 2020']}","{'location': 'kanpur', 'stats_list': [], 'contributions': '418 contributions\n        in the last year', 'description': ['Using linear regression and Random forest.\nlibraries required:\n\npandas\nmatplotlib\nSeaborn\nsklearn\n\nJust clone and run.\n'], 'url_profile': 'https://github.com/sajal1302', 'info_list': ['Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Oct 24, 2020', 'Python', 'Updated May 12, 2020', 'MATLAB', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'R', 'Updated Oct 17, 2020']}","{'location': 'Giza, EGYPT', 'stats_list': [], 'contributions': '123 contributions\n        in the last year', 'description': ['Maximum-temperature Prediction\n'], 'url_profile': 'https://github.com/kouwis', 'info_list': ['Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Oct 24, 2020', 'Python', 'Updated May 12, 2020', 'MATLAB', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'R', 'Updated Oct 17, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '43 contributions\n        in the last year', 'description': ['Random-Forest-Regression\nRandom-Forest-Regression\n'], 'url_profile': 'https://github.com/GIT-Saptarshi', 'info_list': ['Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Oct 24, 2020', 'Python', 'Updated May 12, 2020', 'MATLAB', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'R', 'Updated Oct 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '104 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Nabapadma-sarker', 'info_list': ['Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Oct 24, 2020', 'Python', 'Updated May 12, 2020', 'MATLAB', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'R', 'Updated Oct 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['Team-13-Regression-Predict\nRegression predict for Zindi\n'], 'url_profile': 'https://github.com/Dominic-byte', 'info_list': ['Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Oct 24, 2020', 'Python', 'Updated May 12, 2020', 'MATLAB', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'R', 'Updated Oct 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['lm operator\nDescription\nThe lm operator performs a linear regression in Tercen.\nUsage\n\n\n\nInput projection\n.\n\n\n\n\ny-axis\nmeasurement value\n\n\nx-axis\nexplanatory value\n\n\n\n\n\n\nOutput relations\n.\n\n\n\n\nintercept\nnumeric, p-value calculated per cell\n\n\nslope\nnumeric, p-value calculated per cell\n\n\nfit.x\nnumeric, lowest and highest x values\n\n\nfit.y\nnumeric, lowest and highest predicted y values\n\n\n\nDetails\nThe lm operator performs a linear regression on each cell.\nReferences\nSee Linear regression on Wikipedia and\nlm R function documentation.\nSee Also\nanova\n'], 'url_profile': 'https://github.com/tercen', 'info_list': ['Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Oct 24, 2020', 'Python', 'Updated May 12, 2020', 'MATLAB', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'R', 'Updated Oct 17, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['STAT-3400-Final-Project\nApplied Regression Final Project\nUsing regression analysis to quantify the predictive power of usage percentage as a team statistic in basketball.\nApplications:\n\nWeb Scraping\n\nusage_scrape.py -> scrape advanced and team statistics from basketball-reference.com\nastats.csv -> advanced stats\ntstats.csv -> team stats\n\n\nData Analysis\n\nusage_project.r -> regression analysis with usage dataset\n\n'], 'url_profile': 'https://github.com/johnny-tamanaha', 'info_list': ['R', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 13, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated Sep 24, 2020', '2', 'C', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '1,121 contributions\n        in the last year', 'description': ['Linear Regression with one Label\nThis is a simple linear regression script using sci-kit, python3 and a dataset composed of the average grades of a teacher database over the last 14 months.\nSetup\nYou will need:\n\nvirtualenv\npython 3.7\n\nAfter downloading, create a virtual environment with virtual env, activate and install requirements.txt\nvirtualenv ./ -p python3\nsource bin/activate\npip install -r requirements.txt\n\nRun\npython script.py\n\n'], 'url_profile': 'https://github.com/charliecharlieO-o', 'info_list': ['R', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 13, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated Sep 24, 2020', '2', 'C', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/belenamita', 'info_list': ['R', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 13, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated Sep 24, 2020', '2', 'C', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '68 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Ellariel', 'info_list': ['R', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 13, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated Sep 24, 2020', '2', 'C', 'Updated May 15, 2020']}","{'location': 'Bhubaneswar, India', 'stats_list': [], 'contributions': '76 contributions\n        in the last year', 'description': ['Predicting_Progression_of_Diabetes\n'], 'url_profile': 'https://github.com/LakhiCharanMahato', 'info_list': ['R', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 13, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated Sep 24, 2020', '2', 'C', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '166 contributions\n        in the last year', 'description': ['cvx-regression\nconvex regression notes/code\n'], 'url_profile': 'https://github.com/jacob-roth', 'info_list': ['R', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 13, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated Sep 24, 2020', '2', 'C', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '236 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/arpit282', 'info_list': ['R', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 13, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated Sep 24, 2020', '2', 'C', 'Updated May 15, 2020']}","{'location': 'Kottayam', 'stats_list': [], 'contributions': '64 contributions\n        in the last year', 'description': ['Deep-Neural-Net-regression\nDeep Neural Net regression\n'], 'url_profile': 'https://github.com/akhilkv98', 'info_list': ['R', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 13, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated Sep 24, 2020', '2', 'C', 'Updated May 15, 2020']}","{'location': 'Dallas, Texas', 'stats_list': [], 'contributions': '42 contributions\n        in the last year', 'description': ['house_sales_King_County_part1\nThis is my project for Machine Learning Course.\n'], 'url_profile': 'https://github.com/dtliao', 'info_list': ['R', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 13, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated Sep 24, 2020', '2', 'C', 'Updated May 15, 2020']}","{'location': 'Ahmedabad, India', 'stats_list': [], 'contributions': '488 contributions\n        in the last year', 'description': [""Least Squares Quadratic Curve Fitting in C\nThe C program solves the standard least squares equation using Gauss-Jordan Elimination by getting the reduced row echelon form.\nTest data has one feature and one label. It is inserted in runner.c as well as data.dat. Plots are generated using gnuplot and the script can be found in script.plt. The file 'LeastSquares.m' is a MATLAB implementation of the same idea.\nThe sample data is a quadratic fit, but the code can be slightly modified to fit any standard predefined equation.\nInstructions\nTo execute the program as it is:\ngcc runner.c -o runner\n./runner\nIf you want to plot the equation:\ngnuplot script.plt\n(Obviously, you'll need gnuplot for this)\nSample Data\n$$\nw = ah^2 + bh + c\n$$\nwhere w is the weight and h is the height.\n\n\n\nSerial No\nHeight in cm\nWeight in kg\n\n\n\n\n1\n160\n68\n\n\n2\n155\n78\n\n\n3\n143\n56\n\n\n4\n162\n70\n\n\n5\n170\n72\n\n\n6\n175\n78\n\n\n7\n167\n68\n\n\n8\n163\n54\n\n\n9\n156\n43\n\n\n10\n172\n71\n\n\n11\n180\n65\n\n\n12\n159\n59\n\n\n13\n169\n63\n\n\n14\n157\n62\n\n\n15\n161\n90\n\n\n16\n171\n45\n\n\n17\n181\n62\n\n\n18\n177\n57\n\n\n19\n140\n80\n\n\n\nResult\nWe get: a = 0.003703, b = -1.288406, c = 176.578090\nPlot:\n(The black dot shows the weight corresponding to predicted weight at 185 cm height)\n\n""], 'url_profile': 'https://github.com/yashrajkakkad', 'info_list': ['R', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 13, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated Sep 24, 2020', '2', 'C', 'Updated May 15, 2020']}"
"{'location': 'Delhi', 'stats_list': [], 'contributions': '212 contributions\n        in the last year', 'description': ['Logistric-regression-implementation\ngiven python code shows the implementation of logistic regression with gradient ascent\n'], 'url_profile': 'https://github.com/abhishekshakya', 'info_list': ['2', 'Python', 'Updated May 17, 2020', '2', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'Updated May 15, 2020', 'M', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated Dec 7, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '17 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/nnickelson', 'info_list': ['2', 'Python', 'Updated May 17, 2020', '2', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'Updated May 15, 2020', 'M', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated Dec 7, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020']}","{'location': 'Toronto', 'stats_list': [], 'contributions': '188 contributions\n        in the last year', 'description': ['Machine_Learning_Regression_Comparison-\nComparison among different  Regression Model\n'], 'url_profile': 'https://github.com/anupomr', 'info_list': ['2', 'Python', 'Updated May 17, 2020', '2', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'Updated May 15, 2020', 'M', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated Dec 7, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '34 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/hamzautd7', 'info_list': ['2', 'Python', 'Updated May 17, 2020', '2', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'Updated May 15, 2020', 'M', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated Dec 7, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '22 contributions\n        in the last year', 'description': ['simple-linear-regression\n'], 'url_profile': 'https://github.com/Basavarajnilu', 'info_list': ['2', 'Python', 'Updated May 17, 2020', '2', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'Updated May 15, 2020', 'M', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated Dec 7, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '71 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/yinghaowuzhanbai', 'info_list': ['2', 'Python', 'Updated May 17, 2020', '2', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'Updated May 15, 2020', 'M', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated Dec 7, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '90 contributions\n        in the last year', 'description': ['Del_Outlier\ndelete outliers in linear regression\n'], 'url_profile': 'https://github.com/jhih-ching-yeh', 'info_list': ['2', 'Python', 'Updated May 17, 2020', '2', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'Updated May 15, 2020', 'M', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated Dec 7, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020']}","{'location': 'MUMBAI', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['R--Linear-Regression\nPerforming Linear Regression using R\n'], 'url_profile': 'https://github.com/Abhipsanayak92', 'info_list': ['2', 'Python', 'Updated May 17, 2020', '2', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'Updated May 15, 2020', 'M', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated Dec 7, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Sameera5694', 'info_list': ['2', 'Python', 'Updated May 17, 2020', '2', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'Updated May 15, 2020', 'M', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated Dec 7, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020']}","{'location': 'MUMBAI', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['Python-Logistic-Regression\nLogistic Regression performed in Python\n'], 'url_profile': 'https://github.com/Abhipsanayak92', 'info_list': ['2', 'Python', 'Updated May 17, 2020', '2', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'Updated May 15, 2020', 'M', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated Dec 7, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020']}"
"{'location': 'MUMBAI', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['Python-Logistic-Regression\nLogistic Regression performed in Python\n'], 'url_profile': 'https://github.com/Abhipsanayak92', 'info_list': ['1', 'Python', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated May 20, 2020', 'R', 'Updated May 13, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Aug 31, 2020', '1', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'MUMBAI', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['R--Linear-Regression\nPerforming Linear Regression using R\n'], 'url_profile': 'https://github.com/Abhipsanayak92', 'info_list': ['1', 'Python', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated May 20, 2020', 'R', 'Updated May 13, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Aug 31, 2020', '1', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Sameera5694', 'info_list': ['1', 'Python', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated May 20, 2020', 'R', 'Updated May 13, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Aug 31, 2020', '1', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Medellín, Colombia', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['Regression-Models\nRegression Models in Forestry Science\n'], 'url_profile': 'https://github.com/camilomartinezfo', 'info_list': ['1', 'Python', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated May 20, 2020', 'R', 'Updated May 13, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Aug 31, 2020', '1', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Vashi,Navi Mumbai', 'stats_list': [], 'contributions': '22 contributions\n        in the last year', 'description': ['Salary-Prediction-R\nR script for linear-regression\ncsv file has been attached for reference/demo\n'], 'url_profile': 'https://github.com/knightlyf', 'info_list': ['1', 'Python', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated May 20, 2020', 'R', 'Updated May 13, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Aug 31, 2020', '1', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'MUMBAI', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['R--Logistic-Regression\nPerforming Logistic Regression Using R\n'], 'url_profile': 'https://github.com/Abhipsanayak92', 'info_list': ['1', 'Python', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated May 20, 2020', 'R', 'Updated May 13, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Aug 31, 2020', '1', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/keenbm', 'info_list': ['1', 'Python', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated May 20, 2020', 'R', 'Updated May 13, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Aug 31, 2020', '1', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'New Delhi,India', 'stats_list': [], 'contributions': '233 contributions\n        in the last year', 'description': ['This Repository contains implementation of ML algorithms from scratch.\n\nImplementing Logistic Regression from scratch\n\n'], 'url_profile': 'https://github.com/adimalhotra11', 'info_list': ['1', 'Python', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated May 20, 2020', 'R', 'Updated May 13, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Aug 31, 2020', '1', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '22 contributions\n        in the last year', 'description': ['You can downolad the files via kaggle also. Thank you!!!\n'], 'url_profile': 'https://github.com/Basavarajnilu', 'info_list': ['1', 'Python', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated May 20, 2020', 'R', 'Updated May 13, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Aug 31, 2020', '1', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Surakarta, Indonesia', 'stats_list': [], 'contributions': '432 contributions\n        in the last year', 'description': ['Langkah-langkah:\n\n\nMengimpor modul pandas untuk membaca file CSV\n\n\nMembaca data.csv dengan fungsi pandas.read_csv, tetapkan sebagai df_data\n\n\nMengambil fitur df_data, berupa kolom Age, Total_Purchase, Account_Manager, Years dan Num_Sites, tetapkan sebagai X\n\n\nMengambil target data_df, yakni kolom Churn, tetapkan sebagai Y\n\n\nMegimpor modul sklearn.model_selection untuk melakukan train_test_split, kemudian lakukan train_test_split\n\n\nMegimpor modul sklearn.preprocessing untuk melakukan StandardScaler, kemudian lakukan StandardScaler pada X_train dan Y_train\n\n\nMegimpor modul sklearn.linear_model untuk melakukan fitting model menggunakan fungsi LogisticRegression\n\n\nMelakukan prediksi terhadap X_test\n\n\nMegimpor modul sklearn.metrics untuk membuat confusion matriks menggunakan fungsi confusion_matrix\n\n\nKemudian cek akurasi model menggunakan fungsi accuracy_score dari modul sklearn.metrics\n\n\nMembaca test.csv dengan fungsi pandas.read_csv, tetapkan sebagai test_df\n\n\nMengambil feature test_df, berupa kolom Age, Total_Purchase, Account_Manager, Years dan Num_Sites, tetapkan sebagai X_test_df\n\n\nLakukan StandardScaler pada X_test_df\n\n\nPrediksi data target, tetapkan hasilnya sebagai Y_pred_test_df\n\n\nBuat kolom Churn pada test_df berisikan data dari Y_pred_test_df\n\n\n\nTerima kasih kepada Bapak Dhomas Hatta Fudholi yang sudah menyiapkan mini contestnya\n'], 'url_profile': 'https://github.com/adipurnamk', 'info_list': ['1', 'Python', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'R', 'Updated May 20, 2020', 'R', 'Updated May 13, 2020', '1', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Aug 31, 2020', '1', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}"
"{'location': 'India', 'stats_list': [], 'contributions': '89 contributions\n        in the last year', 'description': ['Ridge-and-Lasso-Regression-implementation\nRidge and Lasso Regression implementation\n'], 'url_profile': 'https://github.com/manojnahak02', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 19, 2020']}","{'location': 'Nairobi-Kenya', 'stats_list': [], 'contributions': '127 contributions\n        in the last year', 'description': [""Linear-regression\nCodecademy Reggy's linear regression project\n""], 'url_profile': 'https://github.com/regan-mu', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 19, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Preciousorifha', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 19, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '26 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/zouden', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 19, 2020']}","{'location': 'Purvanchal, India.', 'stats_list': [], 'contributions': '592 contributions\n        in the last year', 'description': ['House Prices: Advanced Regression Techniques\nKaggle Link\n'], 'url_profile': 'https://github.com/AHTHneeuhl', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 19, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['VCSlinearregresion\n'], 'url_profile': 'https://github.com/JurateNavicke', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 19, 2020']}","{'location': 'Mexico', 'stats_list': [], 'contributions': '127 contributions\n        in the last year', 'description': ['Univariate Linear Regression\n'], 'url_profile': 'https://github.com/roman-cmyk', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 19, 2020']}","{'location': 'Indonesia', 'stats_list': [], 'contributions': '417 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ksmrdn', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 19, 2020']}","{'location': 'MUMBAI', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['Python---Linear-Regression\nPerforming Linear Regression using Python\n'], 'url_profile': 'https://github.com/Abhipsanayak92', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 19, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '82 contributions\n        in the last year', 'description': ['Predicting Employee Churn with Linear Models\nLogistic Regression on HR data\nA data consulting/ analytics company has asked us to develop a model to predict why high performing employees are leaving at a higher rate. This notebook will process the data given and the markdowns will explain what is happening and what insights can be drawn here.\nFiles\nData loading, exploration, visualization and analysis for the project can be found in the Jupyter Notebok HR_assignment.ipynb, which uses Google Colab to load in the dataset from my Google Drive.\nThe script version of the notebook is hr_assignment.py and contains code for the analysis and the modeling to be performed.\nRunning It\nTo run the script:\n\npython hr_assignment.py\n\nResults\nThe results from my project are as follows: ...\nLessons\n'], 'url_profile': 'https://github.com/alvin20142', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 19, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '236 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/arpit282', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Python', 'Updated May 18, 2020', 'JavaScript', 'Updated May 14, 2020', '1', 'Python', 'Updated Sep 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '64 contributions\n        in the last year', 'description': ['inclass_logit_comp\nchurn - Anything goes.\nchurn 2 - Feature engineering only.\nNote to future self : inclass comp data manipulations were applied to the entire training set before splitting for test-train.  This resulted in beeld over during training and validation, leading to a slight over-fit.  Private result performance was lower than cross-validated results.\n'], 'url_profile': 'https://github.com/jrwaggs', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Python', 'Updated May 18, 2020', 'JavaScript', 'Updated May 14, 2020', '1', 'Python', 'Updated Sep 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '216 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/MalaPetra', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Python', 'Updated May 18, 2020', 'JavaScript', 'Updated May 14, 2020', '1', 'Python', 'Updated Sep 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020']}","{'location': 'Richardson, Texas', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['The core purpose of the project is to explore and experiment with modeling regressional problems with ML algorithms and traditional statistical techniques.\n'], 'url_profile': 'https://github.com/AbhishekHosmani', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Python', 'Updated May 18, 2020', 'JavaScript', 'Updated May 14, 2020', '1', 'Python', 'Updated Sep 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020']}","{'location': 'Santo André, SP', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['Este projeto foi criado especificamente para o artigo sobre testes de regressão. A primeira parte do artigo está em:\nhttps://www.linkedin.com/pulse/1-2-3-testando-testndo-andr%25C3%25A9-pontes\nThis project was bootstrapped with Create React App.\nAvailable Scripts\nIn the project directory, you can run:\nnpm start\nRuns the app in the development mode.\nOpen http://localhost:3000 to view it in the browser.\nThe page will reload if you make edits.\nYou will also see any lint errors in the console.\nnpm test\nLaunches the test runner in the interactive watch mode.\nSee the section about running tests for more information.\nnpm run build\nBuilds the app for production to the build folder.\nIt correctly bundles React in production mode and optimizes the build for the best performance.\nThe build is minified and the filenames include the hashes.\nYour app is ready to be deployed!\nSee the section about deployment for more information.\n'], 'url_profile': 'https://github.com/arpontes', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Python', 'Updated May 18, 2020', 'JavaScript', 'Updated May 14, 2020', '1', 'Python', 'Updated Sep 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['RegressionScript\n'], 'url_profile': 'https://github.com/graysonbai', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Python', 'Updated May 18, 2020', 'JavaScript', 'Updated May 14, 2020', '1', 'Python', 'Updated Sep 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020']}","{'location': 'Allahabad,Uttar Pardesh', 'stats_list': [], 'contributions': '28 contributions\n        in the last year', 'description': ['LinearRegression\nLinear Regression using Normal Equation,Gradient Descent and Linearly Weighted Regression\n'], 'url_profile': 'https://github.com/muskanchugh5', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Python', 'Updated May 18, 2020', 'JavaScript', 'Updated May 14, 2020', '1', 'Python', 'Updated Sep 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/SayaliAdmane', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Python', 'Updated May 18, 2020', 'JavaScript', 'Updated May 14, 2020', '1', 'Python', 'Updated Sep 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '26 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Carlos-Gzz', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Python', 'Updated May 18, 2020', 'JavaScript', 'Updated May 14, 2020', '1', 'Python', 'Updated Sep 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '30 contributions\n        in the last year', 'description': ['Statistical-Analysis\nwe are doing the statistical analysis of relationship between Women’s Progress with respect to various aspects like health and other socio-economic factors which are considered in the analyzing Country’s development and growth.\nLogistic Regression, Linear Regression, Anova, CHI- Square, Moderation Analysis, Interaction Effect,Correlation Testing using SAS Studio\n'], 'url_profile': 'https://github.com/Anusha-Kokkinti', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Python', 'Updated May 18, 2020', 'JavaScript', 'Updated May 14, 2020', '1', 'Python', 'Updated Sep 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020']}"
"{'location': 'Paris', 'stats_list': [], 'contributions': '461 contributions\n        in the last year', 'description': [""EPFL-ModReg\nModern Regression Methods 2020's Mini-project\n""], 'url_profile': 'https://github.com/baohien97', 'info_list': ['R', 'Updated Jun 19, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'TeX', 'Updated Jun 24, 2020', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '12 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/RandomlyCreative', 'info_list': ['R', 'Updated Jun 19, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'TeX', 'Updated Jun 24, 2020', 'Updated May 11, 2020']}","{'location': 'tokyo, japan', 'stats_list': [], 'contributions': '76 contributions\n        in the last year', 'description': ['Random-Forest-Regression\nRandom forest regression model on financial data\n'], 'url_profile': 'https://github.com/Mayaz9156', 'info_list': ['R', 'Updated Jun 19, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'TeX', 'Updated Jun 24, 2020', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/brookbangsberg', 'info_list': ['R', 'Updated Jun 19, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'TeX', 'Updated Jun 24, 2020', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['Simple Linear Regression using Gradient Descent\nMeysam Alipuor\nmeysam.alipuor@gmail.com\nhttps://github.com/ameysam/LR-GD\n'], 'url_profile': 'https://github.com/ameysam', 'info_list': ['R', 'Updated Jun 19, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'TeX', 'Updated Jun 24, 2020', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '96 contributions\n        in the last year', 'description': ['Linear-regression-wine-quality-prediction\nLinear Regression on Wine Quality Data\n'], 'url_profile': 'https://github.com/kiranmukesh7', 'info_list': ['R', 'Updated Jun 19, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'TeX', 'Updated Jun 24, 2020', 'Updated May 11, 2020']}","{'location': 'Hyderabad, Telangana, India', 'stats_list': [], 'contributions': '61 contributions\n        in the last year', 'description': [""MA2142-RegressionAnalysis\nR codes for performing Regression analysis\nsplit the given data into train and validation data  sets\ncalculated residuals (Studentized residuals)\nperformed outlier analysis using various criteria like\ni) cook's distance\nii) DF BETAS\niii) COV ratio\nchecked for multicollinearity from cov matrix\nresult no multicollinearity\nploted ridge plot\nAfter we fit the model, number of significant regressors are\nA1,A4,A2 and intercept\noverall model is significant\nand in case of individual significance A1,A2,A4\nThis means octane rating depends on amount of material 1,2 and 4\nsummary(model) tells that they are 4 variables and 44 degrees of freedom\nsum of squares of residuals( residual standard error) is 0.4395\n""], 'url_profile': 'https://github.com/pavankalyan13', 'info_list': ['R', 'Updated Jun 19, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'TeX', 'Updated Jun 24, 2020', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '110 contributions\n        in the last year', 'description': ['Team 19 JHB Regression Predict Notebook\n\nAssignment: Predict the estimated time of arrival (ETA) for motorbike deliveries in Nairobi\n\nThe error metric for this competition is the Root Mean Squared Error\nFor every row in the dataset, submission files should contain 2 columns: order_id and Time from Pickup to Arrival (Predicted time in seconds between arrival and Pickup).\nYour submission file should look like this:\n\n\n\nOrder_No\nTime from Pickup to Arrival\n\n\n\n\nOrder_No_19248\n197\n\n\nOrder_No_12736\n7533\n\n\nOrder_No_768\n768\n\n\n\n'], 'url_profile': 'https://github.com/Lizette95', 'info_list': ['R', 'Updated Jun 19, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'TeX', 'Updated Jun 24, 2020', 'Updated May 11, 2020']}","{'location': 'Kolkata, India', 'stats_list': [], 'contributions': '309 contributions\n        in the last year', 'description': ['crude-oil-price\nCourse project for Regression & Time Series Analysis\nIn this work we aim to examine modeling crude oil prices from publicly available historical\ntime series data. The oil prices are very diffcult to model given their complex and non linear\nbehaviour.\nAccess our report here\n'], 'url_profile': 'https://github.com/vntkumar8', 'info_list': ['R', 'Updated Jun 19, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'TeX', 'Updated Jun 24, 2020', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['763_project\n#This is a description of the project:\n#Using data from a national survey of 2700 US adults, an experiment was conducted to see how beliefs in media bias change when individuals are shown a partisan cue regarding ""algorithmic media bias""\n'], 'url_profile': 'https://github.com/mikhailacalice', 'info_list': ['R', 'Updated Jun 19, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'TeX', 'Updated Jun 24, 2020', 'Updated May 11, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['Boston-House-Pricing\nLinear Regression model predicting House Price.\n'], 'url_profile': 'https://github.com/ansh-keys', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Jun 5, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 19, 2020', 'Jupyter Notebook', 'Updated Jun 12, 2020', 'R', 'Updated Jul 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '53 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/nnavnit90n', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Jun 5, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 19, 2020', 'Jupyter Notebook', 'Updated Jun 12, 2020', 'R', 'Updated Jul 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '154 contributions\n        in the last year', 'description': ['Logistic Regression\nImplementation of binary and multinomial Logistic Regression.\n'], 'url_profile': 'https://github.com/marek-kan', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Jun 5, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 19, 2020', 'Jupyter Notebook', 'Updated Jun 12, 2020', 'R', 'Updated Jul 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '21 contributions\n        in the last year', 'description': ['Youtube-view-counts-regression-analysis\nRegression Analysis course team project(8)\n'], 'url_profile': 'https://github.com/wkdgodbs', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Jun 5, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 19, 2020', 'Jupyter Notebook', 'Updated Jun 12, 2020', 'R', 'Updated Jul 29, 2020']}","{'location': 'France', 'stats_list': [], 'contributions': '32 contributions\n        in the last year', 'description': ['Linear-Regression\nLinear Regression of a set of points\n'], 'url_profile': 'https://github.com/jeremlp', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Jun 5, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 19, 2020', 'Jupyter Notebook', 'Updated Jun 12, 2020', 'R', 'Updated Jul 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '10 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/DeepaKhatwani', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Jun 5, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 19, 2020', 'Jupyter Notebook', 'Updated Jun 12, 2020', 'R', 'Updated Jul 29, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '236 contributions\n        in the last year', 'description': ['Polynomial-Regression\nPolynomial on FuelConsumption dataset, we learn how to use scikit-learn for Polynomial regression. We download a dataset that is related to fuel consumption and Carbon dioxide emission of cars. Then, we split our data into training and test sets, create a model using training set, evaluate our model using test set, and finally use model to predict unknown value.\n'], 'url_profile': 'https://github.com/illumi91', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Jun 5, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 19, 2020', 'Jupyter Notebook', 'Updated Jun 12, 2020', 'R', 'Updated Jul 29, 2020']}","{'location': 'UK', 'stats_list': [], 'contributions': '162 contributions\n        in the last year', 'description': ['tegregr\nMultiple and hierarchical regression in Python.\nThe function teg_regression provides the overall model F-test and t-tests per coefficient, and also provides F-tests for change in explained variance from a baseline to a nested model. See example.py for usage. Results are reported by feeding the output object to teg_report_regr.\nSee example.py for usage. Install via: pip install tegregr\n\n'], 'url_profile': 'https://github.com/thomasgladwin', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Jun 5, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 19, 2020', 'Jupyter Notebook', 'Updated Jun 12, 2020', 'R', 'Updated Jul 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['Linear-regression\nsimple linear regression Excel R project\n'], 'url_profile': 'https://github.com/yadavchetan', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Jun 5, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 19, 2020', 'Jupyter Notebook', 'Updated Jun 12, 2020', 'R', 'Updated Jul 29, 2020']}","{'location': 'Mexico', 'stats_list': [], 'contributions': '21 contributions\n        in the last year', 'description': ['EA2project\nNBA linear regression project for EA2\n'], 'url_profile': 'https://github.com/peanocurve', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Jun 5, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 19, 2020', 'Jupyter Notebook', 'Updated Jun 12, 2020', 'R', 'Updated Jul 29, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '38 contributions\n        in the last year', 'description': ['LinearRegression\nMaking simple linear regression code with and without module.\n'], 'url_profile': 'https://github.com/KimaCuda', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'TeX', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 28, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 18, 2020', 'Updated May 26, 2020']}","{'location': 'Germany', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ashraf-ahmadian', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'TeX', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 28, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 18, 2020', 'Updated May 26, 2020']}","{'location': 'Kharagpur, India', 'stats_list': [], 'contributions': '57 contributions\n        in the last year', 'description': ['crude-oil-price\nCourse project for Regression & Time Series Analysis\nIn this work we aim to examine modeling crude oil prices from publicly available historical\ntime series data. The oil prices are very diffcult to model given their complex and non linear\nbehaviour.\n'], 'url_profile': 'https://github.com/KarthikeyaR', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'TeX', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 28, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 18, 2020', 'Updated May 26, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '41 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/bharanianand', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'TeX', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 28, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 18, 2020', 'Updated May 26, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '100 contributions\n        in the last year', 'description': ['Linear-Regression-Predict-House-Prices-\nLittle Exercise on Linear Regression\n'], 'url_profile': 'https://github.com/thineshsubramani', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'TeX', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 28, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 18, 2020', 'Updated May 26, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '118 contributions\n        in the last year', 'description': ['life-expectancy-prediction-using-multiple-linear-regression\nmultiple linear regression for predict life expectancy\n'], 'url_profile': 'https://github.com/Litaa', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'TeX', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 28, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 18, 2020', 'Updated May 26, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '60 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/LittleBlackSubmarine', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'TeX', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 28, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 18, 2020', 'Updated May 26, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '100 contributions\n        in the last year', 'description': ['Linear-Regression-using-SKlearn-Predicting-Net-Income-\n'], 'url_profile': 'https://github.com/thineshsubramani', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'TeX', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 28, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 18, 2020', 'Updated May 26, 2020']}","{'location': 'Campinas', 'stats_list': [], 'contributions': '50 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/iksmada', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'TeX', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 28, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 18, 2020', 'Updated May 26, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7 contributions\n        in the last year', 'description': ['forecast247\ninput data for multivariable regression analysis\n'], 'url_profile': 'https://github.com/PerryHal', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'TeX', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 28, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 18, 2020', 'Updated May 26, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/imanshuman', 'info_list': ['MATLAB', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', '1', 'HTML', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/raulco1', 'info_list': ['MATLAB', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', '1', 'HTML', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '35 contributions\n        in the last year', 'description': ['In this project, we try to achieve simple linear regression using 3 different methods:\n\nUsing sklearn\nCoding the Math from the scratch\nUsing deep learning model without hidden layer\n\nUsing sklearn:\nLinearRegression class in sklearn was used. \n\n\n\nCoding from the scratch:\nThe Math was coded from the scratch.\n\n\nUsing a ANN (keras):\nLine fits better as the epochs are increased till 200 epochs (approx). The loss seems to be converging at 0.48\n\nepochs:10\n\n\nepochs:50\n\n\nepochs: 100\n\n\nepochs:200\n\n\nepochs:500\n\n\n'], 'url_profile': 'https://github.com/abhishek-kashyap-4', 'info_list': ['MATLAB', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', '1', 'HTML', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['budgets\nLinear Regression for Trials and Purchases\n'], 'url_profile': 'https://github.com/nicoledarnley', 'info_list': ['MATLAB', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', '1', 'HTML', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020']}","{'location': 'Change Healthcare', 'stats_list': [], 'contributions': '762 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/josephedward', 'info_list': ['MATLAB', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', '1', 'HTML', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '101 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/netblue30', 'info_list': ['MATLAB', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', '1', 'HTML', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020']}","{'location': 'Chennai, India', 'stats_list': [], 'contributions': '57 contributions\n        in the last year', 'description': ['Interpretable Linear Regression\nA regular problem in multiple regression is asserting the relative influence of the predictors in the model. Net Effects is a well known technique that are used to measure the shares that each predictor have on the target variable in the coefficient of multiple determination R^2. In the case of correlated inputs, net effects fail to give interpretable results which calls for other positive interpretable metrics.\nIncremental Net Effect is estimated as the marginal influence of the predictor in all possible coalation of predictors on the target variable. This idea directly relates to Shapley values in cooperative game theory.\n'], 'url_profile': 'https://github.com/tlokeshkumar', 'info_list': ['MATLAB', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', '1', 'HTML', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020']}","{'location': 'Dallas, TX', 'stats_list': [], 'contributions': '235 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/elizabeamedalla', 'info_list': ['MATLAB', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', '1', 'HTML', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020']}","{'location': 'India', 'stats_list': [], 'contributions': '165 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Pankti99', 'info_list': ['MATLAB', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', '1', 'HTML', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020']}","{'location': 'Namibia', 'stats_list': [], 'contributions': '777 contributions\n        in the last year', 'description': ['Artificial Intelligence and Computer Graphics\n(AIG710S)\nProblem 1.\nMark: 80\nThe dataset in bank−marketing−campaign.zip represents a collection of examples from a marketing campaign organised by a bank to get its clients\nto place a term deposit. The dataset has 21 columns, described in Table 1.\nYour task is to build a classifier based on this dataset. The classifier should use the regularized logistic regression algorithm, with the regularised\ncross-entropy as its cost function. You will use the sum of the magnitude of all the coefficients (also known as Lasso regularization or L1 regularization) as\nyour regularization technique.\nAssessment Criteria\nThe following criteria will be followed to assess your submission:\n\nData cleaning and preparation in Julia;\nImplementation (from scratch) of the regularized logistic regression algorithm in Julia;\nDesign and implementation of the classifier;\nPerformance metrics^1 , including:\naccuracy:the proportion of correct predictions (clients correctly predicted to have placed a term deposit or not) over all predictions;\nprecision:the proportion of clients the classifier predicted have placed a term deposit actually did so;\nrecall: the proportion of clients that actually placed a term deposit which was predicted by the classifier.\n\n(^1) It is advised to use a confusion matrix.\nSubmission Instructions\n\nThis project is to be completed by groups of maximum two ( 2 ) students\neach.\nFor each group, a repository should be created either on Github ^2 or Gitlab ^3. The URL of the repository should be communicated by\nThursday, May 14th 2020 , with all group members set up as contributors.\nThe submission date is Monday, May 25th 2020, midnight.\nA submission will be assessed based on the clone of its repository at the deadline.\nAny group who fails to submit on time will be awarded the mark 0.\nThere should be no assumption about the execution environment of your code. It could be run using a specific framework or simply on the\ncommand line.\nIn the case of plagiarism (groups copying from each other or submissions copied from the Internet), all submissions involved will be\nawarded the mark 0 , and each student will receive a warning.\n\n(^2) https://github.com\n(^3) https://about.gitlab.com/\n'], 'url_profile': 'https://github.com/Fox520', 'info_list': ['MATLAB', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', '1', 'HTML', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 25, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '128 contributions\n        in the last year', 'description': ['mpg-regression\nA project analyzing automobile mpg with linear regression methods.\nGithub Pages url: https://danieljbpark1.github.io/mpg-regression/index.html\n'], 'url_profile': 'https://github.com/danieljbpark1', 'info_list': ['Updated May 12, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Sep 26, 2020', '1', 'MATLAB', 'Updated Feb 11, 2021', 'Updated May 11, 2020', 'Updated May 14, 2020', '1', 'Agda', 'Updated May 15, 2020', 'Python', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '130 contributions\n        in the last year', 'description': ['用Linear regression 來預測股價\n1907 永豐餘\n2330 台積電\n2454 聯發科\n'], 'url_profile': 'https://github.com/Josiriser', 'info_list': ['Updated May 12, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Sep 26, 2020', '1', 'MATLAB', 'Updated Feb 11, 2021', 'Updated May 11, 2020', 'Updated May 14, 2020', '1', 'Agda', 'Updated May 15, 2020', 'Python', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/MeenakshiArumugam', 'info_list': ['Updated May 12, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Sep 26, 2020', '1', 'MATLAB', 'Updated Feb 11, 2021', 'Updated May 11, 2020', 'Updated May 14, 2020', '1', 'Agda', 'Updated May 15, 2020', 'Python', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'University of Oxford', 'stats_list': [], 'contributions': '466 contributions\n        in the last year', 'description': ['This project aims to produce a model which will accurately predict the median house value of an area based on prior knowledge. A linear regression model will be used to predict these prices as a linear combination of the area’s parameters. These parameters could include, for example, crime rates or the median house size by floor area. A variety of different standard techniques, using different loss functions to quantify performance.\nThe dataset used is the California Housing Data Set, based on the Californian Census in 1990. The dataset is formed of 20433 individual housing districts, each with 8 parameters describing them.\nThe MATLAB functions in src are suitable for general linear regressive tasks. Least-squares and ridge regression optimise the mean squared error (plus regularisation term in the case of ridge), and the remaining functions optimise the mean absolute error plus regularisation term. Ensure that the desired functions are added to the MATLAB path before use (in particular the errors and the shared folders are needed for all methods). Your dataset should have the true values in the final column, with the estimates made from the remaining columns of data.\n'], 'url_profile': 'https://github.com/andrewtplatt', 'info_list': ['Updated May 12, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Sep 26, 2020', '1', 'MATLAB', 'Updated Feb 11, 2021', 'Updated May 11, 2020', 'Updated May 14, 2020', '1', 'Agda', 'Updated May 15, 2020', 'Python', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ac39456', 'info_list': ['Updated May 12, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Sep 26, 2020', '1', 'MATLAB', 'Updated Feb 11, 2021', 'Updated May 11, 2020', 'Updated May 14, 2020', '1', 'Agda', 'Updated May 15, 2020', 'Python', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/mm-repo', 'info_list': ['Updated May 12, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Sep 26, 2020', '1', 'MATLAB', 'Updated Feb 11, 2021', 'Updated May 11, 2020', 'Updated May 14, 2020', '1', 'Agda', 'Updated May 15, 2020', 'Python', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'University of Birmingham', 'stats_list': [], 'contributions': '47 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/tnttodda', 'info_list': ['Updated May 12, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Sep 26, 2020', '1', 'MATLAB', 'Updated Feb 11, 2021', 'Updated May 11, 2020', 'Updated May 14, 2020', '1', 'Agda', 'Updated May 15, 2020', 'Python', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'United States', 'stats_list': [], 'contributions': '85 contributions\n        in the last year', 'description': ['Predicting-Bitcoin-Price-Variations\nPredicting Bitcoin Price Variations using Bayesian Regression\nReference paper: http://arxiv.org/pdf/1410.1231.pdf\nIn this project, you will be tasked with predicting the price variations of bitcoin, a virtual cryptographic currency. These predictions could be used as the foundation of a bitcoin trading strategy. To make these predictions, you will have to familiarize yourself with a machine learning technique, Bayesian Regression, and implement this technique in Python.\n'], 'url_profile': 'https://github.com/parikhs97', 'info_list': ['Updated May 12, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Sep 26, 2020', '1', 'MATLAB', 'Updated Feb 11, 2021', 'Updated May 11, 2020', 'Updated May 14, 2020', '1', 'Agda', 'Updated May 15, 2020', 'Python', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '12 contributions\n        in the last year', 'description': ['README\nThis is the final project for MA429 Algorithmic Techniques for Data Mining.\n\n33815_38816.pdf: Project report\n33815_38816.Rmd: R code\ndata_description.txt: Variables description from Kaggle\ntrain.csv: Training set from Kaggle\ntest.csv: Testing set from Kaggle\noutput.csv: prediction on testing set that submitted on Kaggle\n\n'], 'url_profile': 'https://github.com/Napoleon0313', 'info_list': ['Updated May 12, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Sep 26, 2020', '1', 'MATLAB', 'Updated Feb 11, 2021', 'Updated May 11, 2020', 'Updated May 14, 2020', '1', 'Agda', 'Updated May 15, 2020', 'Python', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '236 contributions\n        in the last year', 'description': ['Simple_regression_analysis\nData exploration and simple regression analysis practice\n'], 'url_profile': 'https://github.com/illumi91', 'info_list': ['Updated May 12, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Sep 26, 2020', '1', 'MATLAB', 'Updated Feb 11, 2021', 'Updated May 11, 2020', 'Updated May 14, 2020', '1', 'Agda', 'Updated May 15, 2020', 'Python', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}"
"{'location': 'Bhopal , India', 'stats_list': [], 'contributions': '85 contributions\n        in the last year', 'description': ['Machine-Learning-Algorithms\nImplementation of Basic Regression And Classification Models\n'], 'url_profile': 'https://github.com/joshidivanshu', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Jul 26, 2020', 'HTML', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '71 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/yts01', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Jul 26, 2020', 'HTML', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '154 contributions\n        in the last year', 'description': ['Linear Regression Implementation\nImplementation of linear regression on steriods.\nOptimized by Batch Gradient Descent with Momentum. I add possibility to fit another sample into trained estimator. All this is done in Python with help of NumPy.\nI compare sklearn\'s Ridge vs my Linear Regression in test.py on boston housing dataset. Results (in MAE) are:\n\nSci-kit Learn: 3.3616\nMy LR: 3.3242\nMy LR after 5 ""online"" examples: 3.1300\n\nI find online learning possibility useful because there is no need for cyclic offline retraining and deployment. Instead, after obtaining true value of target in production it can be fitted to the estimator without need of goinig offline.\n'], 'url_profile': 'https://github.com/marek-kan', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Jul 26, 2020', 'HTML', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020']}","{'location': 'Vietnam', 'stats_list': [], 'contributions': '53 contributions\n        in the last year', 'description': ['This is a implemented of Linear Regression models in R to predict the fish weight.\n'], 'url_profile': 'https://github.com/neumotngayem', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Jul 26, 2020', 'HTML', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '96 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/tusharsarkar3', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Jul 26, 2020', 'HTML', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020']}","{'location': 'San Antonio, TX', 'stats_list': [], 'contributions': '193 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Suggestions-Only', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Jul 26, 2020', 'HTML', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '82 contributions\n        in the last year', 'description': ['weather-prediction\nMy first ML model implementing linear regression\n'], 'url_profile': 'https://github.com/NiharikaGopinath', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Jul 26, 2020', 'HTML', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020']}","{'location': 'Gurugram', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['Multicollinearity\nChecking the collinearity in regression model\n'], 'url_profile': 'https://github.com/tapas-dev', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Jul 26, 2020', 'HTML', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '60 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gauriverma19', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Jul 26, 2020', 'HTML', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020']}","{'location': 'Alexandria', 'stats_list': [], 'contributions': '17 contributions\n        in the last year', 'description': ['logistic_regression_tensorflow\nlogistic regression or classification mnist dataset\n'], 'url_profile': 'https://github.com/AnasHXH', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated Jul 26, 2020', 'HTML', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020']}"
"{'location': 'Washington, DC', 'stats_list': [], 'contributions': '308 contributions\n        in the last year', 'description': ['Kaggle-Competition-Predict-Final-Price-of-Residential-Homes-in-Ames-IA\nData Mining Project - Regression Techniques using R\nWe want to predict house sale prices in Ames,IA using 80 housing features and identify features that have the most influence on house sale price. The best model could be used by realtors and buyers to estimate price for a house with specific features that they want to sell/buy.\nWe applied 11 algorithms from linear techniques such as Lasso to non-linear such as Regression Tree, from parametric techniques such as Best subset selection to non-parametric such as KNN.we conclude that the best regression model is the Gradient Boosting model with a test MSE of 0.0173.\nThe Gradient Boosting model reveals the top 4 most important predictors. They are OverallQual (Overall material and finish quality), GrLivArea (Above grade (ground) living area square feet), TotalBsmtSF (Total square feet of basement area), and YearBuilt (Original construction date).\nModels: Best subset selection, LASSO, Ridge Regression, PCR, PLS, KNN, Regression Tree, Random Forest, Bagging, Boosting\n'], 'url_profile': 'https://github.com/jennifernguyen281', 'info_list': ['HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated Jul 8, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated Oct 27, 2020', '3', 'Jupyter Notebook', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/dwang9846', 'info_list': ['HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated Jul 8, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated Oct 27, 2020', '3', 'Jupyter Notebook', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Jodhpur', 'stats_list': [], 'contributions': '386 contributions\n        in the last year', 'description': ['Machine-learning\nUni-variate and Multi-variate Linear Regression\n'], 'url_profile': 'https://github.com/surinder2000', 'info_list': ['HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated Jul 8, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated Oct 27, 2020', '3', 'Jupyter Notebook', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Germany', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ashraf-ahmadian', 'info_list': ['HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated Jul 8, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated Oct 27, 2020', '3', 'Jupyter Notebook', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Chennai, India', 'stats_list': [], 'contributions': '687 contributions\n        in the last year', 'description': ['Logistic Regression\nImplementation of Logistic regression from scratch\n'], 'url_profile': 'https://github.com/pranjaldatta', 'info_list': ['HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated Jul 8, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated Oct 27, 2020', '3', 'Jupyter Notebook', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Mexico', 'stats_list': [], 'contributions': '121 contributions\n        in the last year', 'description': ['aggression_identification\nIdentification of aggresive language using Logistic Regression classifier.\nagg_class_log_reg_ovr.py\nUsed to classify agr_en_dev.csv using the Logistic Regression classifier using one-versus-rest scheme.\nagg_class_log_reg_grid_ovr.py\nCode used to find the best parameters for the classifier using one-versus-rest scheme.\nOutputs during grid search\n\noutput_ovr_CAG_2020_05_22.txt\noutput_ovr_NAG_2020_05_22.txt\noutput_ovr_OAG_2020_05_22.txt\n\nOutputs during classification of agr_en_dev.csv\n\noutput_CAG_2020_05_23.txt\noutput_NAG_2020_05_23.txt\noutput_OAG_2020_05_23.txt\n\nFile with a summary of best parameters\n\nBestParams_GridSearch.txt\n\n'], 'url_profile': 'https://github.com/asanchez77', 'info_list': ['HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated Jul 8, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated Oct 27, 2020', '3', 'Jupyter Notebook', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Chennai', 'stats_list': [], 'contributions': '53 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/lmntrixsid', 'info_list': ['HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated Jul 8, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated Oct 27, 2020', '3', 'Jupyter Notebook', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '248 contributions\n        in the last year', 'description': ['Decision-Tree-Regression-Age-prediction-of-Abalone\nA decision tree is a flowchart-like structure in which each internal node represents a “test” on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes).\nHere we try to predict the Age of Abalone based on its physical parameters\n\nInstallation\nRequiremenmts\n\nPython 3.3+ or Python 2.7\nscikit learn\nnumpy\npandas\nmatplotlib\n\nInstall the libraries from the pypi.org with the following commands.\npip install scikit-learn\npip install numpy\npip install pandas\npip install matplotlib\n\nPlease do refer stackoverflow for any errors during installation.\n'], 'url_profile': 'https://github.com/dharineeshramtp2000', 'info_list': ['HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated Jul 8, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated Oct 27, 2020', '3', 'Jupyter Notebook', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Abir0810', 'info_list': ['HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated Jul 8, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated Oct 27, 2020', '3', 'Jupyter Notebook', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Dallas, Texas', 'stats_list': [], 'contributions': '42 contributions\n        in the last year', 'description': ['Airbnb_NYC\nThis is my final project for ""Programming for Data Science"" Course.\n'], 'url_profile': 'https://github.com/dtliao', 'info_list': ['HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated Jul 8, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated Oct 27, 2020', '3', 'Jupyter Notebook', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}"
"{'location': 'Kochi Kerala', 'stats_list': [], 'contributions': '67 contributions\n        in the last year', 'description': ['Ames-Housing-Sales-Prediciton\nSalePrice prediction on Ames data set uisng advanced regresson techniques such as lasso regression , ridge regression and gradient boosting.\ndataset from kaggle\n'], 'url_profile': 'https://github.com/SauravSuresh', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Apache-2.0 license', 'Updated May 13, 2020', 'Python', 'Updated May 11, 2020', '2', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Seoul, Republic of Korea', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['Simple-Regression-Neural-Network\nA DNN model that proceeds the regression of simple function, which is named SRNN(Simple Regression Neural Network).\nThis model is written in Python. TensorFlow or any Deep Learing framework WAS NOT USED.\nLibraries you need to compile this are Numpy, matplotlib, and scipy.\nOptimizer is set to ""Adam"" basically, but changable to SGD. If you want to use other optimizers besides them, you can make it easily by modifying class structure. An optimizer class must have the update() method.\nI referred to ""Deep Learning from Scratch"".\n'], 'url_profile': 'https://github.com/three0-s', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Apache-2.0 license', 'Updated May 13, 2020', 'Python', 'Updated May 11, 2020', '2', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'shanghai', 'stats_list': [], 'contributions': '1 contribution\n        in the last year', 'description': ['线性回归\n'], 'url_profile': 'https://github.com/Neal-Huang', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Apache-2.0 license', 'Updated May 13, 2020', 'Python', 'Updated May 11, 2020', '2', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': [""Airbnb Price Prediction Project (Chicago)\n\nTable of Contents\n\nForeword\nInstallation\nFile Descriptions\nResults\nResources\n\nForeword \nThis project is a part of James Rocco Research Scholarship provided by Lake Forest College and was carried out under the supervision of Prof. Arthur Bousquet. The main idea is based on an article by Graciela Carrillo posted on Towards Data Science.\nInstallation \nUsing Anaconda create a new environment from environment.yml.\nconda env create --file environment.yml\nFile Descriptions (Follow in order) \nTo conveniently read all the notebooks follow this link.\nNotebooks/:\n\nEDA.ipynb (Exploratory Data Analysis) - A brief overview and analysis of raw data\nkepler_map.ipynb - Visualization of the whole dataset using Kepler.gl\ndata_preprocessing.ipynb - Preprocessing the data for future uses (outlier detection, feature selection, handling missing data, etc.)\nregressions.ipynb - Development of initial price prediction models\ncta_mapping.ipynb - Visualization of geo_loc.py using Folium maps (Map of routes to CTAs in the radius and shortest path detection)\nmodel.ipynb - Final model for price prediciton that compares the results of datasets with and without newly produced variables\n\nScripts:\n\ngeo_loc.py - A python script for geospatial analysis: creates 5 new variables using such libraries as OSMnx and OpenRouteSerivce:\n\nRestaurants - Number of restaurants in a 1000 meters radius\nCafes - Number of cafes in the radius\nBars - Number of bard in the radius\nCTA - Number of CTA (Chicago Subway) stations in the radius\ntime_to_cta_minutes - Time in minutes to the nearest CTA station (can be out of the radius)\n\n\n\nProject Description and Results \n The main goal of this project is to build a model that predicts the price of a listing given its dependent variables.  The data for both dependent and independent variables is available through Insideairbnb.com. To get a general understanding of the data used for this project, take a look at the map below where the data is projected on the map of Chicago. Listings (i.e. rows in the dataset) are grouped within hexagons whose height represents the listings count and the color represents the price range.\n\nThe accuracy, i.e. how well the model performs, is measured by R^2  a metric commonly used for regression models that represents the proportion of the variance for a dependent variable that's explained by independent variables. To further improve the accuracy and add originality to the project, 5 new variables are created by analyzing surrounding areas and fetching distances to chosen types of locations as well as calculating the walking time to the nearest subway station.\nSince it is possible to visualize locations and routes, below you can see a map with routes to all subway stations within the range of 1000m (the circle) and with the shortest route colored in green. Red dots represent subway station that lie outside the wanted radius.\n\nHere is the list of variables used to predict the price of a listings:\n Numerical variables:  \n\nAccommodates - Number of people a listing can accommodate\nBathrooms - Number of bathrooms\nMinimum_nights - Minimum amount of nights a listing should be booked for\nMaxium_nights - Maximum amount of nights a listing can be booked for\nAvailability_30 - Number of days a listing is available in the next 30 days\nNumber_of_reviews - Total number of reviews\nNumber_of_reviews_ltm - Number of reviews within last month\nRestaurants, Bars, Cafes, Universities - Number of places of specified type within 1000 meters from the listing (4 different variables)\nTime_to_cta_minutes - Time it takes to walk to the nearest subway (in Chicago CTA) station (Distance does not matter)\n\n Categorical variables: \n\nNeighbourhood_cleansed - name of the neighborhood a listing is located in\nProperty_type - type of property a listing is located in (e.g. Apartment, Condomonium, House, etc.)\nBed_type - type of bed present in a listing\nCancellation_policy - type of cancellation policy chosen by the host\n\nAs it can be apparent from file descriptions, a step-by-step approach was taken to build the model. To understand the model and the thought process you can read through the notebooks.\nTo achieve the best possible result I tried various models and these are the results:\n\n\n\n_\nLinear Regression\nLasso Regression\nRidge Regression\nLasso Regression with Polynomial Features\nRidge Regression with Polynomial Features\nXGBoost\n\n\n\n\n No new variables:  Train R2\n0.4298\n0.4294\n0.4296\n0.4918\n0.5143\n0.6428\n\n\nTest R2\n0.4607\n0.462\n0.4615\n0.4867\n0.4925\n0.5391\n\n\n With new variables:  Train R2\n0.4387\n0.4375\n0.4384\n0.5036\n0.5224\n0.6742\n\n\nTest R2\n0.411\n0.4163\n0.4129\n0.4503\n0.453\n0.5445\n\n\n\nA good way to see the difference in modeling between the data without and with the new variables is to look at feature importances computed by XGBoost. Categorical variables are not included not to overcrowd the plot.\nAs we can see on the bottom plot the new features possess high importance (higher than some of the initial features).\n\n\nResources \nPackage Docs\nShapely\nPoint in Polygon\nOSMnx\nOSMnx Example Notebooks\nopenrouteservice-py\nFolium\nKeplerGL for Jupyter Notebook\nDataCamp\nPandas Foundations\nUnsupervised Learning\xa0\nSupervised Learning\xa0\nYoutube Videos\nRidge Regression\nLasso Regression\nMachine Learning Tutorial Playlist\nTheory behind PCA\nComplete Machine Learning Course by Andrew NG\nMedium Articles\nAirbnb Price Prediction Using Linear Regression (Scikit-Learn and StatsModels)\nRidge and Lasso Regression: L1 and L2 Regularization\nPredicting Airbnb prices with machine learning and location data\nExploring Airbnb prices in London: which factors influence price?\nHow to calculate Travel time for any location in the world\nFind and plot your optimal path using OSM, Plotly and NetworkX in Python\nLoading Data from OpenStreetMap with Python and the Overpass API\nHow to Create Eye-Catching Maps With Python and Kepler.gl\nMeasuring pedestrian accessibility\n""], 'url_profile': 'https://github.com/amac-lfc', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Apache-2.0 license', 'Updated May 13, 2020', 'Python', 'Updated May 11, 2020', '2', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '70 contributions\n        in the last year', 'description': ['CropYieldPrediction\nPredicted crop yield using simple linear regression and multiple linear regressions.\nCreated Linear Regression model and fitted using statsmodels.\nCreated visualization using matplotlib to find insights and build linear regression model for analysis.\n'], 'url_profile': 'https://github.com/Aishwarya-A96', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Apache-2.0 license', 'Updated May 13, 2020', 'Python', 'Updated May 11, 2020', '2', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['LogisticRegression-Linear-Regression-Cross-Validation\n'], 'url_profile': 'https://github.com/zengdavid8', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Apache-2.0 license', 'Updated May 13, 2020', 'Python', 'Updated May 11, 2020', '2', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Banglore', 'stats_list': [], 'contributions': '96 contributions\n        in the last year', 'description': ['Regressions\nThis document contains all the 7 types of regressions\n1.Simple Linear Regression(Simple_Linear_Regression_Salary_Data.csv)\n2.Multiple Linear Regression (Multiple_Linear_Regression_50_Startups.csv)\n3.Polynomial Regression(Polynomial_Regression_Position_Salaries.csv)\n4.Decision Tree Regression(Decision_Tree_Regression_Position_Salaries.csv)\n5.Random Forest Regression(Random_Forest_Regression_Position_Salaries.csv)\n6.Logistic Regression (Logistic_Regression_Social_Network_Ads.csv)\n7.KNN (K_Nearest_Neighbors_Social_Network_Ads.csv)\n'], 'url_profile': 'https://github.com/NehaMuraliDharan', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Apache-2.0 license', 'Updated May 13, 2020', 'Python', 'Updated May 11, 2020', '2', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'London, UK', 'stats_list': [], 'contributions': '261 contributions\n        in the last year', 'description': ['\nCoronavirus Cases Prediction\nThis project is a Machine Learning model to predict new coronavirus cases in the UK. It is a supervised regression task. The model used for this project is XGBoost.\nDataset\nThe dataset contains data from the NHS.\nFeatures importance\n\nHow to download a copy of the project\nTo download a copy of the project, just go on the main page of the project on GitHub, click on ""Clone or download"" and then ""Download ZIP"".\nAfter this, you should be able to run the project using Jupyter Notebook.\nLibraries to install\n\nJupyter Notebook\npandas\nnumPy\nSeaborn\nMatplotlib\nscikit-learn\nXGBoost\ngraphviz\n\nAuthor\n\nThomas Le Menestrel\nRaghav Dave\nGabriel L\n\nLicense\nThis project is licensed under the MIT License - see the LICENSE file for details\n'], 'url_profile': 'https://github.com/tlemenestrel', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Apache-2.0 license', 'Updated May 13, 2020', 'Python', 'Updated May 11, 2020', '2', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '110 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Darlatanujcodes10', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Apache-2.0 license', 'Updated May 13, 2020', 'Python', 'Updated May 11, 2020', '2', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '236 contributions\n        in the last year', 'description': ['Multiple_linear_regression\nAbout this Notebook\nIn this notebook, we learn how to use scikit-learn to implement Multiple linear regression. We download a dataset that is related to fuel consumption and Carbon dioxide emission of cars. Then, we split our data into training and test sets, create a model using training set, Evaluate your model using test set, and finally use model to predict unknown value\n'], 'url_profile': 'https://github.com/illumi91', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Apache-2.0 license', 'Updated May 13, 2020', 'Python', 'Updated May 11, 2020', '2', 'Jupyter Notebook', 'Updated Aug 29, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 14, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}"
"{'location': 'India', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/akhilims', 'info_list': ['1', 'Updated May 13, 2020', 'Go', 'MIT license', 'Updated May 16, 2020', 'HTML', 'MIT license', 'Updated Jun 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '201 contributions\n        in the last year', 'description': ['walk-the-camino\nwalk-the-camino uses the Godog testing framework for writing a resuable BDD-based regression suite. Similar to any Godog application, walk-the-camino searches for test case specifications in feature/*.feature files found in the tests/functional folder, and then pairs them with the corresponding FeatureABC(suite * godog.Suite) functions. The backbone of the application was recycled using have-some-func as the backend service.\nCore Structure\nwalk-the-camino\n  ├── app\n  │    ├── handlers_test.go\n  │    ├── handlers.go\n  │    ├── start.go\n  │    └── package.json\n  │\n  ├── cert\n  │    └── ...\n  │\n  ├── data\n  │    └── employee.go\n  │\n  ├── database\n  │    └── processor.go\n  │\n  ├── tests\n  │    └── functional\n  │         ├── reports\n  │         │    ├── node_modules\n  │         │    │    ├── ...\n  │         │    │    └── cucumber-html-reporter\n  │         │    └── main.js\n  │         ├── testutil\n  │         │   └── testutil.go   \n  │         ├── Update-Post-Request\n  │         │    ├── config\n  │         │    ├── features\n  │         │    ├── report\n  │         │    ├── main.go\n  │         │    ├── put_request.go\n  │         │    ├── main_test.go\n  │         │    └── report_test.go\n  │         ├── cleanJson.go\n  │         └── package.json\n  │\n  ├── utils\n  │    └── constants.go\n  │\n  ├── vendor\n  │    └── github.com\n  │         ├── buger\n  │         ├── DATA-DOG\n  │         └── gorilla        \n  │\n  ├── ...\n  ├── dev-compose.yml\n  ├── Dockerfile\n  ├── LICENSE \n  ├── project.go\n  └── README.md\n\nPrerequisites\nGo: go1.11.5 (protip: make sure Go binaries are installed by default)\ngodog: v0.7.9 \n\nUsage\nInstall following libraries:\n\ngo get github.com/cucumber/godog/cmd/godog@v0.9.0\ngo get -u github.com/gorilla/mux\ngo get -u https://github.com/buger/jsonparser\n\nBuild application and functional test cases\n$ docker-compose -f dev-compose.yml up --exit-code-from functional --build functional\n\nExpected Output\nOn the terminal:\nrun PASS ok walk-the-camino/tests/functional/Update-Post-Request 1.000s [no tests to run]\n\nOn the UI:\n\nContributing\nPull requests are welcomed. Feel free to fork and submit a PR to fix a potential bug, suggest improvements, add new features, etc. Any breaking changes will be published in the CHANGELOG.\nLicense\nwalk-the-camino is licensed under \nAdditional Geekery\nConfigure Go toolchain\n\nCucumber Docs\n\nBDD Demo in Go\n'], 'url_profile': 'https://github.com/lhmzhou', 'info_list': ['1', 'Updated May 13, 2020', 'Go', 'MIT license', 'Updated May 16, 2020', 'HTML', 'MIT license', 'Updated Jun 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['\nIn these labs, you will write functions to implement regression\ncalculations. You will be adding functionality to a package called\nregress431.\nLab 5 Instructions\nLab 6 Instructions\n'], 'url_profile': 'https://github.com/Cal-Poly-Advanced-R', 'info_list': ['1', 'Updated May 13, 2020', 'Go', 'MIT license', 'Updated May 16, 2020', 'HTML', 'MIT license', 'Updated Jun 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '54 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/webebe', 'info_list': ['1', 'Updated May 13, 2020', 'Go', 'MIT license', 'Updated May 16, 2020', 'HTML', 'MIT license', 'Updated Jun 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '60 contributions\n        in the last year', 'description': ['DAT512_SparkProject\nProject to create and run a regression model using PySpark\n'], 'url_profile': 'https://github.com/LiamMcFall', 'info_list': ['1', 'Updated May 13, 2020', 'Go', 'MIT license', 'Updated May 16, 2020', 'HTML', 'MIT license', 'Updated Jun 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'Pune', 'stats_list': [], 'contributions': '32 contributions\n        in the last year', 'description': ['Logistic_Regression\nThis assignment is about the application of Logistic Regression Classifier on Donor Chose Dataset.\n'], 'url_profile': 'https://github.com/Dinesh-Mali', 'info_list': ['1', 'Updated May 13, 2020', 'Go', 'MIT license', 'Updated May 16, 2020', 'HTML', 'MIT license', 'Updated Jun 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': ['LinearRegression_Using_sklearn\nsklearn module is used to implement the simple Linear Regression\n'], 'url_profile': 'https://github.com/Praveen11558', 'info_list': ['1', 'Updated May 13, 2020', 'Go', 'MIT license', 'Updated May 16, 2020', 'HTML', 'MIT license', 'Updated Jun 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/keenbm', 'info_list': ['1', 'Updated May 13, 2020', 'Go', 'MIT license', 'Updated May 16, 2020', 'HTML', 'MIT license', 'Updated Jun 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '92 contributions\n        in the last year', 'description': ['Polynomial-Regression\nML Polynomial Regression template I built using Google Colab\n'], 'url_profile': 'https://github.com/Ndu3000', 'info_list': ['1', 'Updated May 13, 2020', 'Go', 'MIT license', 'Updated May 16, 2020', 'HTML', 'MIT license', 'Updated Jun 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '66 contributions\n        in the last year', 'description': ['DL-assignment-3\nNLI using BiLSTM and Logistic regression (using tf-idf features)\nThe models are too large to be uploaded on Github\nso uploaded them on drive. https://drive.google.com/open?id=1xRdwb6mzIfsbsP4eJOi85nZarhRsHQZ6 (link also included in the report)\n'], 'url_profile': 'https://github.com/amaj8', 'info_list': ['1', 'Updated May 13, 2020', 'Go', 'MIT license', 'Updated May 16, 2020', 'HTML', 'MIT license', 'Updated Jun 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}"
"{'location': 'Kolkata, West Bengal, India', 'stats_list': [], 'contributions': '23 contributions\n        in the last year', 'description': ['Linear-Regression\nImplementation of linear regression model in big mart sales prediction.\n'], 'url_profile': 'https://github.com/shruti-214', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'HTML', 'MIT license', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Python', 'Updated May 13, 2020', '1', 'Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '144 contributions\n        in the last year', 'description': ['Towards-a-reservation-lifetime\nSurvival analysis, statistical test, Kaplan-Meier estimator, Cox regression, R\nGeneral dataset description:\nThe dataset is taken from the paper entitled ""Hotel booking demande dataset"" by Nuno Antonio et al. published in open access on ScienceDirect at https://doi.org/10.1016/j.dib.2018.11.126.\nThe dataset is a set of two sub-datasets (we rename H1_resort.csv, H2_CityHotel.csv for convenience). Both dataset share the sames structure with 31 covariates describing 40060 observations for H1_resort, 79330 observations for H2_CityHotel. Each observation represents a resort booking (H1_resort), city hoel booking (H2_CityHotel) . Both datasets comprehend bookings between the 1st of July 2015 and the 31st of August 2017 in Portugal : resort at region of Algarve and hotel in Lisbon. The booking datasets are righ-censored by booking status (cancellation or not) associated with booking time.\nIn the framework of this demonstration, I list below the relevant features involved in the analysis :\n\n\n\nCovariate\nType\nDescription\n\n\n\n\nADR\nNumeric\nAverageDailyRate\n\n\nAdults\nInteger\nNumber of adults\n\n\nBabies\nInteger\nNumber of babies\n\n\nChildren\nInteger\nNumber of children\n\n\nDeposit Type\nCategorical\nType of deposit. Three groups\n\n\nDistributionChannel\nInteger\nBooking distribution channel. Four groups\n\n\nIsCanceled\nCategorical\nValue indicating if the booking was canceled (1) or not (0)\n\n\nLeadTime\nInteger\nNumber of days that elapsed between the booking-arrival dates\n\n\nReservationStatus\nCategorical\nReservation last status.\n\n\nReservationStatusDate\nDate\nDate of last status set. It permits to estimate the time between booking-cancellation dates\n\n\nStaysInWeekendNights\nInteger\nNumber of weekend nights booked/stays\n\n\nStaysInWeekNights\nInteger\nNumber of week nights booked/stays\n\n\n\nMore details about other features can be found in the article.\nWorkflow:\nThe aim of this study is to analyse the survival risk (cancellation or no cancellation) of a (resort, city hotel) booking over the booking time. This allows to build a prediction model based on the robust analysis detailed in this report. The model will permit hotel managers to anticipate a risk of cancellation of a booking, to reorganize their planning and prepare overbooking situation.\nEach part has a same number of sections and I take care of the dataset by following section-by-section plan:\nData exploration: it consits of loading dataset, showing statistical summary and some vizualization to have an overview about the dataset. The idea behind of this section relies on the discussion about the censored data and features, which will be selected for the study.\n\nSurvival analysis : the backbone of our report. I study patterns, possible tests and techniques which appear to be appropriate to the dataset characteristics.\n\nMachine Learning/prediction : selection of the ""best"" model with the help of stepwise tehnique. The selection is of course in the line with the survival analysis. Finally, the evaluation of the model was done by assessing ROC curves.\n\n'], 'url_profile': 'https://github.com/marcdime', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'HTML', 'MIT license', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Python', 'Updated May 13, 2020', '1', 'Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Hyderabad, India', 'stats_list': [], 'contributions': '197 contributions\n        in the last year', 'description': ['LogisticRegression-From-Scratch\nLogistic Regression classification on compressed images using PCA\n'], 'url_profile': 'https://github.com/Aditya-crypto', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'HTML', 'MIT license', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Python', 'Updated May 13, 2020', '1', 'Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['\nIn these labs, you will write functions to implement regression\ncalculations. You will be adding functionality to a package called\nregress431.\nLab 5 Instructions\nLab 6 Instructions\n'], 'url_profile': 'https://github.com/Cal-Poly-Advanced-R', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'HTML', 'MIT license', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Python', 'Updated May 13, 2020', '1', 'Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Ireland', 'stats_list': [], 'contributions': '9 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/mwakaswanga', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'HTML', 'MIT license', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Python', 'Updated May 13, 2020', '1', 'Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['COVID-19 predictions using mobility data and Oxford stringency index\nData Sources\n\n\n\nSource\nDesc\nLink\n\n\n\n\nGoogle\nMobility Data\nhttps://www.google.com/covid19/mobility/\n\n\nApple\nMobility Data\nhttps://www.apple.com/covid19/mobility\n\n\nOxford\nStringency Index\nhttps://github.com/OxCGRT/covid-policy-tracker\n\n\nJHU CSSE\nVirus metrics\nhttps://github.com/CSSEGISandData/COVID-19\n\n\n\n'], 'url_profile': 'https://github.com/nyu-ds-2019', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'HTML', 'MIT license', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Python', 'Updated May 13, 2020', '1', 'Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Fukuoka, Japan', 'stats_list': [], 'contributions': '98 contributions\n        in the last year', 'description': ['Structure\n\nRequirements\nPython\nAll the Python scripts are supported by Python 3.5.3 or later.\n(Option) It is recommended that you have a virtual environment with pyenv and pyenv-virtualenv.\nLibraries and Packages\nnumpy 1.13.3, scikit-learn 0.19.1 and PyYAML 3.12 are required. Use the pip command and install the packages as follows:\npip install -r requirements.txt\nSample Main Script\nRun\npython run.py params.yaml\nwith the config file in YAML format located under the config directory.\nNote\nAs of 5/12/2018, only the Boston house-prices dataset is available.\nReference\nHastie, Trevor, et al. Statistical Learning with Sparsity: the Lasso and Generalizations. CRC Press, Taylor & Francis Group, 2015.\n'], 'url_profile': 'https://github.com/stmsy', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'HTML', 'MIT license', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Python', 'Updated May 13, 2020', '1', 'Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Paris, France', 'stats_list': [], 'contributions': '361 contributions\n        in the last year', 'description': ['PythonGP\nA wrapper of the python libraries implementing GP Regression\nToolboxes :\nSklearn, Shogun, GPy, GPyflow, GPytorch, Openturns\nTo run :\nSyntax:\npython3 run_tests.py\n\nFeatures :\n\nComapares GPR fitting using EMRMSE, PMRMSE for different toolboxes\n\n'], 'url_profile': 'https://github.com/Subhasishbasak', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'HTML', 'MIT license', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Python', 'Updated May 13, 2020', '1', 'Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '323 contributions\n        in the last year', 'description': ['Artificial-Neural-Networks\n[ Implemented several machine learning techniques such as regression, binary classification, multiclass classification using ANNs as part of the Udemy course Neural Networks (ANN) using Keras and Tensorflow in Python ]\nINTRODUCTION\nNeural networks, as its name suggests, is a machine learning technique which is modeled after the brain structure. It comprises a network of learning units called neurons. \nDeep Learning\nDeep Learning is a subfield of machine learning concerned with algorithms inspired by the structure and function of the brain called Neural Networks. Neural networks are typically organized in layers. The term \'deep\' usually refers to the number of hidden layers in the neural network. Traditional neural networks only contain 2-3 hidden layers, while deep networks can have as many as 150. Deep learning models are trained by using large sets of labeled data and neural network architectures that learn features directly from the data without the need for manual feature extraction. The different types of neural networks in deep learning, such as convolutional neural networks(CNN) , recurrent neural networks(RNN), artificial neural networks(ANN).\nArtificial Neural Networks(ANNs)\nAn artificial neuron network (ANN) is a computational model based on the structure and functions of biological neural networks. Information that flows through the network affects the structure of the ANN because a neural network changes - or learns, in a sense - based on that input and output.\nANNs are considered nonlinear statistical data modeling tools where the complex relationships between inputs and outputs are modeled or patterns are found.\nIn this method, first it involves in building the network for the model, parameters to be tuned in the beginning of the training process such as number of input nodes, hidden nodes, output nodes and initial weights, learning rates and activation function.\nSupervised Learning\nSupervised learning is where you have input variables (x) and an output variable (Y) and you use an algorithm to learn the mapping function from the input to the output.\n Y = f(x) \nThe goal is to approximate the mapping function so well that when you have new input data (x) that you can predict the output variables (Y) for that data. Supervised learning technique deals with the labelled data where the output data patterns are known to the system.\n\nClassification\nClassification is a process of categorizing a given set of data into classes, It can be performed on both structured or unstructured data. The process starts with predicting the class of given data points. The classes are often referred to as target, label or categories.\nThe classification predictive modeling is the task of approximating the mapping function from input variables to discrete output variables. The main goal is to identify which class/category the new data will fall into. \nEx. Classifying mail into spam or not spam\n\nBinary Classification\nBinary or binomial classification is the task of classifying the elements of a given set into two groups (predicting which group each one belongs to) on the basis of a classification rule. \nEx. Medical testing to determine if a patient has certain disease or not – the classification property is the presence of the disease.\nMulti-Class Classification\nThe classification with more than two classes, in multi-class classification each sample is assigned to one and only one label or target.\nEx. classify a set of images of fruits which may be oranges, apples, or pears. Multiclass classification makes the assumption that each sample is assigned to one and only one label: a fruit can be either an apple or a pear but not both at the same time.\nMulti-Label Classification\nThe classification where each sample is assigned to a set of labels or targets. This can be thought as predicting properties of a data-point that are not mutually exclusive. \nEx. Find topics that are relevant for a document. A text might be about any of religion, politics, finance or education at the same time or none of these.\n\n\nRegression\nRegression analysis is a form of predictive modelling technique which investigates the relationship between a dependent (target Y) and independent variable(Xs) (predictor). In this case outputs are continuous rather than discrete.\nThere are various kinds of regression techniques available to make predictions, such as Linear Regression, Logistic Regression, Polynomial Regression, Stepwise Regression, Ridge Regression, Lasso Regression, ElasticNet Regression etc.\nEx. Quantify the relative impacts of age, gender, and diet (the predictor variables) on height (the outcome variable). \n\nIMPLEMENTATION\nBinary Classification\nTo implement binary classification, I used iris dataset from sklearn.datasets. Using this dataset, i built a binary classifier that classifies whether a species is ""Setosa"" or not.\nI used Perceptron() model from sklearn.linear_model to fit X (sepal length,sepal width, petal length,petal width) and Y (Setosa(1) or not(0)) into a model. This built model is used to predict whether a species is setosa or not.\nAssignment\nIn this part, we used this dataset. Using this dataset, I implemented binary classifier to predict whether a house is Sold or not. Lot of pre-processing techniques like filling missing values, outlier treatment, removing independent columns that are highly correlated etc. are applied to this dataset. Model was built using ANN Sequential approach with  sigmoid as a final layer activation function, binary_crossentropy as a loss function, stochastic gradient descent as an optimizer and accuracy as metrics. Train accuracy of 65.85% and test accuracy of 58.82% was achieved. \nMulti-Class Classification\nTo implement multi-class classification model, I used Fashion MNIST dataset from keras.datasets. This Dataset consists of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. Model was built using ANN Sequential approach with  softmax as a final layer activation function, sparse_categorical_crossentropy as a loss function, stochastic gradient descent as an optimizer and accuracy as metrics. Train accuracy of 93.42% and test accuracy of 89.14% was achieved.\nRegression\nFor Regression analysis, I used California housing dataset from sklearn.datasets. This dataset consists of 20,640 samples and 9 features. The target variable is the median house value for California districts. Data was normalized using StandardScalar library from sklearn.preprocessing. \nSequential Model was built using ANN Sequential approach with mean_squared_error as a loss function, stochastic gradient descent as an optimizer and mean absolute error as metrics. Training Mean absolute error of 0.4469 and testing mean absolute error of 0.4464 was obtained after running over 120 epochs. \nComplex Functional Model was built using Functional API approach(It specifically allows you to define multiple input or output models as well as models that share layers. More than that, it allows you to define ad hoc acyclic network graphs). Flow diagram of the model built using ANN Functional approach can be seen here. Hyperparameters used for this approach are same as sequential approach. Training Mean absolute error of 0.4220 and testing mean absolute error of 0.4216 is obtained after running over 120 epochs.\nWhile training, various Model Checkpoints are implemented using Keras.callbacks to store best model and early stop model of the above sequential approach. \nINSTALLATIONS\nAnaconda jupyter-notebook numpy pandas seaborn matplotlib Sklearn Keras Tensorflow \n\njupyter notebook setup \n# To Activate Anaconda\n  $ source ~/anaconda3/bin/activate root\n  $ anaconda-navigator\n# Launch jupyter-notebook\n# To Deactivate Anaconda\n  $ conda deactivate\n\nACKNOWLEDGMENTS\nhttps://towardsdatascience.com/applied-deep-learning-part-1-artificial-neural-networks-d7834f67a4f6\nhttps://towardsdatascience.com/introduction-to-artificial-neural-networks-ann-1aea15775ef9\nhttps://towardsdatascience.com/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8\n'], 'url_profile': 'https://github.com/vamc-stash', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'HTML', 'MIT license', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Python', 'Updated May 13, 2020', '1', 'Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Bellingham, WA', 'stats_list': [], 'contributions': '41 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/dm185', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'HTML', 'MIT license', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Python', 'Updated May 13, 2020', '1', 'Python', 'Updated Oct 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['Linear-Regression\nML solution to linear regression problem with multiple features\n'], 'url_profile': 'https://github.com/photonPrograms', 'info_list': ['Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '92 contributions\n        in the last year', 'description': ['Simple-Linear-Regression\nML Simple Linear Regression template I built using Google Colab\n'], 'url_profile': 'https://github.com/Ndu3000', 'info_list': ['Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '9 contributions\n        in the last year', 'description': ['Machine-Learning\nLinear Regression\nPredicting university admission by Machine-Learning\nAccording to some parameters (here according to GRE score), Model will predict chance of admission. You can change the parameters and anticipate based on other parameters. Enjoy !!\n'], 'url_profile': 'https://github.com/javad1es', 'info_list': ['Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'Commack, NY', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['SOCEstimate\nLinear Regression for SOC Estimates vs True SOC values\n'], 'url_profile': 'https://github.com/theameyakale', 'info_list': ['Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '83 contributions\n        in the last year', 'description': ['Poisson-Regression-Website-Traffic\nSimple Implementation of Poisson-Regression to Predict Website Traffic (uses full batch gradient ascent)\n'], 'url_profile': 'https://github.com/natashasaki', 'info_list': ['Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '53 contributions\n        in the last year', 'description': ['LogisticRegression-MNIST\nImplementing simple logistic regression from scratch to identify MNIST digits\nMy model works with an accuracy of 91.07%.\nRun the file LogisticRegression.py on python3.\nTo train the model again, uncomment the two lines 96 and 97\n'], 'url_profile': 'https://github.com/MehakArora', 'info_list': ['Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'Boulder, Colorado', 'stats_list': [], 'contributions': '241 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/PreethiVijai', 'info_list': ['Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'Mathura, India', 'stats_list': [], 'contributions': '76 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Shashank-Mittal', 'info_list': ['Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'tokyo, japan', 'stats_list': [], 'contributions': '76 contributions\n        in the last year', 'description': ['Model-Selection-For-Regression\ntemplates for regression models for financial data analysis\n'], 'url_profile': 'https://github.com/Mayaz9156', 'info_list': ['Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'Tempe, AZ', 'stats_list': [], 'contributions': '118 contributions\n        in the last year', 'description': ['Logistic Regression\nPredicting survival chances with logistic regression algorithm using Python & StatTools\n'], 'url_profile': 'https://github.com/ishah6', 'info_list': ['Python', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 28, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}"
"{'location': 'Chennai/Coimbatore', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/baraths92', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Updated Nov 21, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '10 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/hishamag', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Updated Nov 21, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '270 contributions\n        in the last year', 'description': ['Regression with Automatic Differentiation in TensorFlow\nWe will accomplish the final task by completing each task in the project:\n\nTask 1: Introduction\nTask 2: Tensor Constants\nTask 3: Tensor Variables\nTask 4: Automatic Differentiation\nTask 5: Watching Tensors\nTask 6: Persistent Tape\nTask 7: Generating Data for Linear Regression\nTask 8: Linear Regression\n\n'], 'url_profile': 'https://github.com/sameer-m-dev', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Updated Nov 21, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '92 contributions\n        in the last year', 'description': ['Random-Forest-Regression\nML Random Forest Regression I built using Google Colab\n'], 'url_profile': 'https://github.com/Ndu3000', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Updated Nov 21, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/wayneyong', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Updated Nov 21, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Gurugram', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['Ridge-Lasso-Regression\nImplemenation of hyperparameter optimization using Ridge & Lasso regression\n'], 'url_profile': 'https://github.com/tapas-dev', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Updated Nov 21, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Gurgaon, India ', 'stats_list': [], 'contributions': '68 contributions\n        in the last year', 'description': ['House-_Price_Prediction_ID\nThis is the learning Project for Linear Regression\n'], 'url_profile': 'https://github.com/rohitkuk', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Updated Nov 21, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Uberlândia / Brasil', 'stats_list': [], 'contributions': '78 contributions\n        in the last year', 'description': ['Linear-Regresion-Machine-Learning\nLinear Regression is a machine learning algorithm based on supervised learning. It performs a regression task. Regression models a target prediction value based on independent variables. It is mostly used for finding out the relationship between variables and forecasting. Different regression models differ based on – the kind of relationship between dependent and independent variables, they are considering and the number of independent variables being used.\nThis analysis, applying artificial intelligence algorithm, more precisely machine learning algorithm (Linear Regression), based on a dataset from the Kaggle data repository, which consists of making a prediction of the life expectancy of people, in which the user types the year, and if you have the answer of how many years would be the life expectancy in that year. Python was used with the open-source web jupyter notebook tool, from the Anaconda distribution, which allows us to work with several libraries such as Numpy, Pandas, MatplotLib, Sckit learn for machine learning, and others.\n'], 'url_profile': 'https://github.com/guimaraess2', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Updated Nov 21, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Leicester', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/scottjenkins97', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Updated Nov 21, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Chennai,India', 'stats_list': [], 'contributions': '52 contributions\n        in the last year', 'description': ['Risk-Modelling\nCustomer Risk Modelling and Clustering Analysis using Logistic Regression & K-Means Clustering\nBelow steps has been done to achieve the objective:\n1) Data Preparation\n2) Feature Engineering\n3) Predictive Model building using Logistic Regression\n4) K-Means Clustering to do target Marketing.\n\n'], 'url_profile': 'https://github.com/ami-agrl', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Updated Nov 21, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}"
"{'location': 'tokyo, japan', 'stats_list': [], 'contributions': '76 contributions\n        in the last year', 'description': ['Deciosion-Tree-Regression\nDecision tree regression model application in financial data analysis.\n'], 'url_profile': 'https://github.com/Mayaz9156', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Julia', 'MIT license', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '55 contributions\n        in the last year', 'description': ['Robust linear models in Julia\n\n\n\nCI Status\nCoverage\n\n\n\n\n\n \n\n\n\nThis package defines robust linear models using the interfaces from StatsBase.jl and StatsModels.jl. It defines an AbstractRobustModel type as a subtype of RegressionModel and it defines the methods from the statistical model API like fit/fit!.\nA robust model is a regression model, meaning it finds a relationship between one or several covariates/independent variables X and a response/dependent variable y. Contrary to the ordinary least squares estimate, robust regression mitigates the influence of outliers in the data.\nA standard view for RobustLinearModel is to consider that the residuals are distributed according to a contaminated distribution, that is a mixture model of the distribution of interest F and a contaminating distribution Δ with higher variance. Therefore the residuals r follow the distribution r ~ (1-ε) F + ε Δ, with 0≤ε<1.\nThis package implements:\n\nM-estimators\nS-estimators\nMM-estimators\nτ-estimators\nMQuantile regression (e.g. Expectile regression)\nQuantile regression using interior point method\n\nInstallation\n]add https://github.com/getzze/RobustModels.jl\nUsage\nThe prefered way of performing robust regression is by calling the fit method:\nm = fit(RobustLinearModel, X, y, TukeyEstimator(); initial_scale_estimate=:mad)\nThe same for quantile regression:\nm = fit(QuantileRegression, X, y; quantile=0.5)\nExamples\nusing RDatasets: dataset\nusing StatsModels\nusing RobustModels\nusing RobustModels: HuberEstimator, TukeyEstimator, L2Estimator, YohaiZamarEstimator, TauEstimator\n\ndata = dataset(""robustbase"", ""Animals2"")\ndata.logBrain = log.(data.Brain)\ndata.logBody = log.(data.Body)\nform = @formula(logBrain ~ 1 + logBody)\n\n## M-estimator using Tukey estimator\nm1 = fit(RobustLinearModel, form, data, TukeyEstimator(); method=:cg, initial_scale_estimate=:mad)\n\n## MM-estimator using Tukey estimator\nm2 = fit(RobustLinearModel, form, data, TukeyEstimator(); method=:cg, initial_scale_estimate=:mad, kind=:MMestimate)\n\n## M-estimator using Huber estimator and correcting for covariate outliers using leverage\nm3 = fit(RobustLinearModel, form, data, HuberEstimator(); method=:cg, initial_scale_estimate=:mad, correct_leverage=true)\n\n## M-estimator using Huber estimator, providing an initial scale estimate and using Cholesky method of solving.\nm4 = fit(RobustLinearModel, form, data, HuberEstimator(); method=:chol, initial_scale_estimate=15.0)\n\n## S-estimator using Tukey estimator\nm5 = fit(RobustLinearModel, form, data, TukeyEstimator(); initial_scale_estimate=:mad, kind=:Sestimate)\n\n## τ-estimator using Tukey estimator\nm6 = fit(RobustLinearModel, form, data, TauEstimator(TukeyEstimator); initial_scale_estimate=:mad, kind=:Tauestimate)\n\n## τ-estimator using YohaiZamar estimator and resampling to find the global minimum\nopts = Dict(:Npoints=>10, :Nsteps_β=>3, :Nsteps_σ=>3)\nm7 = fit(RobustLinearModel, form, data, TauEstimator(YohaiZamarEstimator); initial_scale_estimate=:mad, kind=:Tauestimate, resample=true, resampling_options=opts)\n\n## Expectile regression for τ=0.8\nm8 = fit(RobustLinearModel, form, data, L2Estimator(); quantile=0.8)\n#m8 = fit(RobustLinearModel, form, data, ExpectileEstimator(0.8))\n\n## Quantile regression solved by linear programming interior point method\nm9 = fit(QuantileRegression, form, data; quantile=0.2)\n\n## Refit with different parameters\nrefit!(m8; quantile=0.8)\n\nTheory\nM-estimators\nWith ordinary least square (OLS), the objective function is, from maximum likelihood estimation:\nL = ½ Σᵢ (yᵢ - 𝒙ᵢ 𝜷)² = ½ Σᵢ rᵢ²\nwhere yᵢ are the values of the response variable, 𝒙ᵢ are the covectors of individual covariates (rows of the model matrix X), 𝜷 is the vector of fitted coefficients and rᵢ are the individual residuals.\nA RobustLinearModel solves instead for the following objective function: L\' = Σᵢ ρ(rᵢ) (more precisely L\' = Σᵢ ρ(rᵢ/σ) where σ is an estimate of the standard deviation of the residual). Several M-estimators are implemented:\n\nL2Estimator: ρ(r) = ½ r², like ordinary OLS.\nL1Estimator: ρ(r) = |r|, non-differentiable estimator also know as Least absolute deviations. Prefer the QuantileRegression solver.\nHuberEstimator: ρ(r) = if (r<c); ½(r/c)² else |r|/c - ½ end, convex estimator that behaves as L2 cost for small residuals and L1 for large esiduals and outliers.\nL1L2Estimator: ρ(r) = √(1 + (r/c)²) - 1, smooth version of HuberEstimator.\nFairEstimator: ρ(r) = |r|/c - log(1 + |r|/c), smooth version of HuberEstimator.\nLogcoshEstimator: ρ(r) = log(cosh(r/c)), smooth version of HuberEstimator.\nArctanEstimator: ρ(r) = r/c * atan(r/c) - ½ log(1+(r/c)²), smooth version of HuberEstimator.\nCauchyEstimator: ρ(r) = log(1+(r/c)²), non-convex estimator, that also corresponds to a Student\'s-t distribution (with fixed degree of freedom). It suppresses outliers more strongly but it is not sure to converge.\nGemanEstimator: ρ(r) = ½ (r/c)²/(1 + (r/c)²), non-convex and bounded estimator, it suppresses outliers more strongly.\nWelschEstimator: ρ(r) = ½ (1 - exp(-(r/c)²)), non-convex and bounded estimator, it suppresses outliers more strongly.\nTukeyEstimator: ρ(r) = if r<c; ⅙(1 - (1-(r/c)²)³) else ⅙ end, non-convex and bounded estimator, it suppresses outliers more strongly and it is the prefered estimator for most cases.\nYohaiZamarEstimator: ρ(r) is quadratic for r/c < 2/3 and is bounded to 1; non-convex estimator, it is optimized to have the lowest bias for a given efficiency.\n\nThe value of the tuning constants c are optimized for each estimator so the M-estimators have a high efficiency of 0.95. However, these estimators have a low breakdown point.\nS-estimators\nInstead of minimizing Σᵢ ρ(rᵢ/σ), S-estimation minimizes the estimate of the standard deviation σ with the constraint that: Σᵢ ρ(rᵢ/σ) = 1/2.\nS-estimators are only defined for bounded estimators, like TukeyEstimator.\nThese estimators have low efficiency but a high breakdown point of 1/2, by changing the tuning constant c.\nMM-estimators\nIt is a two-pass estimation, 1) Estimate σ using an S-estimator with high breakdown point and 2) estimate 𝜷 using an M-estimator with high efficiency.\nIt results in an estimator with high efficiency and high breakdown point.\nτ-estimators\nLike MM-estimators, τ-estimators combine a high efficiency with a high breakdown point. Similar to S-estimators, it minimize a scale estimate:\nτ² = σ² (2/n Σᵢρ₂(rᵢ/σ)) where σ is an M-scale estimate solution of Σᵢ ρ₁(rᵢ/σ) = 1/2.\nFinding the minimum of a τ-estimator is similar to the procedure for an S-estimator with a special weight function\nthat combines both functions ρ₁ and ρ₂. They should be of the same kind with different tuning constants.\nMQuantile-estimators\nUsing an asymetric variant of the L1Estimator, quantile regression is performed (although the QuantileRegression solver should be prefered because it gives an exact solution). Identically, using an asymetric version of each M-estimator, a generalization of quantiles is obtained. For instance, using an asymetric L2Estimator results in Expectile Regression.\nQuantile regression\nQuantile regression results from minimizing the following objective function:\nL = Σᵢ wᵢ|yᵢ - 𝒙ᵢ 𝜷| = Σᵢ wᵢ(rᵢ) |rᵢ|,\nwhere wᵢ = ifelse(rᵢ>0, τ, 1-τ) and τ is the quantile of interest. τ=½ corresponds to Least Absolute Deviations.\nThis problem can be solved exactly using linear programming techniques like interior point methods using the JuMP package with the GLPK backend.\nCredits\nThis package derives from the RobustLeastSquares package for the initial implementation, especially for the Conjugate Gradient solver and the definition of the M-Estimator functions.\nCredits to the developpers of the GLM and MixedModels packages for implementing the Iteratively Reweighted Least Square algorithm.\n'], 'url_profile': 'https://github.com/getzze', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Julia', 'MIT license', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020']}","{'location': 'Colombo', 'stats_list': [], 'contributions': '12 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/PavaraTharkana', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Julia', 'MIT license', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '75 contributions\n        in the last year', 'description': ['ml-class\n'], 'url_profile': 'https://github.com/buiquangha250199', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Julia', 'MIT license', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020']}","{'location': 'NRW, Germany', 'stats_list': [], 'contributions': '53 contributions\n        in the last year', 'description': ['Linear regression for FIFA 20 player market-vaulues\n#Dataset: https://www.kaggle.com/stefanoleone992/fifa-20-complete-player-dataset\nimport tensorflow as tf\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#data subdirectory\ndir = \'./data/\'\n\n#load data into df and remove players with zero market value\n#exclude free transfer players \ndf = pd.read_csv(dir + ""players_20.csv"")\ndf = df[df.value_eur != 0]\nUsing TensorFlow backend.\n\n#histogramm: distribution of marketvalues\nplt.hist(df.value_eur)\n(array([1.7168e+04, 5.7100e+02, 1.5600e+02, 6.3000e+01, 3.5000e+01,\n        1.6000e+01, 9.0000e+00, 5.0000e+00, 3.0000e+00, 2.0000e+00]),\n array([1.0000e+04, 1.0559e+07, 2.1108e+07, 3.1657e+07, 4.2206e+07,\n        5.2755e+07, 6.3304e+07, 7.3853e+07, 8.4402e+07, 9.4951e+07,\n        1.0550e+08]),\n <a list of 10 Patch objects>)\n\n\n#number rows and columns\ndf.info()\n<class \'pandas.core.frame.DataFrame\'>\nInt64Index: 18028 entries, 0 to 18277\nColumns: 104 entries, sofifa_id to rb\ndtypes: float64(16), int64(45), object(43)\nmemory usage: 14.4+ MB\n\n#use only relevant columns\ndf = df[[\'sofifa_id\',\'value_eur\',\'age\',\'height_cm\',\'weight_kg\',\'nationality\',\'club\',\'overall\',\'potential\',\'wage_eur\',\'preferred_foot\',\'international_reputation\',\'weak_foot\',\'skill_moves\',\'work_rate\',\'team_position\',\'pace\',\'shooting\',\'passing\',\'dribbling\',\'defending\',\'physic\',\'attacking_crossing\',\'attacking_finishing\',\'attacking_heading_accuracy\', \'attacking_short_passing\', \'attacking_volleys\', \'skill_dribbling\', \'skill_curve\', \'skill_fk_accuracy\', \'skill_long_passing\', \'skill_ball_control\', \'movement_acceleration\', \'movement_sprint_speed\', \'movement_agility\', \'movement_reactions\', \'movement_balance\', \'power_shot_power\', \'power_jumping\', \'power_stamina\', \'power_strength\', \'power_long_shots\', \'mentality_aggression\', \'mentality_interceptions\', \'mentality_positioning\', \'mentality_vision\', \'mentality_penalties\', \'mentality_composure\', \'defending_marking\', \'defending_standing_tackle\', \'defending_sliding_tackle\']]\ndf = df.dropna()\ndf = df[df.team_position != \'GK\']\n#tests were made with players only up to 15bn € market value\n#modell needed less epochs, but loss went up 1%\n#telling us that expensive player are rated more accurately\n#df = df[df.value_eur < 15000000]\ndf.info()\n<class \'pandas.core.frame.DataFrame\'>\nInt64Index: 16032 entries, 0 to 18277\nData columns (total 51 columns):\nsofifa_id                     16032 non-null int64\nvalue_eur                     16032 non-null int64\nage                           16032 non-null int64\nheight_cm                     16032 non-null int64\nweight_kg                     16032 non-null int64\nnationality                   16032 non-null object\nclub                          16032 non-null object\noverall                       16032 non-null int64\npotential                     16032 non-null int64\nwage_eur                      16032 non-null int64\npreferred_foot                16032 non-null object\ninternational_reputation      16032 non-null int64\nweak_foot                     16032 non-null int64\nskill_moves                   16032 non-null int64\nwork_rate                     16032 non-null object\nteam_position                 16032 non-null object\npace                          16032 non-null float64\nshooting                      16032 non-null float64\npassing                       16032 non-null float64\ndribbling                     16032 non-null float64\ndefending                     16032 non-null float64\nphysic                        16032 non-null float64\nattacking_crossing            16032 non-null int64\nattacking_finishing           16032 non-null int64\nattacking_heading_accuracy    16032 non-null int64\nattacking_short_passing       16032 non-null int64\nattacking_volleys             16032 non-null int64\nskill_dribbling               16032 non-null int64\nskill_curve                   16032 non-null int64\nskill_fk_accuracy             16032 non-null int64\nskill_long_passing            16032 non-null int64\nskill_ball_control            16032 non-null int64\nmovement_acceleration         16032 non-null int64\nmovement_sprint_speed         16032 non-null int64\nmovement_agility              16032 non-null int64\nmovement_reactions            16032 non-null int64\nmovement_balance              16032 non-null int64\npower_shot_power              16032 non-null int64\npower_jumping                 16032 non-null int64\npower_stamina                 16032 non-null int64\npower_strength                16032 non-null int64\npower_long_shots              16032 non-null int64\nmentality_aggression          16032 non-null int64\nmentality_interceptions       16032 non-null int64\nmentality_positioning         16032 non-null int64\nmentality_vision              16032 non-null int64\nmentality_penalties           16032 non-null int64\nmentality_composure           16032 non-null int64\ndefending_marking             16032 non-null int64\ndefending_standing_tackle     16032 non-null int64\ndefending_sliding_tackle      16032 non-null int64\ndtypes: float64(6), int64(40), object(5)\nmemory usage: 6.4+ MB\n\n#convert float values to int\ndf = df.fillna(0)\ndf.pace = df.pace.astype(\'int64\')\ndf.shooting = df.shooting.astype(\'int64\')\ndf.passing = df.passing.astype(\'int64\')\ndf.dribbling = df.dribbling.astype(\'int64\')\ndf.defending = df.defending.astype(\'int64\')\ndf.physic = df.physic.astype(\'int64\')\n#reset index because rows and columns were removed from pandas dataframe\ndf = df.reset_index()\ndf.head()\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\nindex\nsofifa_id\nvalue_eur\nage\nheight_cm\nweight_kg\nnationality\nclub\noverall\npotential\n...\npower_long_shots\nmentality_aggression\nmentality_interceptions\nmentality_positioning\nmentality_vision\nmentality_penalties\nmentality_composure\ndefending_marking\ndefending_standing_tackle\ndefending_sliding_tackle\n\n\n\n\n0\n0\n158023\n95500000\n32\n170\n72\nArgentina\nFC Barcelona\n94\n94\n...\n94\n48\n40\n94\n94\n75\n96\n33\n37\n26\n\n\n1\n1\n20801\n58500000\n34\n187\n83\nPortugal\nJuventus\n93\n93\n...\n93\n63\n29\n95\n82\n85\n95\n28\n32\n24\n\n\n2\n2\n190871\n105500000\n27\n175\n68\nBrazil\nParis Saint-Germain\n92\n92\n...\n84\n51\n36\n87\n90\n90\n94\n27\n26\n29\n\n\n3\n4\n183277\n90000000\n28\n175\n74\nBelgium\nReal Madrid\n91\n91\n...\n80\n54\n41\n87\n89\n88\n91\n34\n27\n22\n\n\n4\n5\n192985\n90000000\n28\n181\n70\nBelgium\nManchester City\n91\n91\n...\n90\n76\n61\n88\n94\n79\n91\n68\n58\n51\n\n\n\n5 rows × 52 columns\n\n#get train and test set\ndf_train=df.sample(frac=0.8,random_state=200) #random state is a seed value\ndf_test=df.drop(df_train.index)\n#split dataset into seperate datasets for categorical and numerical data \ndf_nominal_train = df_train[[\'nationality\',\'club\',\'preferred_foot\',\'work_rate\',\'team_position\']]\ndf_ordinal_train = df_train.drop(columns = [\'nationality\',\'club\',\'preferred_foot\',\'work_rate\',\'team_position\',\'sofifa_id\',\'value_eur\',\'index\']) #zahlen mit rangordnung\ndf_solutions_train = df_train[[\'sofifa_id\', \'value_eur\']]\n\ndf_nominal_test = df_test[[\'nationality\',\'club\',\'preferred_foot\',\'work_rate\',\'team_position\']]\ndf_ordinal_test = df_test.drop(columns = [\'nationality\',\'club\',\'preferred_foot\',\'work_rate\',\'team_position\',\'sofifa_id\',\'value_eur\',\'index\']) #zahlen mit rangordnung\ndf_solutions_test = df_test[[\'sofifa_id\', \'value_eur\']]\n#Map categorical values to ids \nnationalities = df.nationality.unique()\nnationalities_dict = dict(zip(nationalities, range(len(nationalities))))\nclubs = df.club.unique()\nclubs_dict = dict(zip(clubs, range(len(clubs))))\npreferred_foots = df.preferred_foot.unique()\npreferred_foots_dict = dict(zip(preferred_foots, range(len(preferred_foots))))\nwork_rate = df.work_rate.unique()\nwork_rate_dict = dict(zip(work_rate, range(len(work_rate))))\nteam_positions = df.team_position.unique()\nteam_positions_dict = dict(zip(team_positions, range(len(team_positions))))\n\ndf_nominal_train = df_nominal_train.replace({\'nationality\': nationalities_dict})\ndf_nominal_train = df_nominal_train.replace({\'club\': clubs_dict})\ndf_nominal_train = df_nominal_train.replace({\'preferred_foot\': preferred_foots_dict})\ndf_nominal_train = df_nominal_train.replace({\'work_rate\': work_rate_dict})\ndf_nominal_train = df_nominal_train.replace({\'team_position\': team_positions_dict})\n\ndf_nominal_test = df_nominal_test.replace({\'nationality\': nationalities_dict})\ndf_nominal_test = df_nominal_test.replace({\'club\': clubs_dict})\ndf_nominal_test = df_nominal_test.replace({\'preferred_foot\': preferred_foots_dict})\ndf_nominal_test = df_nominal_test.replace({\'work_rate\': work_rate_dict})\ndf_nominal_test = df_nominal_test.replace({\'team_position\': team_positions_dict})\ndf_nominal_train.head()\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\nnationality\nclub\npreferred_foot\nwork_rate\nteam_position\n\n\n\n\n14383\n62\n90\n1\n2\n18\n\n\n13334\n10\n339\n1\n4\n18\n\n\n14944\n34\n157\n1\n4\n18\n\n\n15516\n14\n420\n1\n4\n13\n\n\n10006\n4\n471\n0\n4\n13\n\n\n\n\n#transform numerical values into the range 0 - 1\ncolumns = df_ordinal_train.columns\n\nscaler = MinMaxScaler()\ndf_ordinal_train = scaler.fit_transform(df_ordinal_train)\ndf_ordinal_test = scaler.transform(df_ordinal_test)\n\ndf_ordinal_train = pd.DataFrame(df_ordinal_train, columns=columns)\ndf_ordinal_test = pd.DataFrame(df_ordinal_test, columns=columns)\ndf_ordinal_train.head()\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\nage\nheight_cm\nweight_kg\noverall\npotential\nwage_eur\ninternational_reputation\nweak_foot\nskill_moves\npace\n...\npower_long_shots\nmentality_aggression\nmentality_interceptions\nmentality_positioning\nmentality_vision\nmentality_penalties\nmentality_composure\ndefending_marking\ndefending_standing_tackle\ndefending_sliding_tackle\n\n\n\n\n0\n0.217391\n0.456522\n0.352941\n0.217391\n0.326087\n0.001773\n0.0\n0.50\n0.0\n0.647887\n...\n0.554217\n0.517647\n0.158537\n0.559524\n0.378049\n0.567901\n0.362319\n0.297619\n0.530864\n0.5250\n\n\n1\n0.217391\n0.804348\n0.568627\n0.260870\n0.413043\n0.000000\n0.0\n0.50\n0.0\n0.422535\n...\n0.060241\n0.658824\n0.646341\n0.154762\n0.195122\n0.320988\n0.188406\n0.571429\n0.654321\n0.6500\n\n\n2\n0.130435\n0.478261\n0.313725\n0.173913\n0.369565\n0.001773\n0.0\n0.50\n0.0\n0.169014\n...\n0.566265\n0.258824\n0.048780\n0.535714\n0.451220\n0.728395\n0.362319\n0.130952\n0.049383\n0.1125\n\n\n3\n0.000000\n0.782609\n0.705882\n0.108696\n0.478261\n0.000000\n0.0\n0.75\n0.0\n0.394366\n...\n0.144578\n0.470588\n0.487805\n0.321429\n0.207317\n0.271605\n0.188406\n0.440476\n0.530864\n0.5125\n\n\n4\n0.130435\n0.782609\n0.607843\n0.347826\n0.565217\n0.000000\n0.0\n0.50\n0.0\n0.577465\n...\n0.313253\n0.717647\n0.573171\n0.202381\n0.158537\n0.320988\n0.420290\n0.595238\n0.716049\n0.6875\n\n\n\n5 rows × 44 columns\n\n#convert categorical values to numpy array\nnp_nat_train = np.array(np_utils.to_categorical(df_nominal_train.nationality))\nnp_club_train = np.array(np_utils.to_categorical(df_nominal_train.club))\nnp_pref_train = np.array(np_utils.to_categorical(df_nominal_train.preferred_foot))\nnp_work_train = np.array(np_utils.to_categorical(df_nominal_train.work_rate))\nnp_team_train = np.array(np_utils.to_categorical(df_nominal_train.team_position))\n\nnp_nat_test = np.array(np_utils.to_categorical(df_nominal_test.nationality))\nnp_club_test = np.array(np_utils.to_categorical(df_nominal_test.club))\nnp_pref_test = np.array(np_utils.to_categorical(df_nominal_test.preferred_foot))\nnp_work_test = np.array(np_utils.to_categorical(df_nominal_test.work_rate))\nnp_team_test = np.array(np_utils.to_categorical(df_nominal_test.team_position))\nprint(np_nat_train[500])\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n\n#merge all data into one big vector (for model performance only numerical values were used,\n#if categorical and numerical columns were used along, the loss would be around 17% )\n#np_nat_train, np_club_train, np_pref_train, np_work_train, np_team_train\ntrain = np.hstack([df_ordinal_train])\ntest = np.hstack([df_ordinal_test])\nsol_train = np.array(df_solutions_train.value_eur)\nsol_test = np.array(df_solutions_test.value_eur)\ntest.shape\n(3206, 44)\n\ntrain.shape\n(12826, 44)\n\nprint(train[0])\n[0.2173913  0.45652174 0.35294118 0.2173913  0.32608696 0.00177305\n 0.         0.5        0.         0.64788732 0.52564103 0.38235294\n 0.45714286 0.36       0.57142857 0.46341463 0.54117647 0.51851852\n 0.49275362 0.56962025 0.51851852 0.25301205 0.38095238 0.45205479\n 0.41666667 0.65277778 0.64788732 0.5942029  0.30769231 0.6056338\n 0.5125     0.52857143 0.67647059 0.54666667 0.55421687 0.51764706\n 0.15853659 0.55952381 0.37804878 0.56790123 0.36231884 0.29761905\n 0.5308642  0.525     ]\n\n#format of the solution dataset \ndf_solutions_train.head()\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\nsofifa_id\nvalue_eur\n\n\n\n\n14383\n233948\n180000\n\n\n13334\n232272\n280000\n\n\n14944\n240105\n140000\n\n\n15516\n248187\n110000\n\n\n10006\n251809\n700000\n\n\n\n\n#create the deep learning model\nfrom keras import optimizers\n\nmodel = Sequential()\nmodel.add(Dense(256, activation=""relu"",input_dim=train.shape[1]))\nmodel.add(Dense(64, activation=""relu""))\nmodel.add(Dense(32, activation=""relu""))\nmodel.add(Dense(1, activation=""linear""))\nmodel.compile(loss=\'mean_absolute_percentage_error\',optimizer=\'adam\')\n\n#train the model\nmodel.fit(train, sol_train, epochs=250, batch_size = 8 )\nEpoch 1/250\n12826/12826 [==============================] - 2s 122us/step - loss: 72.6323\nEpoch 2/250\n12826/12826 [==============================] - 1s 103us/step - loss: 66.5378\nEpoch 3/250\n12826/12826 [==============================] - 1s 104us/step - loss: 64.1988\nEpoch 4/250\n12826/12826 [==============================] - 1s 105us/step - loss: 59.4941\nEpoch 5/250\n12826/12826 [==============================] - 1s 102us/step - loss: 53.2732\n...\nEpoch 10/250\n12826/12826 [==============================] - 2s 146us/step - loss: 33.7721\n...   \n12826/12826 [==============================] - 1s 100us/step - loss: 15.8843\nEpoch 25/250\n...\nEpoch 50/250\n12826/12826 [==============================] - 1s 102us/step - loss: 12.0775\n...\nEpoch 100/250\n12826/12826 [==============================] - 1s 95us/step - loss: 10.0556\n...\nEpoch 250/250\n12826/12826 [==============================] - 1s 103us/step - loss: 9.2848\n\n\n\n\n\n<keras.callbacks.callbacks.History at 0x159561c2588>\n\n#let the model predict the test values\npreds = model.predict(test)  \n#calculate the loss of the test set with the solution set\nabw = []\nfor i in range(len(preds)):\n    abw.append(((sol_test[i] - int(preds[i])) / sol_test[i] * 100 )) \n\nsumm = 0\nfor line in abw:\n    if line < 0:\n        line = line * -1\n    summ = summ + line\n\nprint(summ / len(abw))\n\nprint(max(abw))\nprint(min(abw))\n    \n10.059027271042448\n38.767589743589745\n-173.20374999999999\n\n#plot error distribution of the predictions\nplt.hist(abw)\n(array([3.000e+00, 2.000e+00, 4.000e+00, 1.000e+01, 1.600e+01, 4.300e+01,\n        9.800e+01, 8.340e+02, 2.019e+03, 1.770e+02]),\n array([-173.20375   , -152.00661603, -130.80948205, -109.61234808,\n         -88.4152141 ,  -67.21808013,  -46.02094615,  -24.82381218,\n          -3.62667821,   17.57045577,   38.76758974]),\n <a list of 10 Patch objects>)\n\n\n'], 'url_profile': 'https://github.com/PiePra', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Julia', 'MIT license', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '630 contributions\n        in the last year', 'description': ['Kaggle Titanic Problem with Logistic Regression\nUsing Linear Regression to solve Titanic Problem from Kaggle 👻\n'], 'url_profile': 'https://github.com/gabrielmayers', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Julia', 'MIT license', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '39 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Akashpawashe', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Julia', 'MIT license', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020']}","{'location': 'United Kingdom', 'stats_list': [], 'contributions': '358 contributions\n        in the last year', 'description': ['ML-Regression-Classification\nall the files, projects etc. from Regression or Classification\n'], 'url_profile': 'https://github.com/kacperlsky', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Julia', 'MIT license', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020']}","{'location': 'San Francisco', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['indiegogo\nWeb scraping and linear regression to predict Indiegogo campaign success\n'], 'url_profile': 'https://github.com/ty-adams', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Julia', 'MIT license', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020']}","{'location': 'Canada,London', 'stats_list': [], 'contributions': '48 contributions\n        in the last year', 'description': ['A-B-test-and-logit-regression\nUdacity project of A/B test and logic regression\n'], 'url_profile': 'https://github.com/JianmingDong', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Julia', 'MIT license', 'Updated Jun 4, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '9 contributions\n        in the last year', 'description': ['Econometrics-R-projects\nTime Series Analysis ,Panel Data Analysis, Logit Regression\n'], 'url_profile': 'https://github.com/Amrkuls', 'info_list': ['Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'CC0-1.0 license', 'Updated May 17, 2020', 'Objective-C', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 26, 2020', '1', 'Jupyter Notebook', 'Updated Jun 17, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Istanbul, Turkey', 'stats_list': [], 'contributions': '205 contributions\n        in the last year', 'description': [""Image classification with Logistic Regression from scratch using NumPy\nThis code includes feature extraction, model training, and evaluation steps for image classification with NumPy. Let's see what we will achieve in this notebook in steps:\n\n\nFirst, we wil load and visualize the dataset and extract two different set of features to build a classifier on.\n\n\nWe will run our logistic regression algorithm with gradient descent the representations to classify digits into 1 and 5.\n\n\nWe will experiment with different learning rates to find the best one.\n\n\nFinally, we will evaluate the implemented models, decide which is the best performing one and visualize a decision boundary.\n\n\nOnce again, let's remind ourselves that we won't be using any function or library that accomplishes the task itself. For instance, we won't use scikit-learn to implement cross validation, we will use numpy for that and for all of the other tasks.\n""], 'url_profile': 'https://github.com/leventbass', 'info_list': ['Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'CC0-1.0 license', 'Updated May 17, 2020', 'Objective-C', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 26, 2020', '1', 'Jupyter Notebook', 'Updated Jun 17, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '55 contributions\n        in the last year', 'description': ['Video-Game-Sales\nComparing Linear Regression, Decision tree and and Random Forest\nEA Sports - Noth America sales and Rank Corelation:\n\nTop 10 Publishers in Global Sales from 1995 to 2016\n\nNintendo Sales in 2015 by Genre\n\nDecision Tree for Nintendo Global Sales\n\nLinear Regression for Nintendo Global sales\n\nDecision Tree and Linear Regression Comparison\n\nDecision Tree, Linear Regression and Random Forest Comparison\n\n'], 'url_profile': 'https://github.com/sainathdevulapalli', 'info_list': ['Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'CC0-1.0 license', 'Updated May 17, 2020', 'Objective-C', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 26, 2020', '1', 'Jupyter Notebook', 'Updated Jun 17, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Lotte, Germany', 'stats_list': [], 'contributions': '143 contributions\n        in the last year', 'description': ['Xcode 11.4 Regression LibTool\nWhen building this Lib with Archiving in Xcode there is a regression with libtool.\nError from build log:\n/Applications/Xcode-beta.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool: object: /Users/mariuslandwehr/Library/Developer/Xcode/DerivedData/Networking-bigwxlvidtfvckeysbasqxuzfojq/Build/Intermediates.noindex/ArchiveIntermediates/Networking/BuildProductsPath/Release/CGRPCZlib.o malformed object (string table at offset 0 with a size of 8, overlaps Mach-O headers at offset 0 with a size of 160)\n/Applications/Xcode-beta.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool: object: /Users/mariuslandwehr/Library/Developer/Xcode/DerivedData/Networking-bigwxlvidtfvckeysbasqxuzfojq/Build/Intermediates.noindex/ArchiveIntermediates/Networking/BuildProductsPath/Release/CNIOLinux.o malformed object (string table at offset 0 with a size of 8, overlaps Mach-O headers at offset 0 with a size of 160)\n/Applications/Xcode-beta.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool: object: /Users/mariuslandwehr/Library/Developer/Xcode/DerivedData/Networking-bigwxlvidtfvckeysbasqxuzfojq/Build/Intermediates.noindex/ArchiveIntermediates/Networking/BuildProductsPath/Release/CGRPCZlib.o malformed object (string table at offset 0 with a size of 8, overlaps Mach-O headers at offset 0 with a size of 160)\n/Applications/Xcode-beta.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool: object: /Users/mariuslandwehr/Library/Developer/Xcode/DerivedData/Networking-bigwxlvidtfvckeysbasqxuzfojq/Build/Intermediates.noindex/ArchiveIntermediates/Networking/BuildProductsPath/Release/CNIOLinux.o malformed object (string table at offset 0 with a size of 8, overlaps Mach-O headers at offset 0 with a size of 160)\nCommand Libtool failed with a nonzero exit code\n\nSteps to Reproduce\n\nClone the repository\nOpen the Networking.xcodeproj\nArchive the static library\nBuild Error on linking libNetworking.a\n\nExpected Behaviour\n\nArchive the static library\nBuild Succeeded\n\nAdditional Notes\nThis is also failing on Xcode Beta 11.5 Beta 2\n'], 'url_profile': 'https://github.com/mRs-', 'info_list': ['Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'CC0-1.0 license', 'Updated May 17, 2020', 'Objective-C', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 26, 2020', '1', 'Jupyter Notebook', 'Updated Jun 17, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Kuala Lumpur, Malaysia', 'stats_list': [], 'contributions': '32 contributions\n        in the last year', 'description': [""Linear-Regression\nIIIT-B Linear Regression Assignment\nProblem Statement\nA Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts.\nThey have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\nWhich variables are significant in predicting the price of a car\nHow well those variables describe the price of a car\nBased on various market surveys, the consulting firm has gathered a large dataset of different types of cars across the Americal market.\nBusiness Goal\nYou are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market.\nData Preparation\nThere is a variable named CarName which is comprised of two parts - the first word is the name of 'car company' and the second is the 'car model'. For example, chevrolet impala has 'chevrolet' as the car company name and 'impala' as the car model name. You need to consider only company name as the independent variable for model building.\nModel Evaluation:\nWhen you're done with model building and residual analysis, and have made predictions on the test set, just make sure you use the following two lines of code to calculate the R-squared score on the test set.\nfrom sklearn.metrics import r2_score\nr2_score(y_test, y_pred)\nwhere y_test is the test data set for the target variable, and y_pred is the variable containing the predicted values of the target variable on the test set.\nPlease don't forget to perform this step as the R-squared score on the test set holds some marks. The variable names inside the 'r2_score' function can be different based on the variable names you have chosen.\n""], 'url_profile': 'https://github.com/chandankr7', 'info_list': ['Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'CC0-1.0 license', 'Updated May 17, 2020', 'Objective-C', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 26, 2020', '1', 'Jupyter Notebook', 'Updated Jun 17, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '92 contributions\n        in the last year', 'description': ['Decision-Tree-Regression\nML Decision Tree Regression template I built using Google Colab\n'], 'url_profile': 'https://github.com/Ndu3000', 'info_list': ['Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'CC0-1.0 license', 'Updated May 17, 2020', 'Objective-C', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 26, 2020', '1', 'Jupyter Notebook', 'Updated Jun 17, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '155 contributions\n        in the last year', 'description': ['STOCK PRICE PREDICTION\nA simple stock price predictor using Linear regression model to predict the closing price based on the following data :\n\nopen price\nhigh (+ve peak price)\nlow (-ve peak price)\nvolume (amount of stock sold)\n\nDATASET\n\nTesla Stock Price\n\nREQUIREMENTS\n\nSk learn (pip install sklearn)\nnumpy (pip install numpy)\npickle (pip install pickle-mixin)\npandas (pip install pandas)\n\n'], 'url_profile': 'https://github.com/Kaiserb11', 'info_list': ['Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'CC0-1.0 license', 'Updated May 17, 2020', 'Objective-C', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 26, 2020', '1', 'Jupyter Notebook', 'Updated Jun 17, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Minneapolis, MN', 'stats_list': [], 'contributions': '64 contributions\n        in the last year', 'description': [""Predicting the Stock Market?\nThis project examines the challenge of building machine learning models that can predict the rise and fall of the stock market based on what's in the news. For example, will stock prices rise with more positive\nnews? Are there certain key phrases or words that impact the direction of market values? Are certain analytical approaches better for finding these relationships?\nOur analysis found:\n\nThe stock market is too unpredictable to say that headlines can reliably predict market gains/losses.\nOf the analysis techniques attempted, sentiment analysis came closest to providing signals for future stock market change over time.\nOf the topic modelling approaches used, Latent Dirichlet Allocation (LDA) provided better data for logistic regression analysis than Non-negative Matrix Factorization (NMF)...but both ultimately performed very poorly when attempting to predict stock market change.\nTopic models fitted to fast-changing data like news headlines become outdated quickly, and thus data pipelines should ensure that models are regularly being refitted.\n\nBuilt with\n\npandas\nNLTK\nscikit-learn\ngensim\nmatplotlib\nplotly.js\nJupyter Notebook\n\nA note on workflow\nThis analysis follows a specific workflow:\nsentiment analysis and topic modeling on news headlines -> enhance existing data -> \nrun regression and neural network models using headline topics and sentiments plus \nmarket gains/losses to find relationships\n\nYou'll want to explore the analysis notebooks in this general order:\n\nStock and news headline descriptive analysis\nNLTK (sentiment analysis)\nLDA / NMF (topic modeling)\nLogistic regression / recurrent neural networks\n\nNotebooks containing Golden Cross and SVM analyses were used to help us understand performance benchmarks for market prediction techniques.\nInstallation and use\nDownload the repository\nYou can either download this repository as a zip file, or clone it locally using your favorite command line interface (typically Terminal on Mac or Git Bash on Windows) by running:\ngit clone git@github.com:micahvandersteen/project-3-team-ifrit.git\n\nExploring the data analysis notebooks\n\nInstall the necessary libraries via your CLI. Note: If you are an Anaconda user, you may have most of these libraries pre-installed.\n\npip install pandas\npip install --user -U nltk\npip install jupyterlab\npip install -U scikit-learn\npip install gensim\npython -m pip install -U matplotlib\n\n\nStart a Jupyter Notebook by typing jupyter notebook in your CLI, then navigate to your desired notebook within the Notebooks folder of this repository.\nOpen and run the notebook.\n\nInterpreting the results\nAnalysis results and what they mean are described on the project webpage.\nContributors\n\nAdam Bilski\nAlan Riveros\nBrandon Uhler\nJulia Revier\nKatrina Koenders\nMicah Vandersteen\nStacy Konkiel\n\nCredits\nCopyright for images included on the project webpage belongs to their respective owners.\n""], 'url_profile': 'https://github.com/micahvandersteen', 'info_list': ['Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'CC0-1.0 license', 'Updated May 17, 2020', 'Objective-C', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 26, 2020', '1', 'Jupyter Notebook', 'Updated Jun 17, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['\nIn these labs, you will write functions to implement regression\ncalculations. You will be adding functionality to a package called\nregress431.\nLab 5 Instructions\nLab 6 Instructions\n'], 'url_profile': 'https://github.com/Cal-Poly-Advanced-R', 'info_list': ['Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'CC0-1.0 license', 'Updated May 17, 2020', 'Objective-C', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 26, 2020', '1', 'Jupyter Notebook', 'Updated Jun 17, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['titanic_survival_prediction\nPrediciting the survival of Titanic passengers with logistic regression\n'], 'url_profile': 'https://github.com/jTaiwo', 'info_list': ['Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'CC0-1.0 license', 'Updated May 17, 2020', 'Objective-C', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 26, 2020', '1', 'Jupyter Notebook', 'Updated Jun 17, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '166 contributions\n        in the last year', 'description': ['Polynomial Regression\nIn the real world, it is very common to have data where there is a non-linear relationship between the independent and dependent variables. In these cases, we can use polynomial regression where we assume the relationship between the independent variable x and the dependent variable(s) y is modelled as an nth degree polynomial in x. Here I visualize and interpret such data.\n'], 'url_profile': 'https://github.com/msaif41', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Kolkata, West Bengal', 'stats_list': [], 'contributions': '145 contributions\n        in the last year', 'description': ['News-Category-Classification\nPredicting the category of a news headline using logistic regression with a test accuracy of 95%.\nThe dataset is quite large to be uploaded on github.Visit the link given below to download the dataset.\nhttps://www.kaggle.com/uciml/news-aggregator-dataset/download\nThe categories given are : buisness, science and technology, entertainment, health\n'], 'url_profile': 'https://github.com/aniketmitra2107', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Canada', 'stats_list': [], 'contributions': '35 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/KhalidRajan', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '158 contributions\n        in the last year', 'description': ['German-credit-card-problem\nIn this repository we will see this German credit card problem and try to solve this classification problem using logistic regression\n\nTo run the code follow the below steps:\n1.Install python(3.6+) and need packages.\npip install numpy\n\npip instll pandas\n\npip install matplotlib\n\npip install -U scikit-learn\n\n2.Clone this repository .\nhttps://github.com/karthikeyanthanigai/German-credit-card-problem.git\n\n3.Open command line and set the directory to the cloned repository.\ncd German-credit-card-problem\n\n4.Enter the command.\npython log.py\n\nif you got any error in install the packages then refer Stackoverflow.\n'], 'url_profile': 'https://github.com/karthikeyanthanigai', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '125 contributions\n        in the last year', 'description': ['House-Price-Advance-Regression\nKaggle Competition ""Advance House Prices Regression"" Kaggle Rank top 2%\nSummary:\nSuppose you want to buy a new house, what are the factors that you will consider. My top factors would be the Number of Rooms, Number of Bathrooms, Street Access, whether it has a Garage. But if the house has a each of these features, it would be quite expensive.\nSo eventually the house you buy has to be a balance between the features you want, and the price you are willing to pay. The dataset we have explains the price of 1500 such house with all the features they have, so that you can analyze the features and their effect they have on the price.\nFor a buyer you can estimate the price you should be paying for a property, and for a seller you can estimate a quoting price for a property.\nObjective:\nTo predict house prices based on 79 explanatory variables.\nDataSet:\nThe Ames Housing dataset was compiled by Dean De Cock for use in data science education. It\'s an incredible alternative for data scientists looking for a modernized and expanded version of the often cited Boston Housing dataset.\nProcedure:\n\nData exploration for missing values, outliers\nA thorough data cleaning exercise based on business understanding\nFeature engineer to create intuitive new features\nOne hot encoding to convert categorical features to encoded columns containing zeroes and one\'s\nTraining test split\nTrying basic models- first pass\n37 skewed numerical features to Box Cox transform, to improve accuracy\nTesting a custom stacked regression model, which aggregates the prediction from various models\n\nThe model shows that the features which play an important role in deciding the price of a property\nThe most important features are\n\nThe above ground living area of the property\nThe surface area of the basement\nArea of the entire lot\nSurface area of the first floor\nBasement area\nGarage area\n\n'], 'url_profile': 'https://github.com/alphadatagamma', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '28 contributions\n        in the last year', 'description': ['Linear-Regression-Models\nData Science Report in R Markdown on Linear Regression\n'], 'url_profile': 'https://github.com/mnagired', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '174 contributions\n        in the last year', 'description': ['[Fall 2019] Gaussian Process Regression for eye diagram data, comparing sklearn and pytorch GPR models. Results are summarized here: https://drive.google.com/file/d/13V-SWgtGByc7pOe8EhT3W9hhbgWwzaIU/view?usp=sharing\n'], 'url_profile': 'https://github.com/shresta4', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Cluj-Napoca', 'stats_list': [], 'contributions': '140 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/orsiszocs', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Kottayam', 'stats_list': [], 'contributions': '64 contributions\n        in the last year', 'description': ['MLP\nMLP for regression problem using Keras - Boston House price, MLP applied on Forest Cover Dataset and MLP for multi-class classification problem on Wine dataset\n'], 'url_profile': 'https://github.com/akhilkv98', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Kanpur', 'stats_list': [], 'contributions': '165 contributions\n        in the last year', 'description': ['Linear-Regression\nLinear regression both Single variate as well as multivariate\n'], 'url_profile': 'https://github.com/akshay-gupta123', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '3', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '92 contributions\n        in the last year', 'description': ['Multiple-Linear-Regression\nML Multiple Linear Regression template I built using Google Colab\n'], 'url_profile': 'https://github.com/Ndu3000', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 17, 2020', 'R', 'Updated Jun 17, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 30, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 13, 2020', 'MATLAB', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': ['NBA\nMy Logistic Regression Model for NBA All-Stars\n'], 'url_profile': 'https://github.com/rdatta6', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 17, 2020', 'R', 'Updated Jun 17, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 30, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 13, 2020', 'MATLAB', 'Updated May 13, 2020']}","{'location': 'London, England', 'stats_list': [], 'contributions': '4,607 contributions\n        in the last year', 'description': [""RMS Class Notes 2020\nThis repository contains notes from Frank Harrell's Short Course on Regression Modeling Strategies 2020.\nLinks for Course\n\nRegression Modeling Strategies Text\nRegression Modeling Strategies Notes\nFull Course Syllabus\nCourse Description\n\n""], 'url_profile': 'https://github.com/davidjohnbaker1', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 17, 2020', 'R', 'Updated Jun 17, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 30, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 13, 2020', 'MATLAB', 'Updated May 13, 2020']}","{'location': 'Bangalore-Chennai', 'stats_list': [], 'contributions': '96 contributions\n        in the last year', 'description': ['Linear-Regression-using-TFLite\nUsing Tensorflow Lite training a model to execute linear regression\n'], 'url_profile': 'https://github.com/hemanthh17', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 17, 2020', 'R', 'Updated Jun 17, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 30, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 13, 2020', 'MATLAB', 'Updated May 13, 2020']}","{'location': 'Kolkata', 'stats_list': [], 'contributions': '77 contributions\n        in the last year', 'description': ['Intellify-Random_Forest-\nUsing Random Forest Algorithm for regression and classification.\n'], 'url_profile': 'https://github.com/SayakGiri', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 17, 2020', 'R', 'Updated Jun 17, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 30, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 13, 2020', 'MATLAB', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '92 contributions\n        in the last year', 'description': ['Support-Vector-Regression-SVR-\nML Support Vector Regression template I built using Google Colab\n'], 'url_profile': 'https://github.com/Ndu3000', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 17, 2020', 'R', 'Updated Jun 17, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 30, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 13, 2020', 'MATLAB', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['\nIn these labs, you will write functions to implement regression\ncalculations. You will be adding functionality to a package called\nregress431.\nLab 5 Instructions\nLab 6 Instructions\n'], 'url_profile': 'https://github.com/Cal-Poly-Advanced-R', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 17, 2020', 'R', 'Updated Jun 17, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 30, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 13, 2020', 'MATLAB', 'Updated May 13, 2020']}","{'location': 'Delhi', 'stats_list': [], 'contributions': '212 contributions\n        in the last year', 'description': ['Linear-regression-Implementation\nthis repo contains implementation of linear regression for multivariate features\n'], 'url_profile': 'https://github.com/abhishekshakya', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 17, 2020', 'R', 'Updated Jun 17, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 30, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 13, 2020', 'MATLAB', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/deepakdhull80', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 17, 2020', 'R', 'Updated Jun 17, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 30, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 13, 2020', 'MATLAB', 'Updated May 13, 2020']}","{'location': 'Fortaleza, Brazil', 'stats_list': [], 'contributions': '273 contributions\n        in the last year', 'description': ['Linear Regression\nLinear Regression is a supervised machine learning algorithm used to define a relationship between a dependent variable Y and independent variable X i.e. to make prediction analysis.\nAlgorithm\n1. Load dataset and visualize;\n2. Compute the cost function - mean squared error;\n3. hypothesis h(x) is given by the linear model h(x) := (thetaTranspose * X);\n4. Run Gradient Descent and find the thetas.\n\nVisualize the dataset\n\nVisualize the straight line of the linear regression\n\n'], 'url_profile': 'https://github.com/rubnsbarbosa', 'info_list': ['Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 17, 2020', 'R', 'Updated Jun 17, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 30, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'HTML', 'MIT license', 'Updated May 18, 2020', '1', 'Python', 'Updated May 17, 2020', 'Python', 'Updated May 13, 2020', 'MATLAB', 'Updated May 13, 2020']}"
"{'location': 'USA', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['MachineLearning\nImplements Perceptron Learning, Linear Regression, and vector classifier\n'], 'url_profile': 'https://github.com/pseemaJohn', 'info_list': ['Python', 'Updated May 13, 2020', 'Python', 'GPL-3.0 license', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Sep 23, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '77 contributions\n        in the last year', 'description': ['Salary Predicting Model \nThis is a simple Salary Predicting Model based on Linear Regression and the predicting feature is the amount of experience that the employee has the Model been trained on the Salary given to the past workers.\nVisualizing Model\n\nSalary vs Experience (Training Set)\n\n\n\nSalary vs Experience (Testing Set)\n\n\nThis Model is developed while the learning phase of ML.\n'], 'url_profile': 'https://github.com/mubeenpatel99', 'info_list': ['Python', 'Updated May 13, 2020', 'Python', 'GPL-3.0 license', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Sep 23, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/spectrum128', 'info_list': ['Python', 'Updated May 13, 2020', 'Python', 'GPL-3.0 license', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Sep 23, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': ['House-Prices-Advanced-Regression-Techniques\n'], 'url_profile': 'https://github.com/DarrenCarvalho', 'info_list': ['Python', 'Updated May 13, 2020', 'Python', 'GPL-3.0 license', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Sep 23, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '70 contributions\n        in the last year', 'description': ['HousePricePrediction\nHousePricePrediction using variance inflation factor and build linear regression model.\nPerformed Exploratory Data Analysis and created Visualizations using matplotlib to find insights and built model using linear regression and removed categorical features using  get_dummies\n'], 'url_profile': 'https://github.com/Aishwarya-A96', 'info_list': ['Python', 'Updated May 13, 2020', 'Python', 'GPL-3.0 license', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Sep 23, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'India', 'stats_list': [], 'contributions': '195 contributions\n        in the last year', 'description': ['📈 Linear Regression from Scratch\n\nLinear Regression Implimented with Gradient Descent from Scratch using Numpy in Python\n\n😵 How to\n\n\nMethod 1:\ngit clone https://github.com/priyanshu-bisht/linear_regression.git\nopen linearRegression.py in IDLE or in your favourite IDE\nrun the program\n\n\nMethod 2:\nopen the notebooks\n\n\nMethod 3:\nLinear Regression Notebook: \n\n\nMade with ❤ by Priyanshu Bisht\n'], 'url_profile': 'https://github.com/priyanshu-bisht', 'info_list': ['Python', 'Updated May 13, 2020', 'Python', 'GPL-3.0 license', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Sep 23, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Rochester, NY', 'stats_list': [], 'contributions': '83 contributions\n        in the last year', 'description': ['Multivariate_response_function_Machine_Learning\nMachine_Learning_Ridge_regression\nProject Title\nOne Paragraph of project description goes here\nGetting Started\nThese instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.\nPrerequisites\nWhat things you need to install the software and how to install them\nGive examples\n\nInstalling\nA step by step series of examples that tell you how to get a development env running\nSay what the step will be\nGive the example\n\nAnd repeat\nuntil finished\n\nEnd with an example of getting some data out of the system or using it for a little demo\nRunning the tests\nExplain how to run the automated tests for this system\nBreak down into end to end tests\nExplain what these tests test and why\nGive an example\n\nAnd coding style tests\nExplain what these tests test and why\nGive an example\n\nDeployment\nAdd additional notes about how to deploy this on a live system\nBuilt With\n\nDropwizard - The web framework used\nMaven - Dependency Management\nROME - Used to generate RSS Feeds\n\nContributing\nPlease read CONTRIBUTING.md for details on our code of conduct, and the process for submitting pull requests to us.\nVersioning\nWe use SemVer for versioning. For the versions available, see the tags on this repository.\nAuthors\n\nBillie Thompson - Initial work - PurpleBooth\n\nSee also the list of contributors who participated in this project.\nLicense\nThis project is licensed under the MIT License - see the LICENSE.md file for details\nAcknowledgments\n\nHat tip to anyone whose code was used\nInspiration\netc\n\n'], 'url_profile': 'https://github.com/kevinprinsloo', 'info_list': ['Python', 'Updated May 13, 2020', 'Python', 'GPL-3.0 license', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Sep 23, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '275 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/aakriti1318', 'info_list': ['Python', 'Updated May 13, 2020', 'Python', 'GPL-3.0 license', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Sep 23, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '136 contributions\n        in the last year', 'description': ['stepwise_regression\n'], 'url_profile': 'https://github.com/chris-santiago', 'info_list': ['Python', 'Updated May 13, 2020', 'Python', 'GPL-3.0 license', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Sep 23, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '62 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/techcoreeasy', 'info_list': ['Python', 'Updated May 13, 2020', 'Python', 'GPL-3.0 license', 'Updated May 16, 2020', 'JavaScript', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated Sep 9, 2020', 'Jupyter Notebook', 'Updated Sep 23, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '29 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Camicam311', 'info_list': ['Jupyter Notebook', 'Updated Feb 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Oct 5, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 18, 2020', 'Python', 'Updated May 17, 2020', 'Updated Jul 1, 2020']}","{'location': 'Duluth, GA', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/salochina', 'info_list': ['Jupyter Notebook', 'Updated Feb 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Oct 5, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 18, 2020', 'Python', 'Updated May 17, 2020', 'Updated Jul 1, 2020']}","{'location': 'Mexico', 'stats_list': [], 'contributions': '127 contributions\n        in the last year', 'description': ['Linear-Regression Benchmark\nThis Repository Contains a Benchmark of the Different Linear Regression Algorithms - UAEMex\n'], 'url_profile': 'https://github.com/roman-cmyk', 'info_list': ['Jupyter Notebook', 'Updated Feb 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Oct 5, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 18, 2020', 'Python', 'Updated May 17, 2020', 'Updated Jul 1, 2020']}","{'location': 'Bandung, Indonesia', 'stats_list': [], 'contributions': '47 contributions\n        in the last year', 'description': ['Logistics-Regression\nUnsupervised Learning\n'], 'url_profile': 'https://github.com/davidpratama93121', 'info_list': ['Jupyter Notebook', 'Updated Feb 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Oct 5, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 18, 2020', 'Python', 'Updated May 17, 2020', 'Updated Jul 1, 2020']}","{'location': 'Toronto, ON', 'stats_list': [], 'contributions': '80 contributions\n        in the last year', 'description': ['Regression Modelling\nThis repository contains multiple R markdown files for the purpose of advanced regression modelling on a housing dataset. The goal is predict housing prices as accurately as possible using these techniques.\nFor the purpose of privacy, the dataset has been ommitted, but the variables descriptions have been uploaded.\nIn summary, the housing dataset contains 31 different features and a total of 12,474 observations.\n\n12,474 observations\n31 variables\n\n14 factor variables\n13 integer variables\n4 numeric variables\n\n\n\nThe data will be split in the following manner:\n\ndtrain : containing 10,002 observations\ndtest : containing 2,472 observations\n\n'], 'url_profile': 'https://github.com/ashleymellz', 'info_list': ['Jupyter Notebook', 'Updated Feb 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Oct 5, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 18, 2020', 'Python', 'Updated May 17, 2020', 'Updated Jul 1, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ALlauradoM', 'info_list': ['Jupyter Notebook', 'Updated Feb 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Oct 5, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 18, 2020', 'Python', 'Updated May 17, 2020', 'Updated Jul 1, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/aish-gith', 'info_list': ['Jupyter Notebook', 'Updated Feb 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Oct 5, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 18, 2020', 'Python', 'Updated May 17, 2020', 'Updated Jul 1, 2020']}","{'location': 'Washington, DC', 'stats_list': [], 'contributions': '7 contributions\n        in the last year', 'description': ['Predicting Home Prices\nUsing machine learning to predict home values with Scikit-Learn and Python.\n\n'], 'url_profile': 'https://github.com/michael-wessel', 'info_list': ['Jupyter Notebook', 'Updated Feb 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Oct 5, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 18, 2020', 'Python', 'Updated May 17, 2020', 'Updated Jul 1, 2020']}","{'location': 'Canada', 'stats_list': [], 'contributions': '151 contributions\n        in the last year', 'description': ['Regression-Implementation\nThis repo contains implementations of univariate and multivariate regression in Machine Learning with polynomial and modified relu basis functions along with and without L2 regularization.\nSOWC_combined_simple.csv\n\nDataset for the implementation\n\ndata_utils.py\n\nBase code containing implementations for\n\nloading and cleaning the data\nz-normalizing (standardizing) features\nmodified relu basis function\ncomputing design matrix for polynomial and relu basis functios using data\nestimating weights for learning with and without regularization\nevaluating the regressor\n\n\n\npolynomial_regression.py\n\nUsing base code to perform unregularized multivariate polynomial regressions of degree 1-6\n\npolynomial_regression_1d.py\n\nUsing base code to perform unregularized univariate polynomial regression of degree 3\n\nvisualize_1d.py\n\nTo visualize the learned curve\n\nrelu_regression.py\n\nUsing base code to perform unregularized multivariate relu regression\n\npolynomial_regression_reg.py\n\nUsing base code to perform L2 regularized multivariate polynomial regression of degree 2\nIdentifying the best regularization constant using 10 fold cross-validation implementation\n\nFolders inv and pinv contain visualizations.\nFor execution:\npython3 filename.py\n\n'], 'url_profile': 'https://github.com/sachinnpraburaj', 'info_list': ['Jupyter Notebook', 'Updated Feb 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Oct 5, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 18, 2020', 'Python', 'Updated May 17, 2020', 'Updated Jul 1, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '64 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/dev-aadarsh', 'info_list': ['Jupyter Notebook', 'Updated Feb 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated Oct 5, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 18, 2020', 'Python', 'Updated May 17, 2020', 'Updated Jul 1, 2020']}"
"{'location': 'Vadodara', 'stats_list': [], 'contributions': '124 contributions\n        in the last year', 'description': ['linear_Regression\nusing tensorflow and keras\n'], 'url_profile': 'https://github.com/harshlove9', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020', 'Python', 'Updated May 22, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 16, 2020', '1', 'R', 'Updated Jul 18, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '30 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/OlivierDemeaux', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020', 'Python', 'Updated May 22, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 16, 2020', '1', 'R', 'Updated Jul 18, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '20 contributions\n        in the last year', 'description': ['Moloco  task\nThis task was undertaken as part of the Moloco data scientist application\nQuestion breakdown\nThe first four questions are answered via the google form. The code is in the analysis questions.py script.\nThe regression question is answered through the regression equation and plot which have been uploaded to this repo. The code is in the regression.py script.\nInstalling packages\nThe following packages need to be installed and imported:\n\nimport pandas as pd\nfrom collections import Counter\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n'], 'url_profile': 'https://github.com/rhonadigan', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020', 'Python', 'Updated May 22, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 16, 2020', '1', 'R', 'Updated Jul 18, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7 contributions\n        in the last year', 'description': ['\n  <title>spline_regression</title>\n  <meta charset=""utf-8"">\n  <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">\n  \n  <link rel=""stylesheet"" href=""file:////home/xinyu/.vscode/extensions/shd101wyy.markdown-preview-enhanced-0.5.3/node_modules/@shd101wyy/mume/dependencies/katex/katex.min.css"">\n  \n  \n\n  \n  \n  \n  \n  \n  \n  \n\n  <style>\n  /**\n\n\nprism.js Github theme based on GitHub\'s theme.\n@author Sam Clarke\n/\ncode[class=""language-""],\npre[class*=""language-""] {\ncolor: #333;\nbackground: none;\nfont-family: Consolas, ""Liberation Mono"", Menlo, Courier, monospace;\ntext-align: left;\nwhite-space: pre;\nword-spacing: normal;\nword-break: normal;\nword-wrap: normal;\nline-height: 1.4;\n\n-moz-tab-size: 8;\n-o-tab-size: 8;\ntab-size: 8;\n-webkit-hyphens: none;\n-moz-hyphens: none;\n-ms-hyphens: none;\nhyphens: none;\n}\n/* Code blocks /\npre[class=""language-""] {\npadding: .8em;\noverflow: auto;\n/* border: 1px solid #ddd; /\nborder-radius: 3px;\n/ background: #fff; */\nbackground: #f5f5f5;\n}\n/* Inline code /\n:not(pre) > code[class=""language-""] {\npadding: .1em;\nborder-radius: .3em;\nwhite-space: normal;\nbackground: #f5f5f5;\n}\n.token.comment,\n.token.blockquote {\ncolor: #969896;\n}\n.token.cdata {\ncolor: #183691;\n}\n.token.doctype,\n.token.punctuation,\n.token.variable,\n.token.macro.property {\ncolor: #333;\n}\n.token.operator,\n.token.important,\n.token.keyword,\n.token.rule,\n.token.builtin {\ncolor: #a71d5d;\n}\n.token.string,\n.token.url,\n.token.regex,\n.token.attr-value {\ncolor: #183691;\n}\n.token.property,\n.token.number,\n.token.boolean,\n.token.entity,\n.token.atrule,\n.token.constant,\n.token.symbol,\n.token.command,\n.token.code {\ncolor: #0086b3;\n}\n.token.tag,\n.token.selector,\n.token.prolog {\ncolor: #63a35c;\n}\n.token.function,\n.token.namespace,\n.token.pseudo-element,\n.token.class,\n.token.class-name,\n.token.pseudo-class,\n.token.id,\n.token.url-reference .token.variable,\n.token.attr-name {\ncolor: #795da3;\n}\n.token.entity {\ncursor: help;\n}\n.token.title,\n.token.title .token.punctuation {\nfont-weight: bold;\ncolor: #1d3e81;\n}\n.token.list {\ncolor: #ed6a43;\n}\n.token.inserted {\nbackground-color: #eaffea;\ncolor: #55a532;\n}\n.token.deleted {\nbackground-color: #ffecec;\ncolor: #bd2c00;\n}\n.token.bold {\nfont-weight: bold;\n}\n.token.italic {\nfont-style: italic;\n}\n/* JSON */\n.language-json .token.property {\ncolor: #183691;\n}\n.language-markup .token.tag .token.punctuation {\ncolor: #333;\n}\n/* CSS */\ncode.language-css,\n.language-css .token.function {\ncolor: #0086b3;\n}\n/* YAML */\n.language-yaml .token.atrule {\ncolor: #63a35c;\n}\ncode.language-yaml {\ncolor: #183691;\n}\n/* Ruby */\n.language-ruby .token.function {\ncolor: #333;\n}\n/* Markdown */\n.language-markdown .token.url {\ncolor: #795da3;\n}\n/* Makefile */\n.language-makefile .token.symbol {\ncolor: #795da3;\n}\n.language-makefile .token.variable {\ncolor: #183691;\n}\n.language-makefile .token.builtin {\ncolor: #0086b3;\n}\n/* Bash */\n.language-bash .token.keyword {\ncolor: #0086b3;\n}\n/* highlight */\npre[data-line] {\nposition: relative;\npadding: 1em 0 1em 3em;\n}\npre[data-line] .line-highlight-wrapper {\nposition: absolute;\ntop: 0;\nleft: 0;\nbackground-color: transparent;\ndisplay: block;\nwidth: 100%;\n}\npre[data-line] .line-highlight {\nposition: absolute;\nleft: 0;\nright: 0;\npadding: inherit 0;\nmargin-top: 1em;\nbackground: hsla(24, 20%, 50%,.08);\nbackground: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));\npointer-events: none;\nline-height: inherit;\nwhite-space: pre;\n}\npre[data-line] .line-highlight:before,\npre[data-line] .line-highlight[data-end]:after {\ncontent: attr(data-start);\nposition: absolute;\ntop: .4em;\nleft: .6em;\nmin-width: 1em;\npadding: 0 .5em;\nbackground-color: hsla(24, 20%, 50%,.4);\ncolor: hsl(24, 20%, 95%);\nfont: bold 65%/1.5 sans-serif;\ntext-align: center;\nvertical-align: .3em;\nborder-radius: 999px;\ntext-shadow: none;\nbox-shadow: 0 1px white;\n}\npre[data-line] .line-highlight[data-end]:after {\ncontent: attr(data-end);\ntop: auto;\nbottom: .4em;\n}html body{font-family:""Helvetica Neue"",Helvetica,""Segoe UI"",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,\'Courier New\',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:""\\00a0""}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for=""preview""]) .code-chunk .btn-group{display:none}.markdown-preview:not([for=""preview""]) .code-chunk .status{display:none}.markdown-preview:not([for=""preview""]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for=""html-export""]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=""html-export""]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for=""html-export""]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=""html-export""]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=""html-export""]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for=""html-export""]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=""html-export""]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=""html-export""]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=""html-export""]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=""html-export""]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=""html-export""]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=""html-export""]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for=""html-export""]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=""html-export""]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for=""html-export""]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for=""html-export""]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for=""html-export""]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=""html-export""]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=""html-export""]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=""html-export""]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=""html-export""]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}\n/* Please visit the URL below for more information: /\n/ https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */\n  </style>\n</head>\n<body for=""html-export"">\n  <div class=""mume markdown-preview  "">\n  <h1 class=""mume-header"" id=""math"">Math</h1>\n\n<script type=""text/javascript"" src=""http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default""></script>\nf(x)=ax3+bx2+cx+df′(x)=3ax2+2bx+cf′′(x)=6ax+2b\\begin{aligned}\n    f(x) &= ax^{3} + bx^{2} + cx + d \\\\\n    f^{\'}(x) &= 3ax^{2} + 2bx + c \\\\\n    f^{\'\'}(x) &= 6ax + 2b\n    \\end{aligned}f(x)f′(x)f′′(x)\u200b=ax3+bx2+cx+d=3ax2+2bx+c=6ax+2b\u200b\nFunction i\nfi(x)=aix3+bix2+cix+difi′(x)=3aix2+2bix+cifi′′(x)=6aix+2bi\\begin{aligned}\n    f_{i}(x) &= a_{i}x^{3} + b_{i}x^{2} + c_{i}x + d_{i} \\\\\n    f^{\'}_{i}(x) &= 3a_{i}x^{2} + 2b_{i}x + c_{i} \\\\\n    f^{\'\'}_{i}(x) &= 6a_{i}x + 2b_{i}\n    \\end{aligned}fi\u200b(x)fi′\u200b(x)fi′′\u200b(x)\u200b=ai\u200bx3+bi\u200bx2+ci\u200bx+di\u200b=3ai\u200bx2+2bi\u200bx+ci\u200b=6ai\u200bx+2bi\u200b\u200b\nConstrains\n∀i∈{2…n−1}\\forall i \\in \\{2 \\ldots n-1\\}∀i∈{2…n−1}:\nfi(xi)−fi−1(xi)=0fi′(xi)−fi−1′(xi)=0fi′′(xi)−fi−1′′(xi)=0\\begin{aligned}\n    f_{i}(x_{i}) - f_{i-1}(x_{i}) &= 0 \\\\\n    f^{\'}_{i}(x_{i}) - f^{\'}_{i-1}(x_{i}) &= 0 \\\\\n    f^{\'\'}_{i}(x_{i}) - f^{\'\'}_{i-1}(x_{i}) &= 0\n    \\end{aligned}fi\u200b(xi\u200b)−fi−1\u200b(xi\u200b)fi′\u200b(xi\u200b)−fi−1′\u200b(xi\u200b)fi′′\u200b(xi\u200b)−fi−1′′\u200b(xi\u200b)\u200b=0=0=0\u200b\nadditonally:additonally:additonally:\nf1′′(x1)=0fn−1′′(xn)=0\\begin{aligned}\n    f^{\'\'}_{1}(x_{1}) &= 0 \\\\\n    f^{\'\'}_{n-1}(x_{n}) &= 0\n    \\end{aligned}f1′′\u200b(x1\u200b)fn−1′′\u200b(xn\u200b)\u200b=0=0\u200b\nCost Function\nFi=[fifi′fi′′]TYi=[yiyi′yi′′]TEij=Fi(xj)−Yjgi1=fi(xi)−fi−1(xi)gi2=fi′(xi)−fi−1′(xi)gi3=fi′′(xi)−fi−1′′(xi)gi=[gi1gi2gi3]Tg1=f1′′(x1)gn=fn−1′′(xn)ϕi=[ϕi1ϕi2ϕi3]T\\begin{aligned}\n    F_{i} &= \\begin{bmatrix}f_i & f_i^{\'} & f_i^{\'\'}\\end{bmatrix}^{T} \\\\\n    Y_{i} &= \\begin{bmatrix}y_i & y_i^{\'} & y_i^{\'\'}\\end{bmatrix}^{T} \\\\\n    E_i^j &= F_i(x_j) - Y_j \\\\\n    g_i^1 &= f_{i}(x_{i}) - f_{i-1}(x_{i}) \\\\\n    g_i^2 &= f^{\'}_{i}(x_{i}) - f^{\'}_{i-1}(x_{i}) \\\\\n    g_i^3 &= f^{\'\'}_{i}(x_{i}) - f^{\'\'}_{i-1}(x_{i}) \\\\\n    g_i &= \\begin{bmatrix}g_i^1 & g_i^2 & g_i^3\\end{bmatrix}^{T} \\\\\n    g_1 &=  f_1^{\'\'}(x_1) \\\\\n    g_n &=  f_{n-1}^{\'\'}(x_n) \\\\\n    \\phi_{i} &= \\begin{bmatrix}\\phi_i^1 & \\phi_i^2 & \\phi_i^3\\end{bmatrix}^{T}\n    \\end{aligned}Fi\u200bYi\u200bEij\u200bgi1\u200bgi2\u200bgi3\u200bgi\u200bg1\u200bgn\u200bϕi\u200b\u200b=[fi\u200b\u200bfi′\u200b\u200bfi′′\u200b\u200b]T=[yi\u200b\u200byi′\u200b\u200byi′′\u200b\u200b]T=Fi\u200b(xj\u200b)−Yj\u200b=fi\u200b(xi\u200b)−fi−1\u200b(xi\u200b)=fi′\u200b(xi\u200b)−fi−1′\u200b(xi\u200b)=fi′′\u200b(xi\u200b)−fi−1′′\u200b(xi\u200b)=[gi1\u200b\u200bgi2\u200b\u200bgi3\u200b\u200b]T=f1′′\u200b(x1\u200b)=fn−1′′\u200b(xn\u200b)=[ϕi1\u200b\u200bϕi2\u200b\u200bϕi3\u200b\u200b]T\u200b\nO=∑i=1n−1(EiiTWEii+Eii+1TWEii+1)+∑i=1nϕiTgi\\begin{aligned}\n    O = &\\sum_{i=1}^{n-1}({E_i^i}^TWE_i^i + {E_i^{i+1}}^TWE_i^{i+1}) +\\sum_{i=1}^{n}\\phi_{i}^Tg_i\n    \\end{aligned}O=\u200bi=1∑n−1\u200b(Eii\u200bTWEii\u200b+Eii+1\u200bTWEii+1\u200b)+i=1∑n\u200bϕiT\u200bgi\u200b\u200b\nβi=[aibicidi]TX=[ϕ1Tβ1Tϕ2Tβ2T…ϕn−1Tβn−1TϕnT]T\\begin{aligned}\n    \\beta_i &= \\begin{bmatrix}a_i & b_i & c_i & d_i\\end{bmatrix}^{T} \\\\\n    X &= \\begin{bmatrix}\\phi_1^T & \\beta_1^T & \\phi_2^T & \\beta_2^T &\\ldots & \\phi_{n-1}^T & \\beta_{n-1}^T & \\phi_n^T\\end{bmatrix}^{T}\n    \\end{aligned}βi\u200bX\u200b=[ai\u200b\u200bbi\u200b\u200bci\u200b\u200bdi\u200b\u200b]T=[ϕ1T\u200b\u200bβ1T\u200b\u200bϕ2T\u200b\u200bβ2T\u200b\u200b…\u200bϕn−1T\u200b\u200bβn−1T\u200b\u200bϕnT\u200b\u200b]T\u200b\n∂O∂X=[∂O∂X1…∂O∂Xm]T\\begin{aligned}\n    \\frac{\\partial O}{\\partial X} = \\begin{bmatrix} \\frac{\\partial O}{\\partial X_1} & \\ldots & \\frac{\\partial O}{\\partial X_m} \\end{bmatrix}^{T}\n    \\end{aligned}∂X∂O\u200b=[∂X1\u200b∂O\u200b\u200b…\u200b∂Xm\u200b∂O\u200b\u200b]T\u200b\nH=∂2O∂X2=∂∂X(∂O∂X)=[∂2O∂X12∂2O∂X1∂X2…∂O∂X1∂Xm∂2O∂X2∂X1∂2O∂X22…∂O∂X2∂Xm⋮⋮⋱⋮∂2O∂Xm∂X1∂2O∂Xm∂X2…∂2O∂Xm2]\\begin{aligned}\n    H = \\frac{\\partial^2 O}{\\partial X^2} = \\frac{\\partial }{\\partial X}(\\frac{\\partial O}{\\partial X}) =\n        \\begin{bmatrix}\n            \\frac{\\partial^2 O}{\\partial X_1^2} & \\frac{\\partial^2 O}{\\partial X_1\\partial X_2} & \\ldots & \\frac{\\partial O}{\\partial X_1\\partial X_m} \\\\\n            \\frac{\\partial^2 O}{\\partial X_2\\partial X_1} & \\frac{\\partial^2 O}{\\partial X_2^2} & \\ldots & \\frac{\\partial O}{\\partial X_2\\partial X_m} \\\\\n            \\vdots & \\vdots & \\ddots &\\vdots \\\\\n            \\frac{\\partial^2 O}{\\partial X_m\\partial X_1} & \\frac{\\partial^2 O}{\\partial X_m\\partial X_2} & \\ldots & \\frac{\\partial^2 O}{\\partial X_m^2}\n        \\end{bmatrix}\n    \\end{aligned}H=∂X2∂2O\u200b=∂X∂\u200b(∂X∂O\u200b)=⎣⎢⎢⎢⎢⎢⎢⎡\u200b∂X12\u200b∂2O\u200b∂X2\u200b∂X1\u200b∂2O\u200b⋮∂Xm\u200b∂X1\u200b∂2O\u200b\u200b∂X1\u200b∂X2\u200b∂2O\u200b∂X22\u200b∂2O\u200b⋮∂Xm\u200b∂X2\u200b∂2O\u200b\u200b……⋱…\u200b∂X1\u200b∂Xm\u200b∂O\u200b∂X2\u200b∂Xm\u200b∂O\u200b⋮∂Xm2\u200b∂2O\u200b\u200b⎦⎥⎥⎥⎥⎥⎥⎤\u200b\u200b\nB=−∂O∂X∣X=0B=[B1ϕB1βB2ϕB2β…Bn−1ϕBn−1βBnϕ]TBiϕ=−∂O∂ϕi∣ϕi=0=0Biβ=−∂O∂βi∣βi=0=[2w1(yixi3+yi+1xi+13)+6w2(yi′xi2+yi+1′xi+12)+12w3(yi′′xi+yi+1′′xi+1)2w1(yixi2+yi+1xi+12)+4w2(yi′xi+yi+1′xi+1)+4w3(yi′′+yi+1′′)2w1(yixi+yi+1xi+1)+2w2(yi′+yi+1′)2w1(yi+yi+1)]\\begin{aligned}\n    B &= -\\left.\\frac{\\partial O}{\\partial X}\\right| _{X=0} \\\\\n    B &= \\begin{bmatrix}\n        B_1^{\\phi} & B_1^{\\beta} & B_2^{\\phi} & B_2^{\\beta} & \\ldots & B_{n-1}^{\\phi} & B_{n-1}^{\\beta} & B_n^{\\phi}\n        \\end{bmatrix}^T \\\\\n    B_i^{\\phi} &= -\\left.\\frac{\\partial O}{\\partial \\phi_i}\\right| _{\\phi_i=0} = 0 \\\\\n    B_i^{\\beta} &= -\\left.\\frac{\\partial O}{\\partial \\beta_i}\\right| _{\\beta_i=0} = \\begin{bmatrix}\n        2w_1(y_ix_i^3 + y_{i+1}x_{i+1}^3) + 6w_2(y_i^{\'}x_i^2 + y_{i+1}^{\'}x_{i+1}^2) + 12w_3(y_i^{\'\'}x_i + y_{i+1}^{\'\'}x_{i+1}) \\\\\n        2w_1(y_ix_i^2 + y_{i+1}x_{i+1}^2) + 4w_2(y_i^{\'}x_i + y_{i+1}^{\'}x_{i+1}) + 4w_3(y_i^{\'\'} + y_{i+1}^{\'\'}) \\\\\n        2w_1(y_ix_i + y_{i+1}x_{i+1}) + 2w_2(y_i^{\'} + y_{i+1}^{\'}) \\\\\n        2w_1(y_i + y_{i+1})\n        \\end{bmatrix}\n    \\end{aligned}BBBiϕ\u200bBiβ\u200b\u200b=−∂X∂O\u200b∣∣∣∣∣\u200bX=0\u200b=[B1ϕ\u200b\u200bB1β\u200b\u200bB2ϕ\u200b\u200bB2β\u200b\u200b…\u200bBn−1ϕ\u200b\u200bBn−1β\u200b\u200bBnϕ\u200b\u200b]T=−∂ϕi\u200b∂O\u200b∣∣∣∣∣\u200bϕi\u200b=0\u200b=0=−∂βi\u200b∂O\u200b∣∣∣∣∣\u200bβi\u200b=0\u200b=⎣⎢⎢⎢⎡\u200b2w1\u200b(yi\u200bxi3\u200b+yi+1\u200bxi+13\u200b)+6w2\u200b(yi′\u200bxi2\u200b+yi+1′\u200bxi+12\u200b)+12w3\u200b(yi′′\u200bxi\u200b+yi+1′′\u200bxi+1\u200b)2w1\u200b(yi\u200bxi2\u200b+yi+1\u200bxi+12\u200b)+4w2\u200b(yi′\u200bxi\u200b+yi+1′\u200bxi+1\u200b)+4w3\u200b(yi′′\u200b+yi+1′′\u200b)2w1\u200b(yi\u200bxi\u200b+yi+1\u200bxi+1\u200b)+2w2\u200b(yi′\u200b+yi+1′\u200b)2w1\u200b(yi\u200b+yi+1\u200b)\u200b⎦⎥⎥⎥⎤\u200b\u200b\nHX=BX=H−1B\\begin{aligned}\n    HX = B \\\\\n    X = H^{-1}B\n    \\end{aligned}HX=BX=H−1B\u200b\nForm of H Matrix\nH=[0T1TT1A1−T2−T2T0T2TT2A2−T3−T3T0T3T⋮⋮⋮−Tn−1T0Tn−1TTn−1An−1−Tn−TnT0]\\begin{aligned}\n    H = \\begin{bmatrix}\n            0   & T_1^T                                                                                     \\\\\n            T_1 & A_1       & -T_2                                                                          \\\\\n                & -T_2^T    & 0     & T_2^T                                                                 \\\\\n                &           & T_2   & A_2       & -T_3                                                      \\\\\n                &           &       & -T_3^T    & 0         & T_3^T                                         \\\\\n                &           &       &           & \\vdots    & \\vdots        & \\vdots                        \\\\\n                &           &       &           &           & -T_{n-1}^T    & 0         & T_{n-1}^T         \\\\\n                &           &       &           &           &               & T_{n-1}   & A_{n-1}   & -T_n  \\\\\n                &           &       &           &           &               &           & -T_n^T     & 0\n        \\end{bmatrix} \\\\\n    \\end{aligned}H=⎣⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎡\u200b0T1\u200b\u200bT1T\u200bA1\u200b−T2T\u200b\u200b−T2\u200b0T2\u200b\u200bT2T\u200bA2\u200b−T3T\u200b\u200b−T3\u200b0⋮\u200bT3T\u200b⋮−Tn−1T\u200b\u200b⋮0Tn−1\u200b\u200bTn−1T\u200bAn−1\u200b−TnT\u200b\u200b−Tn\u200b0\u200b⎦⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎤\u200b\u200b\nAi11=2w1(xi6+xi+16)+18w2(xi4+xi+14)+72w3(xi2+xi+12)Ai12=2w1(xi5+xi+15)+12w2(xi3+xi+13)+24w3(xi+xi+1)Ai13=2w1(xi4+xi+14)+6w2(xi2+xi+12)Ai14=2w1(xi3+xi+13)Ai21=2w1(xi5+xi+15)+12w2(xi3+xi+13)+24w3(xi+xi+1)Ai22=2w1(xi4+xi+14)+8w2(xi2+xi+12)+16w3Ai23=2w1(xi3+xi+13)+4w2(xi+xi+1)Ai24=2w1(xi2+xi+12)Ai31=2w1(xi4+xi+14)+6w2(xi2+xi+12)Ai32=2w1(xi3+xi+13)+4w2(xi+xi+1)Ai33=2w1(xi2+xi+12)+4w2Ai34=2w1(xi+xi+1)Ai41=2w1(xi3+xi+13)Ai42=2w1(xi2+xi+12)Ai43=2w1(xi+xi+1)Ai44=4w1Ti=[xi33xi26xixi22xi2xi10100]T1=[6x1200]TTn=[6xn200]T\\begin{aligned}\n    A_i^{11} &= 2w_1(x_i^6+x_{i+1}^6)+18w_2(x_i^4+x_{i+1}^4)+72w_3(x_i^2+x_{i+1}^2) \\\\\n    A_i^{12} &= 2w_1(x_i^5+x_{i+1}^5)+12w_2(x_i^3+x_{i+1}^3)+24w_3(x_i+x_{i+1}) \\\\\n    A_i^{13} &= 2w_1(x_i^4+x_{i+1}^4)+6w_2(x_i^2+x_{i+1}^2) \\\\\n    A_i^{14} &= 2w_1(x_i^3+x_{i+1}^3) \\\\\n    \\\\\n    A_i^{21} &= 2w_1(x_i^5+x_{i+1}^5)+12w_2(x_i^3+x_{i+1}^3)+24w_3(x_i+x_{i+1}) \\\\\n    A_i^{22} &= 2w_1(x_i^4+x_{i+1}^4)+8w_2(x_i^2+x_{i+1}^2)+16w_3 \\\\\n    A_i^{23} &= 2w_1(x_i^3+x_{i+1}^3)+4w_2(x_i+x_{i+1}) \\\\\n    A_i^{24} &= 2w_1(x_i^2+x_{i+1}^2) \\\\\n    \\\\\n    A_i^{31} &= 2w_1(x_i^4+x_{i+1}^4)+6w_2(x_i^2+x_{i+1}^2) \\\\\n    A_i^{32} &= 2w_1(x_i^3+x_{i+1}^3)+4w_2(x_i+x_{i+1}) \\\\\n    A_i^{33} &= 2w_1(x_i^2+x_{i+1}^2)+4w_2 \\\\\n    A_i^{34} &= 2w_1(x_i+x_{i+1}) \\\\\n    \\\\\n    A_i^{41} &= 2w_1(x_i^3+x_{i+1}^3) \\\\\n    A_i^{42} &= 2w_1(x_i^2+x_{i+1}^2) \\\\\n    A_i^{43} &= 2w_1(x_i+x_{i+1}) \\\\\n    A_i^{44} &= 4w_1 \\\\\n    \\\\\n    T_i &= \\begin{bmatrix}\n        x_i^3 & 3x_i^2 & 6x_i \\\\\n        x_i^2 & 2x_i & 2 \\\\\n        x_i & 1 & 0 \\\\\n        1 & 0 & 0\n        \\end{bmatrix} \\\\\n    T_1 &= \\begin{bmatrix}\n        6x_1 & 2 &0 & 0\n        \\end{bmatrix}^T \\\\\n    T_n &= \\begin{bmatrix}\n        6x_n & 2 &0 & 0\n        \\end{bmatrix}^T\n    \\end{aligned}Ai11\u200bAi12\u200bAi13\u200bAi14\u200bAi21\u200bAi22\u200bAi23\u200bAi24\u200bAi31\u200bAi32\u200bAi33\u200bAi34\u200bAi41\u200bAi42\u200bAi43\u200bAi44\u200bTi\u200bT1\u200bTn\u200b\u200b=2w1\u200b(xi6\u200b+xi+16\u200b)+18w2\u200b(xi4\u200b+xi+14\u200b)+72w3\u200b(xi2\u200b+xi+12\u200b)=2w1\u200b(xi5\u200b+xi+15\u200b)+12w2\u200b(xi3\u200b+xi+13\u200b)+24w3\u200b(xi\u200b+xi+1\u200b)=2w1\u200b(xi4\u200b+xi+14\u200b)+6w2\u200b(xi2\u200b+xi+12\u200b)=2w1\u200b(xi3\u200b+xi+13\u200b)=2w1\u200b(xi5\u200b+xi+15\u200b)+12w2\u200b(xi3\u200b+xi+13\u200b)+24w3\u200b(xi\u200b+xi+1\u200b)=2w1\u200b(xi4\u200b+xi+14\u200b)+8w2\u200b(xi2\u200b+xi+12\u200b)+16w3\u200b=2w1\u200b(xi3\u200b+xi+13\u200b)+4w2\u200b(xi\u200b+xi+1\u200b)=2w1\u200b(xi2\u200b+xi+12\u200b)=2w1\u200b(xi4\u200b+xi+14\u200b)+6w2\u200b(xi2\u200b+xi+12\u200b)=2w1\u200b(xi3\u200b+xi+13\u200b)+4w2\u200b(xi\u200b+xi+1\u200b)=2w1\u200b(xi2\u200b+xi+12\u200b)+4w2\u200b=2w1\u200b(xi\u200b+xi+1\u200b)=2w1\u200b(xi3\u200b+xi+13\u200b)=2w1\u200b(xi2\u200b+xi+12\u200b)=2w1\u200b(xi\u200b+xi+1\u200b)=4w1\u200b=⎣⎢⎢⎢⎡\u200bxi3\u200bxi2\u200bxi\u200b1\u200b3xi2\u200b2xi\u200b10\u200b6xi\u200b200\u200b⎦⎥⎥⎥⎤\u200b=[6x1\u200b\u200b2\u200b0\u200b0\u200b]T=[6xn\u200b\u200b2\u200b0\u200b0\u200b]T\u200b\n  </div>\n  \n  \n\n\n\n\n\n\n\n\n\n</body></html>\n\n'], 'url_profile': 'https://github.com/PeiyaoL', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020', 'Python', 'Updated May 22, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 16, 2020', '1', 'R', 'Updated Jul 18, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'China-Shanghai', 'stats_list': [], 'contributions': '41 contributions\n        in the last year', 'description': ['Linear-Regression-\nThis is a simple representaion of linear regression for predicting the house price in Boston!\n\nDependencies:\nBefor you run this code,you must install these packages:\ntensorflow-gpu==1.10.0 \\n\nnumpy==1.14.5 \\n\nsix==1.11.0 \\n\nmatplotlib==3.0.3 \\n\n\nHow to run\nFirst,git clone the code:\n$ git clone git@github.com/xunhui-huang/Linear-Regression-.git yourdir  --SSH协议\n$ git clone git://github.com/xunhui-huang/Linear-Regression-.git yourdir --GIT协议\n$ git clone https://github.com/xunhui-huang/Linear-Regression-.git yourdir --HTTPS协议\nSecond,you just need to run the following command in the terminal:\n% python3 linear_regression.py\n\n'], 'url_profile': 'https://github.com/xunhui-huang', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020', 'Python', 'Updated May 22, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 16, 2020', '1', 'R', 'Updated Jul 18, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '20 contributions\n        in the last year', 'description': ['Logistic-Regression\n'], 'url_profile': 'https://github.com/Gaddam-Vyshnavi', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020', 'Python', 'Updated May 22, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 16, 2020', '1', 'R', 'Updated Jul 18, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '32 contributions\n        in the last year', 'description': ['Logistic-Regression\nThe following code contain Logistic-Regression Implementation Using Python to Classify the Image is of Cat or Not.\n'], 'url_profile': 'https://github.com/spider2510', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020', 'Python', 'Updated May 22, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 16, 2020', '1', 'R', 'Updated Jul 18, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'Los Angeles, CA', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': [""Building a Linear Regression Model to Predict a Song's Valence\nThis project is a re-creation of the final project done in my Linear Regression class during the Spring 2020 semester. A detailed report with all the methods used, graphs, and visualizations can be found here. Otherwise, this README will serve as a TLDR of the report.\nThe goal of this project is to build a linear regression to predict a song's valence from its audio features with the knowledge from my Linear Regression class, and determine if audio features are enough to determine a song's valence. Spoiler alert--it's not. The songs and their audio features are from Spotify and were obtained using Spotify's API, Spotipy. The songs are from six playlists from Spotify's Mood genre.\nProcess and Methods\n\nBest subsets regression with adjusted R2 for selecting predictor variables, which were determined to be danceability, energy, duration of the song, and acousticness\nSeries of partial F-tests to determine significance of the predictor variables\nStudentized deleted residuals to determine outliers, which there were none\nDetermining highly leverage points and determining any highly influential points, which there were none\nBox-Cox plot for transformations to satisfy linearity, equal Variance, and normality conditions\nShapiro-Wilk test to ascertain normality condition is met\n\nWas the model a good model?\nThe model obtained has an adjusted R2 value of 0.3245, so, about 32.45% of the variance found in the response variable, valence, is explained by the predictors danceability, energy, duration of the song, and acousticness. Based on the adjusted R2 alone, we can tell that the model is not a good model to make a prediction about a song’s valence. Thus, audio features alone does not create a good linear regression model to predict a song’s valence.\n""], 'url_profile': 'https://github.com/spsea92', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020', 'Python', 'Updated May 22, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 16, 2020', '1', 'R', 'Updated Jul 18, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '54 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/TD91988', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020', 'Python', 'Updated May 22, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 16, 2020', '1', 'R', 'Updated Jul 18, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'Bangalore, India ', 'stats_list': [], 'contributions': '50 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ShilpaGopal', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Updated May 14, 2020', 'Python', 'Updated May 22, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 16, 2020', '1', 'R', 'Updated Jul 18, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['LINEAR-REGRESSION\nlinear regression is a predictive model used to find the linear Relation between the DV and Many IDV   , It works on the principle of Stright line Equation :Y=mx+c   ,The Linear relation ship between the two Variable is always a stright line.\n'], 'url_profile': 'https://github.com/Yogi5693', 'info_list': ['Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '45 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/AnnieJohnson273', 'info_list': ['Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/vanshika1501', 'info_list': ['Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '60 contributions\n        in the last year', 'description': ['VisualRegression\n\nDescription : This code is built on backstop js and puppeteer engine. It can compare two urls visuals pixel by pixel.\n\nSteps to use the code:\nStep-1 : Download the code.\nStep-2: Create reference url visuals first by below command\n\tbackstop reference --config=backstop-settings.js --pathfile=readcsv.js\n\nStep-3: Create test url visuals and comparision by below command\n\tbackstop test --config=backstop-settings.js --pathfile=readcsv.js\n\nAfter the test the framework will automatically open the browser and show the difference.\n\nPortability modification:\n\nThe view port can be adjusted. The settings are present in backstop-settings.js.\n\n""viewports"": [\n{\n""label"": ""desktop"",\n""width"": 1024,\n""height"": 768\n}\n],\n\n'], 'url_profile': 'https://github.com/prabhudatta22', 'info_list': ['Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020']}","{'location': 'melbourne', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['ml---regression\nmultiple linear reg model\nsimple linear regression is relation bet dependent and independent variable\n'], 'url_profile': 'https://github.com/john-cena-orton', 'info_list': ['Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020']}","{'location': 'Arequipa', 'stats_list': [], 'contributions': '67 contributions\n        in the last year', 'description': ['Logistic-Regression\n'], 'url_profile': 'https://github.com/dantecarlo', 'info_list': ['Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '84 contributions\n        in the last year', 'description': ['Regression-analysis\n'], 'url_profile': 'https://github.com/EPRADDH', 'info_list': ['Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020']}","{'location': 'Ireland', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/sayyedyousuf', 'info_list': ['Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Ameerak124', 'info_list': ['Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '53 contributions\n        in the last year', 'description': ['LOGISTIC_REGRESSION\nTASK :\n\nCreating random data manually\nUse the random data created to train and develop an algorithm to come up with a line that separates the data into discrete classes with minimal error\n\nModel1:Logistic Regression demo work.ipynb\nManually Implementing Sigmoid,Cross Entropy,Gradient Descent\nModel2:Logistic Regrssion using Keras-Perceptron-Single Layer Network\nImplementing the model using Keras\n'], 'url_profile': 'https://github.com/ashissahu', 'info_list': ['Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['Linear-Regression\n'], 'url_profile': 'https://github.com/Sailendri', 'info_list': ['Updated Sep 18, 2020', 'Updated May 28, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'Updated Nov 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['LinearRegression\n'], 'url_profile': 'https://github.com/thinkxacademy', 'info_list': ['Updated Sep 18, 2020', 'Updated May 28, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'Updated Nov 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '60 contributions\n        in the last year', 'description': ['VisualRegression\n\nDescription : This code is built on backstop js and puppeteer engine. It can compare two urls visuals pixel by pixel.\n\nSteps to use the code:\nStep-1 : Download the code.\nStep-2: Create reference url visuals first by below command\n\tbackstop reference --config=backstop-settings.js --pathfile=readcsv.js\n\nStep-3: Create test url visuals and comparision by below command\n\tbackstop test --config=backstop-settings.js --pathfile=readcsv.js\n\nAfter the test the framework will automatically open the browser and show the difference.\n\nPortability modification:\n\nThe view port can be adjusted. The settings are present in backstop-settings.js.\n\n""viewports"": [\n{\n""label"": ""desktop"",\n""width"": 1024,\n""height"": 768\n}\n],\n\n'], 'url_profile': 'https://github.com/prabhudatta22', 'info_list': ['Updated Sep 18, 2020', 'Updated May 28, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'Updated Nov 29, 2020']}","{'location': 'melbourne', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['ml---regression\nmultiple linear reg model\nsimple linear regression is relation bet dependent and independent variable\n'], 'url_profile': 'https://github.com/john-cena-orton', 'info_list': ['Updated Sep 18, 2020', 'Updated May 28, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'Updated Nov 29, 2020']}","{'location': 'Arequipa', 'stats_list': [], 'contributions': '67 contributions\n        in the last year', 'description': ['Logistic-Regression\n'], 'url_profile': 'https://github.com/dantecarlo', 'info_list': ['Updated Sep 18, 2020', 'Updated May 28, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'Updated Nov 29, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '84 contributions\n        in the last year', 'description': ['Regression-analysis\n'], 'url_profile': 'https://github.com/EPRADDH', 'info_list': ['Updated Sep 18, 2020', 'Updated May 28, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'Updated Nov 29, 2020']}","{'location': 'Ireland', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/sayyedyousuf', 'info_list': ['Updated Sep 18, 2020', 'Updated May 28, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'Updated Nov 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Ameerak124', 'info_list': ['Updated Sep 18, 2020', 'Updated May 28, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'Updated Nov 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '53 contributions\n        in the last year', 'description': ['LOGISTIC_REGRESSION\nTASK :\n\nCreating random data manually\nUse the random data created to train and develop an algorithm to come up with a line that separates the data into discrete classes with minimal error\n\nModel1:Logistic Regression demo work.ipynb\nManually Implementing Sigmoid,Cross Entropy,Gradient Descent\nModel2:Logistic Regrssion using Keras-Perceptron-Single Layer Network\nImplementing the model using Keras\n'], 'url_profile': 'https://github.com/ashissahu', 'info_list': ['Updated Sep 18, 2020', 'Updated May 28, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'Updated Nov 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '20 contributions\n        in the last year', 'description': ['Logistinės regresijos modelis\nŠioje repositorijoje pateiktas logistinės regresijos modelis, nustatantis tikimybę susirgti diabetu.\nRepositorijos failai:\n\ndarbo aprašas;\nprograminis kodas, rašytas R kalba;\nduomenų analizei naudotas diabetes2.csv duomenų rinkinys.\n\n'], 'url_profile': 'https://github.com/AgneG25', 'info_list': ['Updated Sep 18, 2020', 'Updated May 28, 2020', 'JavaScript', 'Updated May 17, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'GPL-3.0 license', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'R', 'Updated Nov 29, 2020']}"
"{'location': 'Visakhapatnam', 'stats_list': [], 'contributions': '40 contributions\n        in the last year', 'description': ['Linear-Regression\nIn this repo, I have performed Linear Regression in two ways, i.e.,\n\nLinear Regression using numpy and pandas\nLinear Regression using Tensorflow\n\n'], 'url_profile': 'https://github.com/ManasaMaganti', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'india', 'stats_list': [], 'contributions': '287 contributions\n        in the last year', 'description': ['linear-regression\nIn this notebooks, we learn how to use scikit-learn to implement simple linear regression,multiple linear regression and polynomial regression on the co2 emission dataset.\n'], 'url_profile': 'https://github.com/mayanksharma019', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '344 contributions\n        in the last year', 'description': ['Linear-Regression\nA linear regression model created in Python that predicts profit obtained for a food truck per population in different cities.\n'], 'url_profile': 'https://github.com/NSTiwari', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Hidalgo, México', 'stats_list': [], 'contributions': '88 contributions\n        in the last year', 'description': [""Regression  Project\nThis project aims to predict hotttnesss of a song. It  is a decimal score, between zero and one, based on The Echo Nest data from 2010. It is limited by the subset provided by millionsongdataset. By simplicity, it was only considered the songs attributes of all the information. The major groups are metadata, analysis, and musicbrainz\nTable of contents\n\nTable of contents\nInstallation\nDataset description\n\nAnalysis Group\nMetadata Group\nMusicbrainz Group\n\n\nLinear regression\n\nModel\nCost Function\nResults\n\nResult Group 0\nResult Group 1\nResult Group 2\n\n\n\n\nReferences\nExtra\n\nUseful commands\nImplementation process\n\n\n\nInstallation\nSetup your project folders and files\nchmod +x install.sh\n./install.sh\n⬆️ Return\nDataset description\nDataset of 10k songs, random by MSD. It has three groups: metadata, analysis, musicbrainz\nMetadata Group\nMetadata group with 20 attributes\ndtype([\n    ('analyzer_version', 'S32'),        #0\n    ('artist_7digitalid', '<i4'),       #1\n    ('artist_familiarity', '<f8'),      #2 - Yes\n    ('artist_hotttnesss', '<f8'),       #3 - Yes\n    ('artist_id', 'S32'),               #4\n    ('artist_latitude', '<f8'),         #5\n    ('artist_location', 'S1024'),       #6\n    ('artist_longitude', '<f8'),        #7\n    ('artist_mbid', 'S40'),             #8\n    ('artist_name', 'S1024'),           #9\n    ('artist_playmeid', '<i4'),         #10\n    ('genre', 'S1024'),                 #11 - Maybe\n    ('idx_artist_terms', '<i4'),        #12\n    ('idx_similar_artists', '<i4'),     #13\n    ('release', 'S1024'),               #14\n    ('release_7digitalid', '<i4'),      #15\n    ('song_hotttnesss', '<f8'),         #16 - Target - Can be a NaN | Filter\n    ('song_id', 'S32'),                 #17\n    ('title', 'S1024'),                 #18\n    ('track_7digitalid', '<i4')         #19\n])\n⬆️ Return\nAnalysis Group\nAnalysis group with 31 attributes\ndtype([\n    ('analysis_sample_rate', '<i4'),            #0\n    ('audio_md5', 'S32'),                       #1\n    ('danceability', '<f8'),                    #2 - X Empty [0, 1]\n    ('duration', '<f8'),                        #3 - Yes\n    ('end_of_fade_in', '<f8'),                  #4 - Yes\n    ('energy', '<f8'),                          #5 - X Empty [0, 1]\n    ('idx_bars_confidence', '<i4'),             #6 - X Empty\n    ('idx_bars_start', '<i4'),                  #7 - X Empty\n    ('idx_beats_confidence', '<i4'),            #8 - X Empty\n    ('idx_beats_start', '<i4'),                 #9 - X Empty\n    ('idx_sections_confidence', '<i4'),         #10 - X Empty\n    ('idx_sections_start', '<i4'),              #11 - X Empty\n    ('idx_segments_confidence', '<i4'),         #12 - X Empty\n    ('idx_segments_loudness_max', '<i4'),       #13 - X Empty\n    ('idx_segments_loudness_max_time', '<i4'),  #14 - X Empty\n    ('idx_segments_loudness_start', '<i4'),     #15 - X Empty\n    ('idx_segments_pitches', '<i4'),            #16 - X Empty\n    ('idx_segments_start', '<i4'),              #17 - X Empty\n    ('idx_segments_timbre', '<i4'),             #18 - X Empty\n    ('idx_tatums_confidence', '<i4'),           #19 - X Empty\n    ('idx_tatums_start', '<i4'),                #20 - X Empty\n    ('key', '<i4'),                             #21\n    ('key_confidence', '<f8'),                  #22\n    ('loudness', '<f8'),                        #23\n    ('mode', '<i4'),                            #24\n    ('mode_confidence', '<f8'),                 #25\n    ('start_of_fade_out', '<f8'),               #26\n    ('tempo', '<f8'),                           #27\n    ('time_signature', '<i4'),                  #28\n    ('time_signature_confidence', '<f8'),       #29\n    ('track_id', 'S32')                         #30\n])\n⬆️ Return\nMusicbrainz Group\ndtype([\n    ('idx_artist_mbtags', '<i4'),   #0\n    ('year', '<i4')                 #1\n])\nSome values are undefined, before the training part, there was a validation process to verify non-nullable or missing values. The 10k records downloaded from MSD, are not provided with danceability and energy. In consequence, the model will be missing important attributes.\n⬆️ Return\nLinear regression\nThe model implemented is linear regression. A numeric score should be the result of the model, therefore it is a regression problem. It is limited to attributes that could not be related to the real calc of the measure.\nModel\n\nCost Function\n\nIt will help us to measure the behavior of the model, in other words, what is the loss. As in an article mentioned in the references, the loss(not the same as cost) function describes the form of the error, and the descent will be the downside process. For gradient descent, the loss function should be derivable.\n\nThe chosen cost function to measure our model is RMSE. It is because a linear relation of units will facilitate the analysis, outliers could affect it. Important this function is only for analysis purposes and not for improving the model.\n\n\nThe cost function to train the model\n\nThe purpose is minimize the error between the prediction, so the model needs to move down towards the function. For that, it can be derivated, this value means how much our descent should move, it will be also affected by the learning rate.\n\nIt will be removed to the previous param value\n\n⬆️ Return\nResults\nResult Group 0\nUsing 14 attributes(including bias), with a learning rate of 10, it diverges. Parameters oscillate between positive and negative values, but they can not converge\n\nWe can get better results with a lower learning rate of 0.01\n\n⬆️ Return\nResult Group 1\nWith 5000 epochs, looking for less than 0.01 with a learning rate of 0.1; Train size 2950, Test size 1264\n\n\n\n# Final Parameters\nBias = 4.5689969077910070e-01\naudio_md5 = 5.4573519380770839e-03\nyear = 3.4212693288237568e-02\nloudness = 1.3203266354525294e-02\nmode = -4.3669295455111487e-03\ntempo = 2.6598180921980005e-03\ntime_signature = 4.1232899012358566e-04\nartist_familiarity = 4.6258212788267319e-02\nartist_hotttnesss = 3.4633849986531004e-02\nAfter applying the model with output parameters\nSamples from 562 to 572\n    hyp 0.26586104921065007 y 0.401203522922599\n    hyp 0.4137398358601097 y 0.5684640847172688\n    hyp 0.2416552517044926 y 0.6336199597135092\n    hyp 0.3552855364230894 y 0.435398565057618\n    hyp 0.52549711888017 y 0.43113513759439415\n    hyp 0.6582414367557253 y 0.5033091661911661\n    hyp 0.4176416475968032 y 0.4514920652295682\n    hyp 0.541551997892655 y 0.39091498285641035\n    hyp 0.46384907791765656 y 0.404715590122965\n    hyp 0.5616924111789523 y 0.5144792508848043\n\nThe previous results demonstrate that the variance is significant, but it still keeps in the expected range\nResult Group 2\nThe previous model was tested with multiple epoch values, but the result with higher values does not have a relevant improvement. A fixed learning rate gives a problem if it is bigger than 2. To improve it, a dynamic learning rate can be implemented.\n⬆️ Return\nReferences\n\nhttps://github.com/mdeff/fma\nhttp://millionsongdataset.com/musixmatch/\nhttp://millionsongdataset.com/pages/field-list/\nhttps://medium.com/atchai/in-search-of-the-perfect-music-dataset-ed7e111d3b7e\nhttps://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0\nhttps://towardsdatascience.com/difference-between-batch-gradient-descent-and-stochastic-gradient-descent-1187f1291aa1\nhttps://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a\nhttps://www.dataquest.io/blog/understanding-regression-error-metrics/\n\nThierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, and Paul Lamere.\nThe Million Song Dataset. In Proceedings of the 12th International Society\nfor Music Information Retrieval Conference (ISMIR 2011), 2011.\n⬆️ Return\nExtra\nUseful commands\n#/mnt/d/tmp_ml/msd/MillionSongSubset/data\nfind . -type f -name \\*.h5 -exec cp \\{\\} /mnt/d/tmp_ml/msd/MillionSongSubset/tracks/ \\;\n\n# find . -type f -name \\*.txt -exec cp \\{\\} /home/jupyter/xseed-test/data/domains \\;\n# ls | xargs -I{ cat { > /home/jupyter/xseed-test/data/domains.txt\n⬆️ Return\nImplementation process\n\nLook for music datasets\nUnderstand datasets\nDefine the scope for regression algorithm\nImplement model\nWrite documentation\n\n⬆️ Return\n""], 'url_profile': 'https://github.com/soyantonio', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '161 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/bensmus', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '80 contributions\n        in the last year', 'description': ['Regularized_Regression\n'], 'url_profile': 'https://github.com/divyanamani', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '198 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/kukareja-simran', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '8 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/pradeepseo', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Boston', 'stats_list': [], 'contributions': '27 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/badarinadhv', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Chennai', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['Logistic-Regression\n'], 'url_profile': 'https://github.com/mpandimeena', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}"
"{'location': 'india', 'stats_list': [], 'contributions': '287 contributions\n        in the last year', 'description': ['linear-regression\nIn this notebooks, we learn how to use scikit-learn to implement simple linear regression,multiple linear regression and polynomial regression on the co2 emission dataset.\n'], 'url_profile': 'https://github.com/mayanksharma019', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'R', 'Updated Nov 29, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Jun 6, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '344 contributions\n        in the last year', 'description': ['Linear-Regression\nA linear regression model created in Python that predicts profit obtained for a food truck per population in different cities.\n'], 'url_profile': 'https://github.com/NSTiwari', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'R', 'Updated Nov 29, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Jun 6, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'Hidalgo, México', 'stats_list': [], 'contributions': '88 contributions\n        in the last year', 'description': [""Regression  Project\nThis project aims to predict hotttnesss of a song. It  is a decimal score, between zero and one, based on The Echo Nest data from 2010. It is limited by the subset provided by millionsongdataset. By simplicity, it was only considered the songs attributes of all the information. The major groups are metadata, analysis, and musicbrainz\nTable of contents\n\nTable of contents\nInstallation\nDataset description\n\nAnalysis Group\nMetadata Group\nMusicbrainz Group\n\n\nLinear regression\n\nModel\nCost Function\nResults\n\nResult Group 0\nResult Group 1\nResult Group 2\n\n\n\n\nReferences\nExtra\n\nUseful commands\nImplementation process\n\n\n\nInstallation\nSetup your project folders and files\nchmod +x install.sh\n./install.sh\n⬆️ Return\nDataset description\nDataset of 10k songs, random by MSD. It has three groups: metadata, analysis, musicbrainz\nMetadata Group\nMetadata group with 20 attributes\ndtype([\n    ('analyzer_version', 'S32'),        #0\n    ('artist_7digitalid', '<i4'),       #1\n    ('artist_familiarity', '<f8'),      #2 - Yes\n    ('artist_hotttnesss', '<f8'),       #3 - Yes\n    ('artist_id', 'S32'),               #4\n    ('artist_latitude', '<f8'),         #5\n    ('artist_location', 'S1024'),       #6\n    ('artist_longitude', '<f8'),        #7\n    ('artist_mbid', 'S40'),             #8\n    ('artist_name', 'S1024'),           #9\n    ('artist_playmeid', '<i4'),         #10\n    ('genre', 'S1024'),                 #11 - Maybe\n    ('idx_artist_terms', '<i4'),        #12\n    ('idx_similar_artists', '<i4'),     #13\n    ('release', 'S1024'),               #14\n    ('release_7digitalid', '<i4'),      #15\n    ('song_hotttnesss', '<f8'),         #16 - Target - Can be a NaN | Filter\n    ('song_id', 'S32'),                 #17\n    ('title', 'S1024'),                 #18\n    ('track_7digitalid', '<i4')         #19\n])\n⬆️ Return\nAnalysis Group\nAnalysis group with 31 attributes\ndtype([\n    ('analysis_sample_rate', '<i4'),            #0\n    ('audio_md5', 'S32'),                       #1\n    ('danceability', '<f8'),                    #2 - X Empty [0, 1]\n    ('duration', '<f8'),                        #3 - Yes\n    ('end_of_fade_in', '<f8'),                  #4 - Yes\n    ('energy', '<f8'),                          #5 - X Empty [0, 1]\n    ('idx_bars_confidence', '<i4'),             #6 - X Empty\n    ('idx_bars_start', '<i4'),                  #7 - X Empty\n    ('idx_beats_confidence', '<i4'),            #8 - X Empty\n    ('idx_beats_start', '<i4'),                 #9 - X Empty\n    ('idx_sections_confidence', '<i4'),         #10 - X Empty\n    ('idx_sections_start', '<i4'),              #11 - X Empty\n    ('idx_segments_confidence', '<i4'),         #12 - X Empty\n    ('idx_segments_loudness_max', '<i4'),       #13 - X Empty\n    ('idx_segments_loudness_max_time', '<i4'),  #14 - X Empty\n    ('idx_segments_loudness_start', '<i4'),     #15 - X Empty\n    ('idx_segments_pitches', '<i4'),            #16 - X Empty\n    ('idx_segments_start', '<i4'),              #17 - X Empty\n    ('idx_segments_timbre', '<i4'),             #18 - X Empty\n    ('idx_tatums_confidence', '<i4'),           #19 - X Empty\n    ('idx_tatums_start', '<i4'),                #20 - X Empty\n    ('key', '<i4'),                             #21\n    ('key_confidence', '<f8'),                  #22\n    ('loudness', '<f8'),                        #23\n    ('mode', '<i4'),                            #24\n    ('mode_confidence', '<f8'),                 #25\n    ('start_of_fade_out', '<f8'),               #26\n    ('tempo', '<f8'),                           #27\n    ('time_signature', '<i4'),                  #28\n    ('time_signature_confidence', '<f8'),       #29\n    ('track_id', 'S32')                         #30\n])\n⬆️ Return\nMusicbrainz Group\ndtype([\n    ('idx_artist_mbtags', '<i4'),   #0\n    ('year', '<i4')                 #1\n])\nSome values are undefined, before the training part, there was a validation process to verify non-nullable or missing values. The 10k records downloaded from MSD, are not provided with danceability and energy. In consequence, the model will be missing important attributes.\n⬆️ Return\nLinear regression\nThe model implemented is linear regression. A numeric score should be the result of the model, therefore it is a regression problem. It is limited to attributes that could not be related to the real calc of the measure.\nModel\n\nCost Function\n\nIt will help us to measure the behavior of the model, in other words, what is the loss. As in an article mentioned in the references, the loss(not the same as cost) function describes the form of the error, and the descent will be the downside process. For gradient descent, the loss function should be derivable.\n\nThe chosen cost function to measure our model is RMSE. It is because a linear relation of units will facilitate the analysis, outliers could affect it. Important this function is only for analysis purposes and not for improving the model.\n\n\nThe cost function to train the model\n\nThe purpose is minimize the error between the prediction, so the model needs to move down towards the function. For that, it can be derivated, this value means how much our descent should move, it will be also affected by the learning rate.\n\nIt will be removed to the previous param value\n\n⬆️ Return\nResults\nResult Group 0\nUsing 14 attributes(including bias), with a learning rate of 10, it diverges. Parameters oscillate between positive and negative values, but they can not converge\n\nWe can get better results with a lower learning rate of 0.01\n\n⬆️ Return\nResult Group 1\nWith 5000 epochs, looking for less than 0.01 with a learning rate of 0.1; Train size 2950, Test size 1264\n\n\n\n# Final Parameters\nBias = 4.5689969077910070e-01\naudio_md5 = 5.4573519380770839e-03\nyear = 3.4212693288237568e-02\nloudness = 1.3203266354525294e-02\nmode = -4.3669295455111487e-03\ntempo = 2.6598180921980005e-03\ntime_signature = 4.1232899012358566e-04\nartist_familiarity = 4.6258212788267319e-02\nartist_hotttnesss = 3.4633849986531004e-02\nAfter applying the model with output parameters\nSamples from 562 to 572\n    hyp 0.26586104921065007 y 0.401203522922599\n    hyp 0.4137398358601097 y 0.5684640847172688\n    hyp 0.2416552517044926 y 0.6336199597135092\n    hyp 0.3552855364230894 y 0.435398565057618\n    hyp 0.52549711888017 y 0.43113513759439415\n    hyp 0.6582414367557253 y 0.5033091661911661\n    hyp 0.4176416475968032 y 0.4514920652295682\n    hyp 0.541551997892655 y 0.39091498285641035\n    hyp 0.46384907791765656 y 0.404715590122965\n    hyp 0.5616924111789523 y 0.5144792508848043\n\nThe previous results demonstrate that the variance is significant, but it still keeps in the expected range\nResult Group 2\nThe previous model was tested with multiple epoch values, but the result with higher values does not have a relevant improvement. A fixed learning rate gives a problem if it is bigger than 2. To improve it, a dynamic learning rate can be implemented.\n⬆️ Return\nReferences\n\nhttps://github.com/mdeff/fma\nhttp://millionsongdataset.com/musixmatch/\nhttp://millionsongdataset.com/pages/field-list/\nhttps://medium.com/atchai/in-search-of-the-perfect-music-dataset-ed7e111d3b7e\nhttps://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0\nhttps://towardsdatascience.com/difference-between-batch-gradient-descent-and-stochastic-gradient-descent-1187f1291aa1\nhttps://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a\nhttps://www.dataquest.io/blog/understanding-regression-error-metrics/\n\nThierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, and Paul Lamere.\nThe Million Song Dataset. In Proceedings of the 12th International Society\nfor Music Information Retrieval Conference (ISMIR 2011), 2011.\n⬆️ Return\nExtra\nUseful commands\n#/mnt/d/tmp_ml/msd/MillionSongSubset/data\nfind . -type f -name \\*.h5 -exec cp \\{\\} /mnt/d/tmp_ml/msd/MillionSongSubset/tracks/ \\;\n\n# find . -type f -name \\*.txt -exec cp \\{\\} /home/jupyter/xseed-test/data/domains \\;\n# ls | xargs -I{ cat { > /home/jupyter/xseed-test/data/domains.txt\n⬆️ Return\nImplementation process\n\nLook for music datasets\nUnderstand datasets\nDefine the scope for regression algorithm\nImplement model\nWrite documentation\n\n⬆️ Return\n""], 'url_profile': 'https://github.com/soyantonio', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'R', 'Updated Nov 29, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Jun 6, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '161 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/bensmus', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'R', 'Updated Nov 29, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Jun 6, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '80 contributions\n        in the last year', 'description': ['Regularized_Regression\n'], 'url_profile': 'https://github.com/divyanamani', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'R', 'Updated Nov 29, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Jun 6, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '20 contributions\n        in the last year', 'description': ['Logistinės regresijos modelis\nŠioje repositorijoje pateiktas logistinės regresijos modelis, nustatantis tikimybę susirgti diabetu.\nRepositorijos failai:\n\ndarbo aprašas;\nprograminis kodas, rašytas R kalba;\nduomenų analizei naudotas diabetes2.csv duomenų rinkinys.\n\n'], 'url_profile': 'https://github.com/AgneG25', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'R', 'Updated Nov 29, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Jun 6, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '27 contributions\n        in the last year', 'description': ['Sendy is hosting a challenge on Zindi to predict the estimated time of delivery of orders, from the point of driver pickup to the point of arrival at final destination.\nAn accurate arrival time prediction will help Sendy to improve their logistics and communicate an accurate time to their customers.\nThe notebook contains the steps taken to obtain a model that attempts to predict an accurate delivery time, from picking up a package to arriving at the final destination.\nTrain.csv - is the dataset used to train our model.\nTest.csv - is the dataset on which we applied our model to.\nRiders.csv - contains unique rider Ids, number of orders, age, ratings and number of ratings.\n'], 'url_profile': 'https://github.com/MilkShaikh3', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'R', 'Updated Nov 29, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Jun 6, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['SEIR-Regression\n'], 'url_profile': 'https://github.com/Rosl-Vlad', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'R', 'Updated Nov 29, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Jun 6, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['Regression_Analysis\nThis was a final project for a course dedicated towards understanding and applying regression analysis to data, especially with the use of R.\n'], 'url_profile': 'https://github.com/spalac1', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'R', 'Updated Nov 29, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Jun 6, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/yusufcse', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Python', 'MPL-2.0 license', 'Updated May 28, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 30, 2020', 'R', 'Updated Nov 29, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', 'Jupyter Notebook', 'Updated Jun 6, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['R_regression\n'], 'url_profile': 'https://github.com/ropon3', 'info_list': ['Updated May 16, 2020', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 11, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'MATLAB', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['regression_notebook\n'], 'url_profile': 'https://github.com/ThandoKhumalo', 'info_list': ['Updated May 16, 2020', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 11, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'MATLAB', 'Updated May 17, 2020']}","{'location': 'Pune, Maharashtra', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['Logistic-Regression\nMulti class Classification with Iris dataset\n'], 'url_profile': 'https://github.com/nishitaagrawal', 'info_list': ['Updated May 16, 2020', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 11, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'MATLAB', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/HongYuBinBin', 'info_list': ['Updated May 16, 2020', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 11, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'MATLAB', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '21 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/techolady', 'info_list': ['Updated May 16, 2020', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 11, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'MATLAB', 'Updated May 17, 2020']}","{'location': 'Windhoek', 'stats_list': [], 'contributions': '304 contributions\n        in the last year', 'description': ['logistic-regression\nArtificial Intelligence and Computer Graphics - First Assignment\nProblem\nThe dataset in bank −marketing−campaign.zip represents a collection of examples from a marketing campaign organised by a bank to get its clients to place a term deposit.\nThe dataset has 21 columns, described in Table 1.\nYour task is to build a classifier based on this dataset. The classifier should use the regularised logistic regression algorithm, with the regularised cross-entropy as its cost function.\nYou will use the sum of the magnitude of all the coefficients (also known as Lasso regularisation or L 1 regularisation) as your regularisation technique.\nAssessment Criteria\nThe following criteria will be followed to assess your submission:\n\n\nData cleaning and preparation in Julia;\n\n\nImplementation (from scratch) of the regularised logistic regression al-\ngorithm in Julia;\n\n\nDesign and implementation of the classifier;\n\n\nPerformance metrics including (It is advised to use a confusion matrix.):\naccuracy: the proportion of correct predictions (clients correctly pre-dicted to have placed a term deposit or not) over all predictions;\nprecision: the proportion of clients the classifier predicted have placed a term deposit actually did so;\nrecall: the proportion of clients that actually placed a term deposit which was predicted by the classifier\n\n\n\nSubmission Instructions\n\nThis project is to be completed by groups of maximum two (2) students each.\nFor each group, a repository should be created either on Github or Gitlab. The URL of the repository should be communicated by Thursday, May 14 th 2020, with all group members set up as contributors.\nThe submission date is Monday, May 25 th 2020, midnight.\nA submission will be assessed based on the clone of its repository at the deadline.\nAny group who fails to submit on time will be awarded the mark 0.\nThere should be no assumption about the execution environment of your code. It could be run using a specific framework or simply on the command line.\nIn the case of plagiarism (groups copying from each other or submissions copied from the Internet), all submissions involved will be awarded the mark 0, and each student will receive a warning.\n\n'], 'url_profile': 'https://github.com/CaloloCosta', 'info_list': ['Updated May 16, 2020', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 11, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'MATLAB', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '54 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/TD91988', 'info_list': ['Updated May 16, 2020', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 11, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'MATLAB', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '94 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/mr-sesquipedalian', 'info_list': ['Updated May 16, 2020', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 11, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'MATLAB', 'Updated May 17, 2020']}","{'location': 'Bangalore, India ', 'stats_list': [], 'contributions': '50 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ShilpaGopal', 'info_list': ['Updated May 16, 2020', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 11, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'MATLAB', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '26 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ashvalvi111', 'info_list': ['Updated May 16, 2020', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 11, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'MATLAB', 'Updated May 17, 2020']}"
"{'location': 'Gurgaon', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Lakshay03Feb', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Java', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'R', 'Updated Jun 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'C#', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '99 contributions\n        in the last year', 'description': ['LinearRegression\nRepository demonstrating Linear Regression in Java taking data in from an SQL DB.\n'], 'url_profile': 'https://github.com/r2rokid9', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Java', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'R', 'Updated Jun 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'C#', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 15, 2020']}","{'location': 'Surabaya', 'stats_list': [], 'contributions': '12 contributions\n        in the last year', 'description': ['SMO-Regression\n'], 'url_profile': 'https://github.com/ffuroida', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Java', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'R', 'Updated Jun 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'C#', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/yusufcse', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Java', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'R', 'Updated Jun 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'C#', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '266 contributions\n        in the last year', 'description': ['Linear_Regression_Projects\n'], 'url_profile': 'https://github.com/michelleruas', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Java', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'R', 'Updated Jun 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'C#', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/bisector1', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Java', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'R', 'Updated Jun 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'C#', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 15, 2020']}","{'location': 'Tempe, AZ', 'stats_list': [], 'contributions': '118 contributions\n        in the last year', 'description': ['Advanced Regression Python\nHouse Prices - Data Preprocessing, EDA, Normalisation/Rescaling, Regression methods, Hyperparameter tuning, Ensemble\n'], 'url_profile': 'https://github.com/ishah6', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Java', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'R', 'Updated Jun 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'C#', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Linear Regression\nCanale di regressione lineare\nPagina ufficiale\n'], 'url_profile': 'https://github.com/cTrader-Guru', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Java', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'R', 'Updated Jun 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'C#', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '42 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/athu1512', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Java', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'R', 'Updated Jun 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'C#', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 15, 2020']}","{'location': 'pune', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/chinu9668', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Java', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'R', 'Updated Jun 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'C#', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 15, 2020']}"
"{'location': 'pune', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/chinu9668', 'info_list': ['Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'ghaziabad', 'stats_list': [], 'contributions': '17 contributions\n        in the last year', 'description': ['linear-regression-\nits just a practice code for linear regresion\n'], 'url_profile': 'https://github.com/logisticsshrey001', 'info_list': ['Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '125 contributions\n        in the last year', 'description': ['Linear_Regression\nSome of the basic regression models I worked on during my initial years in college\n'], 'url_profile': 'https://github.com/sheryllindsay', 'info_list': ['Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'Tamilnadu,India', 'stats_list': [], 'contributions': '89 contributions\n        in the last year', 'description': ['Regression_Types\n Simple Linear Regression\n Multiple Linear Regression\n Polynomial Regression\n Decision Tree Regression\n Random Forest Regression\n Support Vector Regression\n'], 'url_profile': 'https://github.com/Prasannashri', 'info_list': ['Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/tbm1004', 'info_list': ['Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/M-AlKasir', 'info_list': ['Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '71 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/wasifekbal', 'info_list': ['Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': [""Linear-Regression\nImplementation of linear regression\nGetting Started\nYou'll need the following dependencies to get started:\n\nnumpy\n\n\npip install numpy (pip standalone installation)\nconda install numpy (anaconda installtion)\n\n\nmatplotlib\n\n\npip install matplotlib (pip standalone installation)\nconda install matplotlib (anaconda installtion)\n\nRefer to linear-regression-rc to implement linear Regession from scratch.\nStep:1\n\nImport data\n\nStep:2\n\nFind the mean squared error\n\nStep:3\n\nFind Gradient Descent\n\nStep:4\n\nPlot line against points and check test accuracy\n\n""], 'url_profile': 'https://github.com/aruncena123', 'info_list': ['Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'Duluth, GA', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['Regression-model\n'], 'url_profile': 'https://github.com/salochina', 'info_list': ['Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'Cairo, Egypt', 'stats_list': [], 'contributions': '87 contributions\n        in the last year', 'description': ['Logistic-Regression\nA full implementation of logistic regression tested on kaggle diabetes  dataset to predict whether a patient has diabetes or not\nResult\nDue to github inability to render notebooks sometimes , the output of the accuracy test is shown below\n\nDatasets\nThis project was built using Kaggle diabetes datasets\n'], 'url_profile': 'https://github.com/yasminehatem', 'info_list': ['Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '20 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/saurav-8908128021', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'MIT license', 'Updated May 12, 2020', 'Updated May 12, 2020', 'Python', 'Updated Jun 4, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '10 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/anahristova', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'MIT license', 'Updated May 12, 2020', 'Updated May 12, 2020', 'Python', 'Updated Jun 4, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '99 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/TheSliceOfPi', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'MIT license', 'Updated May 12, 2020', 'Updated May 12, 2020', 'Python', 'Updated Jun 4, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '29 contributions\n        in the last year', 'description': [""This repository implements Logistic Regression with Nesterov's Accelerated Gradient from scratch with NumPy.\nThe implemented algorithm provides identical classification performance to sklearn logistic regression function.\n\nThe dataset used for this demo is the Credit Card Fraud Detection dataset from Kaggle.\nIt is a difficult dataset due to high class imbalance, and more chances for the algorithm to oscillate / diverge.\nThis is avoided due to the look-ahead in Nesterov's method.\nThe EDA_FeatureSelection notebook shows how four features are selected for the final model. These features are used to demo the algorithm in Gradient_Descent.ipynb.\n//todo: 1. code cleanup (np-pd switches can be avoided by reading X in np)\n2. Cleanup driver code, add function call, allowing switch between SGD and NAG\n3. Contour plots\n""], 'url_profile': 'https://github.com/adi-ar', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'MIT license', 'Updated May 12, 2020', 'Updated May 12, 2020', 'Python', 'Updated Jun 4, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '21 contributions\n        in the last year', 'description': ['Cost-Function-Linear-Regression\n'], 'url_profile': 'https://github.com/aditirani', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'MIT license', 'Updated May 12, 2020', 'Updated May 12, 2020', 'Python', 'Updated Jun 4, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'Saudi Arabia Riyadh', 'stats_list': [], 'contributions': '313 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/marwan1023', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'MIT license', 'Updated May 12, 2020', 'Updated May 12, 2020', 'Python', 'Updated Jun 4, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/HakaiShin047', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'MIT license', 'Updated May 12, 2020', 'Updated May 12, 2020', 'Python', 'Updated Jun 4, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['""# Multiple-Linear-Regression""\n'], 'url_profile': 'https://github.com/fettah-lyza', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'MIT license', 'Updated May 12, 2020', 'Updated May 12, 2020', 'Python', 'Updated Jun 4, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'Beijing,China', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['Fused-Lasso-Logistic-Regression\nUse ADMM and Newton algorithm to solve FLLR model\n主要的算法代码等答辩结束后再上传吧\n'], 'url_profile': 'https://github.com/Tony2h', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'MIT license', 'Updated May 12, 2020', 'Updated May 12, 2020', 'Python', 'Updated Jun 4, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '20 contributions\n        in the last year', 'description': ['Machine-Learning-Ridge-Regression\nThis code uses ridge regression to identify which variables to include in a model estimating the institutional determinants of state spending\nState governments are unique in that they face balanced budget constraints. However, there are several types of balanced budget requirements. Including all of these in an econometric model poses problems, as there is likely to be multi-collinearity. There are several ways around this problem. This code uses ridge regression for model selection.\n'], 'url_profile': 'https://github.com/sjillani87', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 13, 2020', 'Updated May 12, 2020', 'Python', 'MIT license', 'Updated May 12, 2020', 'Updated May 12, 2020', 'Python', 'Updated Jun 4, 2020', 'R', 'Updated May 16, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/AbdellAmansag', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated Nov 26, 2020', 'Python', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Feb 18, 2021', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 13, 2020', 'JavaScript', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'Bengaluru,Karnataka,India', 'stats_list': [], 'contributions': '42 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/belladsagar', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated Nov 26, 2020', 'Python', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Feb 18, 2021', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 13, 2020', 'JavaScript', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['ft_linear_regression\nA simple, basic machine learning algorithm : a program that predicts the price of a car by using a linear function train with a gradient descent algorithm.\n'], 'url_profile': 'https://github.com/tillderoquefeuil-42-ai', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated Nov 26, 2020', 'Python', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Feb 18, 2021', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 13, 2020', 'JavaScript', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '40 contributions\n        in the last year', 'description': ['covid-19-multilinear-regression\nThis project aims to use multi-linear regression to analyze COVID-19 confirmed cases using county demo- graphic, economic and medical information.\nIt provides statistical analysis on how these factors affect the number of confirmed cases in each county, and make predictions for countries using regression model. The results show that the countries with larger population,\ngreater population growth, with more severe aging trend, more developed urbanization, and the countries with a large number of immigrants, tend to have more confirmed cases, possibly due to dense population, highly urbanization, developed economic conditions, and better detection methods.\nKeywords: COVID-19; confirmed cases; multi-linear regression; prediction.\n\n\n'], 'url_profile': 'https://github.com/olivia3395', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated Nov 26, 2020', 'Python', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Feb 18, 2021', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 13, 2020', 'JavaScript', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'São Paulo, BRA', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['Small-Dataset-for-regression\n'], 'url_profile': 'https://github.com/veniciuss', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated Nov 26, 2020', 'Python', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Feb 18, 2021', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 13, 2020', 'JavaScript', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '64 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/FitriaNurAida', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated Nov 26, 2020', 'Python', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Feb 18, 2021', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 13, 2020', 'JavaScript', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '62 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/YashuDhatrika', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated Nov 26, 2020', 'Python', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Feb 18, 2021', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 13, 2020', 'JavaScript', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'Buenos Aires', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/aletorrado', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated Nov 26, 2020', 'Python', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Feb 18, 2021', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 13, 2020', 'JavaScript', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'BSD, Greater Jakarta, Indonesia', 'stats_list': [], 'contributions': '148 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/mnrclab', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated Nov 26, 2020', 'Python', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Feb 18, 2021', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 13, 2020', 'JavaScript', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['Logistic-regression-Model.\n'], 'url_profile': 'https://github.com/AAnbusekaran', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated Nov 26, 2020', 'Python', 'Updated Sep 21, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Feb 18, 2021', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 13, 2020', 'JavaScript', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 16, 2020']}"
"{'location': 'Cairo Egypt ', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['Regression-Model-in-Keras-\nthe Final project of ""introduction to neural networks and deep learning ibm , predicting the strength of different samples of concrete based on the volumes of the different ingredients that were used to make them\n'], 'url_profile': 'https://github.com/Adhm989', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Colombia', 'stats_list': [], 'contributions': '705 contributions\n        in the last year', 'description': ['Linear_regression-example\n'], 'url_profile': 'https://github.com/d1sd41n', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Istanbul', 'stats_list': [], 'contributions': '34 contributions\n        in the last year', 'description': ['regression-tree-from-scratch\nPython notebook predicting house prices by using decision tree algorithm\n'], 'url_profile': 'https://github.com/dogruomerfaruk', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['\nlinear-regression-tensorflow\nIn this tutorial, we will introduce how to train and evaluate a Linear Regression model using TensorFlow. Linear Regression is of the fundamental Machine Learning techniques that are frequently used. In this tutorial, you will learn:\n\nthe concept of Linear Regression\nthe particular case of Linear Regression with one variable\na working example using a well-known dataset\nhow to implement this algorithm in Python and with TensorFlow and Keras\nworking on the dataset using a powerful library such as Pandas\ninvestigating and visualizing the data\n\nOriginal blog post: https://www.machinelearningmindset.com/linear-regression-with-tensorflow\n'], 'url_profile': 'https://github.com/instillai', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Cheongju, Chungbuk  28644, South Korea , ', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['A-Locally-Adaptive-Regression\nIn this work, we introduce a locally adaptive interpretable regression (LoAIR). In LoAIR, a metamodel parameterized by neural networks predicts percentile of a Gaussian distribution for the regression coefficients for a rapid adaptation.\nhttps://arxiv.org/abs/2005.03350\n'], 'url_profile': 'https://github.com/lhagiimn', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/belenamita', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Yogyakarta', 'stats_list': [], 'contributions': '366 contributions\n        in the last year', 'description': ['wineQuality-Regression\n'], 'url_profile': 'https://github.com/amary21', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '260 contributions\n        in the last year', 'description': ['Predict User Ad Selection\nTechnologies: Pandas, Numpy, Seaborn, Matplotlib, scikit-learn\nCreated a model that predicts whether or not a user clicks on an ad, based on their features eg: Daily Time Spent on Site, Area Income, Age etc.\n'], 'url_profile': 'https://github.com/shivam-ajmera', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Raleigh, NC', 'stats_list': [], 'contributions': '64 contributions\n        in the last year', 'description': ['BitcoinPriceRegression\nObjective:\nUse Bayesian Regression to predict the future price variation in the price of bitcoin.\nPython packages:\nNumpy, Pandas, Sklearn, Statsmodels. To install, use ""sudo pip install package"".\n'], 'url_profile': 'https://github.com/devik1367', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Taipei', 'stats_list': [], 'contributions': '110 contributions\n        in the last year', 'description': ['Decission-Tree-Regression\nMy implementation of Decission Tree Regression using the data of position vs salary\n'], 'url_profile': 'https://github.com/ferdyandannes', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated Jun 8, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 13, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}"
"{'location': 'United Arab Emirates', 'stats_list': [], 'contributions': '191 contributions\n        in the last year', 'description': ['Learn regression algorithms using Python and scikit-learn\nThis repository contains the content of a webinar that focuses on regression algorithms and shows how to use Python and scikit-learn library to build regressions models that can predict the price of houses.\nPresentation\nThe presentation of the webinar is the pdf file. Just click it and you will see all the content discussed in the webinar.\nHands-on Session\nFor the hands-on session, follow the steps showed this link: https://developer.ibm.com/tutorials/learn-regression-algorithms-using-python-and-scikit-learn/\n'], 'url_profile': 'https://github.com/kif01', 'info_list': ['Updated May 12, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Oct 1, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '64 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/FitriaNurAida', 'info_list': ['Updated May 12, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Oct 1, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['Tensor-Tucker-Regression\nLearning Tucker form of regression and classification models for tensor data.\n'], 'url_profile': 'https://github.com/PeterLiPeide', 'info_list': ['Updated May 12, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Oct 1, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '69 contributions\n        in the last year', 'description': [""Heart disease detection through logistic regression 1\nThe purposes of this project:\n\nImplement a simple logistic regression model from scratch to detect heart disease.\nVisualize the development of the cross-entropy as a function of iterations.\nGain intuition of model performance through plotting learning curves.\nUnderstanding the limitations of basic logistic regression.\n\nDataset: Heart disease UCI\nThe trained model is a linear model with the same dimensionality as the feature space (13).\nRun program\n\nCall heart_disease(data_file) in heart_disease.py.\nSupply arguments: heart_disease(data_file, iterations=1000, learning_rate=0.01, plot_training_costs=False, plot_learning_curves=False). Only data_file is required.\n\n\nThe above plot demonstrates the convergence of the cost for this model. The convergence value is approx. 0.33.\n \n\nFrom the above plot, it seems like both the training cost and the test cost converge to the same value with increased number of training examples. From the looks of it, the model has low variance and extrapolates well to new examples.\nThe training and test accuracies are approx. the same (80% - 85%). This isn't nearly good enough for the problem of detecting heart disease. From the learning curves, you could hypothesize that the bias is too big. Another model is likely required to improve performance.\nPrecision and recall (F1 score) are normally better validators for this kind of problem. However, since the accuracy of the model is so low, there is really no point in computing these values.\n""], 'url_profile': 'https://github.com/simenjh', 'info_list': ['Updated May 12, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Oct 1, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020']}","{'location': 'Cupertino', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/omkar0613', 'info_list': ['Updated May 12, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Oct 1, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020']}","{'location': 'Bengaluru, India', 'stats_list': [], 'contributions': '156 contributions\n        in the last year', 'description': ['Logistic-Regression--Springboard\nA Logistic Regression pipeline involving modeling of the datasets of heights and weights , tuning the model for hyper-parameter optimization and checking the accuracy of the model through Grid-Search Cross Validation. We also get to know the intuition behind the Logistic Regression algorithm and interpreting the probabilistic model of it.\n'], 'url_profile': 'https://github.com/ikigai-aa', 'info_list': ['Updated May 12, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Oct 1, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '132 contributions\n        in the last year', 'description': ['LinearRegression\n\nBasic multiple linear regression using sci-kit_learn on tennis_stats data to predict the possibility of winning based on some parameters.\nLinear regression on big data of yelp ratings to predict the rating of a neighbourhood shop. The data files are too big to be included here\n\nLogisticRegression\n\nPredicting the survival chances of passengers on titanic from the kaggle dataset\n\n'], 'url_profile': 'https://github.com/sounok1234', 'info_list': ['Updated May 12, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Oct 1, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '20 contributions\n        in the last year', 'description': ['Multi-linear-regression-\n'], 'url_profile': 'https://github.com/Gaddam-Vyshnavi', 'info_list': ['Updated May 12, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Oct 1, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '109 contributions\n        in the last year', 'description': ['simple_linear_regression\nAssignment\nWe will predict employee salaries from different employee characteristics (or features). We are going to use a simple supervised learning technique: linear regression. We want to build a simple model to determine how well Years Worked predicts an employee’s salary. Import the data salary.csv to a Jupyter Notebook. A description of the variables is given in Salary Metadata. You will need the packages matplotlib, pandas and statsmodels.\nSteps and questions\n1.Split your data into a training and test set. Leave the test set for now. Examine the training data for missing and extreme values. Create histograms to show the distribution of the variables and a scatterplot showing the relationship between Years Worked and Salary. Are the data appropriate for linear regression? Is there anything that needs to be transformed or edited first?\n2.Using the statsmodels package and the training data, run a simple linear regression for Salary with one predictor variable: Years Worked.\n\nDoes the model significantly predict the dependent variable? Report the amount of variance explained (R^2) and  significance value (p) to support your answer.\nWhat percentage of the variance in employees’ salaries is accounted for by the number of years they have worked?\n\n3.What does the unstandardized coefficient (B or ‘coef’ in statsmodels) tell you about the relationship between Years Worked and Salary?\n4.What do the 95% confidence intervals [0.025, 0.975] mean?\n5.Calculate the expected salary for someone with 12 years’ work experience.\n6.Calculate the expected salary for someone with 80 years’ work experience. Are there any problems with this prediction? If so, what are they?\n7.We have only looked at the number of years an employee has worked. What other employee characteristics might influence their salary?\nNow fit your model to your test set. DO NOT BUILD A NEW MODEL ON THE TEST SET! Simply use your existing, model, to predict salaries in the test set.\n\nHow does your model compare when running it on the test set - what is the difference in the Root Mean Square Error (RMSE) between the training and test sets? Is there any evidence of overfitting?\n\n'], 'url_profile': 'https://github.com/jbmasemza', 'info_list': ['Updated May 12, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Oct 1, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '402 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/dev-kanishk', 'info_list': ['Updated May 12, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', 'HTML', 'Updated May 13, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Oct 1, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '260 contributions\n        in the last year', 'description': ['Boston House Pricing Analysis through Linear Regression\nTechnologies: Pandas, scikit-learn, Numpy, Seaborn, Matplotlib\nData Analysis, exploration, engineering features, handling null values to estimate the pricing of houses in Boston using various factors.\n'], 'url_profile': 'https://github.com/shivam-ajmera', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', '1', 'R', 'Updated Jul 6, 2020', 'Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '60 contributions\n        in the last year', 'description': ['Chicago-Redlining-Regression-\nRegression analysis to determine whether Home Insurance was being unfairly denied to certain Chicago neighborhoods\nUsing R\nCreated for Integrated Experience Project for Stats 525 at University of Massachusetts\n'], 'url_profile': 'https://github.com/k-falk', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', '1', 'R', 'Updated Jul 6, 2020', 'Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'Raleigh, NC', 'stats_list': [], 'contributions': '111 contributions\n        in the last year', 'description': ['SGD_LinearRegression\nImplementation of Stochastic Gradient Descent for Linear regression with L2 Regularization\n'], 'url_profile': 'https://github.com/srujana13', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', '1', 'R', 'Updated Jul 6, 2020', 'Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'Cebu, Philippines', 'stats_list': [], 'contributions': '51 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/lambobr', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', '1', 'R', 'Updated Jul 6, 2020', 'Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '69 contributions\n        in the last year', 'description': ['Heart disease detection through logistic regression 2\nThis project is a continuation of Heart disease detection through logistic regression 1\nThe above project indicated that the trained linear model was suffering from high bias.\nThe purposes of this project:\n\nVisualize the cross-validation cost of different models.\nAim to find a model with lower bias, using polynomial features (1D-5D).\nAnalyze results.\n\nDataset: Heart disease UCI\nAll the trained models have been regularized.\nRun program\nCall heart_disease(data_file) in heart_disease.py.\n \n\nAs can be seen from the above figure, the variance is increasing with larger model polynomial degree. The linear model looks to be the best in terms of bias-variance tradeoff.\nKey takeaways\n\nNone of the higher-order polynomials beat the linear model in terms of bias-variance tradeoff.\nPossibly, other methods of feature expansion might give better results. Linear or cubic splines could be worth a shot.\nTraining the higher-order polynomial models with more data is likely to bring down the variance.\nMethods like SVMs and neural networks in order to train more advanced models, might be worth exploring.\n\n'], 'url_profile': 'https://github.com/simenjh', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', '1', 'R', 'Updated Jul 6, 2020', 'Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '238 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gary444', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', '1', 'R', 'Updated Jul 6, 2020', 'Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': ['Simple-Linear-Regression\nSLR Example\n'], 'url_profile': 'https://github.com/dlubert3', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', '1', 'R', 'Updated Jul 6, 2020', 'Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'India', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': ['Multiple-Linear-Regression\nA complete study — Model Interpretation →Hypothesis Testing →Feature Selection\nTo read and learn about Multiple Linear Regression, go to the following link:\nhttps://towardsdatascience.com/multiple-linear-regression-8cf3bee21d8b\n'], 'url_profile': 'https://github.com/datasciencewithsan', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', '1', 'R', 'Updated Jul 6, 2020', 'Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '39 contributions\n        in the last year', 'description': ['Principal-Component-Regression-Superconductors\nA research paper detailing the model building process of principal component regression using mathematical notation and a demonstration using the superconductivity dataset from the UCI machine learning repository.  The goal was to build a model using principal component regression to make predictions about the critical temperature of a superconductor.\nThe full report can be found/read in the pdf file uploaded above (still working on it).  I have also uploaded the code used in the analysis in a Jupyter Notebook file, R file, as well as presentation slides associated with the project.\n'], 'url_profile': 'https://github.com/Josh-Fontes', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', '1', 'R', 'Updated Jul 6, 2020', 'Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'Austin, TX', 'stats_list': [], 'contributions': '640 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/edkrueger', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', '1', 'R', 'Updated Jul 6, 2020', 'Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}"
"{'location': 'Raleigh, NC', 'stats_list': [], 'contributions': '111 contributions\n        in the last year', 'description': ['SGD_LinearRegression\nImplementation of Stochastic Gradient Descent for Linear regression with L2 Regularization\n'], 'url_profile': 'https://github.com/srujana13', 'info_list': ['Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020']}","{'location': 'Cebu, Philippines', 'stats_list': [], 'contributions': '51 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/lambobr', 'info_list': ['Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '69 contributions\n        in the last year', 'description': ['Heart disease detection through logistic regression 2\nThis project is a continuation of Heart disease detection through logistic regression 1\nThe above project indicated that the trained linear model was suffering from high bias.\nThe purposes of this project:\n\nVisualize the cross-validation cost of different models.\nAim to find a model with lower bias, using polynomial features (1D-5D).\nAnalyze results.\n\nDataset: Heart disease UCI\nAll the trained models have been regularized.\nRun program\nCall heart_disease(data_file) in heart_disease.py.\n \n\nAs can be seen from the above figure, the variance is increasing with larger model polynomial degree. The linear model looks to be the best in terms of bias-variance tradeoff.\nKey takeaways\n\nNone of the higher-order polynomials beat the linear model in terms of bias-variance tradeoff.\nPossibly, other methods of feature expansion might give better results. Linear or cubic splines could be worth a shot.\nTraining the higher-order polynomial models with more data is likely to bring down the variance.\nMethods like SVMs and neural networks in order to train more advanced models, might be worth exploring.\n\n'], 'url_profile': 'https://github.com/simenjh', 'info_list': ['Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '238 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gary444', 'info_list': ['Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': ['Simple-Linear-Regression\nSLR Example\n'], 'url_profile': 'https://github.com/dlubert3', 'info_list': ['Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020']}","{'location': 'India', 'stats_list': [], 'contributions': '15 contributions\n        in the last year', 'description': ['Multiple-Linear-Regression\nA complete study — Model Interpretation →Hypothesis Testing →Feature Selection\nTo read and learn about Multiple Linear Regression, go to the following link:\nhttps://towardsdatascience.com/multiple-linear-regression-8cf3bee21d8b\n'], 'url_profile': 'https://github.com/datasciencewithsan', 'info_list': ['Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '39 contributions\n        in the last year', 'description': ['Principal-Component-Regression-Superconductors\nA research paper detailing the model building process of principal component regression using mathematical notation and a demonstration using the superconductivity dataset from the UCI machine learning repository.  The goal was to build a model using principal component regression to make predictions about the critical temperature of a superconductor.\nThe full report can be found/read in the pdf file uploaded above (still working on it).  I have also uploaded the code used in the analysis in a Jupyter Notebook file, R file, as well as presentation slides associated with the project.\n'], 'url_profile': 'https://github.com/Josh-Fontes', 'info_list': ['Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020']}","{'location': 'montreal ', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['ML-Linear-regression\n'], 'url_profile': 'https://github.com/chaauhandeepak', 'info_list': ['Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '113 contributions\n        in the last year', 'description': ['Linear Regression from Scratch\nLinear regression model is built from scratch only for a single attribute dataset using statistical formulas\nLicense\nThe dataset is produced on excel using NORMINV(RAND(), x, 3) function and thus is open to use and can be reproduced conveniently by anyone\nObjective\nTo build a linear regression from scratch to correctly predict the target values\n\nData Description\nThe training dataset is a CSV file with 700 data pairs (x,y). The x-values are numbers between 0 and 100. The corresponding y-values have been generated using the Excel function NORMINV(RAND(), x, 3). Consequently, the best estimate for y should be x.\nThe test dataset is a CSV file with 300 data pairs\nLibraries Used\n\nnumpy\npandas\nmatplotlib\nsklearn\n\nFunctions Building\nFunctions for the following operations are built in the notebook :\n - Mean\n - Variance \n - Co Variance\n - Coefficients\n - Root Mean Square\n\nModel Building\nUsing the above functions , linear_regression model is built and implemented. The model is evaluated through RMSE scores .\nConclusion\nThe plots of dataset and predictions are seen and observed if linear regression is working accurately\n'], 'url_profile': 'https://github.com/Kush-Thakral', 'info_list': ['Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020']}","{'location': 'FUTA, Akure Nigera', 'stats_list': [], 'contributions': '300 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Adegitetaiwo', 'info_list': ['Jupyter Notebook', 'Updated May 23, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'Python', 'Updated May 14, 2020', 'MATLAB', 'Updated May 12, 2020', 'Updated May 16, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 27, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020']}"
"{'location': 'Hyderabad', 'stats_list': [], 'contributions': '56 contributions\n        in the last year', 'description': ['Project---Logistic-Regression\nI have done small project on advertising dataset on the use case if internet user clicked on the Advertisement or not\n'], 'url_profile': 'https://github.com/arun2357', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 18, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'Gurugram', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['Multiple-Linear-Regression\nThis is a praactical example of MLR end to end\n'], 'url_profile': 'https://github.com/tapas-dev', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 18, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '72 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/jhoanmartinezz', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 18, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['LogisticRegression_SomeRandom\n'], 'url_profile': 'https://github.com/gauty009', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 18, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '253 contributions\n        in the last year', 'description': [""museums-linear-regression\nCorrelating museums visits with population size\nThis simple python service can look up the most visited museums in the world and fill up a small sqlite database with information about those museums and the city they're located in. This data can then be queried and obtained in a CSV format for easy ingestion in something like a Pandas Dataframe.\nThe Notebook.ipynb Jupyter Notebook presents data analysis and a simple linear regression model to attempt to correlate City Population with Museum Visits. A pre-rendered Notebook.html is available as a read-only version of the analysis.\nA Docker image configuration is provided that will create an instance of the app and run Jupyter with all required dependencies, ready to be connected to.\nTo run the service and connect via Jupyter\nBuild the docker image:\ndocker build -t museums-linear-regression .\n\nRun it, exposing the internal 8888 port used by Jupyter to whatever host port you want\ndocker run -p 8888:8888 museums-linear-regression\n\nConnect using the Jupyter URL provided in the command prompt, replacing the internal 8888 port with whatever port you've exposed\nData sources\nCities population database provided by https://simplemaps.com/data/world-cities\n""], 'url_profile': 'https://github.com/vincentlizotte', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 18, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'montreal ', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['ML-Linear-regression\n'], 'url_profile': 'https://github.com/chaauhandeepak', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 18, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '113 contributions\n        in the last year', 'description': ['Linear Regression from Scratch\nLinear regression model is built from scratch only for a single attribute dataset using statistical formulas\nLicense\nThe dataset is produced on excel using NORMINV(RAND(), x, 3) function and thus is open to use and can be reproduced conveniently by anyone\nObjective\nTo build a linear regression from scratch to correctly predict the target values\n\nData Description\nThe training dataset is a CSV file with 700 data pairs (x,y). The x-values are numbers between 0 and 100. The corresponding y-values have been generated using the Excel function NORMINV(RAND(), x, 3). Consequently, the best estimate for y should be x.\nThe test dataset is a CSV file with 300 data pairs\nLibraries Used\n\nnumpy\npandas\nmatplotlib\nsklearn\n\nFunctions Building\nFunctions for the following operations are built in the notebook :\n - Mean\n - Variance \n - Co Variance\n - Coefficients\n - Root Mean Square\n\nModel Building\nUsing the above functions , linear_regression model is built and implemented. The model is evaluated through RMSE scores .\nConclusion\nThe plots of dataset and predictions are seen and observed if linear regression is working accurately\n'], 'url_profile': 'https://github.com/Kush-Thakral', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 18, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'FUTA, Akure Nigera', 'stats_list': [], 'contributions': '300 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Adegitetaiwo', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 18, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'New York, NY', 'stats_list': [], 'contributions': '117 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/kristybell', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 18, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'Irvine, CA', 'stats_list': [], 'contributions': '80 contributions\n        in the last year', 'description': ['Oil Data Analysis\nOil vs Dollar Value\nData Sources\nThis file is maintained by the Team Oil vs Dollar group for the purpose of calculating the correlation between oil prices and the U.S. dollar value.\nThe correlation between oil prices and the value of the dollar will also examine how external factors such as elections, natural disasters and pandemics will impact oil prices and by association, the value of the dollar.\nMachine Learning:\nhttps://github.com/skotagiri95/Oil-and-Dollar-Value-Analysis-/tree/master/LINEAR%20REGRESSION_OIL\nMaster Brach\nBraches:\nSheela - Sheela Kotagiri\nRole: Square\nRita - Rita Ramos\nRole: Triangle\nJuan - Juan M. Pacheco Nájar\nhttps://github.com/skotagiri95/Oil-and-Dollar-Value-Analysis-/tree/Juan\nRole: Circle\nRepository:\nhttps://github.com/skotagiri95/Oil-and-Dollar-Value-Analysis-/\nREADME.MD\nGoogle Slides Presentation:\nhttps://docs.google.com/presentation/d/16hNtvrhtdxZFnWzaExROaLSNE727WatZV_IeYfpbAK0/edit#slide=id.g76e9fc699e_0_0\nData Sources:\n\n\nEnergy Information Administration\nhttp://www.eia.gov/oil_gas/petroleum/data_publications/wrgp/mogas_history.html\nData 4: Midgrade Conventional\n\n\nUS Dollar Index 43 years\n""www.macrotrends.net"".\n\n\nWTI Crude Oil Prices - 10 Year Daily Chart\n""www.macrotrends.net"".\n\n\nStandard and Poor\'s (S&P) 500 Index Data\nDataHub.io\nhttps://datahub.io/collections/stock-market-data\n\n\nHarvard Business School\nhttps://www.hbs.edu/behavioral-finance-and-financial-stability/data/banking-system/Pages/default.aspx\nGlobal Financial Crisis\n\n\nSqlalchemy\nUsing join to query data in the tables, analysis\nEntity Relashionship Diagram (ERD)\n\nPresentations\nSegment 1:\nhttps://github.com/skotagiri95/Oil-and-Dollar-Value-Analysis-/blob/master/UCB%20Segment%201%20Final%20Project%20Presentation%20.pdf\nSegment 2:\nDashboard:\nhttps://github.com/skotagiri95/Oil-and-Dollar-Value-Analysis-/blob/master/UCB%20SEGMENT%202-Oil%20and%20Dollar%20Value%20Analysis%20Dashboard.pdf\nML:\nhttps://github.com/skotagiri95/Oil-and-Dollar-Value-Analysis-/blob/master/UCB%20SEGMENT%202-%20MACHINE%20LEARNING.pdf\nSegment 3:\nhttps://github.com/skotagiri95/Oil-and-Dollar-Value-Analysis-/blob/master/UCB%20Segment3Final%20Project%20Presentation%20.pdf\nSegment 4:\nhttps://github.com/skotagiri95/Oil-and-Dollar-Value-Analysis-/blob/master/UCB%20Data%20Analytics%20Bootcamp%20Pitch.pptx\nML\nWeekly Oil vs Gasoline Linear Regresion Model\nhttps://github.com/skotagiri95/Oil-and-Dollar-Value-Analysis-/blob/master/LINEAR%20REGRESSION_OIL/OIL%20ML-Weekly.ipynb\nDashboard\nTableau Oil vs Gasoline Linear Regresion Dashboard interactive on Month and Year\n\nOil Analysis Public Link\n\\Resources\\Tableau Oil Analysis Dashboard.png\nhttps://public.tableau.com/views/OilAnalysis_15884725810310/Dashboard?:display_count=y&publish=yes&:origin=viz_share_link\nDescribe Trend Line\n\\Resources\\Describe Oil Trend Model.png\n\nDescribe Model Line\n\\Resources\\Describe Oil TrendLine.png\n\n'], 'url_profile': 'https://github.com/juan-mpn', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 16, 2020', 'HTML', 'Updated May 18, 2020', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/RGTHENO', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'Sunnyvale, California', 'stats_list': [], 'contributions': '38 contributions\n        in the last year', 'description': ['Linear_Regression_from_scratch\nCode for calculating Linear Regression coefficients using gradient descent method, experimenting with different variables and parameters\nThe dataset contains information about energy consumption by appliances and different environment factors like temperature, humidity, weather etc. We must determine the relationship between the energy consumption and the given factors.\nhttps://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction\nA linear regression model on the dataset was implemented to predict the energy usage of appliances., utilizing the gradient descent algorithm with batch update. Sum of squared error normalized by 2*number of samples [J(β0, β1) = (1/2m)[Σ(yᶺ(i) – y(i))2 ] was used as cost and error measures, where m is number of samples\n'], 'url_profile': 'https://github.com/nikanshiyadav', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'San Antonio, TX', 'stats_list': [], 'contributions': '193 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Suggestions-Only', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'Hyderabad', 'stats_list': [], 'contributions': '49 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/anjaleana', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '38 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Nagrajpawar05', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/AbdellAmansag', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': ['Multiple-Linear-Regression\nMLR Example\n'], 'url_profile': 'https://github.com/dlubert3', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'Hyderabad', 'stats_list': [], 'contributions': '56 contributions\n        in the last year', 'description': ['Project---Logistic-Regression\nI have done small project on advertising dataset on the use case if internet user clicked on the Advertisement or not\n'], 'url_profile': 'https://github.com/arun2357', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'Gurugram', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['Multiple-Linear-Regression\nThis is a praactical example of MLR end to end\n'], 'url_profile': 'https://github.com/tapas-dev', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '72 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/jhoanmartinezz', 'info_list': ['Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}"
"{'location': 'San Antonio, TX', 'stats_list': [], 'contributions': '193 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Suggestions-Only', 'info_list': ['R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 17, 2020']}","{'location': 'Hyderabad', 'stats_list': [], 'contributions': '49 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/anjaleana', 'info_list': ['R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '43 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ManasaBsv', 'info_list': ['R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '43 contributions\n        in the last year', 'description': ['Linear Regression Model\n'], 'url_profile': 'https://github.com/Sebion06', 'info_list': ['R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 17, 2020']}","{'location': 'Canberra', 'stats_list': [], 'contributions': '34 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/DannyFirmin', 'info_list': ['R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['PerceptronfromScratch_LinearRegression\n'], 'url_profile': 'https://github.com/alpacino98', 'info_list': ['R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '64 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/FitriaNurAida', 'info_list': ['R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '236 contributions\n        in the last year', 'description': ['linear-and-multiple-regression\nthe source code of the file\nclone the file and run on the R-Studio and save the file bt the extension {filename}.R\n\n.R is the extension of the file in R-Studio\n'], 'url_profile': 'https://github.com/arpit282', 'info_list': ['R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '195 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/metallerok', 'info_list': ['R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ajithmasthan0320', 'info_list': ['R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jan 15, 2021', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 25, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 17, 2020']}"
"{'location': 'Durban, South Africa ', 'stats_list': [], 'contributions': '127 contributions\n        in the last year', 'description': ['Zindi Regression Challenge\nSendy provides an API as well as a web and mobile application platform to link customers who have delivery needs with vetted transporters. The customers select their vehicle of choice, get their price quote upfront and pay using various payment options. The system optimises the route, looks for the closest available riders and dispatches the orders in the most efficient way.\nThis challenge aims to predict the estimated time of delivery of orders, from the point of driver pickup to the point of arrival at final destination.\nlink to the competition: https://zindi.africa/hackathons/edsa-sendy-logistics-challenge\nMotivation\nOur solution will help Sendy improve customer communication and the reliability of their service. Moreover, the solution will allow Sendy to minimise the cost of doing business through better resource management and order scheduling.\nApproach\n\nExploratory Data Analysis\nFeature Selection\nFeature Engineering\nBuilding Various Machine Learning Models\nModel Evaluation and Selection: rmse used as a performance metric\nSubmission\n\nProject Status\nCurrently ranked among the top 40%\nLink to project Trello board: https://trello.com/invite/b/Jvt3ICOf/6936f63598f23bdfa917f7bf23176ceb/regression-predict\nAuthors\n\nRohini Jagath\nNicole Meinie\nConfidence Ledwaba\nPilasande Pakkies\n\nContact Details\nIf you would like to contribute to our repository please contact nicole.meinie@gmail.com\n\n'], 'url_profile': 'https://github.com/NicoleMeinie', 'info_list': ['Jupyter Notebook', 'Updated Jun 4, 2020', 'Updated Sep 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/bahademircioglu', 'info_list': ['Jupyter Notebook', 'Updated Jun 4, 2020', 'Updated Sep 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '50 contributions\n        in the last year', 'description': ['Regression_Classification_Applied_ML\nhttps://www.researchgate.net/publication/323655455_Fraudulent_Firm_Classification_A_Case_Study_of_an_External_Audit\n'], 'url_profile': 'https://github.com/suhas-patil98', 'info_list': ['Jupyter Notebook', 'Updated Jun 4, 2020', 'Updated Sep 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/aminadiawara', 'info_list': ['Jupyter Notebook', 'Updated Jun 4, 2020', 'Updated Sep 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '50 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/VeeMagwaza', 'info_list': ['Jupyter Notebook', 'Updated Jun 4, 2020', 'Updated Sep 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '297 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Super-rookie-Py', 'info_list': ['Jupyter Notebook', 'Updated Jun 4, 2020', 'Updated Sep 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020']}","{'location': 'Johannesburg', 'stats_list': [], 'contributions': '10 contributions\n        in the last year', 'description': ['regression_notebook_team17\nA repository containing a notebook to develop, train and validate a regression model\n'], 'url_profile': 'https://github.com/the-rick', 'info_list': ['Jupyter Notebook', 'Updated Jun 4, 2020', 'Updated Sep 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/magus0', 'info_list': ['Jupyter Notebook', 'Updated Jun 4, 2020', 'Updated Sep 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020']}","{'location': 'Atlanta, Georgia', 'stats_list': [], 'contributions': '79 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/aliakdeniz38', 'info_list': ['Jupyter Notebook', 'Updated Jun 4, 2020', 'Updated Sep 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020']}","{'location': 'Noida', 'stats_list': [], 'contributions': '52 contributions\n        in the last year', 'description': ['MachineLearning-LinearRegression\nData Description:\nThe actual concrete compressive strength (MPa) for a given mixture under a\nspecific age (days) was determined from laboratory. Data is in raw form (not\nscaled).The data has 8 quantitative input variables, and 1 quantitative output\nvariable, and 1030 instances (observations).\nDomain:\nMaterial manufacturing\nContext:\nConcrete is the most important material in civil engineering. The concrete\ncompressive strength is a highly nonlinear function of age and ingredients.\nThese ingredients include cement, blast furnace slag, fly ash, water,\nsuperplasticizer, coarse aggregate, and fine aggregate.\nAttribute Information:\n● Cement : measured in kg in a m3 mixture\n● Blast : measured in kg in a m3 mixture\n● Fly ash : measured in kg in a m3 mixture\n● Water : measured in kg in a m3 mixture\n● Superplasticizer : measured in kg in a m3 mixture\n● Coarse Aggregate : measured in kg in a m3 mixture\n● Fine Aggregate : measured in kg in a m3 mixture\n● Age : day (1~365)\n● Concrete compressive strength measured in MPa\nLearning Outcomes:\n● Exploratory Data Analysis\n● Building ML models for regression\n● Hyper parameter tuning\nObjective:\nModeling of strength of high performance concrete using Machine Learning\nSteps and tasks:\n1. Deliverable -1 (Exploratory data quality report reflecting the following)\na. Univariate analysis\ni. Univariate analysis – data types and description of the\nindependent attributes which should include (name,\nmeaning, range of values observed, central values (mean and\nmedian), standard deviation and quartiles, analysis of the\nbody of distributions / tails, missing values, outliers\nb. Multivariate analysis\ni. Bi-variate analysis between the predictor variables and\nbetween the predictor variables and target column. Comment\non your findings in terms of their relationship and degree of\nrelation if any. Presence of leverage points. Visualize the\nanalysis using boxplots and pair plots, histograms or density\ncurves. Select the most appropriate attributes\nc. Strategies to address the different data challenges such as data\npollution, outliers and missing values\n2. Deliverable -2 (Feature Engineering techniques)\na. Identify opportunities (if any) to create a composite feature, drop a\nfeature\nb. Decide on complexity of the model, should it be simple linear\nmode in terms of parameters or would a quadratic or higher degree\nhelp\nc. Explore for gaussians. If data is likely to be a mix of gaussians,\nexplore individual clusters and present your findings in terms of\nthe independent attributes and their suitability to predict strength\n3. Deliverable -3 (create the model )\na. Obtain feature importance for the individual features using\nmultiple methods and present your findings\n4. Deliverable -4 (Tuning the model)\na. Algorithms that you think will be suitable for this project\nb. Techniques employed to squeeze that extra performance out of the\nmodel without making it overfit or underfit\nc. Model performance range at 95% confidence level\n'], 'url_profile': 'https://github.com/sarveshstays', 'info_list': ['Jupyter Notebook', 'Updated Jun 4, 2020', 'Updated Sep 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '108 contributions\n        in the last year', 'description': ['Simple-Linear-regression\n'], 'url_profile': 'https://github.com/ADITEYARAJ', 'info_list': ['R', 'Updated May 11, 2020', '1', 'TeX', 'Updated May 18, 2020', 'R', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Bretagne, France', 'stats_list': [], 'contributions': '54 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/cmmm976', 'info_list': ['R', 'Updated May 11, 2020', '1', 'TeX', 'Updated May 18, 2020', 'R', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '51 contributions\n        in the last year', 'description': ['ds_linear_regression\n'], 'url_profile': 'https://github.com/sm9io', 'info_list': ['R', 'Updated May 11, 2020', '1', 'TeX', 'Updated May 18, 2020', 'R', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '88 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/jel476', 'info_list': ['R', 'Updated May 11, 2020', '1', 'TeX', 'Updated May 18, 2020', 'R', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['REGRESSION\nBike Sharing Dataset\nBike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues.\nApart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.\ninstant: record index\n\ndteday : date\nseason : season (1:winter, 2:spring, 3:summer, 4:fall)\nyr : year (0: 2011, 1:2012)\nmnth : month ( 1 to 12)\nhr : hour (0 to 23)\nholiday : weather day is holiday or not (extracted from [Web Link])\nweekday : day of the week\nworkingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n\n\nweathersit :\n\n1: Clear, Few clouds, Partly cloudy, Partly cloudy\n2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n\n\n\n\ntemp : Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\natemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)\nhum: Normalized humidity. The values are divided to 100 (max)\nwindspeed: Normalized wind speed. The values are divided to 67 (max)\ncasual: count of casual users\nregistered: count of registered users\ncnt: count of total rental bikes including both casual and registered\n\n'], 'url_profile': 'https://github.com/rishikesh5', 'info_list': ['R', 'Updated May 11, 2020', '1', 'TeX', 'Updated May 18, 2020', 'R', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'Cairo, Egypt', 'stats_list': [], 'contributions': '87 contributions\n        in the last year', 'description': [""Multinomial-logistic-regression\nThis is a full design and implementation of multinomial  logistic regression to predict if a breast cancer patient should have chemotherapy before or after surgery or should go to multidisciplinary team .\n\nIdea and objectives\nImplementation\nOutput and evaluation\nDataset\nRun\n\nIdea and objective\nThis model is made for an application that is dedicated to egyptian breast cancer patients of ABC center .\nthe classification problem has 3 ouputs YES , NO or MDT\nImplementation\n\nLinear model\n\nThe linear model equation is the same as the linear equation in the linear regression model.\nfor N features , the puput is as follows : y= w1x1 + w2x2 + ...+wn xn\n\nSoftmax\n\nThe Softmax function is a probabilistic function which calculates the probabilities for the given score. Using the softmax function return the high probability value for the high scores and fewer probabilities for the remaining scores . for every feature N\n\nCross entropy\n\nThe Cross-entropy is a distance calculation function which takes the calculated probabilities from softmax function and the  one-hot-encoding matrix\n\nOne hot encoding\n\nOne-Hot Encoding is a method to represent the target values into a binary representation. For every feature the one-hot-encoding matrix is with the values of 0 and the 1 for the target class. The total number of values in the one-hot-encoding matrix is equal to the number of classes which is 3 in this dataset(yes\\no\\MDT)\nOutput and evaluation\nDue to github non ability to render notebooks most of time , samples of output are screenshoted below .\nThe accuracy of the training set and testing set is not around a stable range as the dataset isn't large and the training/testing split is random every run . One run is shown below\n\nThe prediction on the testing set is shown below using matplotlib\n\nTo fix that I implemented a cross validation function to get the average accuracy and the results are shown below :\n\nDataset\nThis datset is auto generated  with respect to the medical standars . The students working on this data are cairo univeristy students:\n\nYasmine Hatem\nNermine Safwat\nAhmed Khalifa\nAhmed Khaled\n\nThe dataset is labeled and revised by M.D. Omar Sherif Omar\nRun\nDependencies\n\nmatplotlib.pyplot\nPandas\nNumpy\nsklearn.model_selection.train_test_split\n\n""], 'url_profile': 'https://github.com/yasminehatem', 'info_list': ['R', 'Updated May 11, 2020', '1', 'TeX', 'Updated May 18, 2020', 'R', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '10 contributions\n        in the last year', 'description': ['Linear-Regression-Analysis-Project\n'], 'url_profile': 'https://github.com/CCCCassiee', 'info_list': ['R', 'Updated May 11, 2020', '1', 'TeX', 'Updated May 18, 2020', 'R', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '198 contributions\n        in the last year', 'description': ['14.2-Logistic-Regression\n'], 'url_profile': 'https://github.com/junlimfe', 'info_list': ['R', 'Updated May 11, 2020', '1', 'TeX', 'Updated May 18, 2020', 'R', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '65 contributions\n        in the last year', 'description': ['Linear-Regression-from-scratch\nIt contains both single variate and multi-variate linear regression.\n'], 'url_profile': 'https://github.com/vidushibindroo', 'info_list': ['R', 'Updated May 11, 2020', '1', 'TeX', 'Updated May 18, 2020', 'R', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '236 contributions\n        in the last year', 'description': [""Non_linear_regression_analysis\nWe fit a non-linear model to the datapoints corrensponding to China's GDP from 1960 to 2014.\n""], 'url_profile': 'https://github.com/illumi91', 'info_list': ['R', 'Updated May 11, 2020', '1', 'TeX', 'Updated May 18, 2020', 'R', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '47 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/nadiagherman', 'info_list': ['Updated May 15, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'GPL-3.0 license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'Hyderabad, India', 'stats_list': [], 'contributions': '197 contributions\n        in the last year', 'description': ['LinearRegression-from-scratch\nPractical Applications of LR\n'], 'url_profile': 'https://github.com/Aditya-crypto', 'info_list': ['Updated May 15, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'GPL-3.0 license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '120 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/humanoiA', 'info_list': ['Updated May 15, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'GPL-3.0 license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '30 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Anusha-Kokkinti', 'info_list': ['Updated May 15, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'GPL-3.0 license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'Madurai', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/krithika93', 'info_list': ['Updated May 15, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'GPL-3.0 license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': ['House-Prices-Advanced-Regression\n'], 'url_profile': 'https://github.com/alokprasad2020', 'info_list': ['Updated May 15, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'GPL-3.0 license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': ['SimpleLinearRegression\nRequirements:\npandas\nstatsmodel\nmatplotlib\nnumpy.\nIt is simple linear regression , in this it used the statsmodel api to run the code\n'], 'url_profile': 'https://github.com/Praveen11558', 'info_list': ['Updated May 15, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'GPL-3.0 license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'Espírito Santo, Brazil', 'stats_list': [], 'contributions': '166 contributions\n        in the last year', 'description': ['DATASETS FOR LINEAR REGRESSION EXERCISES\nAll datasets were found here (Access at May 17th, 2020) I have just ""translated"" them to CSV format so my fellow students can easily import them to their codes. I hope it has some use for you 😃.\n'], 'url_profile': 'https://github.com/jorgeuliana1', 'info_list': ['Updated May 15, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'GPL-3.0 license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': ' Australia', 'stats_list': [], 'contributions': '115 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ShashankaRangi', 'info_list': ['Updated May 15, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'GPL-3.0 license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/magus0', 'info_list': ['Updated May 15, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020', 'HTML', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'GPL-3.0 license', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/OsmarS10', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'JavaScript', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 24, 2020', '1', 'R', 'Updated Jun 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['EDSA - Sendy Logistics Challenge\nby EXPLORE Data Science Academy\nIntroduction\nLogistics in Sub-Saharan Africa increases the cost of manufactured goods by up to 320%; while in Europe, it only accounts for up to 90% of the manufacturing cost.  Economies are better when logistics is efficient and affordable. Sendy, in partnership with insight2impact facility, is hosting a Zindi challenge to predict the estimated time of delivery of orders, from the point of driver pickup to the point of arrival at final destination.\nOBjectives:\n\nGETTING STARTED\nTHE FOLLOWING STEPS ASSUMES THAT YOU HAVE ANACONDA INSTALLED OR ANY JUPYTER RELATED SOFTWARE\ndevelopment branch = dev\n\nclone the repo to your local machine:\n\n git clone https://github.com/Explore-EDSA-2020/Sendy-Logistics-Challenge.git\n\n\ncheckout the development branch & pull changes to ensure it\'s up to date.\n\ngit checkout Dev\n\ngit pull \n\n\nCreate your own working branch from Dev.\nNB create a branch with a meaningful task/feature name e.g preprocesing\nif you are aiming on preprocessing the data.\n\ngit branch Task_Name\n\n\nAfter completing a minimal task, you may commit.\n\ngit status\ngit add .\ngit commit -m ""comment on changes""\ngit pull\n\n\nTo push your changes to the online repo use:\nNB replace Task_Name with  the  branch name you created.\n\ngit push --set-upstream origin Task_Name \n\n\nIf task is complete and you wish to merge the work to the Dev branch.\ncreate a pull request for review using the web-based github.\n\nif you come across any dificulties, just create an issue and one of the team members will assist\n'], 'url_profile': 'https://github.com/Explore-EDSA-2020', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'JavaScript', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 24, 2020', '1', 'R', 'Updated Jun 12, 2020']}","{'location': 'Cairo, Egypt', 'stats_list': [], 'contributions': '87 contributions\n        in the last year', 'description': [""Multinomial-logistic-regression\nThis is a full design and implementation of multinomial  logistic regression to predict if a breast cancer patient should have chemotherapy before or after surgery or should go to multidisciplinary team .\n\nIdea and objectives\nImplementation\nOutput and evaluation\nDataset\nRun\n\nIdea and objective\nThis model is made for an application that is dedicated to egyptian breast cancer patients of ABC center .\nthe classification problem has 3 ouputs YES , NO or MDT\nImplementation\n\nLinear model\n\nThe linear model equation is the same as the linear equation in the linear regression model.\nfor N features , the puput is as follows : y= w1x1 + w2x2 + ...+wn xn\n\nSoftmax\n\nThe Softmax function is a probabilistic function which calculates the probabilities for the given score. Using the softmax function return the high probability value for the high scores and fewer probabilities for the remaining scores . for every feature N\n\nCross entropy\n\nThe Cross-entropy is a distance calculation function which takes the calculated probabilities from softmax function and the  one-hot-encoding matrix\n\nOne hot encoding\n\nOne-Hot Encoding is a method to represent the target values into a binary representation. For every feature the one-hot-encoding matrix is with the values of 0 and the 1 for the target class. The total number of values in the one-hot-encoding matrix is equal to the number of classes which is 3 in this dataset(yes\\no\\MDT)\nOutput and evaluation\nDue to github non ability to render notebooks most of time , samples of output are screenshoted below .\nThe accuracy of the training set and testing set is not around a stable range as the dataset isn't large and the training/testing split is random every run . One run is shown below\n\nThe prediction on the testing set is shown below using matplotlib\n\nTo fix that I implemented a cross validation function to get the average accuracy and the results are shown below :\n\nDataset\nThis datset is auto generated  with respect to the medical standars . The students working on this data are cairo univeristy students:\n\nYasmine Hatem\nNermine Safwat\nAhmed Khalifa\nAhmed Khaled\n\nThe dataset is labeled and revised by M.D. Omar Sherif Omar\nRun\nDependencies\n\nmatplotlib.pyplot\nPandas\nNumpy\nsklearn.model_selection.train_test_split\n\n""], 'url_profile': 'https://github.com/yasminehatem', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'JavaScript', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 24, 2020', '1', 'R', 'Updated Jun 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '10 contributions\n        in the last year', 'description': ['Linear-Regression-Analysis-Project\n'], 'url_profile': 'https://github.com/CCCCassiee', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'JavaScript', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 24, 2020', '1', 'R', 'Updated Jun 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '198 contributions\n        in the last year', 'description': ['14.2-Logistic-Regression\n'], 'url_profile': 'https://github.com/junlimfe', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'JavaScript', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 24, 2020', '1', 'R', 'Updated Jun 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '65 contributions\n        in the last year', 'description': ['Linear-Regression-from-scratch\nIt contains both single variate and multi-variate linear regression.\n'], 'url_profile': 'https://github.com/vidushibindroo', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'JavaScript', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 24, 2020', '1', 'R', 'Updated Jun 12, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '236 contributions\n        in the last year', 'description': [""Non_linear_regression_analysis\nWe fit a non-linear model to the datapoints corrensponding to China's GDP from 1960 to 2014.\n""], 'url_profile': 'https://github.com/illumi91', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'JavaScript', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 24, 2020', '1', 'R', 'Updated Jun 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '40 contributions\n        in the last year', 'description': ['Linear-Regression-Gradient-Descent-\n'], 'url_profile': 'https://github.com/denode15', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'JavaScript', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 24, 2020', '1', 'R', 'Updated Jun 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '29 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/garychumd', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'JavaScript', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 24, 2020', '1', 'R', 'Updated Jun 12, 2020']}","{'location': 'Indonesia', 'stats_list': [], 'contributions': '198 contributions\n        in the last year', 'description': ['General sensitivity of Indonesia’s rainfall: pixel-wise regression between rainfall and sea surface temperature\nClimate variability directly influences many aspects of food and nutrition security, particularly food availability and access. Variation in rainfall is a common element of many natural disasters – droughts, floods, typhoons and tsunamis – and is influenced by global, regional and/or local factors.\nGlobal climate factors including El Niño, La Niña and the dipole mode; regional factors include monsoon circulation, the Madden-Julian oscillation and fluctuations in the surface temperature of the Indonesian Sea; and local factors can include elevation, island position, the circulation of land and sea breezes, and land cover.\nThe level of climate risk is measured based on the strength of ENSO signal on rainfall variability using correlation analysis. This approach is applied because production loss of food crops in Indonesia is closely associated with the ENSO phenomena. El Nino years is normally associated with drought years, while La-Nina is often related to wet years which can cause flood hazards. The correlation analysis is applied to monthly rainfall anomaly and sea surface temperature anomaly in NINO3.4.\nThe NINO-3.4 region is optimal for monitoring El Niño-Southern Oscillation (ENSO) and its impacts in Indonesia and possibly Southeast Asia.\nObjective\nChange in rainfall with 1° increase in sea surface temperature (SST) of NINO-3.4 region, as a signal for moderate El Niño.\nMethod\n\nCalculate monthly rainfall anomaly The anomaly is calculated as the following:\nAnomaly(X)ii = Xij – mean(X)i\nWhere Xij is data of month-i in year-j while mean(X)i is average data for month-i over a number of years.\nSimple regression will apply to indicate the correlation between rainfall anomaly in each area to anomaly of SST in the Pacific Ocean which represent ENSO signals. Y = a + bX, where: Y = Rainfall anomaly, a = Y intercept, b = Slope, X = SST anomaly, If the correlation is not significant (p-value > 0.05, slope is set to 0 (zero).\n\nData\nTimor-Leste data are provided for example analysis, both data came from below.\n\n35 years (1981-2017) monthly rainfall data used in the analysis are downloaded from Climate Hazards Center - UC Santa Barbara (https://chc.ucsb.edu/data-sets/chirps), and\nSST anomaly in NINO-3.4 region from ERSST v5 of National Oceanic and Atmospheric Administration (NOAA) (https://www.cpc.ncep.noaa.gov/products/analysis_monitoring/ensostuff/detrend.nino34.ascii.txt).\n\nRainfall data available in GeoTIFF, but SST is in text format. In order to do pixel-wise regression between two rasters, both data must available in GeoTIFF raster format and in the same dimension (width and height). As the SST data is only from single location in NINO3.4 then we need to do some data tweak and manipulation. Follow the procedure as written in this blog post: https://benny.istan.to/blog/20190708-pixel-wise-regression-between-rainfall-and-sea-surface-temperature\nContents\n\nA raster file (GeoTIFF) from the slope and correlation of both data.\nR script for the pixel-wise regression.\n\nExample output\n\nSlope map.\n\nCorrelation map.\n\nPvalue map.\n\n\nReferences\n\nhttps://matinbrandt.wordpress.com/2014/05/26/pixel-wise-regression-between-two-raster-time-series/\nhttps://www.hakimabdi.com/blog/test-pixelwise-correlation-between-two-time-series-of-raster-data-in-r?format=amp\n\nContact\nUsing above reference, this works done by Anggita Annisa, a final year student from Department of Statistics - IPB who is doing an internship in VAM unit of WFP Indonesia from June - August 2019. If you have any question related to this tool and application for other areas, contact Benny Istanto\n'], 'url_profile': 'https://github.com/bennyistanto', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated Jun 10, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'JavaScript', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 24, 2020', '1', 'R', 'Updated Jun 12, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['EDSA - Sendy Logistics Challenge\nby EXPLORE Data Science Academy\nIntroduction\nLogistics in Sub-Saharan Africa increases the cost of manufactured goods by up to 320%; while in Europe, it only accounts for up to 90% of the manufacturing cost.  Economies are better when logistics is efficient and affordable. Sendy, in partnership with insight2impact facility, is hosting a Zindi challenge to predict the estimated time of delivery of orders, from the point of driver pickup to the point of arrival at final destination.\nOBjectives:\n\nGETTING STARTED\nTHE FOLLOWING STEPS ASSUMES THAT YOU HAVE ANACONDA INSTALLED OR ANY JUPYTER RELATED SOFTWARE\ndevelopment branch = dev\n\nclone the repo to your local machine:\n\n git clone https://github.com/Explore-EDSA-2020/Sendy-Logistics-Challenge.git\n\n\ncheckout the development branch & pull changes to ensure it\'s up to date.\n\ngit checkout Dev\n\ngit pull \n\n\nCreate your own working branch from Dev.\nNB create a branch with a meaningful task/feature name e.g preprocesing\nif you are aiming on preprocessing the data.\n\ngit branch Task_Name\n\n\nAfter completing a minimal task, you may commit.\n\ngit status\ngit add .\ngit commit -m ""comment on changes""\ngit pull\n\n\nTo push your changes to the online repo use:\nNB replace Task_Name with  the  branch name you created.\n\ngit push --set-upstream origin Task_Name \n\n\nIf task is complete and you wish to merge the work to the Dev branch.\ncreate a pull request for review using the web-based github.\n\nif you come across any dificulties, just create an issue and one of the team members will assist\n'], 'url_profile': 'https://github.com/Explore-EDSA-2020', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Jupyter Notebook', 'Updated Nov 1, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'R', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Python', 'Updated Sep 4, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 19, 2020']}","{'location': 'Mumbai, India', 'stats_list': [], 'contributions': '295 contributions\n        in the last year', 'description': ['Intrusion-Detection-System\n\nThis Intrusion Detection System uses Logistic Regression to differentiate between Valid URL request queries and Malicious URL request queries for Web Applications.\nThe dataset for Valid Queries can be found at: http://www.secrepo.com/\nThe dataset for Malicious Queries can be found at: https://github.com/foospidy/payloads\nThe pruned datasets can be found in the repo:\nValid Queries \xa0 \xa0 Malicious Queries\nAccuracy\nUsing just Logistic Regression, I was able to achieve an accuracy of 99.94% wherein only 28 out of 8881 malicious queries passed through the Intrusion Detection System.\n\n\n'], 'url_profile': 'https://github.com/premnagdeo', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Jupyter Notebook', 'Updated Nov 1, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'R', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Python', 'Updated Sep 4, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 19, 2020']}","{'location': 'Jaypee University of Engineering and Technology,Guna(M.P)', 'stats_list': [], 'contributions': '595 contributions\n        in the last year', 'description': ['ANN-Perceptron-Linear-Regression-Model-for-Weight_Prediction\nMy implementation of ANN Perceptron Linear Regression Model for Weight Prediction\n'], 'url_profile': 'https://github.com/rajansh87', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Jupyter Notebook', 'Updated Nov 1, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'R', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Python', 'Updated Sep 4, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 19, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '8 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/gsreeram11', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Jupyter Notebook', 'Updated Nov 1, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'R', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Python', 'Updated Sep 4, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 19, 2020']}","{'location': 'Kolkata, West Bengal, India', 'stats_list': [], 'contributions': '121 contributions\n        in the last year', 'description': ['UCI-Bulldozer-Price-Prediction\n'], 'url_profile': 'https://github.com/Debadri3', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Jupyter Notebook', 'Updated Nov 1, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'R', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Python', 'Updated Sep 4, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 19, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': [""Predicting Housing Price\nProject Summary\nIn the Kaggle competition House Prices: Advanced Regression Techniques. We are asked to build a model that to predict the house prices based on characteristics using the provided data set.\nRound 1 - Baseline Modeling\nIn this round of analysis, I looked at the house prices data, performed basic data cleaning and EDA, fit the data with a list of common regression models and compared their performances. I chose XGBoostRegression, without hyperparameter tuning, as the final model and achieved a PL score of 0.13921 (root mean square log error) on the test dataset, ranking at around 50% on Kaggle (as of May 2020).\nData cleaning\n\nDrop 4 columns with over 80% of missing value\nSeparated categorical and numeric variables according to datetype (except for 'MSSubClass')\nReplaced missing values with a new category 'ZZZ' for categorical variables\nReplaced missing values with median for numeric variables\n\nEDA:\n\nVisualized categorical variables and their relationships with target variable using countplot and barplot\nVisualized numeric variables and their relationships with target variable using histplot, box plot, and scatter plot with target variable\nCorrelation matrix (heat map) for numeric variables\nCorrelation and p-value between numeric features and target variable\n\nFeature engineering / selection\n\nApplied StandardScaler to all numeric variables\nCreated new features from categorical variables using OneHotEncoding (with drop_first=True)\nAll features are used for all models\n\nModeling\n\nUsed 5-fold cross-validation to compare a list of regression models (default parameters)\nXGBOOST and GradientBoost have the best performance in terms of 'neg_mean_absolute_error'\nLooked at the feature significance from XGBOOST but no further feature selection is performed\n\nFuture improvements\n\nThe modeling results from SVR and Multi-variate Linear Regression seem to be completely off. It is worth to investigate why. Multicolinearity could be a problem but I am not yet convinced this is the only reason.\nSome numerical variables can be transformed to categorical (e.g. Year, Month)\nWe can spend more time on Linear Models (Ridge, LASSO). This would require more work on feature transformation (normality check + log / box-cox transformation), and feature extraction/selection. Would be good to practice these technics.\nUse GridSearch to tune hyperparameters.\n\nRound 2 - Feature Engineering\nIn this round of analysis, I focused on creating a workflow for data cleaning and feature engineering. More specifically, I have used the following technics:\n\nOrdinal encoding for features with ordinality\nImputing missing values using correlated features\nCreating new features such as NeighborhoodRating\nChecking normality for target variable and important features, and applying log-transform\nVisualizing potential outliers and making careful decision for deletion\nCreating customized One Hot Encoding method to avoid information leakage from test data\nImplementing one subclass of sklearn BaseEstimator per data transformation step, and stacking them into a sklearn Pipeline to allow for clean code and easy manipulation.\n\nAfter feature engineering, I also performed PCA analysis due to the high dimensionality.\nIn the modeling part, I focused on LASSO regression model and used GridSearchCV to tune regularization parameter. We achieved a PL score of 0.12352 with the final model, which was a significant improvement from round 1 (0.13921 XGBOOST).\nExample Visualizations\n\n\n\n\n\nTools\nPython Version: 3.7\nPackages: pandas, numpy, sklearn, matplotlib, seaborn\nResources\nIn order to improve the performance of the machine learning model, I borrowed ideas from some articles online.\n\nHouse Prices Solution [top 1%]\nHouse prices: Lasso, XGBoost, and a detailed EDA\n\n""], 'url_profile': 'https://github.com/epflyingzhang', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Jupyter Notebook', 'Updated Nov 1, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'R', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Python', 'Updated Sep 4, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 19, 2020']}","{'location': 'Earth', 'stats_list': [], 'contributions': '469 contributions\n        in the last year', 'description': [""ETL-ML-Cassandra\nIn this project, by using Google stock data, an ETL job is done with benefits of pandas data frame and Cassandra database. Then after that, all data are extracted from Cassandra and after prepossessing for the purpose of predicting the next month stock's closing price is done, a linear model is going to be developed. Finally, a linear model with Test Accuracy of  96.88 % is designed.\nRun\nBy this command all task will be run:\ndocker-compose up --build\nTo remove containers:\ndocker-compose down -v\nTools\nML: Pandas, Sklearn\nDB: Cassandra\nBuild: docker, docker-compose\nMedium\n""], 'url_profile': 'https://github.com/arezamoosavi', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Jupyter Notebook', 'Updated Nov 1, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'R', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Python', 'Updated Sep 4, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 19, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/christopherkevin11', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Jupyter Notebook', 'Updated Nov 1, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'R', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Python', 'Updated Sep 4, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 19, 2020']}","{'location': 'Hyderabad,Telangana,India', 'stats_list': [], 'contributions': '219 contributions\n        in the last year', 'description': ['Restaurent-Revenue-prediction\nThis is a regression project. RandomForestRegressor is used to achieve 89% accuracy.\nTwo new features are extraction from existing ones.\nTwo dummies are created for categorical attributes.\n'], 'url_profile': 'https://github.com/narsym', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Jupyter Notebook', 'Updated Nov 1, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'R', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Python', 'Updated Sep 4, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 19, 2020']}","{'location': 'LUMS, Lahore', 'stats_list': [], 'contributions': '371 contributions\n        in the last year', 'description': ['sarcasm-detector\nComparing KNN, Logistic Regression and Perceptron classification algorithms for Sarcasm Detection in News Headlines\n'], 'url_profile': 'https://github.com/saadullah01', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', '2', 'Jupyter Notebook', 'Updated Nov 1, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'R', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Python', 'Updated Sep 4, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 19, 2020']}"
"{'location': 'Boston', 'stats_list': [], 'contributions': '165 contributions\n        in the last year', 'description': ['Projects done in R\nThis repository has multiple R projects covering multiple usecases.\n'], 'url_profile': 'https://github.com/lokyGit', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Nov 29, 2020', 'Python', 'Updated Feb 18, 2021', 'R', 'Updated Feb 20, 2021', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Oct 2, 2020']}","{'location': 'Nicosia,North Cyprus', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/MertYakupBaykan', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Nov 29, 2020', 'Python', 'Updated Feb 18, 2021', 'R', 'Updated Feb 20, 2021', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Oct 2, 2020']}","{'location': 'Albuquerque, New Mexico', 'stats_list': [], 'contributions': '215 contributions\n        in the last year', 'description': ['vvtest\nvvtest is a test harness specialized for running regression, validation,\nand verification tests on high performance computing (HPC) platforms.\nAt a high level, vvtest just selects and runs scripts, called tests.\nIt is the test specification and management capabilities together with the\nplugin and control features that enable the execution of complex tests on\nworkstations up to large HPC platforms.\nNotable features include:\n\nPure Python, compatible with versions 2.6+ and 3.x\nBuilt-in CPU & GPU resource management and load balancing\nBuilt-in support for HPC batch queuing systems, such as SLURM and LSF\nTest parameterization, allowing a single script file to produce multiple\ntest instances with different parameter values\nInter-test dependencies - tests can depend on other tests. Dependencies\nare run first and the results are available in the dependent test.\nTest selection and execution control, such as by keyword, parameter,\nplatform, and a general option string\nTests can be any script language, but there is built-in support for Python\nand (to a lesser extent) Bash\nConfiguration and plugins allow control over testing behavior\nTests are executed in a separate directory from the test scripts\n(""out of source"" execution)\nTest result output formats include CDash, GitLab markdown, JUnit, and HTML.\n\nDocumentation\n\nRun vvtest -h to show the options.\nRun vvtest help <subhelp> to get help by topic area, such as ""resources""\nand ""filters"".\nThe RELEASE_NOTES file is kept up to date.\nAdditional documentation available on the wiki.\n\nAdditional Utilities\n\nThe vvtools V&V testing utilities. This is a collection of Exodus-based\nutilities for running verification analyses on simulation output. It has\nits origins in ALEGRA but is much more generally applicable. The main tools\nhere are exodus.py, not to be confused with the  seacas file of the same\nname, and vcomp, a convergence analysis tool.\n\nDownload and Install\nSince the only dependency is a *NIX OS with basic Python, just clone the\nvvtest repository and run the vvtest script. You can optionally run the\ninstall_vvtest script to install into a prefix of your choice.\nAn Example\nConsider a file called mytest.vvt with contents\n# This is my cool test.\n#VVT: parameterize: np = 1 2\n\nimport vvtest_util as vvt\nimport shared_stuff as stuff\n\nprint ( \'Starting test {0} np={1}\'.format( vvt.NAME, vvt.np ) )\n\nstuff.run_simulation( myoption=\'foo\', numcpu=vvt.np )\nstuff.check_results()\n\nThis test could be run as follows:\n$ ls -R\n.:\nconfigdir  mytest.vvt\n\n./configdir:\nshared_stuff.py\n\n$ vvtest --config=configdir\n==================================================\nTest list:\n    completed: 0\n    notrun: 2\n    total: 2\n\nPlatform ceelan, num procs = 16, max procs = 16\nStart time: Fri Jun  5 18:07:34 2020\nStarting: TestResults.ceelan/mytest.np=2\nStarting: TestResults.ceelan/mytest.np=1\nFinished: pass        0:01 06/05 18:07:34 TestResults.ceelan/mytest.np=2\nFinished: pass        0:01 06/05 18:07:34 TestResults.ceelan/mytest.np=1\nProgress: 2/2 = %100.0, time = 1s\n\n==================================================\nSummary:\n    completed: 2\n          2 pass\n    total: 2\n\nFinish date: Fri Jun  5 18:07:35 2020 (elapsed time 2s)\nTest directory: TestResults.ceelan\n\n$ ls -F TestResults.ceelan/mytest.np=2\nexecute.log  mytest.vvt@  vvtest_util.py  vvtest_util.pyc  vvtest_util.sh\n\nNote that the test specification file, mytest.vvt, resulted in two test\ninstances, mytest.np=1 and mytest.np=2, which ran and passed.\nIn the test script, the vvtest_util Python module is specific to each\ntest and contains information about the test instance and runtime parameters.\nThe shared_stuff is a (hypothetical) Python module that the software\nproject itself supplies in a configuration directory.\nFinally, whether the test passes or fails, the execute.log file contains\nthe output (stdout and stderr).\nTesting\nHistory\nvvtest evolved from Mike Wong\'s test infrastructure in the late 1990s,\nthrough a python rewrite in the mid 2000s, to a refactoring in 2016 to\nmake it a project independent utility.\nCopyright\nCopyright 2018 National Technology & Engineering Solutions of Sandia, LLC\n(NTESS). Under the terms of Contract DE-NA0003525 with NTESS, the U.S.\nGovernment retains certain rights in this software.\n\n\nRedistributions of source code must retain the above copyright notice, this\nlist of conditions and the following disclaimer.\n\n\nRedistributions in binary form must reproduce the above copyright notice,\nthis list of conditions and the following disclaimer in the documentation\nand/or other materials provided with the distribution.\n\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n'], 'url_profile': 'https://github.com/rrdrake', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Nov 29, 2020', 'Python', 'Updated Feb 18, 2021', 'R', 'Updated Feb 20, 2021', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Oct 2, 2020']}","{'location': 'Dublin', 'stats_list': [], 'contributions': '43 contributions\n        in the last year', 'description': [""AdultwithMachinelearningModels\n• This project aims to classify the status of the people based on their financial record in order to identify class of people from the given data.\n• The algorithms used for this classification are Random Forest and Support Vector Machine (SVM), which are implemented using R programming and it's libraries.\n• The code is not divided into number of files, it is present only in Adult_dataset.R file. The file  Adult_dataset.R contains main function, which invokes functions to train the model from scratch and then use the trained model to identify salary amount on the given input data.\n• A model trained using train and test function is saved and the final class analysis of the machine learning models are also stored. This file is used to restore the model state when new data is given as input to the model for classification.\n• The details of SVM and Random Forest architecture including are given in the project report file. These models achieved an F1 score of 0.84 (84%) with SVM and 0.96 (96%) with Random Forest when evaluated using test dataset.\n""], 'url_profile': 'https://github.com/Ameyadalal', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Nov 29, 2020', 'Python', 'Updated Feb 18, 2021', 'R', 'Updated Feb 20, 2021', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Oct 2, 2020']}","{'location': 'Dehradun ', 'stats_list': [], 'contributions': '57 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/aish0233', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Nov 29, 2020', 'Python', 'Updated Feb 18, 2021', 'R', 'Updated Feb 20, 2021', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Oct 2, 2020']}","{'location': 'Karnataka, India', 'stats_list': [], 'contributions': '43 contributions\n        in the last year', 'description': ['Linear-Regression-in-R-for-Public-Health\nInvolves building a linear regression model to analyze the public health data\n'], 'url_profile': 'https://github.com/abhishek2079', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Nov 29, 2020', 'Python', 'Updated Feb 18, 2021', 'R', 'Updated Feb 20, 2021', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Oct 2, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '20 contributions\n        in the last year', 'description': ['Boston-Housing-price-prediction-using-machine-learning\nPredict the price of houses(Boston Housing DataSet) using linear regression machine learning algorithm.\nLinearRegression.ipynb\n    This file import dataset and predict the price of houses using linear regression algorithm\n\nMeanSquareError.ipynb\n    This file shows how to generate mean square error from dataset.\n\nThankYou Skyfi Labs to guided me for this project.\n'], 'url_profile': 'https://github.com/vp7096', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Nov 29, 2020', 'Python', 'Updated Feb 18, 2021', 'R', 'Updated Feb 20, 2021', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Oct 2, 2020']}","{'location': 'India', 'stats_list': [], 'contributions': '228 contributions\n        in the last year', 'description': ['Sentiment-Analysis-with-Logistic-Regression\nSentiment Analysis of Movie Reviews using Supervised, Classification Model - Logistic Regression\nAuthor\nGaurav Kabra\nPre-requisites\nGoogle Colab and basic understanding of Logistic regression and Natural Language Processing\n'], 'url_profile': 'https://github.com/gaurav-kabra-official', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Nov 29, 2020', 'Python', 'Updated Feb 18, 2021', 'R', 'Updated Feb 20, 2021', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Oct 2, 2020']}","{'location': 'India', 'stats_list': [], 'contributions': '149 contributions\n        in the last year', 'description': ['Black-Friday-Sales-Prediction\n\nTable Of Contents\n\nProject Introduction\nDataset Description\nEDA\nData Preprocessing\nModeling Phase\nEvaluation Metric\nConclusion\n\nProject Introduction\nBlack Friday is an informal name for the Friday following Thanksgiving Day in the United States, which is celebrated on the fourth Thursday of November. The day after Thanksgiving has been regarded as the beginning of the United States Christmas shopping season since 1952, although the term ""Black Friday"" did not become widely used until more recent decades. Many stores offer highly promoted sales on Black Friday and open very early, such as at midnight, or may even start their sales at some time on Thanksgiving. The major challenge for a Retail store or eCommerce business is to choose product price such that they get maximum profit at the end of the sales. Our project deals with determining the product prices based on the historical retail store sales data. After generating the predictions, our model will help the retail store to decide the price of the products to earn more profits.\nDataset Description\nThe dataset is acquired from an online data analytics hackathon hosted by Analytics Vidhya. The data contained features like age, gender, marital status, categories of products purchased, city demographics, purchase amount etc. The data consists of 12 columns and 537577 records. Our model will be predicting the purchase amount of the products.\nEDA:\nBelow are the observations which we have made from the data visualization done as part of the Data Understanding process.\n\nApproximately, 75% of the number of purchases are made by Male users and rest of the 25% is done by female users. This tells us the Male consumers are the major contributors to the number of sales for the retail store.On average the male gender spends more money on purchase contrary to female, and it is possible to also observe this trend by adding the total value of purchase.\nWhen we combined Purchase and Marital_Status for analysis, we came to know that Single Men spend the most during the Black Friday. It also tells that Men tend to spend less once they are married. It maybe because of the added responsibilities.\nFor Age feature, we observed the consumers who belong to the age group 25-40 tend to spend the most.\nThere is an interesting column Stay_In_Current_City_Years, after analyzing this column we came to know the people who have spent 1 year in the city tend to spend the most. This is understandable as, people who have spent more than 4 years in the city are generally well settled and are less interested in buying new things as compared to the people new to the city, who tend to buy more.\nWhen examining which city the product was purchased to our surprise, even though the city B is majorly responsible for the overall sales income, but when it comes to the above product, it majorly purchased in the city C.\n\nData Preparation\n\nUsed LabelEncoder for encoding the categorical columns like Age, Gender and City_Category\nUsed get_dummies form Pandas package for converting categorical variable State_In_Current_Years into dummy/indicator variables.\nFilled the missing values in the Product_Category_2 and Product_Category_3\n\nModeling Phase\n\nSplitted dataset into into random train and test subset of ratio 80:20\nImplemented multiple supervised models such as Linear Regressor, Decision Tree Regressor, Random Forest Regressor.\n\nEvaluation Metric\nRoot Mean Square Error (RMSE) is a standard way to measure the error of a model in predicting quantitative data. It’s the square root of the average of squared differences between prediction and actual observation.\nConclusion\nImplanted multiple supervised models such as Linear Regressor,Decision Tree Regressor, Random Forest Regressor and XGBOOST Regressor. Out of these supervised models, based on the RMSE scores XGBRegressor/XGBOOST Regressor was the best performer with a score of 2879.\n'], 'url_profile': 'https://github.com/nanthasnk', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Nov 29, 2020', 'Python', 'Updated Feb 18, 2021', 'R', 'Updated Feb 20, 2021', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Oct 2, 2020']}","{'location': 'Nigeria', 'stats_list': [], 'contributions': '69 contributions\n        in the last year', 'description': ['Titanic---Predicting-Survival\nMy implementations of the logistic regression model on the famous Titanic dataset\n'], 'url_profile': 'https://github.com/Anniejoan', 'info_list': ['R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Nov 29, 2020', 'Python', 'Updated Feb 18, 2021', 'R', 'Updated Feb 20, 2021', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 24, 2020', 'Jupyter Notebook', 'Updated Oct 2, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '114 contributions\n        in the last year', 'description': ['Logistic-regression-implementation-from-scratch\nImplemented logistic regression from scratch. Along with it, implemented regularization from scratch.\n'], 'url_profile': 'https://github.com/Pooja269', 'info_list': ['Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Julia', 'Updated May 16, 2020']}","{'location': 'Algiers, Algeria', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['Regressor\npredicting the brain weight size using a linear regression model from scratch in python\nand evaluating the model with the root mean squared error\n, using the headbrain dataset got from Kaggle.com.\nFor more info please mail the following adresse : nassim.elkefif@gmail.com\n'], 'url_profile': 'https://github.com/Nassimalpha', 'info_list': ['Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Julia', 'Updated May 16, 2020']}","{'location': 'San Antonio, TX', 'stats_list': [], 'contributions': '193 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Suggestions-Only', 'info_list': ['Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Julia', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '191 contributions\n        in the last year', 'description': ['Logistic Regression with advanced Optimizers\nAll the optimizers have been followed from  this  research Paper\n'], 'url_profile': 'https://github.com/VinitSR7', 'info_list': ['Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Julia', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '285 contributions\n        in the last year', 'description': ['StatisticalLearning\nPredicting Glioblastoma Survival with Multiple Linear Regression and Random Forest techniques\n'], 'url_profile': 'https://github.com/jmhobbs29', 'info_list': ['Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Julia', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['Mounika-4099-\nIn this file briefly discussion about linear regression in machine learning algorithm\n'], 'url_profile': 'https://github.com/9919004099', 'info_list': ['Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Julia', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/cyberfag', 'info_list': ['Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Julia', 'Updated May 16, 2020']}","{'location': 'San Francisco', 'stats_list': [], 'contributions': '246 contributions\n        in the last year', 'description': ['Python-ML-Workshop\n'], 'url_profile': 'https://github.com/geoffswc', 'info_list': ['Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Julia', 'Updated May 16, 2020']}","{'location': 'Hsinchu, Taiwan', 'stats_list': [], 'contributions': '65 contributions\n        in the last year', 'description': ['Multiclass Tumor Classification Using One-vs-one Classifiers\nThis project aims to classify 5 different classes of tumors based on cleaned tabular data with 800+ features. Given the few samples for each class, I trained a logistic regression classifier for each pair of classes (e.g. 1 classifier to classify if a given data point is more likely to be Class 1 or Class 2) and adopted Learning Valued Preference for Classification (LVPC), a voting strategy that considers the score matrix as a fuzzy preference relation, to aggregate the result.\nAll the codes are written in Python using Pandas, Numpy, Matplotlib and Scikit-learn libraries.\n'], 'url_profile': 'https://github.com/achen353', 'info_list': ['Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Julia', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '57 contributions\n        in the last year', 'description': ['Housing-Price-Predictions\nThis is a project on predicting housing prices using Linear and Polynomial Regression, using feature selection\n'], 'url_profile': 'https://github.com/iamdas3', 'info_list': ['Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 16, 2020', 'Updated May 17, 2020', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Julia', 'Updated May 16, 2020']}"
"{'location': 'Pune', 'stats_list': [], 'contributions': '154 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/amitdivekar30', 'info_list': ['R', 'Updated May 13, 2020', 'R', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['machine-learning\nClassification and regression Machine learning algorithms have been implemented on few datasets using R studios\nIn the attached Zip file you can find 3 different datasets.\n\nSignal prediction.   ---------       logistic and Support vector machine.\nBike sharing prediction.------       Linear, Lasso which also includes Ridge regression.\nFuel consumption prediction.--       linear and random forest regression.\n\nthis algorithms includes data cleaning as well.\n'], 'url_profile': 'https://github.com/Maheswar00', 'info_list': ['R', 'Updated May 13, 2020', 'R', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '28 contributions\n        in the last year', 'description': ['Binary-Classifiers\nData Science Project in R Markdown using LDA, QDA, and Logistic Regression\n'], 'url_profile': 'https://github.com/mnagired', 'info_list': ['R', 'Updated May 13, 2020', 'R', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '40 contributions\n        in the last year', 'description': ['mlr_project\nFinal group project for MTH291 Multiple Regression at Smith College (Spring 2018)\nApplied topics in multiple regression to explore the relationship between health condition and individual income among disabled people\nTeam: Ha Cao, Jeny Kwon, Maddie Haines\n'], 'url_profile': 'https://github.com/jenykwon', 'info_list': ['R', 'Updated May 13, 2020', 'R', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '54 contributions\n        in the last year', 'description': ['MachineLearning\n'], 'url_profile': 'https://github.com/yogendra221', 'info_list': ['R', 'Updated May 13, 2020', 'R', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020']}","{'location': 'Gothenburg, Sweden', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': ['Titanic-ML-LR-KNN-DT-RF-\nTitanic- Predict survival rate using Logistic Regression, K-Nearest Neighbors, Decision Tree, Random Forest\n'], 'url_profile': 'https://github.com/sandeepthimmappa', 'info_list': ['R', 'Updated May 13, 2020', 'R', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020']}","{'location': ' Gujarat, India', 'stats_list': [], 'contributions': '75 contributions\n        in the last year', 'description': [""ML_Algorithm_to_check_COVID_Infection\nUsing Logistic Regression the algorithm is trained with assumed data to detect the probability of infection\nErrors yet to deal\nThere are few errors\n\nData isn't accurate\nThe probablitiy is incorrect\n\nAlso the main.py file contains file\nJupyter Notebooks to train data\nThe data.csv file is trained on Jupyter server\nThe probability is correct on the jupyter sever the flaws are observed in the Flask sever while obtaining data from the user.\n""], 'url_profile': 'https://github.com/Shreybanugariya', 'info_list': ['R', 'Updated May 13, 2020', 'R', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['HeartDisease\nDeploying Logistic Regression to predict possible death from given test parameters.\n'], 'url_profile': 'https://github.com/neelabhpaul', 'info_list': ['R', 'Updated May 13, 2020', 'R', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['Student-Performance-Analysis\nAnalysed student dataset and predicted the marks with the help of linear regression.\n'], 'url_profile': 'https://github.com/abhinav195', 'info_list': ['R', 'Updated May 13, 2020', 'R', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '8 contributions\n        in the last year', 'description': ['regbayes\nAn R package for linear regression with bayesian and classical inference.\nHow to install\nlibrary(devtools)\ninstall_github(""marialaura-mllm/regbayes"")\nHow to use\nUse the function lm_regbayes(formula, data, approach=c(""mle"",""bayes""), mu_beta=0, sigma_beta=10, a_sigma=0.1, b_sigma=0.1, ...)\nto adjust a liner regrssion model. With the approach parameter you can choose the estimation method, mle for maximum likelihood\nestimation and bayes for estimation via bayesian inference.\nExample:\n#load package\nlibray(regbayes) \n#adjusting the model\nmod <- lm_regbayes(Sepal.Length~Petal.Length, approach=""bayes"", data = iris)\n#observing the model adjust result\nsummary(mod)\n'], 'url_profile': 'https://github.com/marialaura-mllm', 'info_list': ['R', 'Updated May 13, 2020', 'R', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020']}"
"{'location': 'Syracuse, NY', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': [""Adult Income Prediction\nA prediction model to determine if a person's income is over $50,000 a year.\nDataset\nThe dataset is extracted from the 1994 Census database and is available on the UCI repository. The size of the dataset is 48,842 rows and includes 14 attributes such as age, gender, occupation, number of hours the individual works per week, etc.\nApproach\n\nExploratory data analysis (uni-variate and bi-variate)\nData preprocessing (deduplication, handling missing values)\nClassification using logistic regression\nClassification using a gradient boosting machine\nFeature engineering\n\nResults\n\n\n\nAlgorithm\nAccuracy\nArea under the curve\n\n\n\n\nLogistic regression\n81.63%\n0.862\n\n\nGradient boosting machine\n82.58%\n0.881\n\n\n\n""], 'url_profile': 'https://github.com/nisharangnani', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'Noida, India', 'stats_list': [], 'contributions': '43 contributions\n        in the last year', 'description': ['programming_best_fit_line_linear_reg_from_scratch\nProgramming best fit line for linear regression using only numpy (and matplotlib for visualization)\n'], 'url_profile': 'https://github.com/maulik30', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['HeartDisease\nDeploying Logistic Regression to predict possible death from given test parameters.\n'], 'url_profile': 'https://github.com/neelabhpaul', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '36 contributions\n        in the last year', 'description': ['Student-Performance-Analysis\nAnalysed student dataset and predicted the marks with the help of linear regression.\n'], 'url_profile': 'https://github.com/abhinav195', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '8 contributions\n        in the last year', 'description': ['regbayes\nAn R package for linear regression with bayesian and classical inference.\nHow to install\nlibrary(devtools)\ninstall_github(""marialaura-mllm/regbayes"")\nHow to use\nUse the function lm_regbayes(formula, data, approach=c(""mle"",""bayes""), mu_beta=0, sigma_beta=10, a_sigma=0.1, b_sigma=0.1, ...)\nto adjust a liner regrssion model. With the approach parameter you can choose the estimation method, mle for maximum likelihood\nestimation and bayes for estimation via bayesian inference.\nExample:\n#load package\nlibray(regbayes) \n#adjusting the model\nmod <- lm_regbayes(Sepal.Length~Petal.Length, approach=""bayes"", data = iris)\n#observing the model adjust result\nsummary(mod)\n'], 'url_profile': 'https://github.com/marialaura-mllm', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '80 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/MiguelAspis', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'Egypt', 'stats_list': [], 'contributions': '88 contributions\n        in the last year', 'description': [""Yelp-Restaurant-s-Rate-Predictor\nA Linear Regression model built on the famous rating service (Yelp!) for predicting restaurant's rating.\n\n\n\nCorrelations\n\n\n\n\n\n\n\n\n\n\n\n\nModeling Based on Sentiment-only\n\n\n\nModeling Based on Binary Features\n\n\n\nModeling Based on Numeric Features\n\n\n\nModeling Based on All Features\n\n\n\nVisualizing Scores\n\n\n\n""], 'url_profile': 'https://github.com/Muhammad-Yousef', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '249 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Marthacz', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'Charlotte, NC', 'stats_list': [], 'contributions': '82 contributions\n        in the last year', 'description': ['Boston House price prediction\nRegression predictive modeling machine learning problem from end-to-end in Python.\nEach record in the database describes a Boston suburb or town. The data was drawn from the Boston Standard Metropolitan Statistical Area (SMSA) in 1970. The attributes are deﬁned as follows (taken from the UCI Machine Learning Repository1): CRIM: per capita crime rate by town\n\nZN: proportion of residential land zoned for lots over 25,000 sq.ft.\nINDUS: proportion of non-retail business acres per town\nCHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\nNOX: nitric oxides concentration (parts per 10 million)\nRM: average number of rooms per dwelling\nAGE: proportion of owner-occupied units built prior to 1940\nDIS: weighted distances to ﬁve Boston employment centers\nRAD: index of accessibility to radial highways\nTAX: full-value property-tax rate per $10,000\nPTRATIO: pupil-teacher ratio by town 12. B: 1000(Bk−0.63)2 where Bk is the proportion of blacks by town 13. LSTAT: % lower status of the population\nMEDV: Median value of owner-occupied homes in $1000s\n\nIn this, I have used:\n\nLogistic Regression\nLinear Regression\nXGBoost Regressor\nRandom Forest Regressor\nSVM\nand compare which one of them gives me the most fitted model to predict the house price.\n\nData taken from Kaggle.\n'], 'url_profile': 'https://github.com/anshusingh43', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '10 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/DeepaKhatwani', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'C++', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 14, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '62 contributions\n        in the last year', 'description': ['MarkovChainMonteCarlo_MetropolisHasting\n'], 'url_profile': 'https://github.com/mufeng703', 'info_list': ['Jupyter Notebook', 'Updated Jan 5, 2021', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Gherkin', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 23, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '12 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/marcus4relius', 'info_list': ['Jupyter Notebook', 'Updated Jan 5, 2021', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Gherkin', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 23, 2020']}","{'location': 'Jodhpur', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['Iris-dataset-ML-beginner-all-models-and-classification\nIn this repository I have applied all the possible ML regression and classification models on popular Iris dataset which you can can find at kaggle.com . Hope so you will find it helpful!\nThankYou!!!\n'], 'url_profile': 'https://github.com/kashishlohiya', 'info_list': ['Jupyter Notebook', 'Updated Jan 5, 2021', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Gherkin', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 23, 2020']}","{'location': 'Singapore', 'stats_list': [], 'contributions': '181 contributions\n        in the last year', 'description': [""\nData-Analysis-on-cereal-Prediction-of-ratings\nPerforming data analysis and building a linear regression model on cereal dataset\nWhat do we see?\nIn this dataset, we look into the criteria that determine the ratings of renown cereals. Here, we will answer the question on whether the effect of variables such as calories, sugar, carbohydrates, protein, fibers, sodium, etc is significant on consumer's rating.\nDataset\nYou can download the dataset here(5 KB).\nContributing\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\nLicense\nMIT\n""], 'url_profile': 'https://github.com/kianweelee', 'info_list': ['Jupyter Notebook', 'Updated Jan 5, 2021', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Gherkin', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 23, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '42 contributions\n        in the last year', 'description': ['Heights-and-Weights-Using-Logistic-Regression\nIn this project, I worked on Heights and Weights Using Logistic Regression\n'], 'url_profile': 'https://github.com/mahmuterenkoca', 'info_list': ['Jupyter Notebook', 'Updated Jan 5, 2021', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Gherkin', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 23, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7 contributions\n        in the last year', 'description': ['Rates API Test Suite\nRegression test suite for the Rates API at https://api.ratesapi.io/api.\nBug Report\nBased on results of Rates API regression tests the\nfollowing test scenarios failed:\nEUR symbols return 400 instead of 200\n  Scenario Outline: specify symbols for latest date\n    When I submit a GET request for ""<dateSpec>"" rates and symbols ""<symbols>""\n    Then the response status is 200\n    And the response base value is ""EUR""\n    And the response rates value is an object with keys ""<symbols>"" and double values\n    And the response date is the latest available\n\n  Examples:\n    | dateSpec | symbols |                                                                                                                        |\n    | latest   | EUR     | \n    | latest   | USD,EUR  | \n\n  Scenario Outline: specify base currency and symbols for latest date\n    When I submit a GET request for ""<dateSpec>"" rates and base currency ""<base>"" and symbols ""<symbols>""\n    Then the response status is 200\n    And the response base value is ""<base>""\n    And the response rates value is an object with keys ""<symbols>"" and double values\n    And the response date is the latest available\n\n  Examples:\n    | dateSpec | base | symbols |                                                                                                                        |\n    | latest   | EUR  | EUR     |\n\nReason of failure: EUR value is missing in the “rates” list for default base\nInvalid path does not return 404\n  Scenario Outline: Incorrect path in url results in \'bad request\'\n    When I submit a GET request for ""<dateSpec>"" rates\n    Then the response status is <status>\n\n    Examples:\n      | dateSpec | status |\n      |          | 404    |\n      | last     | 404    |\n\nReason of failure: According to HTTP standards,\na request with invalid path parameter should return 404 Not Found response code\nRecommendation: Above use cases should be confirmed with consumer’s requirements\n'], 'url_profile': 'https://github.com/automatTester', 'info_list': ['Jupyter Notebook', 'Updated Jan 5, 2021', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Gherkin', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 23, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '48 contributions\n        in the last year', 'description': ['House_Price_prediction_project\nPrediction of house prices in Seattle using Linear Regression in Python\n'], 'url_profile': 'https://github.com/hmmychoice', 'info_list': ['Jupyter Notebook', 'Updated Jan 5, 2021', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Gherkin', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 23, 2020']}","{'location': 'Doha', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': ['ML---Session-1\nWalkthrough of - Confusion Matrix, Simple & Multiple Linear Regression, Binary & Multiclass Logistic Classification\n'], 'url_profile': 'https://github.com/sanxdoc87', 'info_list': ['Jupyter Notebook', 'Updated Jan 5, 2021', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Gherkin', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 23, 2020']}","{'location': 'China', 'stats_list': [], 'contributions': '138 contributions\n        in the last year', 'description': ['Imporved-weed-algorithm-to-optimize-BP-network\nIn the matlab environment, by combining the differential evolution algorithm and the weed optimization algorithm, an improved differential evolution weed optimization algorithm is formed, and the algorithm is used to optimize the weights of the BP network to achieve regression fitting. For details, see my blog:\nmatlab环境，通过结合差分进化算法与杂草优化算法，形成改进的差分进化杂草优化算法，并将该算法用于优化BP网络的权重实现回归拟合，详情见我博客：\nhttps://blog.csdn.net/qq_41043389/article/details/103852306\n需要代码的联系我，qq2919218574\n'], 'url_profile': 'https://github.com/fish-kong', 'info_list': ['Jupyter Notebook', 'Updated Jan 5, 2021', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Gherkin', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 23, 2020']}","{'location': 'London, UK', 'stats_list': [], 'contributions': '261 contributions\n        in the last year', 'description': ['\nClassifying Companies Bankruptcy Risks\nThis project is a Machine Learning model to predict companies\' bankruptcies based on key financial indiactors.\nDataset\nThis data set has been sourced from the Machine Learning Repository of the University of California.\nHow to download a copy of the project\nTo download a copy of the project, just go on the main page of the project on GitHub, click on ""Clone or download"" and then ""Download ZIP"".\nAfter this, you should be able to run the project using Jupyter Notebook.\nLibraries to install\n\nJupyter Notebook\npandas\nnumPy\nSeaborn\nMatplotlib\nscikit-learn\n\nAuthor\n\nThomas Le Menestrel\n\nLicense\nThis project is licensed under the MIT License - see the LICENSE file for details\n'], 'url_profile': 'https://github.com/tlemenestrel', 'info_list': ['Jupyter Notebook', 'Updated Jan 5, 2021', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Gherkin', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 23, 2020']}"
"{'location': 'Kigali, Rwanda', 'stats_list': [], 'contributions': '25 contributions\n        in the last year', 'description': ['Shuttle-Dataset\nA comparative study of basic Machine Learning algorithms: Logistic Regression, K Nearest Neighbor, Support Vector Machine on Statlog Shuttle dataset\n'], 'url_profile': 'https://github.com/lucresse', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 12, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'R', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '20 contributions\n        in the last year', 'description': ['Models\nA variety of simple classification, regression and game playing models implemented from the ground up.\n'], 'url_profile': 'https://github.com/alekjedrosz', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 12, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'R', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['happiness_project\nECON 386 classification and linear regression models on predicting Country Happiness\n'], 'url_profile': 'https://github.com/twoods-ml', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 12, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'R', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['CarPricePrediction\nWe are going to predict car price using regression function R studio\n'], 'url_profile': 'https://github.com/khalidaanggun', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 12, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'R', 'Updated May 13, 2020']}","{'location': 'Dammam, Saudi Arabia', 'stats_list': [], 'contributions': '29 contributions\n        in the last year', 'description': ['Udacity-A-B-Test-Project\nProbability, A/B Testing and Regression as part of Data Analysis Nano Degree Project 3.\n'], 'url_profile': 'https://github.com/AbdulrahmanAM', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 12, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'R', 'Updated May 13, 2020']}","{'location': 'Texas, USA', 'stats_list': [], 'contributions': '26 contributions\n        in the last year', 'description': ['4355-Project\nLinear Regression Model and Report for STAT 4355 class using R\n'], 'url_profile': 'https://github.com/dattranm', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 12, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'R', 'Updated May 13, 2020']}","{'location': 'Canada,London', 'stats_list': [], 'contributions': '48 contributions\n        in the last year', 'description': ['Datacamp-Predicting-Credit-Card-Approvals\nUse logistic regression/grid search in sklearn package to predict the approval of credit card\n'], 'url_profile': 'https://github.com/JianmingDong', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 12, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'R', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '37 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/dony234', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 12, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'R', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '60 contributions\n        in the last year', 'description': ['Cat vs Non-Cat L-layer NN\nA logistic regression classifier to recognize cats using neural network mindset in python\n'], 'url_profile': 'https://github.com/parthsaxena1909', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 12, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'R', 'Updated May 13, 2020']}","{'location': 'Herndon,VA', 'stats_list': [], 'contributions': '27 contributions\n        in the last year', 'description': ['Prediction of Life Expectancy using WDI Indicators\nTrained Ridge, Lasso and Linear Regression models along with Decision Trees\n'], 'url_profile': 'https://github.com/ayu1812', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'HTML', 'Updated May 12, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 26, 2020', 'R', 'Updated May 13, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '88 contributions\n        in the last year', 'description': ['Machine-Learning-Excercise---INT3405_20\nExcercise for INT3405_20 Machine Learning class. Stock predicting using Sklearn Linear Regression model.\n'], 'url_profile': 'https://github.com/chickenfingerwu', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'India', 'stats_list': [], 'contributions': '829 contributions\n        in the last year', 'description': ['Cat-image-recognizer\nIt uses Logistic Regression to reconize that the image is of cat or not cat\n'], 'url_profile': 'https://github.com/Brillianttyagi', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '43 contributions\n        in the last year', 'description': ['Regression Course - University of Washington/Coursera\nRegression course, part of Machile Learning especialization provided by University of Washington via Coursera.\nTopics covered:\nModels:\n    •Linear regression\n    • Regularization: Ridge (L2), Lasso (L1)\n    • Nearest neighbor and kernel regression\nAlgorithms:\n    • Gradient descent\n    • Coordinate descent \nConcepts:\n    • Loss functions, bias-variance tradeoff,\n    cross-validation, sparsity, overfitting,\n    model selection, feature selection\n\nAll notebooks were made in Pandas, Numpy and Scikit-learn instead of Graphlab and TuriCreate suggested by the course.\n'], 'url_profile': 'https://github.com/eduardobaratela', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '41 contributions\n        in the last year', 'description': ['Polynomial-Curve-fitting-using-Regression\nThis repository contains the implementation of polynomial curve fitting using a regression model.\nThe file Curve Fitting.pdf is the pdf version of the python notebook which contains the code to fit a polynomial curve through data points in 2-D space.\nThe entire flow of the implemented follows 3 steps:\n(1) Identifying an optimal degree for the polynomial using the validation set\n(2) Fitting the model (with selected degree) using the training and validation data and printing the training and test errors\n(3) Plotting the polynomial function that was fitted\n'], 'url_profile': 'https://github.com/saikrishnawds', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '9 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/nurlaitamalia', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '21 contributions\n        in the last year', 'description': ['AdvanceRegression_HousePricePrediction\nUsing concepts of Advanced regression (Ridge and Lasso) predicting prices of house for a Australian Market\n'], 'url_profile': 'https://github.com/amanjha04', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'Jakarta', 'stats_list': [], 'contributions': '42 contributions\n        in the last year', 'description': ['Which-Debts-Are-Worth-the-Bank-s-Effort_\nPlay bank data scientist and use regression discontinuity to see which debts are worth collecting.\nAfter a debt has been legally declared ""uncollectable"" by a bank, the account is considered to be ""charged-off."" But that doesn\'t mean the bank simply walks away from the debt. They still want to collect some of the money they are owed. In this project, you will look at a situation where a bank assigned delinquent customers to different recovery strategies based on the expected amount the bank believed it would recover from the customer. The goal for the data scientist is to determine in this non-random assignment whether the incremental amount the bank earns exceeded the additional cost of assigning customers to a higher recovery strategy.\nThreshold assignments like this also one occur in medicine (above a certain temperature you get medicine), education (above a certain test score students get admitted to a special class), other areas of finance (above a certain wealth customers get different levels of service), and public sector (below a certain income someone is eligible for housing benefits). Regression discontinuity is an intuitive and useful analysis method in any situation of a threshold assignment.\n'], 'url_profile': 'https://github.com/fikriakbar-chng', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'Boston ', 'stats_list': [], 'contributions': '132 contributions\n        in the last year', 'description': ['House Price Estimation Using ML Methods\nIn this project we develop and implement different regression methods on datasets with a large number of both numerical and categorical features. We will explore linear regression as well as ensemble methods such as Gradient Boosting and Random Forest. We then evaluate each methods advantages along with their limitations such as overfitting.\nCode\nThe code is divided to four categories:\n\nThe Preprocessing.ipynb Jupyter Notebook contains the code to preprocess the raw data.\nThe Regression.ipynb Jupyter Notebook contains the linear regression methods\nThe Random_Forest.ipynb Jupyter Notebook contains the random forest regression model.\nThe Gradient Boosting file contains MATLAB files to implement gradient boosting method.\n\nMore details of the project can be found on Description.pdf pdf file.\nThis project have done by Gabrielle Belok, Artin Spiridonoff and Me, Supervised by Professor Prakash Ishwar.\n'], 'url_profile': 'https://github.com/MehradSm', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '37 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/dony234', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/vpros7253', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated Jun 3, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020']}"
"{'location': 'Ireland', 'stats_list': [], 'contributions': '92 contributions\n        in the last year', 'description': ['Machine-Learning-2\nML package I have chosen for my regression task is Linear Regression model and K-Nearest Neighbour regression model. I am choosing Scikit-learn library in Python. This is because I am already familiar with Scikit-learn library.\nLinear Regression is a predictive analysis algorithm which is used for finding a relationship between dependent variable and one or more independent predictors which are linear in nature. A simple linear regression equation is of form y = mx + b where y is the dependent variable, x is the independent variable, m is the slope and b is the intercept. It is a model based on supervised learning. If we plot independent variable on the x-axis and dependent variable on the y-axis, we can perform linear regression over this dataset to get the best fitted line for our linear regression model. This concept can me expended for multiple linear regression as y = b0 + m1b1 + m2b2 + ... mnbn. This is also an equation for the hyperplane.\nI am using linear regression for my regression task because linear regression is easy to implement and understand. It can be trained fast as compared to other algorithms. It is good for predicting data where Y is continuous in nature (like out strength data). It is good for solving problems with complex nature. Though it might not be the best algorithm to be used on data with real life scenarios. I want to try and compare it with KNN algorithm. Also, we need to calculate RMSE in the end for evaluation, that’s another reason to use linear regression as it makes more sense to calculate mean squared error as the metric of loss in Linear regression model.\nK-Nearest Neighbour is a supervised learning Machine learning model. Supervised learning models works when Data is already provided. It can be used for both classification and regression. Here we are using KNN for regression. KNN algorithm assumes that the similar data points are close to each other. KNN algorithm is based on similarity of data and classifying them accordingly into groups. In KNN algorithm, we initialize a K which is equal to the number of neighbours to that cluster. We calculate the distance between the data points and put them accordingly in an ordered fashion. Then we sort that ordered fashion in ascending order by calculation the distances between them. Then we pick first K entries and label them return the mean of the K labels for regression.\nI am using K-Nearest Neighbour because it is easy to implement and a simple machine learning model. There are only few parameters to tune when it comes to KNN. I have also used KNN for classification for my first Machine Learning assignment, therefore I was curious to see how it can be used for regression as well. Choosing the correct K value is very important for KNN to give accurate predictions. KNN is used in recommender systems (e.g. Netflix, Spotify etc.)\nPreparing the data for ML package:\n\nDownload the “steel.txt”.\nOpen excel and import the .txt file.\nUse excel to Delimit the file as “Characters such as commas or tabs separate each field”.\nAdd the title to each file\nSave the file as .CSV file. The data preparation to input data in ML package is complete. I have saved the .CSV file as steel.csv.\n\nALGORITHM 1 – LINEAR REGRESSION:\nLinear Regression is a predictive linear model. It is one of the most commonly used machine learning models and used in lots of business applications. It explains the relationship between a dependent variable(y) and one or more independent variable(x). It is used for finding a relationship between dependent variable and one or more independent predictors which are linear in nature.\nlr.predict predict the values for test data based on linear regression trained model. lr.score print the accuracy of the model which in our case is coming to be 83.5. Mean aaccuracy after performing the 10-fold cross validation is coming to be 68.8%. Mean Absoluter Error is 32.3%, and Root Mean Squared Error is coming to be 39.7%.  Later we are plotting the actual values against fitted values.\nProcess for Developing Linear Regression Model and choosing the parameters: For Linear Regression Model, I am taking most values as default parameters. Test size for training and testing data is taken to be 0.3 as under this setting I was getting the best accuracy for my model. Apart from that I am performing cross validation to cover other test parameters as well. The parameters of the Linear regression Model are as follows:\nLinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n•\tFit_intercept=True (by default) to calculate the intercept for this model.\n•\tNormalize= False (by default) as there is no need for normalization.\n•\tCopy_X = True (by default) as there is no need for overwriting X.\n•\tN_jobs= Number of jobs for the computation which is none (by default) as we are not performing parallel backend job.\nI tried and experimenting with different parameter settings for my linear regression model. By changing test size, by normalizing my data, by overwriting X values and changing the number of jobs for the computation. But mostly on the default setting itself, I got the best values among other values for my model. Hence above settings were my chosen parameter setting for the model.\nALGORITHM 2 – K NEAREST NEIGHBOUR (KNN):\nK-Nearest Neighbour is a supervised learning Machine learning model. Supervised learning models works when Data is already provided. It learns from Data given by training the model on test data. After the training is complete, the test data is inputted to predict the output values. This model works by taking a data point and looking for the K-closest neighbour to that data point. K can be any number from 1 to n. Accuracy of the model varies depending on the value of K. For my assignment, I am taking K as 3. After that, most of the data point are given a label and clustered accordingly.\nknn.predict predict the values for test data based on knn trained model. Knn.score print the accuracy of the model which in our case is coming to be 65%. Mean accuracy after performing the 10-fold cross validation is 33%. Mean Absoluter Error is 42.2%, and Root Mean Squared Error is 57.3%.  Later we are plotting the actual values against fitted values to see how accurate our prediction is in plot. We are also calculating the RMSE values for all the values of K from 1 to 50 to figure out the best K.\nProcess for Developing K-Nearest Neighbour Regression Model and choosing the parameters: For K-Nearest Neighbour Regression Model, I am taking most values as default parameters. Test size for training and testing data is taken to be 0.3 as under this setting I was getting the best accuracy for my model. Apart from that I am performing cross validation to cover other test parameters as well. I also calculated all the RMSE values for different values of K (1 to 50) to get the best value of K for my model. After calculating different RMSE, I chose K=3 for my model because at this value of K, I was getting the least error as compared to other values of K. At K = 3, RMSE is 57.3%. The parameters of the Linear regression Model are as follows:\nKNeighborsRegressor(n_neighbors=3, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=None)\n•\tN_neighbours = 3, explained above as I am getting least RMSE at this value of K.\n•\tWeights = ‘uniform’ (by default) as all points in the neighbourhood are weighted equally in this case and I don’t need to calculate weight points by inverse of their distance.\n•\tAlgorithm=’auto’ (by default) as it will decide the best algorithm among BallTree, KDTree and Brute based on fit.\n•\tLeaf_size=30 (by default) as it can affect the speed as well as memory required to store the Tree. So, I am taking optimum value by default.\n•\tP=2 as we are using Euclidean distance for our Minkowski metric.\n•\tMetric = ‘minkowski’ (by default), we can use Euclidean metric as well\n•\tMetric_params = None (by default) as there are no additional parameter being used for metric.\n•\tN_jobs= Number of jobs for the computation which is none (by default) as we are not performing parallel backend job.\nI tried and experimenting with different parameter settings for my linear regression model. For selecting the parameters for my regression model, I choose test size as 0.3 for best case scenario. K=3 as it gave the least RMSE for this value. Weights are uniform by default and metric used is minkowski metric. Most values are used as default because these values were giving the best result in the form of accuracy for my model.\nUnderfitting and Overfitting Monitoring:\nUnderfitting means that training error rate in the model is too high while overfitting means that the result of error rate of model training is lower that the result of rate of testing dataset. To get the best value of training and testing dataset, I have chosen my test size as 0.3, to divide the training and test data in 70-30 ratio. I came to this conclusion by randomly selecting the different values of test size and calculating the accuracy of my model based on that test size. After that I started plotting the graph between actual and fitted values as seen above to compare both the data. I also performed 10- fold cross validation to avoid the problem of underfitting and overfitting of data and to get 10 different accuracy result and taking there mean for my result. There won’t be much of overfitting as this is a small dataset. But to avoid underfitting, we have taken test size as 0.3.\nPerformance Metric and Conclusion:\nFrom the results, we can see that KNN given the accuracy of 65% and Linear Regression predicts an accuracy of 83%. Based on this prediction we can say that; Linear Regression might be a better algorithm than Linear Regression for prediction the variety of our steel dataset. As the dataset contains only 553 values, the model is trained on 387 values and testing is done on 166 values. It won’t be a good criterion to access the model based on this single test. Therefore, later we performed a 10-fold Cross Validation on both our algorithm to get a different set of accuracies for different set of test data build by Cross Validation as cv=10. Taking mean of these accuracy for comparing both the algorithms, we found that KNN gave an average accuracy of 35% after 10-fold cross validation while Linear Regression gave an average accuracy of 68.8%. We still can’t say for sure as both results are not great for comparison.  Now, we are performing RMSE and MAE on our predicted and test values. MAE measures the overall magnitude of the errors in a set of predictions. It is the average of the absolute differences between predicted and actual values where all singular distances have equal weights. It doesn’t consider the direction. RMSE is the square root of average of squared differences between actual and predicted values. RMSE is more useful when large errors are undesirable.\nFor my model, I am performing both the metric for evaluation, RMSE AND MAE. The RMSE for Linear Regression is 39.7 and MAE for Linear Regression is 32.3. While RMSE for KNN is 57.38 and MAE for KNN is 42.2. Lower the value of error, better will be the model. As we can see RMSE and MAE are both low for Linear Regression and comparatively higher for KNN. Both the models give very different results in terms of accuracy, RMSE and MAE. This result is due to that fact that KNN is slower when we have a real-world scenario. We need to provide a proper scaling for fair treatment among features of KNN. Hyperparameters like K-value and Distance function also effect the model accuracy. Whereas Linear Regression can be used easily for real-world problems. It can also be easily implemented for space complex solution. It can perform well when there are large number of features as compared to KNN which might be the problem in our dataset. Given such large number of features might be difficult for KNN to make a good prediction model. Also, KNN is slower than Linear regression as Linear regression can easily get output values from the already tuned coefficients while KNN have to keep a track of all the training data and finding the neighbour node. Considering these factors, we can conclude that Linear Regression is a better regression algorithm than KNN for our ‘steel.txt’ dataset.\nREFERENCES AND ACKOWLEDGEMENT:\n•\thttps://www.udemy.com/course/machinelearning/ (Machine Learning A-Z™: Hands-On Python & R in Data Science)\n•\thttps://towardsdatascience.com/building-a-k-nearest-neighbors-k-nn-model-with-scikit-learn-51209555453a\n•\thttps://towardsdatascience.com/comparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222\n•\thttps://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n•\thttps://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n•\thttps://www.analyticsvidhya.com/blog/2018/08/k-nearest-neighbor-introduction-regression-python/\n•\thttps://www.statisticssolutions.com/what-is-linear-regression/\n•\thttps://towardsdatascience.com/linear-regression-detailed-view-ea73175f6e86\n•\thttps://machinelearningmastery.com/linear-regression-for-machine-learning/\n•\thttps://datafai.com/2017/10/31/python-machine-learning-linear-regression-with-scikit-learn/\n•\thttps://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d\n•\thttps://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/\n•\thttps://blog.usejournal.com/a-quick-introduction-to-k-nearest-neighbors-algorithm-62214cea29c7\n•\thttps://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761\n•\thttps://d2l.ai/chapter_multilayer-perceptrons/underfit-overfit.html\n'], 'url_profile': 'https://github.com/rishabhjain16', 'info_list': ['Python', 'Updated Jun 16, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '17 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/buahinak', 'info_list': ['Python', 'Updated Jun 16, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'San Francisco', 'stats_list': [], 'contributions': '124 contributions\n        in the last year', 'description': ['Predicting-Diabetes-\nUsing different forms of classifiers to predict diabetes (SVM, Random Forest, Logistic Regression)\nContext\nDiabetes is one of the deadliest and chronic diseases. About one in seven U.S. adults has diabetes now. By 2050, as many as one in three may become diabetic.\nMany complications occur if diabetes remains untreated and unidentified.\nIdentifying patients who are at high-risk of becoming diabetic allows early medical interventions.\nThis dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nProject\n\nDevelop ML models By applying LogisticRegression, SVM, RandomForest classification algorithms. \nApply GridSearchCV to find the best hyperparameters for your models\nAssess model performance (confusion matrix, precision, recall, ROC AUC) and interpret performance from business impact viewpoint (false negatives vs false positives).\n\n'], 'url_profile': 'https://github.com/khaledimad', 'info_list': ['Python', 'Updated Jun 16, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'San Francisco', 'stats_list': [], 'contributions': '280 contributions\n        in the last year', 'description': ['Predicting Wage Using Linear Regression\nUsing USA 2012 Census Data\n'], 'url_profile': 'https://github.com/mdhwang', 'info_list': ['Python', 'Updated Jun 16, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '42 contributions\n        in the last year', 'description': ['\n'], 'url_profile': 'https://github.com/Viniciusmoda', 'info_list': ['Python', 'Updated Jun 16, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '96 contributions\n        in the last year', 'description': ['Salary_Analysis_simple_Linear-Regression\n'], 'url_profile': 'https://github.com/NikShrish', 'info_list': ['Python', 'Updated Jun 16, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'San Antonio, TX', 'stats_list': [], 'contributions': '193 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Suggestions-Only', 'info_list': ['Python', 'Updated Jun 16, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '76 contributions\n        in the last year', 'description': ['Python_Linear_Regression_E-commerce\nEste é um projeto desenvolvido no curso ""Python para Data Science e Machine Learning"" na plataforma Udemy.\nObjetivo\nTreinamento e posterior avaliação de um modelo de machine learning em Python utilizando regressão linear para análise e previsão de vendas.\nProblema de negócio\nUma empresa (fictícia) de comércio eletrônico com sede na cidade de Nova York que vende roupas online.\nOs clientes entram na loja, têm sessões / reuniões com um estilista pessoal, então podem ir para casa e encomendarem em um aplicativo\nmóvel ou site a roupa que desejam.\nA empresa está tentando decidir se deve concentrar seus esforços em sua experiência em aplicativos móveis ou em seu site.\nImplementação\nApós a importação dos dados que estavam em formato csv, foi realizada uma análise exploratória para se conhecer melhor o dataset e\npara encontrar relações entre a variável target e as demais.\nCom o Seaborn foram criados diversos gráficos para uma melhor visualização dessas relações.\nO dadaset foi então dividido em duas partes (treino e teste). Os dados treino foram usados para o treinamento de um modelo de machine\nlearning utilizando o algoritmo de regressão linear do scikit-learn.\nCom o modelo treinado, foi possível fazer previsões com os dados de testes.\nFinalmente, foi feita uma avaliação da performance do modelo e os coeficientes gerados por ele auxiliaram a rsolução do problema\nde negócio.\n'], 'url_profile': 'https://github.com/Daniel-Solano', 'info_list': ['Python', 'Updated Jun 16, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '23 contributions\n        in the last year', 'description': ['Wall-Mart-Price-prediction-Regression-\n'], 'url_profile': 'https://github.com/SurajMota', 'info_list': ['Python', 'Updated Jun 16, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'Shiraz - IRAN', 'stats_list': [], 'contributions': '76 contributions\n        in the last year', 'description': ['Linear-Regression-Stock-Price-Prediction\n'], 'url_profile': 'https://github.com/sinabr', 'info_list': ['Python', 'Updated Jun 16, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'MIT license', 'Updated May 13, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '35 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/EAP1011', 'info_list': ['Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'HTML', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 14, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'Mathura, India', 'stats_list': [], 'contributions': '76 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Shashank-Mittal', 'info_list': ['Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'HTML', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 14, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': ['LinearRegression_Using_GradientDescent-\n'], 'url_profile': 'https://github.com/Praveen11558', 'info_list': ['Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'HTML', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 14, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '77 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Esther145', 'info_list': ['Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'HTML', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 14, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'Bengaluru', 'stats_list': [], 'contributions': '8 contributions\n        in the last year', 'description': ['Multiple Linear Regression\nCar Price Prediction\nA Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts.\nThey have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\n\nWhich variables are significant in predicting the price of a car\nHow well those variables describe the price of a car\n\nBased on various market surveys, the consulting firm has gathered a large dataset of different types of cars across the Americal market.\n'], 'url_profile': 'https://github.com/ravib-geek', 'info_list': ['Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'HTML', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 14, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'Hanoi, Haiphong. Vietnam', 'stats_list': [], 'contributions': '45 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ngducmanh', 'info_list': ['Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'HTML', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 14, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['uft-one-aos-web-regression\nThis is a UFT One script created to demo execution against the Advantage Online Shopping demo site.\n'], 'url_profile': 'https://github.com/admpresales', 'info_list': ['Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'HTML', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 14, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'Nashik', 'stats_list': [], 'contributions': '71 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Nilayy7', 'info_list': ['Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'HTML', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 14, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '140 contributions\n        in the last year', 'description': ['LinearRegression-first-algorithm-Machinelearning\nThis is the implementation of linear regression alogorithm from scatch using python\n'], 'url_profile': 'https://github.com/KrishnaPoojithaV', 'info_list': ['Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'HTML', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 14, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}","{'location': 'Riyadh ', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Samaherkh', 'info_list': ['Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'HTML', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated Jun 14, 2020', 'Jupyter Notebook', 'Updated May 17, 2020']}"
"{'location': 'Pune,Maharashtra', 'stats_list': [], 'contributions': '25 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Jitendra160892', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Dearborn, Michigan', 'stats_list': [], 'contributions': '29 contributions\n        in the last year', 'description': ['Linear-Regression-with-StatsModels\n'], 'url_profile': 'https://github.com/abhijitp17', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Paris, France', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/kartyoussef', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Pune, India', 'stats_list': [], 'contributions': '65 contributions\n        in the last year', 'description': ['Breast-Cancer-Detection---Logistic-Regression\n'], 'url_profile': 'https://github.com/amaan2810', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'South Africa', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['Flask-based Model API\nEXPLORE Data Science Academy Regression Predict\nTable of Contents\n\nFlask-based Model API\n- EXPLORE Data Science Academy Regression Predict\n\n1) Overview\n\n1.1) Wait, what is an API again?\n1.2) How our API will work\n\nDescription of files\n\n\n\n\n2) Usage Instructions\n\n2.1) Creating a copy of this repo\n2.2) Running the API on your local machine\n2.3) Updating the API to use your own model\n\nPrerequisites\nMaking the changes\n\n\n2.4) Running the API on a remote AWS EC2 instance\n\n\n3) FAQ\n\n\n\n1) Overview\nThis repository forms the basis of Task 2 for the Regression Predict within EDSA\'s Data Science course. It hosts template code which will enable students to deploy their own developed models through a web server-based API.\n1.1) Wait, what is an API again?\n\nAn API - or Application Programming Interface - refers to a set of procedures and protocols that allows us to send and request information between ourselves and remote applications. You can think of this as a channel of communication to a remote server using specific commands that allow you to use their applications without needing to host that functionality yourself. Many types of API\'s exist, but for this predict task we are interested specifically in Web API\'s. These allow us to send and receive information using web development languages, such as HTML and JSON. The video above provides a simple and intuitive explanation of how API\'s operate.\n1.2) How our API will work\n\nDescription of files\nSeveral files within this repository enable the correct functioning of our API. We provide a high-level description of these salient files within the table below:\n\n\n\nFile Name\nDescription\n\n\n\n\napi.py\nFlask web server application definition and instantiation.\n\n\nmodel.py\nContains helper functions to separate model specific code from our API definition.\n\n\nutils/request.py\nSimple script to simulate a POST request sent to our API.\n\n\nutils/train_model.py\nCode used to train the simple model used for demonstration of the API\'s functioning.\n\n\n\n2) Usage Instructions\n2.1) Creating a copy of this repo\n\n\n\n⚡ WARNING ⚡\n\n\n\n\nDo NOT clone this repository. Instead follow the instructions in this section to fork the repo.\n\n\n\nAs described within the Predict instructions for the Regression Sprint, this code represents a template from which you can base your own model\'s API. As such, in order to modify the template to serve your own model (and the associated code changes which are required for this), you will need to fork this repository. Failing to do this will lead to complications when trying to work on the API remotely.\n\nTo fork the repo, simply ensure that you are logged into your GitHub account, and then click on the \'fork\' button at the top of this page as indicated within the figure above.\n2.2) Running the API on your local machine\nAs a first step to becoming familiar with our API\'s functioning, we recommend setting up a running instance on your own local machine.\nTo do this, follow the steps below by running the given commands within a Git bash (Windows), or terminal (Mac/Linux):\n\nEnsure that you have the prerequisite Python libraries installed on your local machine:\n\npip install -U flask numpy pandas scikit-learn\n\nClone the forked repo to your local machine.\n\ngit clone https://github.com/{your-account-name}/regression-predict-api-template.git\n\nNavigate to the base of the cloned repo, and run the API web-server initialisation script.\n\ncd regression-predict-api-template/\npython api.py\nIf the web server was able to initialise successfully, the following message should be displayed within your bash/terminal session:\n----------------------------------------\nModel succesfully loaded\n----------------------------------------\n * Serving Flask app ""api"" (lazy loading)\n * Environment: production\n   WARNING: This is a development server. Do not use it in a production deployment.\n   Use a production WSGI server instead.\n * Debug mode: off\n * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n\n\nLeave the web server script running within the current bash/terminal session. Open a new session, and navigate to the utils subfolder of the cloned repo.\n\ncd {your/custom/path}/regression-predict-api-template/utils/\n\n\nRun the request.py script located within the utils subfolder to simulate a POST request for our running API.\n\npython request.py\n\nIf you receive an error at this point, please ensure that the web server is still running in your original bash/terminal session. If the script ran successfully, you should receive similar output to the message shown below:\nSending POST request to web server API at: http://127.0.0.1:5000/api_v0.1\n\nQuerying API with the following data:\n [\'Order_No_21660\', \'User_Id_1329\', \'Bike\', 3, \'Business\', 31, 5, \'12:16:49 PM\', 31, 5, \'12:22:48 PM\', 31, 5, \'12:23:47 PM\', 31, 5, \'12:38:24 PM\', 4, 21.8, nan, -1.2795183, 36.8238089, -1.273056, 36.811298, \'Rider_Id_812\', 4402, 1090, 14.3, 1301]\n\nReceived POST response:\n**************************************************\nAPI prediction result: 1547.3014476106036\nThe response took: 0.004323 seconds\n**************************************************\n\nCongratulations! You\'ve now officially deployed your first web server API, and have successfully received a response from it.\nWith these steps completed, we\'re now ready to both modify the template code to place our own model within the API, and to host this API within an AWS EC2 instance. These processes are outlined within the sections below.\n2.3) Updating the API to use your own model\n\n\n\nℹ️ NOTE ℹ️\n\n\n\n\nWe strongly encourage you to be familiar with running the API as described in Section 2.2 before attempting to use your own model.\n\n\n\nPrerequisites\nBefore you can update the API code-base to use your own custom model, you will need to have the following:\n\n\nYour own sklearn model, trained and saved as a .pkl file.\nFor a simple example of how to pickle your model, review the script found in utils/train_model.py. For further instructions, consult the \'Saving and Restoring Models in Python\' train in Athena.\n(Note: You are not limited to use only a single model within the API. Furthermore, other sklearn structures which have saved parameters may be required for your model to function as well. Obviously, you are expected to handle the loading of such structures in a similar way as described within this section.)\n\n\nCode for the data preprocessing pipeline used to train your model.\nThis code should cover aspects such as data cleaning, feature engineering, feature selection, and feature transformations.\nThe requirement of this code is vital as your API is built to provide a standard interface for POST requests. I.e. someone asking your API to make a prediction shouldn\'t have to worry about what specific features your model uses internally. Instead, anyone who sends a request with the standard features within the public dataset, should expect to receive a prediction result. This design principle makes it far easier to swap out an old model for a newer one, even if ends up using radically different features.\n\n\nMaking the changes\nOnce you\'ve gathered the prerequisites from the above section, making the changes to API is relatively straight forward. It involves three steps:\n\n\nPlace your .pkl file within the assets/trained-models/ directory of the repo.\n\n\nModify the api.py file by changing the path_to_model variable to reflect the new model .pkl file.\n\n\nModify the model.py file by adding your data preprocessing code to the _preprocess_data() helper function.\n\n\nIf the following steps were carried out successfully, running the API should now produce a new prediction result.\n2.4) Running the API on a remote AWS EC2 instance\n\n\n\nℹ️ NOTE ℹ️\n\n\n\n\nYou will only be able to work on this section of the API setup once you\'ve completed the \'Introduction to Amazon AWS - Part I\' train on Athena.\n\n\n\nThe following steps will enable you to run your web server API on a remote EC2 instance, allowing it to the accessed by any device/application which has internet access.\nWithin these setup steps, we will be using a remote EC2 instance, which we will refer to as the Host, in addition to our local machine, which we will call the Client. We use these designations for convenience, and to align our terminology with that of common web server practices. In cases where commands are provided, use Git bash (Windows) or Terminal (Mac/Linux) to enter these.\n\n\nEnsure that you have access to a running AWS EC2 instance with an assigned public IP address. Instructions for this process are found within the \'Introduction to Amazon AWS - Part I\' train on Athena.\n\n\nInstall the prerequisite python libraries on both the Host (EC2 instance), and Client (local machine):\n\n\npip install -U flask numpy pandas scikit-learn\n\nClone your copy of the API repo onto both the Host and Client machines, then navigate to the base of the cloned repo:\n\ngit clone https://github.com/{your-account-name}/regression-predict-api-template.git\ncd regression-predict-api-template/\n[On the Host]:\n\nRun the API web-server initialisation script.\n\npython api.py\nIf this command ran successfully, the following output should be observed on the Host:\n----------------------------------------\nModel succesfully loaded\n----------------------------------------\n * Serving Flask app ""api"" (lazy loading)\n * Environment: production\n   WARNING: This is a development server. Do not use it in a production deployment.\n   Use a production WSGI server instead.\n * Debug mode: off\n * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n\n[On the Client]:\n\nNavigate to the utils subdirectory within the repo.\n\ncd utils/\n\n\nOpen the request.py file using your favourite text editor.\nChange the value of the url variable to reflect the public IP address of the Host. (Instructions for getting the public IP address are provided within the ‘Introduction to Amazon AWS - Part I’ train on Athena.)\n\n\nurl = \'http://{public-ip-address-of-remote-machine}:5000/api_v0.1\'\n\nOnce the editing is completed, close the file and run it:\n\npython request.py\nIf the command ran successfully, you should see output similar to the following:\nSending POST request to web server API at: http://54.229.152.221:5000/api_v0.1\n\nQuerying API with the following data:\n [\'Order_No_21660\', \'User_Id_1329\', \'Bike\', 3, \'Business\', 31, 5, \'12:16:49 PM\', 31, 5, \'12:22:48 PM\', 31, 5, \'12:23:47 PM\', 31, 5, \'12:38:24 PM\', 4, 21.8, nan, -1.2795183, 36.8238089, -1.273056, 36.811298, \'Rider_Id_812\', 4402, 1090, 14.3, 1301]\n\nReceived POST response:\n**************************************************\nAPI prediction result: 1547.3014476106036\nThe response took: 0.406473 seconds\n**************************************************\n\nIf you have completed the steps in 2.3), then the prediction result should differ from the one given above.\n[On the Host]\nYou should also see an update to the web server output, indicating that it was contacted by the Client (the values of this string will differ for your output):\n102.165.194.240 - - [08/May/2020 07:31:31] ""POST /api_v0.1 HTTP/1.1"" 200 -\n\nIf you are able to see these messages on both the Host and Client, then your API has succesfully been deployed to the Web. Snap ⚡!\n3) FAQ\nThis section of the repo will be periodically updated to represent common questions which may arise around its use. If you detect any problems/bugs, please create an issue and we will do our best to resolve it as quickly as possible.\nWe wish you all the best in your learning experience 🚀\n\n'], 'url_profile': 'https://github.com/Ntokozo-J', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Jaipur , Rajasthan', 'stats_list': [], 'contributions': '487 contributions\n        in the last year', 'description': ['Linear-Multiple-Linear-Regression-sample-code\n'], 'url_profile': 'https://github.com/dikshantmali', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Lahore', 'stats_list': [], 'contributions': '274 contributions\n        in the last year', 'description': ['Titanic Predictive model using Losgistic Regression\n'], 'url_profile': 'https://github.com/Hassibayub', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '77 contributions\n        in the last year', 'description': [""Implementation-of-Locally-Weighted-Regression\nLocally weighted linear regression is a non-parametric algorithm, that is, the model does not learn a fixed set of parameters as is done in ordinary linear regression. Rather parameters 'theta' are computed individually for each query point x. While computing 'theta', a higher “preference” is given to the points in the training set lying in the vicinity of x than the points lying far away from x.\nThe code above shows variation of the Locally Weighted Regression curve for various values of 'Tau'.\nTo run the code, please make sure that the latest version of Python, Jupyter and aforementioned libraries are installed in your system.\n""], 'url_profile': 'https://github.com/GitCode11', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Moscow', 'stats_list': [], 'contributions': '80 contributions\n        in the last year', 'description': ['OTUS_PS07_LogRegression\nРешение задачи о логистической регрессии курса OTUS ""Разработчик Python""\n'], 'url_profile': 'https://github.com/AlexandrNikitin3776', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'BSD, Greater Jakarta, Indonesia', 'stats_list': [], 'contributions': '148 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/mnrclab', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '106 contributions\n        in the last year', 'description': ['titanic-kaggle-with-logisticRegression\nThere is 2 file one name with :\n1.simple working : used this to see how logistic regression works and predict the binary outcome.\nwhether passenger survive or not. survived (1) or not survived(0).\n\nkaggle : this generate the prediction in submission.csv file with 418 passengers outcome which required by kaggle\ntitanic competion.\n\n'], 'url_profile': 'https://github.com/umangdubey', 'info_list': ['Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'CC0-1.0 license', 'Updated Sep 22, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Amravati, Maharashtra', 'stats_list': [], 'contributions': '85 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/rohitrrg', 'info_list': ['Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'CC0-1.0 license', 'Updated Sep 22, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Aakash2810', 'info_list': ['Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'CC0-1.0 license', 'Updated Sep 22, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': ['MltipleLinearRegression_SkLearn-\n'], 'url_profile': 'https://github.com/Praveen11558', 'info_list': ['Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'CC0-1.0 license', 'Updated Sep 22, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'New Jersey', 'stats_list': [], 'contributions': '146 contributions\n        in the last year', 'description': ['Logistic-Regression-From-Scratch-R\nTask\nWritting a logistic regression algorithm in R using the sigmoid function from scratch, which prints coefficients and accuracy metrics.\nThe Steps of Logistic Regression From Scratch\n\nRead the data\nDivide the data into training and test data\nDetermine the number of iteration n\nTrain the model using the training dataset\nMake predictions using the test dataset\nTest the model\n\nReceiver Operating Characteristic (ROC) Curve\n\n\n'], 'url_profile': 'https://github.com/Karimatajin', 'info_list': ['Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'CC0-1.0 license', 'Updated Sep 22, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Mohali', 'stats_list': [], 'contributions': '82 contributions\n        in the last year', 'description': ['It is a trained Neural Network model that will be able to predict House Prices with Regression using Keras and TensorFlow.\nIt takes some information like the age of the house, geographical location as input and predicts the price of a house.\nThis model is based on Keras with TensorFlow as its backend and uses it to solve a basic regression problem.\nSteps to Solve the Problem:\n\nCreate, train, and evaluate neural network models.\nUse neural networks to solve regression problems.\n\n'], 'url_profile': 'https://github.com/vishalkaushik0804', 'info_list': ['Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'CC0-1.0 license', 'Updated Sep 22, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Hyderabad', 'stats_list': [], 'contributions': '32 contributions\n        in the last year', 'description': ['Housing-Price-Prediction-Advanced-Regression\n'], 'url_profile': 'https://github.com/RavikanthCh', 'info_list': ['Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'CC0-1.0 license', 'Updated Sep 22, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['Conditions_for_linear_regressions-R-\nR code: 5 Functions to test linear regression assumptions (linearity, homoskedasticity, autocorrelation, normality of errors and multicolinearity). Prepared for one IV regressions (except multicolinearity function with three IV). This includes recommendations to fix unmet conditions, and solutions.\n'], 'url_profile': 'https://github.com/mlafuentem', 'info_list': ['Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'CC0-1.0 license', 'Updated Sep 22, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '168 contributions\n        in the last year', 'description': ['Mushroom_dataset-using-Logistic-regression\n'], 'url_profile': 'https://github.com/ChandrashekharM3018', 'info_list': ['Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'CC0-1.0 license', 'Updated Sep 22, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '21 contributions\n        in the last year', 'description': ['LinearRegression_CarPricePrediction\nA Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit. They have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know: Which variables are significant in predicting the price of a car How well those variables describe the price of a car\n'], 'url_profile': 'https://github.com/amanjha04', 'info_list': ['Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'CC0-1.0 license', 'Updated Sep 22, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}"
"{'location': 'Bangalore', 'stats_list': [], 'contributions': '21 contributions\n        in the last year', 'description': ['LinearRegression_CarPricePrediction\nA Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit. They have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know: Which variables are significant in predicting the price of a car How well those variables describe the price of a car\n'], 'url_profile': 'https://github.com/amanjha04', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Updated May 19, 2020', 'R', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020']}","{'location': 'Hyderabad', 'stats_list': [], 'contributions': '35 contributions\n        in the last year', 'description': ['Kernel-Truncated-Randomised-Ridge-Regression\nStudy Project for course Kernel Methods offered by department of Electrical Engineering, IIT Hyderabad\n'], 'url_profile': 'https://github.com/gaurav-1205', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Updated May 19, 2020', 'R', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '75 contributions\n        in the last year', 'description': ['Housing-Price-Prediction--Regression-Problem\nFinding insights about the housing price prediction such that at what features price of house is highly correlated\n'], 'url_profile': 'https://github.com/souravkgoyal', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Updated May 19, 2020', 'R', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020']}","{'location': 'Pune,Maharashtra', 'stats_list': [], 'contributions': '25 contributions\n        in the last year', 'description': ['Machine-Learning-with-Logistic-Regression\n'], 'url_profile': 'https://github.com/Jitendra160892', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Updated May 19, 2020', 'R', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020']}","{'location': 'Delhi', 'stats_list': [], 'contributions': '181 contributions\n        in the last year', 'description': ['Predicting-House-Prices-with-Regression\nA Shallow Neural Network was built using Keras and Tensorflow (backend) in python to solve a Multiple Linear Regression problem. House Prices were predicted using this NN. The data consisted of 5000 entries and 6 Features. Seaborn was used for data visualization. Entries were standardized before using them for training the NN. The model had 4 Dense layers and 1000 epochs were carried for training the model.\nTraining MAE: 0.413\nValidation MAE: 0.430\nTesting MAE: 0.436\n'], 'url_profile': 'https://github.com/priyanshkedia04', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Updated May 19, 2020', 'R', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['predicting-college-admission-using-Regression\nIn this note book, i predicted the probability of getting admission into a college using different Regression Algorithms.\n'], 'url_profile': 'https://github.com/kumaraddala', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Updated May 19, 2020', 'R', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '19 contributions\n        in the last year', 'description': ['Age-Regression-from-Brain-MRI\nThe result can be found in the PDF file.\nMany thanks for my teammates!\n'], 'url_profile': 'https://github.com/liyiyang0227', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Updated May 19, 2020', 'R', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020']}","{'location': 'New York', 'stats_list': [], 'contributions': '166 contributions\n        in the last year', 'description': ['Mashable_Online_News_Popularity\n'], 'url_profile': 'https://github.com/jng985', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Updated May 19, 2020', 'R', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '39 contributions\n        in the last year', 'description': ['Multiple-Regression-Airbnb-SantaClara\nA group research paper exploring multiple regression techniques to predict the rental prices of Airbnb locations in Santa Clara country, CA.\nThe report can be found in the pdf file above.  The code used for the analysis in the report can be found in the RStudio file.\n'], 'url_profile': 'https://github.com/Josh-Fontes', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Updated May 19, 2020', 'R', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020']}","{'location': 'United States', 'stats_list': [], 'contributions': '29 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/PriyadharsiniNarahari', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 2, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'Updated May 19, 2020', 'R', 'Updated May 17, 2020', '1', 'R', 'Updated May 17, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '54 contributions\n        in the last year', 'description': [""Spring Petclinic Regression Test Repository\nThis repository is used by mdop-cartridge-java to run regression tests against spring petclinic application.\nLicense\nPlease view license information for the software contained on this image.\nDocumentation\nDocumentation will be captured within this README.md and this repository's Wiki.\nIssues\nIf you have any problems with or questions about this image, please contact us through a GitHub issue.\nContribute\nYou are invited to contribute new features, fixes, or updates, large or small; we are always thrilled to receive pull requests, and do our best to process them as fast as we can.\nBefore you start to code, we recommend discussing your plans through a GitHub issue, especially for more ambitious contributions. This gives other contributors a chance to point you in the right direction, give you feedback on your design, and help you find out if someone else is working on the same thing.\n""], 'url_profile': 'https://github.com/majidpal', 'info_list': ['Java', 'Apache-2.0 license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated Jul 9, 2020', 'Updated May 15, 2020', 'R', 'Updated Aug 21, 2020', 'Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'Mombasa', 'stats_list': [], 'contributions': '416 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ada-k', 'info_list': ['Java', 'Apache-2.0 license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated Jul 9, 2020', 'Updated May 15, 2020', 'R', 'Updated Aug 21, 2020', 'Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '66 contributions\n        in the last year', 'description': ['50 Startups - Principal Component Analysis\nPerform PCA on 50 Startups and get the best model using the following algorithms 1. Linear Regression 2. Linear SVR 3. Random Forest Regressor\n'], 'url_profile': 'https://github.com/reenathomas18', 'info_list': ['Java', 'Apache-2.0 license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated Jul 9, 2020', 'Updated May 15, 2020', 'R', 'Updated Aug 21, 2020', 'Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'israel', 'stats_list': [], 'contributions': '95 contributions\n        in the last year', 'description': ['decision-tree-and-random-forest\n🌳 🧮  decision tree & random forest classifier and regressor\nimplementing the 4 models using python from scratch\n'], 'url_profile': 'https://github.com/lashka12', 'info_list': ['Java', 'Apache-2.0 license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated Jul 9, 2020', 'Updated May 15, 2020', 'R', 'Updated Aug 21, 2020', 'Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'Mombasa', 'stats_list': [], 'contributions': '416 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ada-k', 'info_list': ['Java', 'Apache-2.0 license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated Jul 9, 2020', 'Updated May 15, 2020', 'R', 'Updated Aug 21, 2020', 'Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '87 contributions\n        in the last year', 'description': ['Evidence of Absence Regression Package\nThese are routines implement Evidence of Absence Regression (EoAR).\nEoAR relates the number of found entities after a series of\nsearches to covariates to estimate the number of missed entities.\nSpecial cases are\nthe Evidence of Absence (EoA) model of Huso et al. (2015) and the\nInformed Evidence of Absence (IEoA) approaches.\nHow to git it:\nTo obtain a local copy of the source, download it from GitHub using the following\ncommands in a git shell:\ncd <directory you want>  \ngit clone https://github.com/tmcd82070/eoar.git  \n\nThe above commands will download all source from GitHub to your computer.\nAmong other things,\nyou should see a DESCRIPTION file and R directory.\nYou do not need a local copy unless you plan to edit the code.  If you\nsimply want to run EoAR, use the \'devtools and GitHub\' installation method below.\nIntalling:\nEoAR depends on rjags.  It is best to install rjags prior to\natempting install of EoAR.  Prior to attempting installation of\nrjags, it is best to install JAGS.  If you already have the\nJAGS runtime on your machine, skip this step and install\nrjags immediately.\nInstall JAGS run time\nTo install the JAGS\nruntime, navigate here:\nhttp://www.sourceforge.net/projects/mcmc-jags/files, and\ndownload the JAGS installer. Execute it and accept all defaults.\nInstall rjags\nIssue the following command in R:\ninstall.packages(""rjags"")\n\nYou have JAGS and rjags installed properly if you attach rjags and\ndo not get an error message.  I.e., something like the following:\n> library(rjags)\nLoading required package: coda\nLinked to JAGS 4.3.0\nLoaded modules: basemod,bugs\n\nInstall EoAR\nUsing devtools and GitHub\nYou can install the latest release of EoAR directly from GitHub without\nobtaining a local copy.  Issue the following command:\ndevtools::install_github(""tmcd82070/EoAR"")\n\nUsing devtools and local repository\nIf you cloned the EoAR repository, you have a local copy of the source on your\nhard drive.  Open R and setwd() to the directory containing the DESCRIPTION file. In R issue the following:\nlibrary(devtools)  \ndocument()  \ninstall()   \n\nManual install\nOpen a command window, change directory to the folder containing DESCRIPTION and issue\nthe following command:\nr CMD INSTALL EoAR\n\nTo Contribute\nIf you change something, and it\'s useful, I would be very interested to hear about it.\nUsage Example\nThe main routine is eoar.  It takes a count vector, model for lambda, and g-values,\nHere is an example :\nThis is fake data from a three year study on seven sites.  First, the\nalpha and beta parameters for g-value distributions, one per year.\nns <- 3  \nny <- 7  \ng <- data.frame(  \n  alpha = rnorm(ns*ny,70,2),  \n  beta = rnorm(ns*ny,700,25)  \n)\n\nThe following command generates a carcasses count vector, one count per site per year.\nY <- rbinom(ns*ny, c(rep(20,ny), rep(40,ny), rep(60,ny)), g$alpha/(g$alpha+g$beta))\n\nThe following command generates a fake covariate data frame.\nThis example data frame contains Year as a linear\neffect (1,2,3,etc) and year as a factor (2015, 2016, 2017, etc).\ndf <- data.frame(year=factor(c(rep(""2015"",ny),rep(""2016"",ny),rep(""2017"",ny))),  \n    Year=c(rep(1,ny),rep(2,ny),rep(3,ny)))\n\nThe following relates carcass deposition rates to year using\nvague priors for coefficients:\neoa.1 <- eoar(Y~year, g, df )\n\nThe following uses informed distributions:\n# Assume prior mean is 10 and prior sd is 3  \n# Fit intercept-only model to get one mean lambda   \nintMean <- 2*log(10) - 0.5*log(3^2 + 10^2)  \nintSd <- sqrt(-2*log(10) + log(3^2 + 10^2))  \nprior <- data.frame(mean=intMean, sd=intSd, row.names=""(Intercept)"")  \neoa.1 <- eoa(Y~1, g, df, priors=prior )  \n\nAfter either run, you should check convergence.\nTo do so, run a traceplot and Gelman stats.  Any Rhats > 1.1 indicate suspect\nconvergence. The following commands are useful for inspecting\nmixing and convergence:\nlibrary(lattice)\nxyplot(ieoa.1$out[,labels(ieoa.1)])\nacfplot(ieoa.1$out[,labels(ieoa.1)])   \ndensityplot(ieoa.1$out[,labels(ieoa.1)])  \ngelman.diag(ieoa.1$out) # gelmanStats  \ngelman.plot(ieoa.1$out) # gelmanPlot  \n\n'], 'url_profile': 'https://github.com/tmcd82070', 'info_list': ['Java', 'Apache-2.0 license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated Jul 9, 2020', 'Updated May 15, 2020', 'R', 'Updated Aug 21, 2020', 'Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'IIT BHU, India', 'stats_list': [], 'contributions': '609 contributions\n        in the last year', 'description': ['Regression-kNN-and-DecisionTrees\nIn this repository, we will be using k-NN for Regression and Decision Trees Regression for regression purpose. We will be comparing mean squared error for both and will be choosing the best algorithm among them with best tree depth and umber of nearest neighbours.\n'], 'url_profile': 'https://github.com/shubham1710', 'info_list': ['Java', 'Apache-2.0 license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated Jul 9, 2020', 'Updated May 15, 2020', 'R', 'Updated Aug 21, 2020', 'Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'Newcastle upon Tyne ', 'stats_list': [], 'contributions': '185 contributions\n        in the last year', 'description': ['Machine-Learning-with-Python\nJupyter Notebooks exploring Machine Learning techniques -- regression, classification (K-nearest neighbour (KNN), Decision Trees, Logistic regression vs Linear regression, Support Vector Machine), clustering (k-means, Hierarchical Clustering, DBSCAN), sci-kit learn and SciPy -- and where it applies to the real world, including cancer detection, predicting economic trends, predicting customer churn, recommendation engines, and see how it affects society in ways you may not have guessed!\nUsed as part of the IBM Data Science Professional Certificate on Coursera.\n'], 'url_profile': 'https://github.com/asm11es', 'info_list': ['Java', 'Apache-2.0 license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated Jul 9, 2020', 'Updated May 15, 2020', 'R', 'Updated Aug 21, 2020', 'Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '52 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/SandyWhale', 'info_list': ['Java', 'Apache-2.0 license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated Jul 9, 2020', 'Updated May 15, 2020', 'R', 'Updated Aug 21, 2020', 'Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'MIT license', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '12 contributions\n        in the last year', 'description': ['Machine-Learning-1-regressions-and-classify\n机器学习系列\n本仓库包含正规方程组、梯度下降法、感知机分类、广义线性函数回归（阶梯函数）的实现\n生成数据集\n首先在生成数据集文件夹下生成数据集，代码见生成数据集\\code文件夹。\n在生成数据集\\data文件夹下有三个文件：二分类模型.csv和回归模型.csv为生成数据集代码生成的文件。由于感知机分类对数据要求较高。所以感知机分类（我写的这个是最基础的，尚未进行改进）并不适用生成的数据集。所以感知机分类数据.csv是感知机分类的特有数据集。\n学习模型数据集\n本文件夹包含两个子文件夹，分类和线性回归，具体代码实现见文件夹内的代码。\n有问题欢迎与笔者交流，笔者邮箱599529935@qq.com\n'], 'url_profile': 'https://github.com/Venture-Zhao', 'info_list': ['Java', 'Apache-2.0 license', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated Jul 9, 2020', 'Updated May 15, 2020', 'R', 'Updated Aug 21, 2020', 'Python', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 21, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Python', 'MIT license', 'Updated May 13, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '63 contributions\n        in the last year', 'description': ['Performing-different-regressions-and-their-comparisons\n'], 'url_profile': 'https://github.com/mihirjasminrathod', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '52 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/DimovDimitar', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': ['MultipleLinearRegression_RealWorldProblem\ncar sales data is taken and analysis of the data is done.\n'], 'url_profile': 'https://github.com/Praveen11558', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7 contributions\n        in the last year', 'description': ['Linear Regression with NumPy and Python\nIn this project, I am going to focus on three learning objectives:\n\nImplement the gradient descent algorithm from scratch.\nPerform univariate linear regression with Numpy and Python.\nCreate data visualizations and plots using matplotlib.\n\nBy the end of this project, I was able to build linear regression models from scratch using NumPy and Python, without the use of machine learning frameworks such as scikit-learn and statsmodels.\nThe project on Linear Regression with NumPy and Python was divided into the following tasks:\n\n\nTask 1: Introduction and Import Libraries\nIntroduction to the data set and the problem overview.\nImport essential modules and helper functions from NumPy and Matplotlib.\n\n\nTask 2: Load the Data and Libraries\nLoad the dataset using pandas.\nExplore the pandas dataframe using the head() and info() functions.\n\n\nTask 3: Visualize the Data\nUnderstand the data by visualizing it.\nFor this dataset, I will use a scatter plot using Seaborn to visualize the data, since it has only two variables: the         profit and population.\n\n\nTask 4: Compute the Cost 𝐽(𝜃)\nA look at the machinery that powers linear regression: Gradient Descent.\nI want to fit the linear regression parameters 𝜃 to my dataset using gradient descent.\nThe objective of linear regression is to minimize the cost function J(𝜃).\nWe can think of the cost as the error my model made in estimating a value.\n\n\nTask 5: Implement Gradient Descent from scratch in Python\nThe parameters of my model are the 𝜃_j values.\nThese are the values I will adjust to minimize the cost J(𝜃).\nOne way to do this is to use the batch gradient descent algorithm.\nIn batch gradient descent, each iteration performs the following update.\nWith each step of gradient descent, the parameters 𝜃_j come closer to the optimal values that will achieve the lowest           cost J(𝜃).\n\n\nTask 6: Visualizing the Cost Function J(𝜃)\nTo better understand the cost function J(𝜃),I will plot the cost over a 2-dimensional grid of 𝜃_0 and 𝜃_1 values.\n\n\nTask 7: Plotting the Convergence\nPlotting how the cost function varies with the number of iterations.\nWhen I ran gradient descent previously, it returns the history of J(𝜃) values in a vector “costs”.\nI will now plot the J values against the number of iterations.\n\n\nTask 8: Training Data with Univariate Linear Regression Fit\nNow that I have correctly implemented and run gradient descent and arrived at the final parameters of my model, I    can use these parameters to plot the linear fit.\n\n\nTask 9: Inference using the optimized 𝜃 values\nIn this final task, I will use my final values for 𝜃 to make predictions on profits in cities of 35,000 and 70,000 people.\n\n\n'], 'url_profile': 'https://github.com/Snow-Master', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020']}","{'location': 'Bengaluru', 'stats_list': [], 'contributions': '29 contributions\n        in the last year', 'description': ['adityagoel08-Introduction-to-Linear-Regression-in-R\n'], 'url_profile': 'https://github.com/adityagoel08', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['Stock_Price_Prediction-with-ML-Regression-ALgorithms\n'], 'url_profile': 'https://github.com/Vikas-Sony', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '100 contributions\n        in the last year', 'description': ['Linear-Regression-Multiple-Variables-Salary-Predictor-\nThis system predict person salary based on some features.\n'], 'url_profile': 'https://github.com/thineshsubramani', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/kushagrajain11', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '182 contributions\n        in the last year', 'description': [""Linear-Regression-with-NumPy-and-Python\nThis repository contains all files related to the Coursera course 'Linear Regression with NumPy and Python' by instructor Snehan Kekre.\nLink to the coursera certificate: https://coursera.org/share/3c8924cc8a26aa3fb4c6469de5b6b8d1\n""], 'url_profile': 'https://github.com/AshTiwari', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020']}","{'location': 'San Diego, California', 'stats_list': [], 'contributions': '120 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/vbihare', 'info_list': ['Jupyter Notebook', 'Updated May 16, 2020', '1', 'Python', 'Updated May 20, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020']}"
"{'location': 'Bangalore', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/kushagrajain11', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020', '1', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '182 contributions\n        in the last year', 'description': [""Linear-Regression-with-NumPy-and-Python\nThis repository contains all files related to the Coursera course 'Linear Regression with NumPy and Python' by instructor Snehan Kekre.\nLink to the coursera certificate: https://coursera.org/share/3c8924cc8a26aa3fb4c6469de5b6b8d1\n""], 'url_profile': 'https://github.com/AshTiwari', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020', '1', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'San Diego, California', 'stats_list': [], 'contributions': '120 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/vbihare', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020', '1', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'Agra, India', 'stats_list': [], 'contributions': '60 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/bhavuk0909', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020', '1', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '182 contributions\n        in the last year', 'description': [""Coursera-Logistic-Regression\nThis repository contains all the files relating to the Coursera course 'Logistic Regression with NumPy and Python' by instructor Snehan Kekre on the platform Rhyme.\nLink to certificate:\nhttps://coursera.org/share/b265aeca55f568d92d35cb94a89d19f3\n""], 'url_profile': 'https://github.com/AshTiwari', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020', '1', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'Hyderabad', 'stats_list': [], 'contributions': '61 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/narayana8799', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020', '1', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '126 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/GopalSharma14', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020', '1', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '94 contributions\n        in the last year', 'description': ['Predict-HousePrices-Regression-EnsembleTechniques\nUtilizing Ensemble Models to Predict House Prices\n'], 'url_profile': 'https://github.com/srisha03', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020', '1', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '66 contributions\n        in the last year', 'description': ['Classification and Regression Models with Viz\n'], 'url_profile': 'https://github.com/reenathomas18', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020', '1', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}","{'location': 'Pune', 'stats_list': [], 'contributions': '25 contributions\n        in the last year', 'description': ['Logistic-Regression-using-German-credit-data\nData cleaning,use INFORMATION VALUE, use Map function, get_dummies,Logit Regression Results,ROC Curve, Odds Ratios,Variance Inflation Factor\n'], 'url_profile': 'https://github.com/rahulpawar0712', 'info_list': ['1', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated Jul 9, 2020', '1', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['MSE-ROC-AUC-curve-Linear-Regression\n'], 'url_profile': 'https://github.com/zengdavid8', 'info_list': ['HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', '1', 'R', 'Updated May 12, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': [""Logistic Regression - Introduction\nIntroduction\nIn this you'll be introduced to a new type of machine learning technique: classification! You'll learn about an algorithm called logistic regression as well as different ways that data scientists can evaluate the performance of classification models.\nLogistic Regression\nYou're familiar with linear regression to predict continuous values. You're now going to return to regression to look at how it can be used as a classifier instead to determine the likelihood of a given data point being associated with one of two categories.\nWe'll start by introducing the sigmoid function and showing how it can be used to fit a curve that matches a binary classifier (e.g. does someone make over or under $40k a year or are they a good or bad credit risk).\nEvaluating Classifiers\nWe'll then look at the practicalities of evaluating logistic regression models based on precision, recall, and accuracy to evaluate other classifiers.\nWe also take a little time to look at how to plot a confusion matrix for a logistic regression classifier and introduce a couple of key concepts for determining the optimal precision-recall trade-off for a given classifier - Receiver Operating Characteristic (ROC) curves and AUC (the Area Under the Curve).\nClass Imbalance Problems\nWe then introduce the concept of class imbalance. Imagine a classifier for cancer where only 1 screened individual in 1000 is sick. You could obtain over 99 percent accuracy by just saying everyone is fine, but that wouldn't be a very useful approach. We look at the ideas of class weights and over/undersampling and how they can be used to work with highly imbalanced classes.\nSummary\nIt's important to be aware of logistic regression as one of the most basic classifiers that you can use, and many of the concepts around model evaluation will be useful whenever you're trying to solve a classification problem.\n""], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', '1', 'R', 'Updated May 12, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '52 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/SandyWhale', 'info_list': ['HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', '1', 'R', 'Updated May 12, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Pune', 'stats_list': [], 'contributions': '25 contributions\n        in the last year', 'description': ['Logistic-Regression-using-German-credit-data\nData cleaning,use INFORMATION VALUE, use Map function, get_dummies,Logit Regression Results,ROC Curve, Odds Ratios,Variance Inflation Factor\n'], 'url_profile': 'https://github.com/rahulpawar0712', 'info_list': ['HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', '1', 'R', 'Updated May 12, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Mumbai, Maharashtra', 'stats_list': [], 'contributions': '575 contributions\n        in the last year', 'description': ['Artificial Neural Networks Classification and Regression Models\nIn this project, various datasets are considered for study and the classification and regression models are made accordingly.\nThe datasets considered are Iris dataset, Fashion MNIST dataset, California Housing.\n'], 'url_profile': 'https://github.com/aparna0522', 'info_list': ['HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', '1', 'R', 'Updated May 12, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '88 contributions\n        in the last year', 'description': ['MIT-xPRO-DSxCase-Study-2.3-Do-Poor-Countries-Grow-Faster-than-Rich-Countries-\nCase Study 2.3: Do Poor Countries Grow Faster than Rich Countries? Instructor: Victor Chernuzkov Activity Type: Optional  Case Study Description: Answer the question: ¨Do poor countries grow faster than rich countries?¨by using a large dimensional dataset. Why this Case Study? Participants are equipped with tools which can handle high dimensional datasets. They can apply these tools to any high dimensional dataset. Self-Help Package Contents:   The video that covers this case study is given in Module 2, Segment 2.4.  Self-Help-Package.zip  Codebook.txt contains the name of the variables and a brief description. growth.Rdata: The dataset contains the variables used in the regression. Regression 2.4.CaseStudy.R: looks at how the rates at which economies of different countries grow related to initial wealth levels in each country controlling for several country-specific characteristics. This relationship is estimated in two ways. In the first analysis, a simple regression linear model is used. In the second analysis control variables are partialled out using the Lasso method and then residuals of the dependent variable are regressed on residuals of the indepedent variable. Regression.2.4.pdf is the set of slides that describes the estimation technique and present the results. .Rapp.history .Rhistory\n'], 'url_profile': 'https://github.com/claudio-toledo', 'info_list': ['HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', '1', 'R', 'Updated May 12, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Toronto', 'stats_list': [], 'contributions': '59 contributions\n        in the last year', 'description': ['Salary-Classification\nUse of various logistic regression models to classify salaries of data science professionals based of Kaggle data science survey\nUsing the ""2019 Kaggle ML & DS Survey Challenge"" dataset the performance of ordinal logistic regression, multivariate logisitic regression, and one-vs-rest type logistic regression are analyzed.\nThe survey data is provided in the .csv file.\n'], 'url_profile': 'https://github.com/taylrcawte', 'info_list': ['HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', '1', 'R', 'Updated May 12, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '12 contributions\n        in the last year', 'description': [""Bayesian-Opioid-Analysis\nVarious Bayesian multiple linear regression models are fit on the U.S. Opioid Epidemic from CDC's Wonder tool\nThe Opioid market size in the United States is valued at over 11 billions dollars with more than 150 million prescriptions\nwritten every year since 2015--a rate that would be over 50 prescriptions per 100 people. In 2018, more than 40,000 Americans died\nfrom opioid overdose; the year before, the United States Department of Health and Human Services (HHS) declared a public health\nemergency for the US Opioid Epidemic.\nIn this analysis, data from CDC's Wonder tool is explored to see which demographics have been impacted the most by the\nopioid epidemic. We also propose the overall crude rate (mortality rate) can be modeled using a Bayesian multiple linear\nregression along with Bayesian model averaging, while comparing its predictive qualities to a regular frequentist multiple linear regression.\n""], 'url_profile': 'https://github.com/stonew10', 'info_list': ['HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', '1', 'R', 'Updated May 12, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Ireland', 'stats_list': [], 'contributions': '92 contributions\n        in the last year', 'description': ['Machine-Learning-1\nIntroduction to Machine learning using sklearn library. I am using KNN and Logistic regression algorithm with 10-fold cross validation\nThere are lots of open source machine learning packages available online for performing all kind of things. The popular ones include:\n•\tTensor Flow, an open source ML framework created by Google. It incorporates with other technologies like Python, Java, C++, JavaScript and few others as well.\n•\tKeras, an open source ML software designed to work on Deep learning and to simplify deep learning models.\n•\tScikit-learn, it is one of the most famous Machine Learning library. It is built in Python and can be used with other technologies as well. It includes lots of pre-build machine learning models for performing various tasks like regression, classification, data mining, clustering etc.\n•\tTheano, it is one of the oldest ML library and is being used by industry for deep learning.\n•\tCaffe- Convolutional Architecture for Fast Feature Embedding is a ML framework written in C++.\n•\tTorch- It is an open source library written in C which provides optimized results without causing unnecessary complexities.\n•\tAccord.NET – Open source framework for ML written in C.\nThese are some of the popular ML Framework. For my Machine Learning Assignment, I am choosing Scikit-learn library. This is because I am already familiar with Scikit-learn library. During summer this year, I took a ‘Machine Learning A-Z’ online course on UDEMY which taught me how to use Scikit-learn for performing machine learning. Apart from that it can be used with Python. Python is one of the best open source programming tools available. Because I am already familiar with Scikit-Learn and python, I choose to do my assignment using them. Scikit-learn comes with various inbuilt Machine learning models. All you need to do is import the library and build the model with a single line of code. That’s all it takes to start studying ML with Scikit-learn and Python. It’s very flexible and documented. There is a proper documentation available for Scikit-learn making it easy to understand and implement. Sample scripts are available to understand the working and all other API’s are well documented and safeguarded. It comes with various other tools like NumPy, Pandas, matplotlib which are combined with other machine learning packages to play with data, visualize content, create meaningful graphs or to debug a problem. Therefore, to sum it up, Scikit-learn is one of the easiest and productive way to getting to start with Machine Learning programming. Its very well documented with sample scripts available for easy understanding. It is a robust library and provides various range of supervised, unsupervised, semi-supervised and reinforcement learning algorithms. It is built upon SciPy and therefore used along with various other libraries. Also due to my familiarity with python and Scikit-learn from before, I choose to do my machine learning assignment with Scikit-Learn library.\nMain features of Scikit-learn library include:\n\n\nContains popular algorithm and libraries.\n\n\nContains popular packages like NumPy, Pandas, Matplotlib, SciPy which are popularly used in ML\n\n\nData Mining and Data Analysis\n\n\nOpen Source – BSD Licence\n\n\nReusable and easy implementation\n\n\nWell written documentation\n\n\nCan perform all kind of ML tasks like Preprocessing, Model Selection, Classification, Regression, Clustering, Dimensionality Reduction etc.\n\n\nPreparing the data for ML package:\n\nDownload the “hazelnuts.txt” file from blackboard.\nOpen excel and import the .txt file.\nUse excel to Delimit the file as “Characters such as commas or tabs separate each field”.\nTranspose the delimited files from rows to columns and columns to rows.\nAdd the title to each file\nSave the file as .CSV file. The data preparation to input data in ML package is complete. I have saved the .CSV file as Data.csv.\n\nALGORITHM 1 – K NEAREST NEIGHBOUR (KNN) WITH 10-FOLD CROSS VALIDATION\nK-Nearest Neighbour is a supervised learning Machine learning model. Supervised learning models works when Data is already provided. It learns from Data given by training the model on test data. After the training is complete, the test data is inputted to predict the output values. This model works by taking a data point and looking for the K-closest neighbour to that data point. K can be any number from 1 to n. Accuracy of the model varies depending on the value of K. For my assignment, I am taking k as 3. But we can use another algorithm to find the best value of k using Scikit-learn and get the most accurate model of prediction. After that, most of the data point are given a label and clustered accordingly. For our assignment, we are using Scikit learn to predict the dataset for accuracy. After that we are performing 10-fold cross validation on our dataset to predict more accuracy based on 10 different test data to get the best validation for our dataset.\nknn.predict predict the values for test data based on knn trained model. Knn.score print the accuracy of the model which in our case is coming to be 95%. Later we are using Cross validation over our KNN model  to get the best parameters for our retrained model and to avoid the situation of overfitting. print(cv_scores) prints the cross validation result of 10-fold cross validation and later their mean is calculated to get an average value of accuracy after performing the 10-fold cross validation which is coming to be 84%. Cross Validation is performed on 10 different test data to predict 10 different accuracy based on the test data to get more validate result for our dataset.\nALGORITHM 2 – LOGISTIC REGRESSION WITH 10-FOLD CROSS VALIDATION\nLogistic Regression is a predictive linear model. It is one of the most commonly used machine learning models and used in lots of business applications. It explains the relationship between a dependent variable(y) and one or more independent variable(x). It uses a sigmoid function to predict the output which is usually between 0 and 1. It also uses given data to create and train a model and then use that model to predict the test data. For our assignment, we are using Scikit learn to predict the test dataset and accuracy of the trained logistic regression model. After that we are performing 10-fold cross validation on our dataset to predict more accuracy based on 10 different test data to get the most validated accuracy for our dataset.logisticRegr.predict predict the values for test data based on logistic regression trained model. logisticRegr.score print the accuracy of the model which in our case is coming to be 92.6%. Later we are using Cross validation over our KNN model  to get the best parameters for our retrained model and to avoid the situation of overfitting. print(cv_scores) prints the cross validation result of 10-fold cross validation and later their mean is calculated to get an average value of accuracy after performing the 10-fold cross validation which is coming to be 91%. Cross Validation is performed on 10 different test data to predict 10 different accuracy based on the test data to get more validate result for our dataset.\nCONCLUSION:\nIn this assignment, I am using two machine learning algorithms on “hazelnuts.txt”. First, Data is being prepared in excel to be imported in our machine learning model. Then using Spyder tool, we are using Python language to add our dataset. Then we are using Pandas and NumPy to read the csv file. After that we are using sklearn to split the data into training and test data, making the machine learning model and predicting the output along with the accuracy of the model. In the end, 10-fold Cross Validation is performed on the model to predict 10 more accuracies of the model on 10 different test data. And then their mean is taken to get a more precise result. First algorithm used is K-Nearest neighbour and the second algorithm used is Logistic Regression. Now we will be comparing the results based on both algorithms.\nFrom the result, we can see that KNN given the accuracy of 95% and Logistic Regression predicts an accuracy of 92%. Based on this prediction we can say that, KNN might be a better algorithm than Logistic Regression for prediction the variety of out hazelnuts dataset. As the dataset contains only 201 values, the model is trained on 160 values and testing is done on 41 values. It won’t be a good criterion to access the model based on this single test. Therefore, later we performed a 10-fold Cross Validation on both our algorithm to get a different set of accuracies for different set of test data build by Cross Validation as cv=10. Taking mean of these accuracy for comparing both the algorithms, we found that KNN gave an average accuracy of 84% after 10-fold cross validation while Logistic Regression gave an average accuracy of 91%. After performing 10-fold Cross Validation, we got a better set of results based on 10 test data. Hence, we can now conclude that accuracy of Logistic Regression (91%) algorithm is better than the accuracy of K-Nearest Neighbour algorithm (84%). Therefore, Logistic Regression is a better classification algorithm than KNN for our ‘hazelnuts.txt’ dataset.\nREFERENCES AND ACKOWLEDGEMENT:\n•\thttps://www.udemy.com/course/machinelearning/ (Machine Learning A-Z™: Hands-On Python & R in Data Science)\n•\thttps://machinelearningmastery.com/a-gentle-introduction-to-scikit-learn-a-python-machine-learning-library/\n•\thttps://www.thelearningmachine.ai/tree-id3\n•\thttps://medium.com/@Mandysidana/machine-learning-types-of-classification-9497bd4f2e14\n•\thttps://scikit-learn.org/stable/modules/cross_validation.html\n•\thttps://scikit-learn.org/stable/modules/preprocessing.html\n•\thttps://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/\n•\thttps://towardsdatascience.com/building-a-k-nearest-neighbors-k-nn-model-with-scikit-learn-51209555453a\n•\thttp://www.insightsbot.com/blog/1uOwGy/python-logistic-regression-with-scikit-learn\n•\thttps://scikit-learn.org/stable/index.html\n'], 'url_profile': 'https://github.com/rishabhjain16', 'info_list': ['HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', '1', 'R', 'Updated May 12, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'Hyderabad', 'stats_list': [], 'contributions': '56 contributions\n        in the last year', 'description': ['Heart-disease-prediction\nPredicting heart disease  whether the patient has 10-year risk of future coronary heart disease (CHD) using Logistic Regression\n'], 'url_profile': 'https://github.com/arun2357', 'info_list': ['HTML', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', '1', 'R', 'Updated May 12, 2020', 'Python', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020']}"
"{'location': 'Greater Noida | Noida | Chennai', 'stats_list': [], 'contributions': '288 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/prateekagrawaliiit', 'info_list': ['Python', 'Updated May 15, 2020', 'Python', 'Apache-2.0 license', 'Updated Dec 30, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 22, 2020', 'Java', 'Updated May 17, 2020', 'R', 'Updated May 18, 2020', '1', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'Milwaukee, WI', 'stats_list': [], 'contributions': '35 contributions\n        in the last year', 'description': ['linreg_py_Medium\nThis is the repository for my Medium post An Introduction to Regression in Python with statsmodels and scikit-learn.\n'], 'url_profile': 'https://github.com/scottadams26', 'info_list': ['Python', 'Updated May 15, 2020', 'Python', 'Apache-2.0 license', 'Updated Dec 30, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 22, 2020', 'Java', 'Updated May 17, 2020', 'R', 'Updated May 18, 2020', '1', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '82 contributions\n        in the last year', 'description': [""quality-of-red-wine\nNot a very important topic in today's scenario...but a good example to implement multiple regression\n""], 'url_profile': 'https://github.com/NiharikaGopinath', 'info_list': ['Python', 'Updated May 15, 2020', 'Python', 'Apache-2.0 license', 'Updated Dec 30, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 22, 2020', 'Java', 'Updated May 17, 2020', 'R', 'Updated May 18, 2020', '1', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'New Delhi', 'stats_list': [], 'contributions': '147 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ankurawat4', 'info_list': ['Python', 'Updated May 15, 2020', 'Python', 'Apache-2.0 license', 'Updated Dec 30, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 22, 2020', 'Java', 'Updated May 17, 2020', 'R', 'Updated May 18, 2020', '1', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '54 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/milicajevremovic', 'info_list': ['Python', 'Updated May 15, 2020', 'Python', 'Apache-2.0 license', 'Updated Dec 30, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 22, 2020', 'Java', 'Updated May 17, 2020', 'R', 'Updated May 18, 2020', '1', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'New York, NY', 'stats_list': [], 'contributions': '16 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/choang94', 'info_list': ['Python', 'Updated May 15, 2020', 'Python', 'Apache-2.0 license', 'Updated Dec 30, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 22, 2020', 'Java', 'Updated May 17, 2020', 'R', 'Updated May 18, 2020', '1', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '26 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Carlos-Gzz', 'info_list': ['Python', 'Updated May 15, 2020', 'Python', 'Apache-2.0 license', 'Updated Dec 30, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 22, 2020', 'Java', 'Updated May 17, 2020', 'R', 'Updated May 18, 2020', '1', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '22 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/MaciekTW', 'info_list': ['Python', 'Updated May 15, 2020', 'Python', 'Apache-2.0 license', 'Updated Dec 30, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 22, 2020', 'Java', 'Updated May 17, 2020', 'R', 'Updated May 18, 2020', '1', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['BlackFridaySales\nThis Project is based on regression problem. It includes dataset that comprises of sales transactions captured at a retail store.\n'], 'url_profile': 'https://github.com/varshneyakaash', 'info_list': ['Python', 'Updated May 15, 2020', 'Python', 'Apache-2.0 license', 'Updated Dec 30, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 22, 2020', 'Java', 'Updated May 17, 2020', 'R', 'Updated May 18, 2020', '1', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '57 contributions\n        in the last year', 'description': ['Flight-Delay-Prediction\nThis is a logistic regression project on Flight delays with variable selection and data visualisation using scikit-learn\n'], 'url_profile': 'https://github.com/iamdas3', 'info_list': ['Python', 'Updated May 15, 2020', 'Python', 'Apache-2.0 license', 'Updated Dec 30, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Sep 22, 2020', 'Java', 'Updated May 17, 2020', 'R', 'Updated May 18, 2020', '1', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 18, 2020', 'Python', 'Updated May 16, 2020']}"
"{'location': 'India', 'stats_list': [], 'contributions': '543 contributions\n        in the last year', 'description': ['Income Classification Using Logistic Regression\nModel Deployed using Flask and Heroku\nLink: https://income-classification-model.herokuapp.com/ \nUsed Logistic Regression to predict the income class of a person based on given fields of information.\n\n'], 'url_profile': 'https://github.com/Sharan-Babu', 'info_list': ['1', 'Jupyter Notebook', 'Updated Dec 27, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 17, 2020', '1', 'Python', 'Updated May 17, 2020', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Boston', 'stats_list': [], 'contributions': '527 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/srinjoychakravarty', 'info_list': ['1', 'Jupyter Notebook', 'Updated Dec 27, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 17, 2020', '1', 'Python', 'Updated May 17, 2020', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '53 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/nnavnit90n', 'info_list': ['1', 'Jupyter Notebook', 'Updated Dec 27, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 17, 2020', '1', 'Python', 'Updated May 17, 2020', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Sydney, Australia', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/neerajsaxena040885', 'info_list': ['1', 'Jupyter Notebook', 'Updated Dec 27, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 17, 2020', '1', 'Python', 'Updated May 17, 2020', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['NONE'], 'url_profile': 'https://github.com/cran', 'info_list': ['1', 'Jupyter Notebook', 'Updated Dec 27, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 17, 2020', '1', 'Python', 'Updated May 17, 2020', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'London, United Kingdom', 'stats_list': [], 'contributions': '51 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/astham05', 'info_list': ['1', 'Jupyter Notebook', 'Updated Dec 27, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 17, 2020', '1', 'Python', 'Updated May 17, 2020', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Arlington', 'stats_list': [], 'contributions': '208 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/kunal19899', 'info_list': ['1', 'Jupyter Notebook', 'Updated Dec 27, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 17, 2020', '1', 'Python', 'Updated May 17, 2020', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '22 contributions\n        in the last year', 'description': ['""# AD-prediction""\n'], 'url_profile': 'https://github.com/D-AG', 'info_list': ['1', 'Jupyter Notebook', 'Updated Dec 27, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 17, 2020', '1', 'Python', 'Updated May 17, 2020', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '628 contributions\n        in the last year', 'description': ['Analysis of Inflammatory Biomarkers\nProject Description\nUsed logistic regression models, along with associated causal diagrams (DAGs),\nto infer the relationship between two inflammatory biomarkers and cardiovascular\ndeath. The biomarkers (C-reactive protein and fibrinogen) were measured as part\nof a larger observational study on the elderly. The logistic models were fit\nbased on presupposed biological causality, to control for potential confounding\nand mediating variables.\nFile Details\nThe file inflamm.txt contains the data for the analysis, in tab-separated\nformat.\nThe file inflamm_biomarker_analysis.Rmd contains the actual analysis. This\nproject was intended as a paper or report, and is written to summarize and\ndisplay the data, before performing a formal analysis.\nThe file inflamm_biomarker_analysis.pdf is the output of the .Rmd file, for\nthose who simply wish to view the final result, without downloading and\nre-knitting the .Rmd file.\nCompilation Issues on Linux\nAs a courtesy, I thought I would let readers know that the ggdag package used\nfor creating the causal diagrams causes problems on Linux distributions. Often,\nthe package V8, called libv8-dev in Ubuntu respositories, must be installed\nbefore ggdag and its dependencies, specifically daggity. Having worked on\nthis project cross-platform, I thought it would be best to inform interested\npeople of the complications of running and compiling the included code.\n'], 'url_profile': 'https://github.com/BostonTLee', 'info_list': ['1', 'Jupyter Notebook', 'Updated Dec 27, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 17, 2020', '1', 'Python', 'Updated May 17, 2020', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'San Francisco Bay Area', 'stats_list': [], 'contributions': '52 contributions\n        in the last year', 'description': ['Is_Diabetic_Prediction\nI predict if a patient is Diabetic using several Machine Learning algorithms (logistic regression, random forest, perceptron)\n'], 'url_profile': 'https://github.com/SophiePlt', 'info_list': ['1', 'Jupyter Notebook', 'Updated Dec 27, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 17, 2020', '1', 'Python', 'Updated May 17, 2020', 'Updated Jun 28, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '190 contributions\n        in the last year', 'description': ['Advance-Housing-Prices\nIn the Advance-Housing-Prices we have to predict the SalePrice of the houses\n'], 'url_profile': 'https://github.com/rahulv1999', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'R', 'CC0-1.0 license', 'Updated May 13, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 17, 2020', 'Updated May 17, 2020']}","{'location': 'Jogeshwari, Mumbai, Maharashtra 400102', 'stats_list': [], 'contributions': '258 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ganesh10-india', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'R', 'CC0-1.0 license', 'Updated May 13, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 17, 2020', 'Updated May 17, 2020']}","{'location': 'Ernakulam', 'stats_list': [], 'contributions': '662 contributions\n        in the last year', 'description': ['temperature_predictor\nA logistic regression based ML model to predict temperature based on mass, fuel and working hours of machine\n'], 'url_profile': 'https://github.com/aashnanaushad', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'R', 'CC0-1.0 license', 'Updated May 13, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 17, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['RRMMs\nThis repository contains examples for fitting random regression mixed models (RRMMs) to a simulated dataset for days to first flower.\n'], 'url_profile': 'https://github.com/pieterarnold', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'R', 'CC0-1.0 license', 'Updated May 13, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 17, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': ['Sales-prediction-with-R-studio\nPredicting the upcoming sales value for Big mart using descriptive statistics, correlation matrix and regression data modeling\nThe data scientists at BigMart have collected 2013 sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product and store have been defined. The aim is to build a predictive model and predict the sales of each product at a particular outlet.\nUsing this model, BigMart will try to understand the properties of products and outlets which play a key role in increasing sales.\n'], 'url_profile': 'https://github.com/NikitaGorathe', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'R', 'CC0-1.0 license', 'Updated May 13, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 17, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '196 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/titoeb', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'R', 'CC0-1.0 license', 'Updated May 13, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 17, 2020', 'Updated May 17, 2020']}","{'location': 'Tempe, AZ', 'stats_list': [], 'contributions': '118 contributions\n        in the last year', 'description': ['Design of Experiments\nDesigning a Lego Car through DOE method; Executed Full factorial design, Hypothesis testing, Regression Analysis ANOVA analysis in Minitab\n'], 'url_profile': 'https://github.com/ishah6', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'R', 'CC0-1.0 license', 'Updated May 13, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 17, 2020', 'Updated May 17, 2020']}","{'location': 'Hamilton, Ontario, Canada', 'stats_list': [], 'contributions': '226 contributions\n        in the last year', 'description': ['DiamondPricePredicor\nThis script predicts the prices of diamonds given parameters, which include clarity, cut, and color. This is achieved by using a machine learning linear regression model.\n'], 'url_profile': 'https://github.com/dipoarowona', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'R', 'CC0-1.0 license', 'Updated May 13, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 17, 2020', 'Updated May 17, 2020']}","{'location': 'USA', 'stats_list': [], 'contributions': '39 contributions\n        in the last year', 'description': ['Violent Crime and State Population\nExperimental Machine Learning/Data Science Regression Models to Gain Insights on Violent Crimes in Relation to Jurisdiction (State) Population\nData Source: https://www.kaggle.com/christophercorrea/prisoners-and-crime-in-united-states?select=crime_and_incarceration_by_state.csv\n'], 'url_profile': 'https://github.com/nikkiautery', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'R', 'CC0-1.0 license', 'Updated May 13, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 17, 2020', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '3 contributions\n        in the last year', 'description': ['kusuma\nIn this file a briefly discussed about a linear regression in machine learning algorithm. By using the juptyernotebook.\n'], 'url_profile': 'https://github.com/kusuma051', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 12, 2020', 'R', 'CC0-1.0 license', 'Updated May 13, 2020', 'R', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated Jun 13, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'R', 'Updated May 17, 2020', 'Updated May 17, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '9 contributions\n        in the last year', 'description': ['Predict-Movie-Box-Office\nIn this project we are predicting the Gross Revenue of the Movie based on Gross Production Budget Using Linear Regression\n'], 'url_profile': 'https://github.com/MdSalman216', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Jun 21, 2020', '7', 'HTML', 'BSD-3-Clause license', 'Updated Jul 10, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Sep 28, 2020', 'Python', 'Updated Sep 20, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Jan 2, 2021', 'Jupyter Notebook', 'Updated Aug 31, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020']}","{'location': 'Manchester, UK', 'stats_list': [], 'contributions': '73 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/MLacra', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Jun 21, 2020', '7', 'HTML', 'BSD-3-Clause license', 'Updated Jul 10, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Sep 28, 2020', 'Python', 'Updated Sep 20, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Jan 2, 2021', 'Jupyter Notebook', 'Updated Aug 31, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020']}","{'location': 'Chicago, IL', 'stats_list': [], 'contributions': '42 contributions\n        in the last year', 'description': [""Predicting Urban Development\nThis project uses the Google Earth Engine (GEE) Python API to identify trends in development surrounding Denver International Airport (DIA) from time-series Landsat imagery. The package geemap is used to visualize map layers. This repository was initially created as Richard Udell’s final project for the Earth Data Analytics Professional Certificate from the Earth Lab at University of Colorado - Boulder.\nHow to run this workflow\nThere are two Jupyter Notebooks in the Notebooks folder.\nThe first notebook, LinearFit_Workflow_Only.ipynb, contains the analysis that identifies urban trend surrounding DIA using GEE’s built-in ee.Reducer.linearFit().\nThe second notebook, GEE_Python_API_Tutorial.ipynb, includes a tutorial for the first notebook!  This is a great place to start if you are new to Python and the GEE Python API.\nBest place to start\nStart with the workflow tutorial notebook: GEE_Python_API_Tutorial.ipynb\nEnvironment and setup\nTo set up the development environment, create a new environment from the environment-ee.yml file.\n>conda env create -f environment-ee.yml\n\nA Google Earth Engine account is necessary to use the Google Earth Engine API (a university email address may be accepted more quickly).\nAn excellent resource for Google Earth Engine Python API is Dr. Quisheng Wu's GitHub package geemap.\nData needed\nThe notebooks will create their own data by exporting it from GEE - this means the data that is needed to import into the workflow is created and exported earlier in the workflow.  The data will export as a .TIF to your Downloads/ folder on your home directory.  Landsat 5 satellite imagery is the initial source data for both notebooks.  The entire Landsat 5 collection is loaded from the GEE Data Catalog with the GEE Python API, preventing it to never have to exist locally on your computer.\nThe data folder contains the exports that will be created if you run the workflow with the preset circular ROI.  You will only need to reference this data if the export does not work.  In this case you will have to change the input directory for importing the .TIF file.\nNote on relevance of this repository\nIt is clear to any observer that a large amount of development has occurred around the Denver International Airport since its completion of construction in 1995. Since the Denver International Airport was the last major airport constructed in the United States (no major airport has been constructed since 1995), understanding the impact DIA had on the development of the surrounding region is of interest to policy makers, business owners, and citizens in the Denver Metro Area. The goal of this project is to develop a model that can predict future development.\nGoogle Earth Engine is a powerful tool, however, fewer workflows involve the the python API than the built-in JavaScript API. Additionally, the geemap package was first released in March 2020. With proper installation of these packages, the workflow can be run in a Jupyter Notebook (.ipynb) - workflow is contained in one script.\n""], 'url_profile': 'https://github.com/richardudell', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Jun 21, 2020', '7', 'HTML', 'BSD-3-Clause license', 'Updated Jul 10, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Sep 28, 2020', 'Python', 'Updated Sep 20, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Jan 2, 2021', 'Jupyter Notebook', 'Updated Aug 31, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020']}","{'location': 'Bengaluru, India', 'stats_list': [], 'contributions': '928 contributions\n        in the last year', 'description': ['House-Rental-Prediction\n(Under Development)\nAbout\n\nAn application which predicts the monthly rental of a house based on the given attributes.\nA Macine Learning Project focused on predicting house prices for a house purchase.\n\nAttributes:\n\nId: listing id\nurl: listing URL\nregion: craigslist region\nregion_url: region URL\ntype: housing type\nsqfeet: total square footage\nbeds:number of beds\nbaths:number of bathrooms\ncats_allowed: cats allowed boolean (1 = yes, 0 = no)\ndogs_allowed: dogs allowed boolean\nsmoking_allowed: smoking allowed boolean\nwheelchair_access: has wheelchair access boolean\nelectric_vehicle_charge: has electric vehicle charger boolean\ncomes_furnished: comes with furniture boolean\nlaundry_options: laundry options available\nparking_options: parking options available\nimage_url: image URL\ndescription: description by poster\nlat: latitude\nlong: longitude\nstate: state of listing\nprice: rent per month (Target Column)\n\nDataset Citation:\n\nLicense\tCC0: Public Domain\nDomain\tPublic\nSources\tCraigslist.org\nDataset owner\tAustin Reese\nDate created\t2020-01-07\n\nImplementation\nProject access Link:\nhttp://ec2-18-188-83-100.us-east-2.compute.amazonaws.com:8088\nProject Code Link:\nhttps://github.com/blurred-machine/Real-Estate-Rental-Pricing-Prediction\nProject demo video Link:\nhttps://www.youtube.com/watch?v=PO_off_VSnY&t\nAuthor\n\nParas Varshney\n\n'], 'url_profile': 'https://github.com/blurred-machine', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Jun 21, 2020', '7', 'HTML', 'BSD-3-Clause license', 'Updated Jul 10, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Sep 28, 2020', 'Python', 'Updated Sep 20, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Jan 2, 2021', 'Jupyter Notebook', 'Updated Aug 31, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '48 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ashsometimes', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Jun 21, 2020', '7', 'HTML', 'BSD-3-Clause license', 'Updated Jul 10, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Sep 28, 2020', 'Python', 'Updated Sep 20, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Jan 2, 2021', 'Jupyter Notebook', 'Updated Aug 31, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020']}","{'location': 'Durham, NC, United States', 'stats_list': [], 'contributions': '5 contributions\n        in the last year', 'description': ['Bike-Sharing-Demand-Forecasting\nAfter data visualizations and simple feature selections. I split the train file into training dataset and testing dataset. Then I conducted linear regression, Lasso regression, Ridge regression, Decision tree regressor, random forest regressor as well as adaptive boosting regressor to train the model. Meanwhile, I used GridSearchCV to help conduct hyperparameter tuning to improve the performances of models. Afterwards, I evaluated the performance of models based on the RMSE of the testing dataset and chose adaptive boosting model as the final model to predict the user count in test file.\n'], 'url_profile': 'https://github.com/zachzhaoduke', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Jun 21, 2020', '7', 'HTML', 'BSD-3-Clause license', 'Updated Jul 10, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Sep 28, 2020', 'Python', 'Updated Sep 20, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Jan 2, 2021', 'Jupyter Notebook', 'Updated Aug 31, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020']}","{'location': 'London, UK', 'stats_list': [], 'contributions': '182 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/sebastianBIanalytics', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Jun 21, 2020', '7', 'HTML', 'BSD-3-Clause license', 'Updated Jul 10, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Sep 28, 2020', 'Python', 'Updated Sep 20, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Jan 2, 2021', 'Jupyter Notebook', 'Updated Aug 31, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '27 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/vikanksh15', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Jun 21, 2020', '7', 'HTML', 'BSD-3-Clause license', 'Updated Jul 10, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Sep 28, 2020', 'Python', 'Updated Sep 20, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Jan 2, 2021', 'Jupyter Notebook', 'Updated Aug 31, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020']}","{'location': 'Windsor, Ontario, Canada', 'stats_list': [], 'contributions': '162 contributions\n        in the last year', 'description': [""Analyze-A-B-Test-Results\nOverview\nFor this project, I worked to understand the results of an A/B test run by an e-commerce website. The company has developed a new web page in order to try and increase the number of users. My goal was to help the company understand if they should implement this new page, keep the old page, or perhaps run the experiment longer to make their decision.\nWhat Software Do I Need?\nTo complete this project, i'll require the following softwares:\n\nPython (Numpy, Pandas, Matplotlib, StatsModels, Scipy)\nJupyter Notebook\n\nPart I - Probability\nStatistics were computed to find out the probabilities of converting regardless of page. These were used to analyze if one page or the other led to more conversions.\nPart II - A/B Test\nNext, hypothesis testing was conducted assuming the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%.\nThe data was bootstrapped and sampling distributions were determined for both pages. Conclusions were drawn on conversions for both pages by calculating p-values.\nPart III - Regression\nLogistic regression was then performed to confirm  results of the previous steps.  Null and alternative hypotheses associated with this regression model were stated and verified using statsmodel.\nNext, along with testing if the conversion rate changes for different pages, I added an effect based on which country a user lives. Statistical output using logistic regression was provided to check if country had an impact on conversion.\nConclusions\n\nThere was no evidence suggesting that those who explore either page will neccessary lead to more conversions\nThe country of the user did not impact the rate of conversion between the two pages\n\n""], 'url_profile': 'https://github.com/iKhushPatel', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Jun 21, 2020', '7', 'HTML', 'BSD-3-Clause license', 'Updated Jul 10, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Sep 28, 2020', 'Python', 'Updated Sep 20, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Jan 2, 2021', 'Jupyter Notebook', 'Updated Aug 31, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '45 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/piyush18184', 'info_list': ['Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated Jun 21, 2020', '7', 'HTML', 'BSD-3-Clause license', 'Updated Jul 10, 2020', '2', 'Jupyter Notebook', 'MIT license', 'Updated Sep 28, 2020', 'Python', 'Updated Sep 20, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', 'Jupyter Notebook', 'Updated Jan 2, 2021', 'Jupyter Notebook', 'Updated Aug 31, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Logistic Regression - Recap\nKey Takeaways\n\nIn this section you learned about a different supervised learning technique: classification! Specifically, you practiced building a very basic classification model from scratch - a logistic regression model\nLogistic regression uses a sigmoid function which helps to plot an ""s""-like curve that enables a linear function to act as a binary classifier\nYou can evaluate logistic regression models using some combination of precision, recall, and accuracy\nA confusion matrix is another common way to visualize the performance of a classification model\nReceiver Operating Characteristic (ROC) curve and the Area Under the Curve (AUC) can be used to help determine the best precision-recall tradeoff for a given classifier\nClass weights, under/oversampling, and SMOTE can be used to deal with class imbalance problems\n\n'], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jul 19, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 11, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 15, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Evaluating Logistic Regression Models - Lab\nIntroduction\nIn regression, you are predicting continous values so it makes sense to discuss error as a distance of how far off our estimates were. When classifying a binary variable, however, a model is either correct or incorrect. As a result, we tend to quantify this in terms of how many false positives versus false negatives we come across. In particular, we examine a few different specific measurements when evaluating the performance of a classification algorithm. In this lab, you\'ll review precision, recall, accuracy, and F1 score in order to evaluate our logistic regression models.\nObjectives\nIn this lab you will:\n\nImplement evaluation metrics from scratch using Python\n\nTerminology review\nLet\'s take a moment and review some classification evaluation metrics:\n$$ \\text{Precision} = \\frac{\\text{Number of True Positives}}{\\text{Number of Predicted Positives}} $$\n$$ \\text{Recall} = \\frac{\\text{Number of True Positives}}{\\text{Number of Actual Total Positives}} $$\n$$ \\text{Accuracy} = \\frac{\\text{Number of True Positives + True Negatives}}{\\text{Total Observations}} $$\n$$ \\text{F1 score} = 2 * \\frac{\\text{Precision * Recall}}{\\text{Precision + Recall}} $$\nAt times, it may be best to tune a classification algorithm to optimize against precision or recall rather than overall accuracy. For example, imagine the scenario of predicting whether or not a patient is at risk for cancer and should be brought in for additional testing. In cases such as this, we often may want to cast a slightly wider net, and it is preferable to optimize for recall, the number of cancer positive cases, than it is to optimize precision, the percentage of our predicted cancer-risk patients who are indeed positive.\nSplit the data into training and test sets\nimport pandas as pd\ndf = pd.read_csv(\'heart.csv\')\ndf.head()\nSplit the data first into X and y, and then into training and test sets. Assign 25% to the test set and set the random_state to 0.\n# Import train_test_split\n\n\n# Split data into X and y\ny = None\nX = None\n\n# Split the data into a training and a test set\nX_train, X_test, y_train, y_test = None\nBuild a vanilla logistic regression model\n\nImport and instantiate LogisticRegression\nMake sure you do not use an intercept term and use the \'liblinear\' solver\nFit the model to training data\n\n# Import LogisticRegression\n\n\n# Instantiate LogisticRegression\nlogreg = None\n\n# Fit to training data\nmodel_log = None\nmodel_log\nWrite a function to calculate the precision\ndef precision(y, y_hat):\n    # Your code here\n    pass\nWrite a function to calculate the recall\ndef recall(y, y_hat):\n    # Your code here\n    pass\nWrite a function to calculate the accuracy\ndef accuracy(y, y_hat):\n    # Your code here\n    pass\nWrite a function to calculate the F1 score\ndef f1_score(y, y_hat):\n    # Your code here\n    pass\nCalculate the precision, recall, accuracy, and F1 score of your classifier\nDo this for both the training and test sets.\n# Your code here\ny_hat_train = None\ny_hat_test = None\nGreat job! Now it\'s time to check your work with sklearn.\nCalculate metrics with sklearn\nEach of the metrics we calculated above is also available inside the sklearn.metrics module.\nIn the cell below, import the following functions:\n\nprecision_score\nrecall_score\naccuracy_score\nf1_score\n\nCompare the results of your performance metrics functions above with the sklearn functions. Calculate these values for both your train and test set.\n# Your code here\nNicely done! Did the results from sklearn match that of your own?\nCompare precision, recall, accuracy, and F1 score for train vs test sets\nCalculate and then plot the precision, recall, accuracy, and F1 score for the test and training splits using different training set sizes. What do you notice?\nimport matplotlib.pyplot as plt\n%matplotlib inline\ntraining_precision = []\ntesting_precision = []\ntraining_recall = []\ntesting_recall = []\ntraining_accuracy = []\ntesting_accuracy = []\ntraining_f1 = []\ntesting_f1 = []\n\nfor i in range(10, 95):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= None) # replace the ""None"" here\n    logreg = LogisticRegression(fit_intercept=False, C=1e20, solver=\'liblinear\')\n    model_log = None\n    y_hat_test = None\n    y_hat_train = None \n    \n    # Your code here\nCreate four scatter plots looking at the train and test precision in the first one, train and test recall in the second one, train and test accuracy in the third one, and train and test F1 score in the fourth one.\nWe already created the scatter plot for precision:\n# Train and test precision\nplt.scatter(list(range(10, 95)), training_precision, label=\'training_precision\')\nplt.scatter(list(range(10, 95)), testing_precision, label=\'testing_precision\')\nplt.legend()\nplt.show()\n# Train and test recall\n# Train and test accuracy\n# Train and test F1 score\nSummary\nNice! In this lab, you calculated evaluation metrics for classification algorithms from scratch in Python. Going forward, continue to think about scenarios in which you might prefer to optimize one of these metrics over another.\n'], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jul 19, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 11, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 15, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '161 contributions\n        in the last year', 'description': ['10-Microsoft-Artificial-Intelligence-multi-class-classification-using-logistic-regression\n'], 'url_profile': 'https://github.com/semg101', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jul 19, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 11, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 15, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Ridge and Lasso Regression\nIntroduction\nAt this point, you\'ve seen a number of criteria and algorithms for fitting regression models to data. You\'ve seen the simple linear regression using ordinary least squares, and its more general regression of polynomial functions. You\'ve also seen how we can overfit models to data using polynomials and interactions. With all of that, you began to explore other tools to analyze this general problem of overfitting versus underfitting, all this using training and test splits, bias and variance, and cross validation.\nNow you\'re going to take a look at another way to tune the models you create. These methods all modify the mean squared error function that you are optimizing against. The modifications will add a penalty for large coefficient weights in the resulting model.\nObjectives\nYou will be able to:\n\nDefine Lasso regression\nDefine Ridge regression\nDescribe why standardization is necessary before Ridge and Lasso regression\nCompare and contrast Lasso, Ridge, and non-regularized regression\nUse Lasso and Ridge regression with scikit-learn\n\nOur regression cost function\nFrom an earlier lesson, you know that when solving for a linear regression, you can express the cost function as\n$$ \\text{cost_function}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - (mx_i + b))^2$$\nThis is the expression for simple linear regression (for 1 predictor $x$). If you have multiple predictors, you would have something that looks like:\n$$ \\text{cost_function}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(m_jx_{ij} ) -b )^2$$\nwhere $k$ is the number of predictors.\nPenalized estimation\nYou\'ve seen that when the number of predictors increases, your model complexity increases, with a higher chance of overfitting as a result. We\'ve previously seen fairly ad-hoc variable selection methods (such as forward/backward selection), to simply select a few variables from a longer list of variables as predictors.\nNow, instead of completely ""deleting"" certain predictors from a model (which is equal to setting coefficients equal to zero), wouldn\'t it be interesting to just reduce the values of the coefficients to make them less sensitive to noise in the data? Penalized estimation operates in a way where parameter shrinkage effects are used to make some or all of the coefficients smaller in magnitude (closer to zero). Some of the penalties have the property of performing both variable selection (setting some coefficients exactly equal to zero) and shrinking the other coefficients. Ridge and Lasso regression are two examples of penalized estimation. There are multiple advantages to using these methods:\n\nThey reduce model complexity\nThe may prevent from overfitting\nSome of them may perform variable selection at the same time (when coefficients are set to 0)\nThey can be used to counter multicollinearity\n\nLasso and Ridge are two commonly used so-called regularization techniques. Regularization is a general term used when one tries to battle overfitting. Regularization techniques will be covered in more depth when we\'re moving into machine learning!\nRidge regression\nIn ridge regression, the cost function is changed by adding a penalty term to the square of the magnitude of the coefficients.\n$$ \\text{cost_function_ridge}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(m_jx_{ij})-b)^2 + \\lambda \\sum_{j=1}^p m_j^2$$\nIf you have two predictors the full equation would look like this (notice that there is a penalty term m for each predictor in the model - in this case, two) :\n$$ \\text{cost_function_ridge}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = $$\n$$ \\sum_{i=1}^n(y_i - ((m_1x_{1i})-b)^2 + \\lambda m_1^2 + (m_2x_{2i})-b)^2 + \\lambda m_2^2)$$\nRemember that you want to minimize your cost function, so by adding the penalty term $\\lambda$, ridge regression puts a constraint on the coefficients $m$. This means that large coefficients penalize the optimization function. That\'s why ridge regression leads to a shrinkage of the coefficients and helps to reduce model complexity and multicollinearity.\n$\\lambda$ is a so-called hyperparameter, which means you have to specify the value for lambda. For a small lambda, the outcome of your ridge regression will resemble a linear regression model. For large lambda, penalization will increase and more parameters will shrink.\nRidge regression is often also referred to as L2 Norm Regularization.\nLasso regression\nLasso regression is very similar to Ridge regression, except that the magnitude of the coefficients are not squared in the penalty term. So, while Ridge regression keeps the sum of the squared regression coefficients (except for the intercept) bounded, the Lasso method bounds the sum of the absolute values.\nThe resulting cost function looks like this:\n$$ \\text{cost_function_lasso}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(m_jx_{ij})-b)^2 + \\lambda \\sum_{j=1}^p \\mid m_j \\mid$$\nIf you have two predictors the full equation would look like this (notice that there is a penalty term m for each predictor in the model - in this case, two):\n$$ \\text{cost_function_lasso}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = $$\n$$\\sum_{i=1}^n(y_i - ((m_1x_{1i})-b)^2 + \\lambda \\mid m_1 \\mid) + ((m_2x_{2i})-b)^2 + \\lambda \\mid m_2 \\mid) $$\nThe name ""Lasso"" comes from ""Least Absolute Shrinkage and Selection Operator"".\nWhile it may look similar to the definition of the Ridge estimator, the effect of the absolute values is that some coefficients might be set exactly equal to zero, while other coefficients are shrunk towards zero. Hence the Lasso method is attractive because it performs estimation and selection simultaneously. Especially for variable selection when the number of predictors is very high.\nLasso regression is often also referred to as L1 Norm Regularization.\nStandardization before Regularization\nAn important step before using either Lasso or Ridge regularization is to first standardize your data such that it is all on the same scale. Regularization is based on the concept of penalizing larger coefficients, so if you have features that are on different scales, some will get unfairly penalized. Below, you can see that we are using a MinMaxScaler to standardize our data to the same scale. A downside of standardization is that the value of the coefficients become less interpretable and must be transformed back to their original scale if you want to interpret how a one unit change in a feature impacts the target variable.\nAn example using our auto-mpg data\nLet\'s transform our continuous predictors in auto-mpg and see how they perform as predictors in a Ridge versus Lasso regression.\nWe import the dataset and, seperate the target and predictors and then split the data into training and test sets:\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import Lasso, Ridge, LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = pd.read_csv(\'auto-mpg.csv\') \n\ny = data[[\'mpg\']]\nX = data.drop([\'mpg\', \'car name\', \'origin\'], axis=1)\n\n# Perform test train split\nX_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12)\nAfter splitting the data into training and test sets, we use the MixMaxScaler() to fit and transform X_train and transform X_test.\n\nNOTE: You want to fit and transform only the training data because in a real-world setting, you only have access to this data. You can then use the same scalar object to transform the test data. It\'s not uncommon for people to first transform the data and then split into training and test sets -- which leads to data-leakage.\n\nscale = MinMaxScaler()\nX_train_transformed = scale.fit_transform(X_train)\nX_test_transformed = scale.transform(X_test)\nWe will not fit the Ridge, Lasso, and Linear regression models to the transformed training data. Notice that the Ridge and Lasso models have the parameter alpha, which is Scikit-Learn\'s version of $\\lambda$ in the regularization cost functions.\n# Build a Ridge, Lasso and regular linear regression model  \n# Note that in scikit-learn, the regularization parameter is denoted by alpha (and not lambda)\nridge = Ridge(alpha=0.5)\nridge.fit(X_train_transformed, y_train)\n\nlasso = Lasso(alpha=0.5)\nlasso.fit(X_train_transformed, y_train)\n\nlin = LinearRegression()\nlin.fit(X_train_transformed, y_train)\nLinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n\nNext, let\'s generate predictions for both the training and test sets:\n# Generate preditions for training and test sets\ny_h_ridge_train = ridge.predict(X_train_transformed)\ny_h_ridge_test = ridge.predict(X_test_transformed)\n\ny_h_lasso_train = np.reshape(lasso.predict(X_train_transformed), (274, 1))\ny_h_lasso_test = np.reshape(lasso.predict(X_test_transformed), (118, 1))\n\ny_h_lin_train = lin.predict(X_train_transformed)\ny_h_lin_test = lin.predict(X_test_transformed)\nLook at the RSS for training and test sets for each of the three models:\nprint(\'Train Error Ridge Model\', np.sum((y_train - y_h_ridge_train)**2))\nprint(\'Test Error Ridge Model\', np.sum((y_test - y_h_ridge_test)**2))\nprint(\'\\n\')\n\nprint(\'Train Error Lasso Model\', np.sum((y_train - y_h_lasso_train)**2))\nprint(\'Test Error Lasso Model\', np.sum((y_test - y_h_lasso_test)**2))\nprint(\'\\n\')\n\nprint(\'Train Error Unpenalized Linear Model\', np.sum((y_train - lin.predict(X_train_transformed))**2))\nprint(\'Test Error Unpenalized Linear Model\', np.sum((y_test - lin.predict(X_test_transformed))**2))\nTrain Error Ridge Model mpg    2684.673787\ndtype: float64\nTest Error Ridge Model mpg    2067.795707\ndtype: float64\n\n\nTrain Error Lasso Model mpg    4450.979518\ndtype: float64\nTest Error Lasso Model mpg    3544.087085\ndtype: float64\n\n\nTrain Error Unpenalized Linear Model mpg    2658.043444\ndtype: float64\nTest Error Unpenalized Linear Model mpg    1976.266987\ndtype: float64\n\nWe note that Ridge is clearly better than Lasso here, but that the unpenalized model performs best here. Let\'s see how including Ridge and Lasso changed our parameter estimates.\nprint(\'Ridge parameter coefficients:\', ridge.coef_)\nprint(\'Lasso parameter coefficients:\', lasso.coef_)\nprint(\'Linear model parameter coefficients:\', lin.coef_)\nRidge parameter coefficients: [[ -2.06904445  -2.88593443  -1.81801505 -15.23785349  -1.45594148\n    8.1440177 ]]\nLasso parameter coefficients: [-9.09743525 -0.         -0.         -4.02703963  0.          3.92348219]\nLinear model parameter coefficients: [[ -1.33790698  -1.05300843  -0.08661412 -19.26724989  -0.37043697\n    8.56051229]]\n\nDid you notice that Lasso shrinked a few parameters to 0? The Ridge regression mostly affected the fourth parameter (estimated to be -19.26 for the linear regression model).\nAdditional reading\nFull code examples for Ridge and Lasso regression, advantages and disadvantages, and how to code ridge and Lasso in Python can be found here.\nMake sure to have a look at the Scikit-Learn documentation for Ridge and Lasso.\nSummary\nGreat! You now know how to perform Lasso and Ridge regression. Let\'s move on to the lab so you can use these!\n'], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jul 19, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 11, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 15, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Mathura, Uttar Pradesh', 'stats_list': [], 'contributions': '1,023 contributions\n        in the last year', 'description': ['Project-Logistic-Regression-with-NumPy-and-Python\nLogistic Regression\nLogistic regression is a statistical analysis method used to predict a data value based on prior observations of a data set. Logistic regression has become an important tool in the discipline of machine learning. The approach allows an algorithm being used in a machine learning application to classify incoming data based on historical data. As more relevant data comes in, the algorithm should get better at predicting classifications within data sets. Logistic regression can also play a role in data preparation activities by allowing data sets to be put into specifically predefined buckets during the extract, transform, load (ETL) process in order to stage the information for analysis.\nThings Done in Project\n\nCreate a function to return model instances\nData Processing\nKeras model checkpoint callback\nCreate and evaluate a new model instance\nExplore the save weights and the save function on model instances\nUse the save weights and the save functions to export to and import from the Saved Model format\n\nSKILLS\n\n. . . . . . . . . . . . . . . . . . . . . . . . .\n\nData Science\nMachine Learning\nPython Programming\nClassification\nNumpy\n\n\n\n'], 'url_profile': 'https://github.com/yugam08', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jul 19, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 11, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 15, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Fitting a Logistic Regression Model - Lab\nIntroduction\nIn the last lesson you were given a broad overview of logistic regression. This included an introduction to two separate packages for creating logistic regression models. In this lab, you\'ll be investigating fitting logistic regressions with statsmodels. For your first foray into logistic regression, you are going to attempt to build a model that classifies whether an individual survived the Titanic shipwreck or not (yes, it\'s a bit morbid).\nObjectives\nIn this lab you will:\n\nImplement logistic regression with statsmodels\nInterpret the statistical results associated with model parameters\n\nImport the data\nImport the data stored in the file \'titanic.csv\' and print the first five rows of the DataFrame to check its contents.\n# Import the data\n\n\ndf = None\nDefine independent and target variables\nYour target variable is in the column \'Survived\'. A 0 indicates that the passenger didn\'t survive the shipwreck. Print the total number of people who didn\'t survive the shipwreck. How many people survived?\n# Total number of people who survived/didn\'t survive\nOnly consider the columns specified in relevant_columns when building your model. The next step is to create dummy variables from categorical variables. Remember to drop the first level for each categorical column and make sure all the values are of type float:\n# Create dummy variables\nrelevant_columns = [\'Pclass\', \'Age\', \'SibSp\', \'Fare\', \'Sex\', \'Embarked\', \'Survived\']\ndummy_dataframe = None\n\ndummy_dataframe.shape\nDid you notice above that the DataFrame contains missing values? To keep things simple, simply delete all rows with missing values.\n\nNOTE: You can use the .dropna() method to do this.\n\n# Drop missing rows\ndummy_dataframe = None\ndummy_dataframe.shape\nFinally, assign the independent variables to X and the target variable to y:\n# Split the data into X and y\ny = None\nX = None\nFit the model\nNow with everything in place, you can build a logistic regression model using statsmodels (make sure you create an intercept term as we showed in the previous lesson).\n\nWarning: Did you receive an error of the form ""LinAlgError: Singular matrix""? This means that statsmodels was unable to fit the model due to certain linear algebra computational problems. Specifically, the matrix was not invertible due to not being full rank. In other words, there was a lot of redundant, superfluous data. Try removing some features from the model and running it again.\n\n# Build a logistic regression model using statsmodels\nAnalyze results\nGenerate the summary table for your model. Then, comment on the p-values associated with the various features you chose.\n# Summary table\n# Your comments here\nLevel up (Optional)\nCreate a new model, this time only using those features you determined were influential based on your analysis of the results above. How does this model perform?\n# Your code here\n# Your comments here\nSummary\nWell done! In this lab, you practiced using statsmodels to build a logistic regression model. You then interpreted the results, building upon your previous stats knowledge, similar to linear regression. Continue on to take a look at building logistic regression models in Scikit-learn!\n'], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jul 19, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 11, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 15, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'New Delhi, India', 'stats_list': [], 'contributions': '62 contributions\n        in the last year', 'description': ['Project-3-Hardwork-Pays-Off-Challenge-using-Linear-Regression\nIntroduction:\nPredicting Exam Scores using Machine Learning\nSince we are student of Coding Blocks, we are expected to work hard and get better results than others. To track our time and expected performance in the Machine Learning Challenge, Prateek bhayia has asked us to install walkatime on our device which is an efficient time tracking tool to track our daily coding activity. It measures how much time we have spend on coding daily.\n\nProblem Statement:\nIn this challenge, Prateek bhayia gives us walkatime data of his past students and how they performed in the evaluation exam. Our task is to predict the score we will get given the amount of time we spend on coding daily.\nRequirements:\n\nJupyter Notebook\n\nDataset:\n\n\nInput:- We are given one feature corresponding to time noted by walkatime.\n\n\nOutput:- A scalar denoting the level of perfomance student achived by devoting the given time.\n\n\nImporting the Modules:\n\nNumpy\nMatplotlib\nPandas\n\nLinearRegression:\nLinear Regression is a machine learning algorithm based on supervised learning. It performs a regression task. Regression models a target prediction value based on independent variables. It is mostly used for finding out the relationship between variables and forecasting. Different regression models differ based on – the kind of relationship between dependent and independent variables, they are considering and the number of independent variables being used.\n\nScore:\nFor this model, the accuracy on the test set is 0.97, which means the model made the right prediction for 97% of the  dataset. We can expect the model to be correct 97% of the time for predicting the new values from different students.\nSummary:\nThe Hardwork Pays Off Challenge (and our implementation) is a perfect example to illustrate how a machine learning problem should be approached and how useful the outcome can be to a potential student who wanted to track his performance.\n'], 'url_profile': 'https://github.com/Yuvrajchopra25', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jul 19, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 11, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 15, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '45 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/piyush18184', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jul 19, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 11, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 15, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Mathura, Uttar Pradesh', 'stats_list': [], 'contributions': '1,023 contributions\n        in the last year', 'description': ['Project-Linear-Regression-with-NumPy-and-Python\nLinear Regression\nLinear regression is probably one of the most important and widely used regression techniques. It’s among the simplest regression methods. One of its main advantages is the ease of interpreting results.\nThings Done in Project\n\nImplement the gradient descent algorithm from scratch\nPerform univariate linear regression with Numpy and Python\nCreate data visualizations and plots using matplotlib\n\nSKILLS\n\n. . . . . . . . . . . . . . . . . . . . . . . . .\n\nData Science\nMachine Learning\nPython Programming\nRegression\nNumpy\n\n\n\n'], 'url_profile': 'https://github.com/yugam08', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jul 19, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 11, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 15, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'United States', 'stats_list': [], 'contributions': '23 contributions\n        in the last year', 'description': [""Predicting-house-prices-using-regression-techniques-in-python\nPredicted house prices for 1500 houses based on 79 features with an accuracy of 88% using XG-Boost model\nDataset Source: Kaggle\nSummary\nIf you ask a home buyer to describe their dream house, they probably won't begin with the height of the basement ceiling or\nthe proximity to an east-west railroad. This project proves that much more influences price negotiations than the number of\nbedrooms or a white-picket fence.\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this project posed a challenge\nto predict the final price of each home.\nModeling Steps\n\nMissing Value Treatment: missing values were imputed\nData Visualization: matplotlib and seaborn libraries in python were used to explore variables in the data and their correlation\nFeature Encoding: was carried out using OneHotEncoder\nModel Building: Random forest and XG-boost models were fit on the data\nHyperparameter Tuning: was carried out to find an optimal fit\n\nFinal Model Selected: XGBoost\nAccuracy (train data): 88.28%\nAccuracy (test data): 87.45%\nMost important features as per the model:\n\nAbove ground living area square feet\nLot size in square feet\nBasement finished square feet (type 1)\nTotal square feet of basement area\nFirst floor square feet\nUnfinished square feet of basement area\nSize of garage in square feet\n\n""], 'url_profile': 'https://github.com/Ritika5', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jul 19, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'MIT license', 'Updated May 11, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 15, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '45 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/piyush18184', 'info_list': ['1', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '161 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/semg101', 'info_list': ['1', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'bhubaneswar', 'stats_list': [], 'contributions': '70 contributions\n        in the last year', 'description': ['Deployment-Of-Datascience-Linear-Regression-Model-In-a-web-page\nHere i have deployed a python data science model to a web page.\n'], 'url_profile': 'https://github.com/iamchiranjeeb', 'info_list': ['1', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Logistic Regression Model Comparisons - Lab\nIntroduction\nIn this lab, you\'ll further investigate how to tune your own logistic regression implementation, as well as that of scikit-learn in order to produce better models.\nObjectives\n\nCompare the different inputs with logistic regression models and determine the optimal model\n\nIn the previous lab, you were able to compare the output of your own implementation of the logistic regression model with that of scikit-learn. However, that model did not include an intercept or any regularization. In this investigative lab, you will analyze the impact of these two tuning parameters.\nImport the data\nAs with the previous lab, import the dataset stored in \'heart.csv\':\n# Import the data\n\ndf = None\n\n# Print the first five rows of the data\nSplit the data\nDefine X and y as with the previous lab. This time, follow best practices and also implement a standard train-test split. Assign 25% to the test set and set the random_state to 17.\n# Define X and y\ny = None\nX = None\n\n# Split the data into training and test sets\n\n\nX_train, X_test, y_train, y_test = None\nprint(y_train.value_counts(),\'\\n\\n\', y_test.value_counts())\nInitial Model - Personal Implementation\nUse your code from the previous lab to once again train a logistic regression algorithm on the training set.\n# Your code from previous lab\nimport numpy as np\n\ndef sigmoid(x):\n    x = np.array(x)\n    return 1/(1 + np.e**(-1*x))\n\ndef grad_desc(X, y, max_iterations, alpha, initial_weights=None):\n    """"""Be sure to set default behavior for the initial_weights parameter.""""""\n    if initial_weights is None:\n        initial_weights = np.ones((X.shape[1], 1)).flatten()\n    weights_col = pd.DataFrame(initial_weights)\n    weights = initial_weights\n    # Create a for loop of iterations\n    for iteration in range(max_iterations):\n        # Generate predictions using the current feature weights\n        predictions = sigmoid(np.dot(X, weights))\n        # Calculate an error vector based on these initial predictions and the correct labels\n        error_vector = y - predictions\n        # Calculate the gradient \n        # As we saw in the previous lab, calculating the gradient is often the most difficult task.\n        # Here, your are provided with the closed form solution for the gradient of the log-loss function derived from MLE\n        # For more details on the derivation, see the additional resources section below.\n        gradient = np.dot(X.transpose(), error_vector)\n        # Update the weight vector take a step of alpha in direction of gradient \n        weights += alpha * gradient\n        weights_col = pd.concat([weights_col, pd.DataFrame(weights)], axis=1)\n    # Return finalized weights\n    return weights, weights_col\n\nweights, weights_col = grad_desc(X_train, y_train, 50000, 0.001)\nMake [probability] predictions on the test set\n# Predict on test set\ny_hat_test = None\nnp.round(y_hat_test, 2)\nCreate an ROC curve for your predictions\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\ntest_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_hat_test)\n\nprint(\'AUC: {}\'.format(auc(test_fpr, test_tpr)))\n\n# Seaborn\'s beautiful styling\nsns.set_style(\'darkgrid\', {\'axes.facecolor\': \'0.9\'})\n\nplt.figure(figsize=(10, 8))\nlw = 2\n\nplt.plot(test_fpr, test_tpr, color=\'darkorange\',\n         lw=lw, label=\'Test ROC curve\')\n\nplt.plot([0, 1], [0, 1], color=\'navy\', lw=lw, linestyle=\'--\')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.yticks([i/20.0 for i in range(21)])\nplt.xticks([i/20.0 for i in range(21)])\nplt.xlabel(\'False Positive Rate\')\nplt.ylabel(\'True Positive Rate\')\nplt.title(\'Receiver operating characteristic (ROC) Curve\')\nplt.legend(loc=\'lower right\')\nplt.show()\nUpdate your ROC curve to include the training set\ny_hat_train = None\n\ntrain_fpr, train_tpr, train_thresholds = None\n\ntest_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_hat_test)\n\n# Train AUC\nprint(\'Train AUC: {}\'.format( None ))\nprint(\'AUC: {}\'.format(auc(test_fpr, test_tpr)))\n\n# Seaborn\'s beautiful styling\nsns.set_style(\'darkgrid\', {\'axes.facecolor\': \'0.9\'})\n\nplt.figure(figsize=(10, 8))\nlw = 2\n\nplt.plot(train_fpr, train_tpr, color=\'blue\',\n         lw=lw, label=\'Train ROC curve\')\nplt.plot(test_fpr, test_tpr, color=\'darkorange\',\n         lw=lw, label=\'Test ROC curve\')\n\nplt.plot([0, 1], [0, 1], color=\'navy\', lw=lw, linestyle=\'--\')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.yticks([i/20.0 for i in range(21)])\nplt.xticks([i/20.0 for i in range(21)])\nplt.xlabel(\'False Positive Rate\')\nplt.ylabel(\'True Positive Rate\')\nplt.title(\'Receiver operating characteristic (ROC) Curve\')\nplt.legend(loc=\'lower right\')\nplt.show()\nCreate a confusion matrix for your predictions\nUse a standard decision boundary of 0.5 to convert your probabilities output by logistic regression into binary classifications. (Again this should be for the test set.) Afterward, feel free to use the built-in scikit-learn function to compute the confusion matrix as we discussed in previous sections.\n# Your code here\nInitial Model - scikit-learn\nUse scikit-learn to build a similar model. To start, create an identical model as you did in the last section; turn off the intercept and set the regularization parameter, C, to a ridiculously large number such as 1e16.\n# Your code here\nCreate an ROC Curve for the scikit-learn model\nUse both the training and test sets\n# Your code here\n\ny_train_score = None\ny_test_score = None\n\ntrain_fpr, train_tpr, train_thresholds = None\ntest_fpr, test_tpr, test_thresholds = None\n\n\nprint(\'Train AUC: {}\'.format(auc(train_fpr, train_tpr)))\nprint(\'Test AUC: {}\'.format(auc(test_fpr, test_tpr)))\n\nplt.figure(figsize=(10, 8))\nlw = 2\n\nplt.plot(train_fpr, train_tpr, color=\'blue\',\n         lw=lw, label=\'Train ROC curve\')\nplt.plot(test_fpr, test_tpr, color=\'darkorange\',\n         lw=lw, label=\'Test ROC curve\')\n\nplt.plot([0, 1], [0, 1], color=\'navy\', lw=lw, linestyle=\'--\')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.yticks([i/20.0 for i in range(21)])\nplt.xticks([i/20.0 for i in range(21)])\nplt.xlabel(\'False Positive Rate\')\nplt.ylabel(\'True Positive Rate\')\nplt.title(\'Receiver operating characteristic (ROC) Curve\')\nplt.legend(loc=\'lower right\')\nplt.show()\nAdd an Intercept\nNow add an intercept to the scikit-learn model. Keep the regularization parameter C set to a very large number such as 1e16.\n# Create new model\nlogregi = None\nPlot all three models ROC curves on the same graph.\n# Initial model plots\ntest_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_hat_test)\ntrain_fpr, train_tpr, train_thresholds = roc_curve(y_train, y_hat_train)\n\n\nprint(\'Custom Model Test AUC: {}\'.format(auc(test_fpr, test_tpr)))\nprint(\'Custome Model Train AUC: {}\'.format(auc(train_fpr, train_tpr)))\n\nplt.figure(figsize=(10,8))\nlw = 2\n\nplt.plot(test_fpr, test_tpr, color=\'darkorange\',\n         lw=lw, label=\'Custom Model Test ROC curve\')\nplt.plot(train_fpr, train_tpr, color=\'blue\',\n         lw=lw, label=\'Custom Model Train ROC curve\')\n\n\n# Second model plots\ny_test_score = logreg.decision_function(X_test)\ny_train_score = logreg.decision_function(X_train)\n\ntest_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_test_score)\ntrain_fpr, train_tpr, train_thresholds = roc_curve(y_train, y_train_score)\n\nprint(\'Scikit-learn Model 1 Test AUC: {}\'.format(auc(test_fpr, test_tpr)))\nprint(\'Scikit-learn Model 1 Train AUC: {}\'.format(auc(train_fpr, train_tpr)))\n\n\nplt.plot(test_fpr, test_tpr, color=\'yellow\',\n         lw=lw, label=\'Scikit learn Model 1 Test ROC curve\')\nplt.plot(train_fpr, train_tpr, color=\'gold\',\n         lw=lw, label=\'Scikit learn Model 1 Train ROC curve\')\n\n\n# Third model plots\ny_test_score = None\ny_train_score = None\n\ntest_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_test_score)\ntrain_fpr, train_tpr, train_thresholds = roc_curve(y_train, y_train_score)\n\nprint(\'Scikit-learn Model 2 with intercept Test AUC: {}\'.format(auc(test_fpr, test_tpr)))\nprint(\'Scikit-learn Model 2 with intercept Train AUC: {}\'.format(auc(train_fpr, train_tpr)))\n\n\nplt.plot(test_fpr, test_tpr, color=\'purple\',\n         lw=lw, label=\'Scikit learn Model 2 with intercept Test ROC curve\')\nplt.plot(train_fpr, train_tpr, color=\'red\',\n         lw=lw, label=\'Scikit learn Model 2 with intercept Train ROC curve\')\n\n# Formatting\nplt.plot([0, 1], [0, 1], color=\'navy\', lw=lw, linestyle=\'--\')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.yticks([i/20.0 for i in range(21)])\nplt.xticks([i/20.0 for i in range(21)])\nplt.xlabel(\'False Positive Rate\')\nplt.ylabel(\'True Positive Rate\')\nplt.title(\'Receiver operating characteristic (ROC) Curve\')\nplt.legend(loc=""lower right"")\nplt.show()\nAltering the Regularization Parameter\nNow, experiment with altering the regularization parameter. At a minimum, create 5 different subplots with varying regularization (C) parameters. For each, plot the ROC curve of the training and test set for that specific model.\nRegularization parameters between 1 and 20 are recommended. Observe the difference in test and training AUC as you go along.\n# Your code here\nHow did the regularization parameter impact the ROC curves plotted above?\nSummary\nIn this lab, you reviewed many of the accuracy measures for classification algorithms and observed the impact of additional tuning models using intercepts and regularization.\n'], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['1', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Ridge and Lasso Regression - Lab\nIntroduction\nIn this lab, you\'ll practice your knowledge of Ridge and Lasso regression!\nObjectives\nIn this lab you will:\n\nUse Lasso and Ridge regression with scikit-learn\nCompare and contrast Lasso, Ridge and non-regularized regression\n\nHousing Prices Data\nLet\'s look at yet another house pricing dataset:\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings(\'ignore\')\n\ndf = pd.read_csv(\'Housing_Prices/train.csv\')\nLook at .info() of the data:\n# Your code here\n\nFirst, split the data into X (predictor) and y (target) variables\nSplit the data into 75-25 training-test sets. Set the random_state to 10\nRemove all columns of object type from X_train and X_test and assign them to X_train_cont and X_test_cont, respectively\n\n# Create X and y\ny = None\nX = None\n\n# Split data into training and test sets\nX_train, X_test, y_train, y_test = None\n\n# Remove ""object""-type features from X\ncont_features = None\n\n# Remove ""object""-type features from X_train and X_test\nX_train_cont = None\nX_test_cont = None\nLet\'s use this data to build a first naive linear regression model\n\nFill the missing values in data using median of the columns (use SimpleImputer)\nFit a linear regression model to this data\nCompute the R-squared and the MSE for both the training and test sets\n\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.impute import SimpleImputer\n\n# Impute missing values with median using SimpleImputer\nimpute = None\nX_train_imputed = None\nX_test_imputed = None\n\n# Fit the model and print R2 and MSE for training and test sets\nlinreg = None\n\n# Print R2 and MSE for training and test sets\nNormalize your data\n\nNormalize your data using a StandardScalar\nFit a linear regression model to this data\nCompute the R-squared and the MSE for both the training and test sets\n\nfrom sklearn.preprocessing import StandardScaler\n\n# Scale the train and test data\nss = None\nX_train_imputed_scaled = None\nX_test_imputed_scaled = None\n\n# Fit the model\nlinreg_norm = None\n\n\n# Print R2 and MSE for training and test sets\nInclude categorical variables\nThe above models didn\'t include categorical variables so far, let\'s include them!\n\nInclude all columns of object type from X_train and X_test and assign them to X_train_cat and X_test_cat, respectively\nFill missing values in all these columns with the string \'missing\'\n\n# Create X_cat which contains only the categorical variables\nfeatures_cat = None\nX_train_cat = None\nX_test_cat = None\n\n# Fill missing values with the string \'missing\'\n\n\nOne-hot encode all these categorical columns using OneHotEncoder\nTransform the training and test DataFrames (X_train_cat) and (X_test_cat)\nRun the given code to convert these transformed features into DataFrames\n\nfrom sklearn.preprocessing import OneHotEncoder\n\n# OneHotEncode categorical variables\nohe = None\n\n# Transform training and test sets\nX_train_ohe = None\nX_test_ohe = None\n\n# Convert these columns into a DataFrame\ncolumns = ohe.get_feature_names(input_features=X_train_cat.columns)\ncat_train_df = pd.DataFrame(X_train_ohe.todense(), columns=columns)\ncat_test_df = pd.DataFrame(X_test_ohe.todense(), columns=columns)\n\nCombine X_train_imputed_scaled and cat_train_df into a single DataFrame\nSimilarly, combine X_test_imputed_scaled and cat_test_df into a single DataFrame\n\n# Your code here\nX_train_all = None\nX_test_all = None\nNow build a linear regression model using all the features (X_train_all). Also, print the R-squared and the MSE for both the training and test sets.\n# Your code here\nNotice the severe overfitting above; our training R-squared is very high, but the test R-squared is negative! Similarly, the scale of the test MSE is orders of magnitude higher than that of the training MSE.\nRidge and Lasso regression\nUse all the data (normalized features and dummy categorical variables, X_train_all) to build two models - one each for Lasso and Ridge regression. Each time, look at R-squared and MSE.\nLasso\nWith default parameter (alpha = 1)\n# Your code here\nWith a higher regularization parameter (alpha = 10)\n# Your code here\nRidge\nWith default parameter (alpha = 1)\n# Your code here\nWith default parameter (alpha = 10)\n# Your code here\nCompare the metrics\nWrite your conclusions here:\n\nCompare number of parameter estimates that are (very close to) 0 for Ridge and Lasso\nUse 10**(-10) as an estimate that is very close to 0.\n# Number of Ridge params almost zero\n# Number of Lasso params almost zero\nprint(len(lasso.coef_))\nprint(sum(abs(lasso.coef_) < 10**(-10))/ len(lasso.coef_))\nLasso was very effective to essentially perform variable selection and remove about 25% of the variables from your model!\nPut it all together\nTo bring all of our work together lets take a moment to put all of our preprocessing steps for categorical and continuous variables into one function. This function should take in our features as a dataframe X and target as a Series y and return a training and test DataFrames with all of our preprocessed features along with training and test targets.\ndef preprocess(X, y):\n    \'\'\'Takes in features and target and implements all preprocessing steps for categorical and continuous features returning \n    train and test DataFrames with targets\'\'\'\n    \n    # Train-test split (75-25), set seed to 10\n\n    \n    # Remove ""object""-type features and SalesPrice from X\n\n\n    # Impute missing values with median using SimpleImputer\n\n\n    # Scale the train and test data\n\n\n    # Create X_cat which contains only the categorical variables\n\n\n    # Fill nans with a value indicating that that it is missing\n\n\n    # OneHotEncode Categorical variables\n\n    \n    # Combine categorical and continuous features into the final dataframe\n    \n    return X_train_all, X_test_all, y_train, y_test\nGraph the training and test error to find optimal alpha values\nEarlier we tested two values of alpha to see how it effected our MSE and the value of our coefficients. We could continue to guess values of alpha for our Ridge or Lasso regression one at a time to see which values minimize our loss, or we can test a range of values and pick the alpha which minimizes our MSE. Here is an example of how we would do this:\nX_train_all, X_test_all, y_train, y_test = preprocess(X, y)\n\ntrain_mse = []\ntest_mse = []\nalphas = []\n\nfor alpha in np.linspace(0, 200, num=50):\n    lasso = Lasso(alpha=alpha)\n    lasso.fit(X_train_all, y_train)\n    \n    train_preds = lasso.predict(X_train_all)\n    train_mse.append(mean_squared_error(y_train, train_preds))\n    \n    test_preds = lasso.predict(X_test_all)\n    test_mse.append(mean_squared_error(y_test, test_preds))\n    \n    alphas.append(alpha)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfig, ax = plt.subplots()\nax.plot(alphas, train_mse, label=\'Train\')\nax.plot(alphas, test_mse, label=\'Test\')\nax.set_xlabel(\'Alpha\')\nax.set_ylabel(\'MSE\')\n\n# np.argmin() returns the index of the minimum value in a list\noptimal_alpha = alphas[np.argmin(test_mse)]\n\n# Add a vertical line where the test MSE is minimized\nax.axvline(optimal_alpha, color=\'black\', linestyle=\'--\')\nax.legend();\n\nprint(f\'Optimal Alpha Value: {int(optimal_alpha)}\')\nTake a look at this graph of our training and test MSE against alpha. Try to explain to yourself why the shapes of the training and test curves are this way. Make sure to think about what alpha represents and how it relates to overfitting vs underfitting.\nSummary\nWell done! You now know how to build Lasso and Ridge regression models, use them for feature selection and find an optimal value for $\\text{alpha}$.\n'], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['1', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Linear to Logistic regression\nIntroduction\nIn this lesson, you\'ll be introduced to the logistic regression model. You\'ll start with an introductory example using linear regression, which you\'ve seen before, to act as a segue into logistic regression. After that, you\'ll learn about the formal notation of logistic regression models. Then, you\'ll conclude this lesson by looking at a real-world example.\nObjectives\nYou will be able to:\n\nDescribe the need for logistic regression\nInterpret the parameters of a logistic regression model\n\nRecap of the linear regression model\nYou have previously learned about linear regression models. In these models, you are trying to fit a linear relationship between two variables. An example is given below. In this example, you want to find a relationship between age and monthly income. It is reasonable to assume that, on average, older people have a higher income than younger people who are newer to the job market and have less experience. A potential relationship could look like the plot below. The monthly income is shown in 1000s of USD.\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nnp.random.seed(1234)\n\nage = np.random.uniform(18, 65, 100)\nincome = np.random.normal((age/10), 0.5)\nage = age.reshape(-1,1)\n\nfig = plt.figure(figsize=(8,6))\nfig.suptitle(\'age vs income\', fontsize=16)\nplt.scatter(age, income)\nplt.xlabel(\'age\', fontsize=14)\nplt.ylabel(\'monthly income\', fontsize=14)\nplt.show()\n\nIn linear regression, you would try to find a relationship between age and monthly income. Conceptually, this means fitting a line that represents the relationship between age and monthly income, as shown below.\nfig = plt.figure(figsize=(8, 6))\nfig.suptitle(\'linear regression\', fontsize=16)\nplt.scatter(age, income)\nplt.plot(age, age/10, c=\'black\')\nplt.xlabel(\'age\', fontsize=14)\nplt.ylabel(\'monthly income\', fontsize=14)\nplt.show()\n\nThe idea is that you could use this line to make predictions in the future. In this case, the relationship is modeled as follows: the expected monthly income for someone who is, say, 40 years old, is 3000 (3 on the y-axis). Of course, the actual income will most likely be different, but this indicates what the model predicts as the salary value.\nSo how is this related to logistic regression?\nNow, imagine you get a dataset where no information on exact income is given (after all, people don\'t like to talk about how much they earn!), but you only have information on whether or not they earn more than 4000 USD per month. Starting from the generated data we used before, the new variable income_bin was transformed to 1 when someone\'s income is over 4000 USD, and 0 when the income is less than 4000 USD.\nincome_bin = income > 4\nincome_bin = income_bin.astype(int)  \nprint(income_bin)\n[0 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0\n 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0\n 0 1 0 0 0 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 1 0 1]\n\nHave a look at what happens when you plot this.\nfig = plt.figure(figsize=(8, 6))\nfig.suptitle(\'age vs binary income\', fontsize=16)\nplt.scatter(age, income_bin)\nplt.xlabel(\'age\', fontsize=14)\nplt.ylabel(\'monthly income (> or < 4000)\', fontsize=14)\nplt.show()\n\nYou can already tell that fitting a straight line will not work here. Take a look at what happens when you fit a regression line to these data.\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\n\n# Create linear regression model\nlin_reg = LinearRegression()\nlin_reg.fit(age, income_bin)\n# Store the coefficients\ncoef = lin_reg.coef_\ninterc = lin_reg.intercept_\n# Create the line\nlin_income = (interc + age * coef)\nfig = plt.figure(figsize=(8, 6))\nfig.suptitle(\'linear regression\', fontsize=16)\nplt.scatter(age, income_bin)\nplt.xlabel(\'age\', fontsize=14)\nplt.ylabel(\'monthly income\', fontsize=14)\nplt.plot(age, lin_income, c=\'black\')\nplt.show()\n\nYou can see that this doesn\'t make a lot of sense. This straight line cannot grasp the true structure of what is going on when using a linear regression model. Now, without going into the mathematical details for now, look at a logistic regression model and fit that to the dataset.\n# Instantiate a Logistic regression model\n# Solver must be specified to avoid warning, see documentation for more information\n# liblinear is recommended for small datasets\n# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\nregr = LogisticRegression(C=1e5, solver=\'liblinear\')\n\n# Fit the model to the training set\nregr.fit(age, income_bin)\nLogisticRegression(C=100000.0, class_weight=None, dual=False,\n                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n                   max_iter=100, multi_class=\'warn\', n_jobs=None, penalty=\'l2\',\n                   random_state=None, solver=\'liblinear\', tol=0.0001, verbose=0,\n                   warm_start=False)\n\n# Store the coefficients\ncoef = regr.coef_\ninterc = regr.intercept_\n\n# Create the linear predictor\nlin_pred = (age * coef + interc)\n\n# Perform the log transformation\nmod_income = 1 / (1 + np.exp(-lin_pred))\n\n# Sort the numbers to make sure plot looks right\nage_ordered, mod_income_ordered = zip(*sorted(zip(age ,mod_income.ravel()),key=lambda x: x[0]))\nfig = plt.figure(figsize=(8, 6))\nfig.suptitle(\'logistic regression\', fontsize=16)\nplt.scatter(age, income_bin)\nplt.xlabel(\'age\', fontsize=14)\nplt.ylabel(\'monthly income\', fontsize=14)\nplt.plot(age_ordered, mod_income_ordered, c=\'black\')\nplt.show()\n\nThis already looks a lot better! You can see that this function has an S-shape which plateaus to 0 in the left tale and 1 to the right tale. This is exactly what we needed here. Hopefully this example was a good way of showing why logistic regression is useful. Now, it\'s time to dive into the mathematics that make logistic regression possible.\nLogistic regression model formulation\nThe model\nAs you might remember from the linear regression lesson, a linear regression model can be written as:\n$$ \\hat y = \\hat\\beta_0 + \\hat\\beta_1 x_1 + \\hat\\beta_2 x_2 +\\ldots + \\beta_n x_n $$\nWhen there are $n$ predictors $x_1,\\ldots,x_n$ and $n+1$ parameter estimates that are estimated by the model $\\hat\\beta_0, \\hat\\beta_1,\\ldots, \\hat\\beta_n$.  $ \\hat y $ is an estimator for the outcome variable.\nTranslating this model formulation to our example, this boils down to:\n$$ \\text{income} = \\beta_0 + \\beta_1 \\text{age} $$\nWhen you want to apply this to a binary dataset, what you actually want to do is perform a classification of your data in one group versus another one. In our case, we want to classify our observations (the 100 people in our dataset) as good as possible in ""earns more than 4k"" and ""earns less than 4k"". A model will have to guess what the probability is of belonging to one group versus another. And that is exactly what logistic regression models can do!\nEssentially, what happens is, the linear regression is transformed in a way that the outcome takes a value between 0 and 1. This can then be interpreted as a probability (e.g., 0.2 is a probability of 20%). Applied to our example, the expression for a logistic regression model would look like this:\n$$ P(\\text{income} > 4000) = \\displaystyle \\frac{1}{1+e^{-(\\hat \\beta_0+\\hat \\beta_1 \\text{age})}}$$\nNote that the outcome is written as $P(\\text{income} > 4000)$. This means that the output should be interpreted as the probability that the monthly income is over 4000 USD.\nIt is important to note that this is the case because the income variable was relabeled to be equal to 1 when the income is bigger than 4000, and 0 when smaller than 4000. In other words, the outcome variable should be interpreted as the probability of the class label to be equal to 1.\nInterpretation\nAs mentioned before, the probability of an income over 4000 can be calculated using:\n$$ P(\\text{income} > 4000) = \\displaystyle \\frac{1}{1+e^{-(\\hat \\beta_o+\\hat \\beta_1 \\text{age})}}$$\nYou can show that, by multiplying both numerator and denominator by $e^{(\\hat \\beta_0+\\hat \\beta_1 \\text{age})}$\n$$ P(\\text{income} > 4000) = \\displaystyle \\frac{e^{\\hat \\beta_0+\\hat \\beta_1 \\text{age}}}{1+e^{\\hat \\beta_o+\\hat \\beta_1 \\text{age}}}$$\nAs a result, you can compute $P(\\text{income} \\leq 4000)$ as:\n$$ P(\\text{income} < 4000) = 1- \\displaystyle \\frac{e^{\\hat \\beta_0+\\hat \\beta_1 \\text{age}}}{1+e^{\\hat \\beta_o+\\hat \\beta_1 \\text{age}}}= \\displaystyle \\frac{1}{1+e^{\\hat \\beta_0+\\hat \\beta_1 \\text{age}}}$$\nThis doesn\'t seem to be very spectacular, but combining these two results leads to an easy interpretation of the model parameters, triggered by the odds\n$$ \\dfrac{P(\\text{income} > 4000)}{P(\\text{income} < 4000)} = e^{\\hat \\beta_0+\\hat \\beta_1 \\text{age}} $$\nThis expression can be interpreted as the odds in favor of an income greater than 4000 USD.\nThis result, in combination with mathematical properties of exponential functions, leads to the fact that, applied to our example:\nif age goes up by 1, the odds are multiplied by $e^{\\beta_1}$\nIn our example, there is a positive relationship between age and income, this will lead a positive $\\beta_1 > 0$, so $e^{\\beta_1}>1$, and the odds will increase as age increases.\nA real-world example\nNow you will apply these concepts to a real-world dataset:\nimport statsmodels as sm\nimport sklearn.preprocessing as preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom scipy import stats\nsalaries = pd.read_csv(\'salaries_final.csv\', index_col=0)\nsalaries.head()\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\nAge\nEducation\nOccupation\nRelationship\nRace\nSex\nTarget\n\n\n\n\n0\n39\nBachelors\nAdm-clerical\nNot-in-family\nWhite\nMale\n<=50K\n\n\n1\n50\nBachelors\nExec-managerial\nHusband\nWhite\nMale\n<=50K\n\n\n2\n38\nHS-grad\nHandlers-cleaners\nNot-in-family\nWhite\nMale\n<=50K\n\n\n3\n53\n11th\nHandlers-cleaners\nHusband\nBlack\nMale\n<=50K\n\n\n4\n28\nBachelors\nProf-specialty\nWife\nBlack\nFemale\n<=50K\n\n\n\n\nFor this example, you will fit a logistic regression model to Target using Age, Race, and Sex. Since Target, Race, and Sex are categorical, they need to be be converted to a numeric datatype first.\nThe get_dummies() function will only convert object and category datatypes to dummy variables so it is safe to pass Age to get_dummies(). Note that we also pass two additional arguments, drop_first=True and dtype=float. The drop_first=True argument removes the first level for each categorical variable and the dtype=float argument converts the datatype of all the dummy variables to float. The data must be float in order to obtain accurate statistical results from statsmodels.\n# Convert race and sex using get_dummies() \nx_feats = [\'Race\', \'Sex\', \'Age\']\nX = pd.get_dummies(salaries[x_feats], drop_first=True, dtype=float)\n\n# Convert target using get_dummies\ny = pd.get_dummies(salaries[\'Target\'], drop_first=True, dtype=float)\ny = y[\'>50K\']\nimport statsmodels.api as sm\n\n# Create intercept term required for sm.Logit, see documentation for more information\nX = sm.add_constant(X)\n\n# Fit model\nlogit_model = sm.Logit(y, X)\n\n# Get results of the fit\nresult = logit_model.fit()\nOptimization terminated successfully.\n         Current function value: 0.498651\n         Iterations 6\n\n\n//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n  return ptp(axis=axis, out=out, **kwargs)\n\nresult.summary()\n\nLogit Regression Results\n\nDep. Variable: >50K   No. Observations:    32561\n\n\nModel: Logit   Df Residuals:        32554\n\n\nMethod: MLE   Df Model:                6\n\n\nDate: Wed, 20 Nov 2019   Pseudo R-squ.:      0.09666\n\n\nTime: 14:55:31   Log-Likelihood:      -16237.\n\n\nconverged: True   LL-Null:             -17974.\n\n\nCovariance Type: nonrobust   LLR p-value:         0.000\n\n\n\n\n coef std err z P>|z| [0.025 0.975]\n\n\nconst    -4.4248     0.189   -23.380  0.000    -4.796    -4.054\n\n\nAge     0.0387     0.001    38.530  0.000     0.037     0.041\n\n\nRace_Asian-Pac-Islander     0.9991     0.197     5.079  0.000     0.614     1.385\n\n\nRace_Black     0.1812     0.191     0.950  0.342    -0.193     0.555\n\n\nRace_Other    -0.1143     0.282    -0.406  0.685    -0.667     0.438\n\n\nRace_White     0.8742     0.183     4.782  0.000     0.516     1.232\n\n\nSex_Male     1.2069     0.035    34.380  0.000     1.138     1.276\n\n\nnp.exp(result.params)\nconst                      0.011977\nAge                        1.039480\nRace_Asian-Pac-Islander    2.715861\nRace_Black                 1.198638\nRace_Other                 0.891987\nRace_White                 2.396965\nSex_Male                   3.343142\ndtype: float64\n\nYou can also use scikit-learn to retrieve the parameter estimates. The disadvantage here though is that there are no p-values for your parameter estimates!\nlogreg = LogisticRegression(fit_intercept = False, C = 1e15, solver=\'liblinear\')\nmodel_log = logreg.fit(X, y)\nmodel_log\nLogisticRegression(C=1000000000000000.0, class_weight=None, dual=False,\n                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n                   max_iter=100, multi_class=\'warn\', n_jobs=None, penalty=\'l2\',\n                   random_state=None, solver=\'liblinear\', tol=0.0001, verbose=0,\n                   warm_start=False)\n\nmodel_log.coef_\narray([[-4.38706342,  0.03871011,  0.96178902,  0.14397983, -0.14384057,\n         0.83689457,  1.2067121 ]])\n\nSummary\nIn this lab you built upon your previous knowledge of linear regression and built an intuitive understanding of how this could be adapted for classification. We then demonstrated tools for performing logistic regression. In the upcoming lessons you will continue to investigate logistic regression from other viewpoints.\n'], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['1', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Coding Logistic Regression From Scratch - Lab\nIntroduction\nIn this lab, you\'ll practice your ability to translate mathematical algorithms into Python functions. This will deepen and solidify your understanding of logistic regression!\nObjectives\nIn this lab you will:\n\nBuild a logistic regression model from scratch using gradient descent\n\nOverview\nRecall that the logistic regression algorithm builds upon the intuition from linear regression. In logistic regression, you start by taking the input data, X, and multiplying it by a vector of weights for each of the individual features, which produces an output, y. Afterward, you\'ll work on using an iterative approach via gradient descent to tune these weights.\nLinear regression setup\nWrite a simple function predict_y() that takes in a matrix X of observations and a vector of feature weights w and outputs a vector of predictions for the various observations.\nRecall that this is the sum of the product of each of the feature observations and their corresponding feature weights:\n$\\large \\hat{y}i = X{i1} \\cdot w_1 + X_{i2} \\cdot w_2 + X_{i3} \\cdot w_3 + ... + X_{in} \\cdot w_n$\n\nHint: Think about which mathematical operation you\'ve seen previously that will take a matrix (X) and multiply it by a vector of weights (w). Use NumPy!\n\n# Your code here\nimport numpy as np\n\ndef predict_y(X, w): \n    pass\nThe sigmoid function\nRecall that the sigmoid function is used to map the linear regression model output to a range of 0 to 1, satisfying basic premises of probability. As a reminder, the sigmoid function is defined by:\n$S(x) = \\dfrac{1}{1+e^(-x)}$\nWrite this as a Python function where x is the input and the function outputs the result of the sigmoid function.\n\nHint: Use NumPy!\n\n# Your code here\nPlot the sigmoid\nFor good measure, let\'s do a brief investigation of your new function. Plot the output of your sigmoid() function using 10,000 values evenly spaced from -20 to 20.\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Plot sigmoid\nGradient descent with the sigmoid function\nRecall that gradient descent is a numerical method for finding a minimum to a cost function. In the case of logistic regression, you are looking to minimize the error between the model\'s predictions and the actual data labels. To do this, you first calculate an error vector based on the current model\'s feature weights. You then multiply the transpose of the training matrix itself by this error vector in order to obtain the gradient. Finally, you take the gradient, multiply it by the step size and add this to our current weight vector to update it. Below, write such a function. It will take 5 inputs:\n\nX\ny\nmax_iterations\nalpha (the step size)\ninitial_weights\n\nBy default, have your function set the initial_weights parameter to a vector where all feature weights are set to 1.\n# Your code here\ndef grad_desc(X, y, max_iterations, alpha, initial_weights=None):\n    """"""Be sure to set default behavior for the initial_weights parameter.""""""\n    # Create a for loop of iterations\n        # Generate predictions using the current feature weights\n        # Calculate an error vector based on these initial predictions and the correct labels\n        # Calculate the gradient \n        # As we saw in the previous lab, calculating the gradient is often the most difficult task.\n        # Here, your are provided with the closed form solution for the gradient of the log-loss function derived from MLE\n        # For more details on the derivation, see the additional resources section below.\n        gradient = np.dot(X.transpose(), error_vector) \n        # Update the weight vector take a step of alpha in direction of gradient \n    # Return finalized weights\n    \nRunning your algorithm\nNow that you\'ve coded everything from the ground up, you can further investigate the convergence behavior of the gradient descent algorithm. Remember that gradient descent does not guarantee a global minimum, only a local minimum, and that small deviations in the starting point or step size can lead to different outputs.\nFirst, run the following cell to import the data and create the predictor and target variables:\n# Import data\nimport pandas as pd\ndf = pd.read_csv(\'heart.csv\')\n\n# Create the predictor and target variables\ny = df[\'target\']\nX = df.drop(columns=[\'target\'], axis=1)\n\nprint(y.value_counts())\nX.head()\nRun your algorithm and plot the successive weights of the features through iterations. Below is a dataset, with X and y predefined for you. Use your logistic regression function to train a model. As the model trains, record the iteration cycle of the gradient descent algorithm and the weights of the various features. Then, plot this data on subplots for each of the individual features. Each graph should have the iteration number on the x-axis and the value of that feature weight for that iteration cycle on the y-axis. This will visually display how the algorithm is adjusting the weights over successive iterations, and hopefully show convergence to stable weights.\n# Your code here\nScikit-learn\nFor comparison, import scikit-learn\'s standard LogisticRegression() function. Initialize it with no intercept and C=1e16 or another very high number. The reason is as follows: our implementation has not used an intercept, and you have not performed any regularization such as Lasso or Ridge (scikit-learn uses l2 by default). The high value of C will essentially negate this. Also, set the random_state to 2 and use the \'liblinear\' solver.\nAfter initializing a regression object, fit it to X and y.\n# Your code here\nCompare the models\nCompare the coefficient weights of your model to that generated by scikit-learn.\n# Your code here\nLevel up (Optional)\nUpdate the gradient descent algorithm to also return the cost after each iteration. Then rerun the algorithm and create a graph displaying the cost versus the iteration number.\n# Your code here\nAdditional Resources\nIf you want to see more of the mathematics behind the gradient derivation above, check out section 4.4.1 from the Elements of Statistical Learning which can be found here: https://web.stanford.edu/~hastie/ElemStatLearn//.\nSummary\nCongratulations! You just coded logistic regression from the ground up using NumPy! With this, you should have a fairly deep understanding of logistic regression and how the algorithm works! In the upcoming labs, you\'ll continue to explore this from a few more angles, plotting your data along with the decision boundary for our predictions.\n'], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['1', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '45 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/piyush18184', 'info_list': ['1', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '128 contributions\n        in the last year', 'description': ['This project report explores the Naïve - Bayes and Logistic regression classifiers, discusses the implementation of both the classifiers\non the problem of classifying the MNIST dataset that contains the images of handwritten numbers. Assumption on probability of each class\nare made to classify the images.\nConclusions:\n\nLogistic regression is more efficient than the Naïve – Bayes algorithm, the overall accuracy obtained is 91.85% where in Naïve – Bayes\nended up 61.82% test accuracy. Logistic Regression being complex as compared to the Naïve – Bayes algorithm, Logistic Regression model\nperformed well in classifying the images.\nLogistic Regression is more computationally expensive than Naïve Bayes. The Naïve Bayes took less than a minute to train and predict\nthe labels, whereas Logistic Regression took about an hour to train and predict the labels.\nNaïve Bayes classifier assumes all the dimensions as independent to one another which is not true.\n\nReferences\n[1] CS5841\u200a-\u200aMachine learning by Dr. Timoty Havens, Lecture slides.\n[2] Lazy Programmers- Source of deep learning and Machine Learning.\n[3] K. Elissa, ""Title of paper if known,"" unpublished.\n[4] Logistic Regression Overview Towards Data Science..\n[5] Pattern recognition and Machine Learning by Bishop.\n[6] DataCamp Ridge and Lasso Regularization.\n[7] Machine Learning Mastery\u200a-\u200aNaive Bayes.\n[8] Kaggle Logistic Regression without Scikit Learn.\n'], 'url_profile': 'https://github.com/Rajath1995', 'info_list': ['1', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '161 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/semg101', 'info_list': ['1', 'R', 'Updated May 11, 2020', 'Python', 'Updated May 14, 2020', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', '1', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 14, 2020']}"
"{'location': 'Luebeck, Berlin', 'stats_list': [], 'contributions': '48 contributions\n        in the last year', 'description': ['num1 = float(input(""enter first number:""))\nop = input(""enter operator:"")\nnum2 = float(input(""enter second number:""))\nif op == ""+"":\nprint(num1 + num2)\nelif op == ""-"":\nprint(num1 - num2)\nelif op == ""/"":\nprint(num1 / num2)\nelif op == ""*"":\nprint(num1 * num2)\nelse:\nprint(""invalid operator"")\n'], 'url_profile': 'https://github.com/karisobomac', 'info_list': ['1', 'Jupyter Notebook', 'Updated Oct 20, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '17 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ranjanksinha', 'info_list': ['1', 'Jupyter Notebook', 'Updated Oct 20, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '161 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/semg101', 'info_list': ['1', 'Jupyter Notebook', 'Updated Oct 20, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '66 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/emreozb', 'info_list': ['1', 'Jupyter Notebook', 'Updated Oct 20, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 17, 2020']}","{'location': 'bhubaneswar', 'stats_list': [], 'contributions': '70 contributions\n        in the last year', 'description': ['Deployed-Data-Science-Logistic-Regression-To-a-Web-Page\nHere i have deployed a logistic regressionn model to a web page in python\n'], 'url_profile': 'https://github.com/iamchiranjeeb', 'info_list': ['1', 'Jupyter Notebook', 'Updated Oct 20, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '45 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/piyush18184', 'info_list': ['1', 'Jupyter Notebook', 'Updated Oct 20, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '45 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/piyush18184', 'info_list': ['1', 'Jupyter Notebook', 'Updated Oct 20, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': [""Logistic Regression in scikit-learn - Lab\nIntroduction\nIn this lab, you are going to fit a logistic regression model to a dataset concerning heart disease. Whether or not a patient has heart disease is indicated in the column labeled 'target'. 1 is for positive for heart disease while 0 indicates no heart disease.\nObjectives\nIn this lab you will:\n\nFit a logistic regression model using scikit-learn\n\nLet's get started!\nRun the following cells that import the necessary functions and import the dataset:\n# Import necessary functions\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\n# Import data\ndf = pd.read_csv('heart.csv')\ndf.head()\nDefine appropriate X and y\nRecall the dataset contains information about whether or not a patient has heart disease and is indicated in the column labeled 'target'. With that, define appropriate X (predictors) and y (target) in order to model whether or not a patient has heart disease.\n# Split the data into target and predictors\ny = None\nX = None\nNormalize the data\nNormalize the data (X) prior to fitting the model.\n# Your code here\nX = None\nX.head()\nTrain- test split\n\nSplit the data into training and test sets\nAssign 25% to the test set\nSet the random_state to 0\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = None\nFit a model\n\nInstantiate LogisticRegression\n\nMake sure you don't include the intercept\nset C to a very large number such as 1e12\nUse the 'liblinear' solver\n\n\nFit the model to the training data\n\n# Instantiate the model\nlogreg = None\n\n# Fit the model\nPredict\nGenerate predictions for the training and test sets.\n# Generate predictions\ny_hat_train = None\ny_hat_test = None\nHow many times was the classifier correct on the training set?\n# Your code here\nHow many times was the classifier correct on the test set?\n# Your code here\nAnalysis\nDescribe how well you think this initial model is performing based on the training and test performance. Within your description, make note of how you evaluated performance as compared to your previous work with regression.\n# Your analysis here\nSummary\nIn this lab, you practiced a standard data science pipeline: importing data, split it into training and test sets, and fit a logistic regression model. In the upcoming labs and lessons, you'll continue to investigate how to analyze and tune these models for various scenarios.\n""], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['1', 'Jupyter Notebook', 'Updated Oct 20, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': [""Logistic Regression in scikit-learn\nIntroduction\nGenerally, the process for fitting a logistic regression model using scikit-learn is very similar to that which you previously saw for statsmodels. One important exception is that scikit-learn will not display statistical measures such as the p-values associated with the various features. This is a shortcoming of scikit-learn, although scikit-learn has other useful tools for tuning models which we will investigate in future lessons.\nThe other main process of model building and evaluation which we didn't to discuss previously is performing a train-test split. As we saw in linear regression, model validation is an essential part of model building as it helps determine how our model will generalize to future unseen cases. After all, the point of any model is to provide future predictions where we don't already know the answer but have other informative data (X).\nWith that, let's take a look at implementing logistic regression in scikit-learn using dummy variables and a proper train-test split.\nObjectives\nYou will be able to:\n\nFit a logistic regression model using scikit-learn\n\nImport the data\nimport pandas as pd\n\ndf = pd.read_csv('titanic.csv')\ndf.head()\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\nDefine X and y\nNote that we first have to create our dummy variables, and then we can use these to define X and y.\ndf = pd.get_dummies(df, drop_first=True)\nprint(df.columns)\ndf.head()\nIndex(['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare',\n       'Name_Abbott, Mr. Rossmore Edward',\n       'Name_Abbott, Mrs. Stanton (Rosa Hunt)', 'Name_Abelson, Mr. Samuel',\n       ...\n       'Cabin_F G63', 'Cabin_F G73', 'Cabin_F2', 'Cabin_F33', 'Cabin_F38',\n       'Cabin_F4', 'Cabin_G6', 'Cabin_T', 'Embarked_Q', 'Embarked_S'],\n      dtype='object', length=1726)\n\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\nPassengerId\nSurvived\nPclass\nAge\nSibSp\nParch\nFare\nName_Abbott, Mr. Rossmore Edward\nName_Abbott, Mrs. Stanton (Rosa Hunt)\nName_Abelson, Mr. Samuel\n...\nCabin_F G63\nCabin_F G73\nCabin_F2\nCabin_F33\nCabin_F38\nCabin_F4\nCabin_G6\nCabin_T\nEmbarked_Q\nEmbarked_S\n\n\n\n\n0\n1\n0\n3\n22.0\n1\n0\n7.2500\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n1\n2\n1\n1\n38.0\n1\n0\n71.2833\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n3\n1\n3\n26.0\n0\n0\n7.9250\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n3\n4\n1\n1\n35.0\n1\n0\n53.1000\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n4\n5\n0\n3\n35.0\n0\n0\n8.0500\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n\n5 rows × 1726 columns\n\nWow! That's a lot of columns! (Way more then is useful in practice: we now have columns for each of the passengers names. This is an example of what not to do. Let's try that again, this time being mindful of which variables we actually want to include in our model.\ndf = pd.read_csv('titanic.csv')\ndf.head()\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\nx_feats = ['Pclass', 'Sex', 'Age', 'SibSp', 'Fare', 'Cabin', 'Embarked']\nX = pd.get_dummies(df[x_feats], drop_first=True)\ny = df['Survived']\nX.head() # Preview our data to make sure it looks reasonable\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\nPclass\nAge\nSibSp\nFare\nSex_male\nCabin_A14\nCabin_A16\nCabin_A19\nCabin_A20\nCabin_A23\n...\nCabin_F G63\nCabin_F G73\nCabin_F2\nCabin_F33\nCabin_F38\nCabin_F4\nCabin_G6\nCabin_T\nEmbarked_Q\nEmbarked_S\n\n\n\n\n0\n3\n22.0\n1\n7.2500\n1\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n1\n1\n38.0\n1\n71.2833\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n3\n26.0\n0\n7.9250\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n3\n1\n35.0\n1\n53.1000\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n4\n3\n35.0\n0\n8.0500\n1\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n\n\n\n5 rows × 153 columns\n\nNormalization\nAnother important model tuning practice is to normalize your data. That is, if the features are on different scales, some features may impact the model more heavily then others. To level the playing field, we often normalize all features to a consistent scale of 0 to 1.\n# Fill missing values\nX = X.fillna(value=0) \nfor col in X.columns:\n    # Subtract the minimum and divide by the range forcing a scale of 0 to 1 for each feature\n    X[col] = (X[col] - min(X[col]))/ (max(X[col]) - min(X[col])) \n\nX.head()\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\nPclass\nAge\nSibSp\nFare\nSex_male\nCabin_A14\nCabin_A16\nCabin_A19\nCabin_A20\nCabin_A23\n...\nCabin_F G63\nCabin_F G73\nCabin_F2\nCabin_F33\nCabin_F38\nCabin_F4\nCabin_G6\nCabin_T\nEmbarked_Q\nEmbarked_S\n\n\n\n\n0\n1.0\n0.2750\n0.125\n0.014151\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n1\n0.0\n0.4750\n0.125\n0.139136\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n2\n1.0\n0.3250\n0.000\n0.015469\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n3\n0.0\n0.4375\n0.125\n0.103644\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n4\n1.0\n0.4375\n0.000\n0.015713\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n\n\n\n5 rows × 153 columns\n\nTrain-test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\nFit a model\nFit an initial model to the training set. In scikit-learn, you do this by first creating an instance of the LogisticRegression class. From there, then use the .fit() method from your class instance to fit a model to the training data.\nfrom sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(fit_intercept=False, C=1e12, solver='liblinear')\nmodel_log = logreg.fit(X_train, y_train)\nmodel_log\nLogisticRegression(C=1000000000000.0, class_weight=None, dual=False,\n                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n                   warm_start=False)\n\nPredict\nNow that we have a model, lets take a look at how it performs.\ny_hat_test = logreg.predict(X_test)\ny_hat_train = logreg.predict(X_train)\nimport numpy as np\n# We could subtract the two columns. If values or equal, difference will be zero. Then count number of zeros \nresiduals = np.abs(y_train - y_hat_train)\nprint(pd.Series(residuals).value_counts())\nprint(pd.Series(residuals).value_counts(normalize=True))\n0    563\n1    105\nName: Survived, dtype: int64\n0    0.842814\n1    0.157186\nName: Survived, dtype: float64\n\nNot bad; our classifier was about 85% correct on our training data!\nresiduals = np.abs(y_test - y_hat_test)\nprint(pd.Series(residuals).value_counts())\nprint(pd.Series(residuals).value_counts(normalize=True))\n0    174\n1     49\nName: Survived, dtype: int64\n0    0.780269\n1    0.219731\nName: Survived, dtype: float64\n\nAnd still about 80% accurate on our test data!\nSummary\nIn this lesson, you took a more complete look at a data science pipeline for logistic regression, splitting the data into training and test sets and using the model to make predictions. You'll practice this on your own in the upcoming lab before having a more detailed discussion of more nuanced methods for evaluating a classifier's performance.\n""], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['1', 'Jupyter Notebook', 'Updated Oct 20, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 17, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '88 contributions\n        in the last year', 'description': ['Board-Game-Review-Predictor\nRating/Review of a Board Game is predicted by given attributes first by a Linear Regression Model and then by  Forest Regressor which is a Non-Linear model (decision trees)\n'], 'url_profile': 'https://github.com/malvi-aditya', 'info_list': ['1', 'Jupyter Notebook', 'Updated Oct 20, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Python', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 11, 2020', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 17, 2020']}"
"{'location': 'Canada', 'stats_list': [], 'contributions': '208 contributions\n        in the last year', 'description': ['R-Projects-in-Time-Series-Analysis\nA collection of time series analysis and modelling projects using R. Models implemented includes (seasonal) ARIMA models, multivariate VAR models, GARCH, and ARMA-error regression model with other external regressors.\n'], 'url_profile': 'https://github.com/leetim13', 'info_list': ['1', 'R', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Julia', 'MIT license', 'Updated Jul 26, 2020', '1', 'MATLAB', 'Updated Sep 24, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '37 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/BarreiroLindoF', 'info_list': ['1', 'R', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Julia', 'MIT license', 'Updated Jul 26, 2020', '1', 'MATLAB', 'Updated Sep 24, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['NONE'], 'url_profile': 'https://github.com/cran', 'info_list': ['1', 'R', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Julia', 'MIT license', 'Updated Jul 26, 2020', '1', 'MATLAB', 'Updated Sep 24, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 29, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '96 contributions\n        in the last year', 'description': ['NY-Airbnb-price-prediction\n'], 'url_profile': 'https://github.com/BenRoshan100', 'info_list': ['1', 'R', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Julia', 'MIT license', 'Updated Jul 26, 2020', '1', 'MATLAB', 'Updated Sep 24, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 29, 2020']}","{'location': 'Cambridge', 'stats_list': [], 'contributions': '56 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/TudorParas', 'info_list': ['1', 'R', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Julia', 'MIT license', 'Updated Jul 26, 2020', '1', 'MATLAB', 'Updated Sep 24, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '538 contributions\n        in the last year', 'description': ['House-Prise-predection\nIn which I make a linear regression algorithm to predict the price of house. If area of houses is giving to me\n'], 'url_profile': 'https://github.com/maneesh06', 'info_list': ['1', 'R', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Julia', 'MIT license', 'Updated Jul 26, 2020', '1', 'MATLAB', 'Updated Sep 24, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '61 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/adityavadalkar', 'info_list': ['1', 'R', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Julia', 'MIT license', 'Updated Jul 26, 2020', '1', 'MATLAB', 'Updated Sep 24, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '21 contributions\n        in the last year', 'description': ['Identifying-depression-with-NLP\nIdentified trends in Twitter data indicative of depression for early intervention using NLP Sentiment analysis and statistical methods.\n\nTested and evaluated performance of various machine learning models on the data including Recurrent Neural Networks, Logistic Regression, Naive Bayes\nApplied statistical methods such as ANOVA in conjunction with prior literature to identify trends indicative of depression\nVarious libraries were employed including NLTK and PyTorch\n\n'], 'url_profile': 'https://github.com/malik-hasan', 'info_list': ['1', 'R', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Julia', 'MIT license', 'Updated Jul 26, 2020', '1', 'MATLAB', 'Updated Sep 24, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '17 contributions\n        in the last year', 'description': ['youtube-video-views-predictor\nTraining a linear regression model and a neural network model to predict the number of views of a YouTube videos given the\nnumber of likes, dislikes and subscribers.\n'], 'url_profile': 'https://github.com/hasinisperera', 'info_list': ['1', 'R', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Julia', 'MIT license', 'Updated Jul 26, 2020', '1', 'MATLAB', 'Updated Sep 24, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 29, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '97 contributions\n        in the last year', 'description': [""Predicting-Number-of-visits\nIt's a regression problem where you have to use machine learning to predict how often do we visit doctors annually.\n""], 'url_profile': 'https://github.com/FahdZaghdoudi', 'info_list': ['1', 'R', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'R', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Julia', 'MIT license', 'Updated Jul 26, 2020', '1', 'MATLAB', 'Updated Sep 24, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jan 28, 2021', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 29, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': ['Heart-Disease-Prediction-\n'], 'url_profile': 'https://github.com/pkhurana24', 'info_list': ['R', 'Updated May 15, 2020', 'R', 'Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Aug 14, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', 'R', 'Updated May 12, 2020']}","{'location': 'New York', 'stats_list': [], 'contributions': '1,522 contributions\n        in the last year', 'description': ['Financial Distress\nSTA-9890-Project\nIn this exercise we are attempting at running various regression models through namely Lasso, Ridge, Elastic Net and Random Forrest to predict on a financial dataset from multiple firms to see if we can predict distress.\nUnderstanding the models\nElastic Net:\nIn statistics and, in particular, in the fitting of linear or logistic regression models, the elastic net is a regularized regression method that linearly combines the L1 and L2 penalties of the lasso and ridge methods.\nThe elastic net method overcomes the limitations of the LASSO (least absolute shrinkage and selection operator) method which uses a penalty function. In addition to setting and choosing a lambda value elastic net also allows us to tune the alpha parameter where 𝞪 = 0 corresponds to ridge and 𝞪 = 1 to lasso. Simply put, if you plug in 0 for alpha, the penalty function reduces to the L1 (ridge) term and if we set alpha to 1 we get the L2 (lasso) term. Therefore, we can choose an alpha value between 0 and 1 to optimize the elastic net. Effectively this will shrink some coefficients and set some to 0 for sparse selection. In this exercise we will have 𝞪 = 0.5\nLasso:\nLasso regression uses the L1 penalty term and stands for Least Absolute Shrinkage and Selection Operator. The penalty applied for L2 is equal to the absolute value of the magnitude of the coefficients.\nSimilar to ridge regression, a lambda value of zero spits out the basic OLS equation, however given a suitable lambda value lasso regression can drive some coefficients to zero. The larger the value of lambda the more features are shrunk to zero. This can eliminate some features entirely and give us a subset of predictors that helps mitigate multi-collinearity and model complexity. Predictors not shrunk towards zero signify that they are important and thus L1 regularization allows for feature selection (sparse selection).\nRidge:\nRidge regression uses L2 regularization which adds the penalty term to the OLS equation.\nThe L2 term is equal to the square of the magnitude of the coefficients. In this case if lambda(λ) is zero then the equation is the basic OLS but if it is greater than zero then we add a constraint to the coefficients. This constraint results in minimized coefficients (aka shrinkage) that trend towards zero the larger the value of lambda. Shrinking the coefficients leads to a lower variance and in turn a lower error value. Therefore, Ridge regression decreases the complexity of a model but does not reduce the number of variables, it rather just shrinks their effect.\nRandom Forest:\nA Random Forest is an ensemble technique capable of performing both regression and classification tasks with the use of multiple decision trees and a technique called Bootstrap Aggregation, commonly known as bagging. What is bagging you may ask? Bagging, in the Random Forest method, involves training each decision tree on a different data sample where sampling is done with replacement.\nThe basic idea behind this is to combine multiple decision trees in determining the final output rather than relying on individual decision trees.\nKnowing the dataset\nWe have a total of 66 features and 3761 observation. Our y-variable is called \'financial distress\'. We are trying to know how stable firms are when compared to all other financial institutions.\nBasically, if the value of financial distress is less than -1 for any firm it means they are not doing well and thus have a high risk of filing for bankruptcy. Similarly, if the value of distress is between -1 to 0 then it seems like the firm is unstable. Lastly, anything over 1 means the firm is safe and is doing well in open markets. That way, we can do a classification exercise out of this data as well but it is beyong our scope for this project.\nRight now, we focus on identifying the variables that are useful for our regression, and then run the above 4 models and see how well can they predict the financial distress, and which are the most prominent features that help us achieve better prediction.\nProcedure\n\nIdentify the predictors and re-name them to X1 to X66 for easier representation. For complete details check slide 2 here\nStandardize the x-variables\nCheck out for skewness in y - variable. If the skew is high then transform.\nThe y-variable here was highly skewed and also had negative values so had to transform using log:\n\ny = log(y + 1- min(y))\n\n\nBreak the dataset into two parts. Training set has 80% of the records and test set has remianing 20%\nRun the simulation for all 4 regression models discussed earlier for 100 times.\nFor Elastic Net, Lasso and Ridge we use 10-fold cross validation method to tune the lambdas.\nThen we use the R-square test equation given to us as part of the project guideline in part 3.d here\nWe plot the box-plot of train and test sets and then also plot the box-plot for the residuals once the simulation is over.\nAlso, we plot the 10-fold CV curves for Elastic Net, Lasso, Ridge.\nAll the plots can be seen in the final report on the root directory - ""STA 9890_Project Report_Tanay Mukherjee.pptx""\nfeatures and how are they coming for 4 regression models we discussed above in brief.\nLastly, we also measure the time needed to tune each of these models and compare it with others to see the efficiency.\n\nSteps to replicate\n\nDownload the file from data folder in this repo.\nOpen R Studio and set your working directory to the place where you have the file from previous step saved.\nLoad the code available on the root directory here\nRun the code, and see the analysis unfold as each model tries to regress the feature variables to predict the best distress for financial institutions.\n\nAppendix\n\nFolder: Guidelines, has all the tasks mentioned with the submission template\nFolder: Plots - it has all the plots as png files\nFolder: Output has the result of all R-squares saved from the console\nProposal: It has the initial proposal submitted on the assignment of this project confirming the chosen dataset.\nVideo Presentation: It has the pdf file used in the video recording\nVideo recording: https://vimeo.com/420873137. It is password protected and is available for view to only Prof. Rad.\n\nSubmission to\n\nProf. Kamiar Rahnama Rad\n\nSubject: 9890 - Statistical Learning for Data Mining\nSession: Fall, 2020\n\n'], 'url_profile': 'https://github.com/tanaymukherjee', 'info_list': ['R', 'Updated May 15, 2020', 'R', 'Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Aug 14, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', 'R', 'Updated May 12, 2020']}","{'location': 'India', 'stats_list': [], 'contributions': '129 contributions\n        in the last year', 'description': [""Iris_Dataset_Modeling\nI achieved a 97% accuracy on the test dataset using a logistic regression with these parameters :\nLogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)\n\n""], 'url_profile': 'https://github.com/sakshm-aurora', 'info_list': ['R', 'Updated May 15, 2020', 'R', 'Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Aug 14, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', 'R', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '20 contributions\n        in the last year', 'description': ['Spark_Project_Analysis_Example\nExample of machine learning at scale (distributed data). Developing a distributed PySpark pipeline for implementing logistic regression and random forest algorithms to predict click-through rates.\nSteps to follow files in this repository\nLoad_Parquet_files.ipynb: takes raw data and converts to parquet and dataframe formats\nEDA_Pandas.ipynb: converts raw data to pandas dataframe and performs fulsome EDA in Pandas\nEDA_Spark.ipynb: converts parquet files to Spark dataframe and performs light EDA in Spark\nFeatureEngineering-Spark.ipynb: takes Spark dataframe and performs light EDA checks and data processing\nData_Processing.ipynb: takes Spark dataframe and performs data processing required for creating processed dataframe for algorithm implementation\nLogistic_regression_implementation.ipynb: takes processed dataframe and performs logistic regression algorithm implementation (with and without hash transformation)\nRandom_forest_implementation.ipynb: takes processed dataframe and performs random forest algorithm implementation\n'], 'url_profile': 'https://github.com/dalvarez83', 'info_list': ['R', 'Updated May 15, 2020', 'R', 'Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Aug 14, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', 'R', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '227 contributions\n        in the last year', 'description': ['Diabetes-Prediction-Using-Machine-Learning\nUsing The Concept Of Logistic Regression ,I Tried To Predict Whether A person suffers From Diabetes Or Not, By Analysis Of Diabetes Dataset.\n\n'], 'url_profile': 'https://github.com/rohan-007', 'info_list': ['R', 'Updated May 15, 2020', 'R', 'Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Aug 14, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', 'R', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/8999848370', 'info_list': ['R', 'Updated May 15, 2020', 'R', 'Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Aug 14, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', 'R', 'Updated May 12, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '66 contributions\n        in the last year', 'description': ['Cancer Dataset - Principal Component Analysis\nPerform PCA on Cancer DataSet and get the best models using the following algorithms 1. Decision Tree Classifier 2. Logistic Regression 3. XGBoost Classifier 4. SVC\n'], 'url_profile': 'https://github.com/reenathomas18', 'info_list': ['R', 'Updated May 15, 2020', 'R', 'Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Aug 14, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', 'R', 'Updated May 12, 2020']}","{'location': 'Philadelphia', 'stats_list': [], 'contributions': '519 contributions\n        in the last year', 'description': [""Cousera Machine Learning\nPython review code from Cousera's ML program\n""], 'url_profile': 'https://github.com/katjanewilson', 'info_list': ['R', 'Updated May 15, 2020', 'R', 'Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Aug 14, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', 'R', 'Updated May 12, 2020']}","{'location': 'Ahmedabad, Gujarat, India', 'stats_list': [], 'contributions': '95 contributions\n        in the last year', 'description': ['Air-Quality-Prediction-using-Machine-Learning-Algorithms\nTable of contents\n\nGeneral info\nTechnologies\n\nGeneral info\nThe objective of this project is to apply four main techniques which are considered as the pillars\nof machine learning, namely - Regression, Classication, Dimensionality Reduction and Density\nEstimation. These methods will be applied to a dataset that includes data from different states of\nIndia. It consists of parameters like SO2, NO2, RSPM, SPM, PM2.5, and other meteorological\nparameters useful for air quality prediction.\nTechnologies\nProject is created with:\n\nSoftware: Google Colab, Jupyter Notebook\nProgramming Language: Python\n\n'], 'url_profile': 'https://github.com/MuskanM1', 'info_list': ['R', 'Updated May 15, 2020', 'R', 'Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Aug 14, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', 'R', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': ['COVID19DataAnalysisAndPrediction\nAnalysis and prediction of COVID-19 Data for confirmed, recovered and death cases using Linear Regression Model and Arima Model in R language\n1.Install RStudio to execute R scripts.\n2.Change setwd directory as per folder structure.\n'], 'url_profile': 'https://github.com/nehamanalwar', 'info_list': ['R', 'Updated May 15, 2020', 'R', 'Updated May 22, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 14, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Aug 14, 2020', 'Jupyter Notebook', 'MIT license', 'Updated Jun 2, 2020', 'R', 'Updated May 12, 2020']}"
"{'location': 'Dallas, Texas', 'stats_list': [], 'contributions': '42 contributions\n        in the last year', 'description': ['UCI_Credit_Card_part1\nThis is my project for Machine Learning Course.\n'], 'url_profile': 'https://github.com/dtliao', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 16, 2020', 'NetLogo', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'MATLAB', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '29 contributions\n        in the last year', 'description': ['Predicting-Stock-Prices\nPredicting stock prices for 35 days into the future using Linear Regression on wiki EOD stock price data by Alphabet, available on quandle. The code predicts the stock prices and plots a graph between the dates and stock prices including the already trained data and the predicted data.\nThe code contains self-explanatory comments to help the reader to understand the code.\n'], 'url_profile': 'https://github.com/MihirSrivastava1004', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 16, 2020', 'NetLogo', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'MATLAB', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '6 contributions\n        in the last year', 'description': [""ABM-surrogates\nR code and simulation data for performing sensitivity analysis of ABMs using support vector machine and support vector regression surrogate models.\nThe file 'fishery_analysis.R' contains the analysis code for the fishery ABM. The file 'rc_python_replicate_shared.R' contains code for the resource consumer ABM.\n""], 'url_profile': 'https://github.com/GuustenBroeke', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 16, 2020', 'NetLogo', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'MATLAB', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Bangalore', 'stats_list': [], 'contributions': '115 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Sahana-M', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 16, 2020', 'NetLogo', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'MATLAB', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '189 contributions\n        in the last year', 'description': ['Amazon_Fine_Food_Reviews-Analysis\nThe famous Amazon fine food reviews dataset on Kaggle for text classification. I have performed sentiment analysis on the dataset using Logistic Regression.\nFirst the data is cleaned and pre-processed using standard NLP techniques like tokenization,stemming ,stop-words removal among others.  Then I have performed sentiment analysis on the dataset using Logistic Regression which yield 91.3% of accuracy\nOutput\n[Output](\n'], 'url_profile': 'https://github.com/prashan1', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 16, 2020', 'NetLogo', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'MATLAB', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '152 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Vib-UX', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 16, 2020', 'NetLogo', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'MATLAB', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '24 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/kantiprasanna', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 16, 2020', 'NetLogo', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'MATLAB', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Mumbai, Maharashtra', 'stats_list': [], 'contributions': '8 contributions\n        in the last year', 'description': ['Absenteeism_Data_Analysis\nA simple approach to pre-process the raw absenteeism data and implement simple linear regression model to do some analysis and prediction\nLibraries Used:\n\nPandas\nNumpy\nSci-kit Learn\nPickle\n\n'], 'url_profile': 'https://github.com/AmirKhan2', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 16, 2020', 'NetLogo', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'MATLAB', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Saskatoon, Saskatchewan, Canada', 'stats_list': [], 'contributions': '76 contributions\n        in the last year', 'description': ['Predicting-nitrogen-and-water-content-in-plants-using-gaussian-process-regression\nGPR (Gaussian Process For Regression) model for predicting the nitrogen and water content in plant leaf using  spectral reflectance data captured at 12 optical bands\n#For details- please open the file Published Paper.pdf\n'], 'url_profile': 'https://github.com/habibbueteee', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 16, 2020', 'NetLogo', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'MATLAB', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '83 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/PranayChauhan2516', 'info_list': ['Jupyter Notebook', 'Updated May 14, 2020', 'Python', 'Updated May 16, 2020', 'NetLogo', 'Updated Jan 14, 2021', 'Jupyter Notebook', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', '1', 'MATLAB', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}"
"{'location': 'Saarbrucken, Saarland, Germay', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ForoutanNeda', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 7, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Python', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['NONE'], 'url_profile': 'https://github.com/cran', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 7, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Python', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '157 contributions\n        in the last year', 'description': ['Machine-Learning-in-Python\nApplying Machine Learning techniques in Python\n'], 'url_profile': 'https://github.com/shubhkamble26', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 7, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Python', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '44 contributions\n        in the last year', 'description': ['ads-revenue-impact-on-sales\nIn this project, I build and evaluate a simple linear regression model using Python. I employ the scikit-learn module for calculating the linear regression, while using pandas for data management, and seaborn for plotting. I work with the very popular Advertising data set to predict sales revenue based on advertising spending through mediums such as TV, radio, and newspaper. By the end of this project, I can explain the core ideas of linear regression to technical and non-technical audiences, build a simple linear regression model in Python with scikit-learn, employ Exploratory Data Analysis (EDA) to small data sets with seaborn and pandas, and evaluate a simple linear regression model using appropriate metrics.\n'], 'url_profile': 'https://github.com/onelastchance', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 7, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Python', 'Updated May 11, 2020']}","{'location': 'Chicago, IL', 'stats_list': [], 'contributions': '25 contributions\n        in the last year', 'description': ['Predicting Data using R (Machine Learning)\n\nTechlologys and methodologies used in this project\n-1 Data Preparation. \n-2 Build a multiple linear regression model.\n-3 Build a regression tree model.\n-4 Build a random forest model.\n-5 Build a support vector machine model.\n-6 Perform the k-means cluster analysis.\n-7 Build a neural networks model.\n-8 Putting it all together. Compering all models.\n'], 'url_profile': 'https://github.com/Bubenko', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 7, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Python', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '59 contributions\n        in the last year', 'description': ['IST-718-Filght-Delay-Cancellation-Prediction-Big-Data-Analytics-\nPerformed exploratory data analysis and feature engineering for dataset over 5.8 million records • Developed classification and regression models to predict flight delays and cancellations from various features by building pyspark pipelines • Used PySpark ML to train logistic regression, Random Forest, SVM and Gradient boosting trees models, performed hyper-parameter tuning and assessed generalization performance\n'], 'url_profile': 'https://github.com/AbhirajSingh88', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 7, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Python', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '68 contributions\n        in the last year', 'description': ['USA-_Housing_Price\nProblem:Data Set gives some information about a bunch of houses in the regions of the United\nStates. Create a model that allows to put in a few features of house and returns back an estimate of what\nthe house would sell for.\nSolution:Checking out the data. Values are the continuous the Linear Regression might be a good path to\nsolve the problem. Perform the Exploratory Data Analysis (EDA), Creating and Training the Linear\nRegression Model, Model Evaluation and Prediction from the model.\n'], 'url_profile': 'https://github.com/azmeena1311', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 7, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Python', 'Updated May 11, 2020']}","{'location': 'New York', 'stats_list': [], 'contributions': '46 contributions\n        in the last year', 'description': [""StatisticalTesting-CovidData\nProbability and Statistics for Data Scientist - Course Project. Various Testing(Hypothesis, T-Test, Z-Test, KS Test etc) are performed on Covid and crime dataset for Los Angeles. Auto Regression and Linear Regression are also performed without using scimitar libraries in python.\nData Cleaning is performed by handling null values, detecting outliers using tukey's rule.\nVarious Hypothesis Testing are also performed without using any inbuilt libraries.\nRegression models(AR and Linear) without using scikit.\n""], 'url_profile': 'https://github.com/Aditya-1001', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 7, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Python', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Regression with CART Trees\nIntroduction\nAs we\'ve learned, a Decision Tree is a supervised machine learning model that can be used both for classification and regression tasks. We have seen that a decision tree uses a tree structure to predict an output class for a given input example in a classification task. For regression analysis, In the tree, each path from the root node to a leaf node represents a decision path that ends in a predicted value. In this lesson , we shall see how regression is performed in using a decision tree regressor using a simple example.\nNote: Kindly visit the Official doc. for the regressor tree function used in this lesson.\nObjectives\nYou will be able to:\n\nUnderstand and explain recursive partitioning\nUnderstand the maths behind recursive partitioning of sample space by CART trees\nRun a simple regression experiment with regression trees and evaluate/visualize the results\n\nRecursive Partitioning\nLinear regression is considered a global model as there is a single model holding over the entire sample space. For data containing complex features holding complicated and nonlinear relations, assembling such a single global model can be very difficult and computationally expensive task.\nAnother way to handle to nonlinear regressions is to partition the sample space into smaller regions, as we have already seen in previous lessons with classification trees. This isn\'t much different in regression--here, our goal is partition down to increasingly smaller, simpler subsets until we can fit simple linear regression models to them. Since each subset is a partition of a smaller subset that is itself a subset, this makes it a textbook example of Recursive Partioning.\nRecall that in classification trees, the leaf nodes (the deepest nodes, at the end of each particular path) are the ones that contained the purest overall subsets of the data. Regression Trees work a bit differently, but the general idea is still the same. With Regression Trees , each leaf node of the tree represents a cell of the partition. These cells are the smallest unit where a simple regression can be fit to the data accurately.  Splitting the data still works the same way as we saw in previous lessons for classification--we use our tree model to continuously subset down to smaller, more specific subsets until we reach a level where we can build the simplest regression to the most specific subset in our data. For example, a regression tree may recursively partition the model down further and further until it gets all customers over the age of 50 residing in Florida with an income over #60k/year, and then fit a simple regression to only the data points that fit within this specific subset.\nSimple Local Models\nOne point worth noting is that the simple regression models for each partition aren\'t being used as regressions in real-time. Instead, they take the sample mean of the dependent variable for that partition. Whenever the model makes a prediction, it uses this sample mean rather than calculating the actual regression model. In practice, this works quite well, and has some distinct advantages. Models are easier to interpret, and faster to use for inference (making predictions) since they are just retrieving the stored mean value rather than calculating the actual output of the regression.\nThis is more easily understood when visualized. Consider the Regression tree below, which predicts the price of cars based on wheelbase and horsepower:\n\nOnce we have created a decision tree, we can visualize the decision boundaries of that tree (assuming that the dimensionality is small enough for visualization). Notice that all the dividing lines are parallel to the axes, because each internal node checks whether a single variable is above or below a given value. In simpler terms, all decision boundaries with decision trees will always be horizontal or vertical if visualized--there are no diagonal, wavy, or curvy lines, because of the nature of the boolean (true/false) logic used by decision trees to determine the splits!\n\nThe tree correctly represents the interaction between Horsepower and Wheelbase, i.e. when Horsepower > 0.6, Wheelbase no longer matters. When both are equally important, the tree switches between them.\nOnce we train the tree, the local models are completely understood,  so all the effort should go into finding a good partitioning of the data.\nCART training algorithm\nIn this lab we will focus on the CART algorithm (Classification and Regression Trees) for regression.\n\nThe CART algorithm builds a binary tree in which every non-leaf node has exactly two children (corresponding to a yes/no answer).\n\nGiven a set of training examples and their labels, the algorithm repeatedly splits the training examples $D$ into two subsets $D_{left}, D_{right}$ using some feature set $f$ and feature threshold $t_f$ such that samples with the same label are grouped together.\nAt each node, the algorithm selects the split $\\theta = (f, t_f)$ that produces the smallest mean squared error (MSE) (alternatively, we could use the mean absolute error).\nSo at each step, the algorithm selects the parameters $\\theta$ that minimize the following cost function:\n\\begin{equation}\nJ(D, \\theta) = \\frac{n_{left}}{n_{total}} MSE_{left} + \\frac{n_{right}}{n_{total}} MSE_{right}\n\\end{equation}\n\n$D$: remaining training examples\n$n_{total}$ : number of remaining training examples\n$\\theta = (f, t_f)$: feature and feature threshold\n$n_{left}/n_{right}$: number of samples in the left/right subset\n$MSE_{left}/MSE_{right}$: MSE of the left/right subset\n\nThis step is repeated recursively until the maximum allowable depth is reached or the current number of samples $n_{total}$ drops below some minimum number. The original equations can be found here.\nAfter building the tree, new examples can be classified by navigating through the tree, testing at each node the corresponding feature until a leaf node/prediction is reached.\nMean Squared Error (MSE)\nWhen performing regression with CART trees (i.e. the target values are continuous) we can evaluate a split using its MSE. The MSE of node $m$ is computed as follows:\n\\begin{equation}\n\\hat{y}m = \\frac{1}{n{m}} \\sum_{i \\in D_m} y_i\n\\end{equation}\n\\begin{equation}\nMSE_m = \\frac{1}{n_{m}} \\sum_{i \\in D_m} (y_i - \\hat{y}_m)^2\n\\end{equation}\n\n$D_m$: training examples in node $m$\n$n_{m}$ : total number of training examples in node $m$\n$y_i$: target value of $i-$th example\n\nLet\'s see above in action with a simple experiment. We shall generate some non-linear synthetic data for our X and y attributes and fit it to a regression tree. So let\'s move ahead with this. In order to have a visual understanding of how this works, we shall only a simple regression problem between two variables X and y , where y is a simple function of X that we want to learn. Let\'s see this below:\nGenarate Data\nRun the cell below to generate the data for this lesson.\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nplt.style.use(\'seaborn\')\nnp.random.seed(124)\n\n#Generate 100 examples of X and y(a simple cubic function of X ). \nX = np.linspace(-3, 3, 100)\ny = X ** 3 + np.random.randn(100)\n\n# Plot the data \nplt.figure(figsize=(15,6))\nplt.scatter(X, y)\nplt.title(""Simple quadratic dataset with noise"")\nplt.xlabel(""Feature values"")\nplt.ylabel(""Target values"")\nText(0, 0.5, \'Target values\')\n\nYou can try and further complicate the relationship with a more complex function.  Let\'s now create our features and labels, and also perform a 75/25 split sfor the training and test set.\nX = X[:, np.newaxis]\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\n# Print the data dimensions\nprint(f\'Shape X_train: {X_train.shape}\')\nprint(f\'Shape y_train: {y_train.shape}\')\nprint(f\'Shape X_test: {X_test.shape}\')\nprint(f\'Shape y_test: {y_test.shape}\')\nShape X_train: (75, 1)\nShape y_train: (75,)\nShape X_test: (25, 1)\nShape y_test: (25,)\n\nFit a Regression Tree\nScikit-learn offers a regression tree under the class DecisionTreeRegressor. Let\'s create an instance of this class just like the classification tasks and fit the data. For now , we\'ll set the max depth parameter to 3, as we now know that increasing this could lead to overfitting. We can experiment with different depths later.\nfrom sklearn.tree import DecisionTreeRegressor\nregressor = DecisionTreeRegressor(random_state = 10, max_depth=3)\nregressor.fit(X_train, y_train)\nDecisionTreeRegressor(criterion=\'mse\', max_depth=3, max_features=None,\n           max_leaf_nodes=None, min_impurity_decrease=0.0,\n           min_impurity_split=None, min_samples_leaf=1,\n           min_samples_split=2, min_weight_fraction_leaf=0.0,\n           presort=False, random_state=10, splitter=\'best\')\n\nPrediction and Evaluation\nThe output of the cell above shows us the default values for most hyperparameters. You are encouraged to check the official documentation for this class for details on options available to you for growing regression trees!\nWe can now predict labels with previously unseen data and calculate mse. As an extra measure , we can also look at calculating the R-squared value to inspect the goodness of fit for our model.\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import r2_score\n\n# Make predictions and evaluate \ny_pred = regressor.predict(X_test)\nprint (\'MSE score:\', mse(y_test, y_pred))\nprint(\'R-sq score:\',r2_score(y_test,y_pred))\nMSE score: 5.165993713178738\nR-sq score: 0.9620185253771402\n\nVisualize the Model Fit\nOur R squared score tells us that this appears to be a very good fit (remember r2 ranges from 0(poor) to 1(best)). Let\'s visualize the learnt function below with our scatter plot from earlier and see how well it fits.\nX_grid = np.arange(min(X), max(X), 0.01)\nX_grid = X_grid.reshape((len(X_grid), 1))\nplt.figure(figsize=(15,6))\nplt.scatter(X, y, color = \'red\', label=\'data\')\nplt.plot(X_grid, regressor.predict(X_grid), color = \'green\', label=\'Regression function\')\nplt.title(\'Decision Tree Regression\')\nplt.xlabel(\'Features\')\nplt.ylabel(\'Target\')\nplt.legend()\nplt.show()\n\nSo we found this regression line without using any complex non-linear functions, in a fraction of time. This is the key benefit of regression trees over other regression techniques that we have seen earlier.\nSome Observations\n\nWe can notice the graph is not continuous.\nHorizontal lines are averages of all data points in sections created.\nThese horizontal lines represent sections. Predictions are averages of data points in sections. So prediction for each value lying in one section will be the same.\n\nTry changing the max_depth parameter in the model and grow the tree again. The resulting visualization will clearly show you the impact of tree depth on overfitting.\nCaveats\nWithout regularization, decision trees are likely to overfit the training examples. This can be prevented using techniques like pruning or by providing a maximum allowed tree depth and/or a minimum number of samples required to split a node further as we saw with regression.\nAdditional Resources\n\nAn Introduction to Recursive Partitioning: Rationale, Application and Characteristics of Classification and Regression Trees, Bagging and Random Forests\nCART: Classification And Regression Trees for Machine Learning\nPopular Decision Tree: Classification and Regression Trees (C&RT)\nYoutube: CART trees\n\nSummary\nIn this lesson, you learned about CART trees for regression and classification. You looked at how CART algorithm works, along with MSE, as a loss measure used as a learning mechanism. You saw a simple experiment with some synthetic data  where we used a tree regressor to learn a non linear function. You learned that this approach is much simpler and computationally efficient than using non-linear regression functions.\n'], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 7, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Python', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '45 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/piyush18184', 'info_list': ['Jupyter Notebook', 'Updated May 13, 2020', 'R', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated Jun 7, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Python', 'Updated May 11, 2020']}"
"{'location': 'New Delhi, India', 'stats_list': [], 'contributions': '62 contributions\n        in the last year', 'description': ['Project-5-MNIST-Handwritten-Digit-Recognition-using-Sklearn-and-LogisticRegression\nIntroduction:\nThis is the famous MNIST Machine Learning project in which we have to predict handwritten digits. The dataset used in this project is taken from kaggle.\nDigit Recognition System\nDigit recognition system is the working of a machine to train itself or recognizing the digits from different sources like emails, bank cheque, papers, images, etc. and in different real-world scenarios for online handwriting recognition on computer tablets or system, recognize number plates of vehicles, processing bank cheque amounts, numeric entries in forms filled up by hand.\nProblem Statement:\nThis is the famous MNIST Machine Learning project in which we have to predict handwritten digits.\nRequirements:\n\nJupyter Notebook\n\nMNIST Dataset:\nSamples provided from MNIST (Modified National Institute of Standards and Technology) dataset includes handwritten digits total of 70,000 images consisting of 60,000 examples in training set and 10,000 examples in testing set, both with labeled images from 10 digits (0 to 9). This is a small segment form the wide set from NIST where size was normalized to fit a 2020 pixel box and not altering the aspect ratio. Handwritten digits are images in the form of 28 * 28 gray scale intensities of images representing an image along with the first column to be a label (0 to 9) for every image. The same has opted for the case of the testing set as 10,000 images with a label of 0 to 9.\n\nLogistic regression:\nLogistic regression is another technique borrowed by machine learning from the field of statistics.\nIt is the go-to method for binary classification problems (problems with two class values). In this post you will discover the logistic regression algorithm for machine learning.\nLogistic Function\nLogistic regression is named for the function used at the core of the method, the logistic function.\n\nLogistic function\nThe logistic function, also called the sigmoid function was developed by statisticians to describe properties of population growth in ecology, rising quickly and maxing out at the carrying capacity of the environment. It’s an S-shaped curve that can take any real-valued number and map it into a value between 0 and 1, but never exactly at those limits.\n1 / (1 + e^-value)\nWhere e is the base of the natural logarithms (Euler’s number or the EXP() function in your spreadsheet) and value is the actual numerical value that you want to transform. Below is a plot of the numbers between -5 and 5 transformed into the range 0 and 1 using the logistic function.\n\nRepresentation Used for Logistic Regression\nLogistic regression uses an equation as the representation, very much like linear regression.\nInput values (x) are combined linearly using weights or coefficient values (referred to as the Greek capital letter Beta) to predict an output value (y). A key difference from linear regression is that the output value being modeled is a binary values (0 or 1) rather than a numeric value.\nBelow is an example logistic regression equation:\ny = e^(b0 + b1x) / (1 + e^(b0 + b1x))\nWhere y is the predicted output, b0 is the bias or intercept term and b1 is the coefficient for the single input value (x). Each column in your input data has an associated b coefficient (a constant real value) that must be learned from your training data.\nThe actual representation of the model that you would store in memory or in a file are the coefficients in the equation (the beta value or b’s).\nImporting the Modules:\n\nNumpy\nMatplotlib\nSklearn\n\nScore:\nFor this model, the accuracy on the test set is 0.97, which means the model made the right prediction for 97% of the handwritten digits in the given dataset. We can expect the model to be correct 97% of the time for predicting the handwritten digits.\nSummary:\nThe MNIST handwritten digit recognition (and our implementation) is a perfect example to illustrate how a machine learning problem should be approached and how useful the outcome could be for computer vision.\n'], 'url_profile': 'https://github.com/Yuvrajchopra25', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated May 14, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '7 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/KennethY319', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated May 14, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Evaluating Logistic Regression Models - Lab\nIntroduction\nIn regression, you are predicting values so it makes sense to discuss error as a distance of how far off our estimates were. When classifying a binary variable, however, a model is either correct or incorrect. As a result, we tend to quantify this in terms of how many false positives versus false negatives we come across. In particular, we examine a few different specific measurements when evaluating the performance of a classification algorithm. In this review lab, we\'ll review precision, recall, accuracy, and F1-score in order to evaluate our logistic regression models.\nObjectives\nYou will be able to:\n\nUnderstand and assess precision, recall, and accuracy of classifiers\nEvaluate classification models using various metrics\n\nTerminology Review\nLet\'s take a moment and review some classification evaluation metrics:\n$Precision = \\frac{\\text{Number of True Positives}}{\\text{Number of Predicted Positives}}$\n$Recall = \\frac{\\text{Number of True Positives}}{\\text{Number of Actual Total Positives}}$\n$Accuracy = \\frac{\\text{Number of True Positives + True Negatives}}{\\text{Total Observations}}$\n$\\text{F1-Score} = 2\\ \\frac{Precision\\ x\\ Recall}{Precision + Recall}$\nAt times, it may be superior to tune a classification algorithm to optimize against precision or recall rather than overall accuracy. For example, imagine the scenario of predicting whether or not a patient is at risk for cancer and should be brought in for additional testing. In cases such as this, we often may want to cast a slightly wider net, and it is preferable to optimize for recall, the number of cancer positive cases, than it is to optimize precision, the percentage of our predicted cancer-risk patients who are indeed positive.\n1. Split the data into train and test sets\nimport pandas as pd\ndf = pd.read_csv(\'heart.csv\')\n#Your code here\n2. Create a standard logistic regression model\n#Your code here\n3. Write a function to calculate the precision\ndef precision(y_hat, y):\n    #Your code here\n4. Write a function to calculate the recall\ndef recall(y_hat, y):\n    #Your code here\n5. Write a function to calculate the accuracy\ndef accuracy(y_hat, y):\n    #Your code here\n6. Write a function to calculate the F1-score\ndef f1_score(y_hat,y):\n    #Your code here\n7. Calculate the precision, recall, accuracy, and F1-score of your classifier.\nDo this for both the train and the test set\n#Your code here\nGreat Job! Now it\'s time to check your work with sklearn.\n8. Calculating Metrics with sklearn\nEach of the metrics we calculated above is also available inside the sklearn.metrics module.\nIn the cell below, import the following functions:\n\nprecision_score\nrecall_score\naccuracy_score\nf1_score\n\nCompare the results of your performance metrics functions with the sklearn functions above. Calculate these values for both your train and test set.\n#Your code here\n9. Comparing Precision, Recall, Accuracy, and F1-Score of Test vs Train Sets\nCalculate and then plot the precision, recall, accuracy, and F1-score for the test and train splits using different training set sizes. What do you notice?\nimport  matplotlib.pyplotmatplot  as plt\n%matplotlib inline\ntraining_Precision = []\ntesting_Precision = []\ntraining_Recall = []\ntesting_Recall = []\ntraining_Accuracy = []\ntesting_Accuracy = []\n\nfor i in range(10,95):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= None) #replace the ""None"" here\n    logreg = LogisticRegression(fit_intercept = False, C = 1e12)\n    model_log = None\n    y_hat_test = None\n    y_hat_train = None\n\n# Your code here\nCreate 4 scatter plots looking at the test and train precision in the first one, test and train recall in the second one, test and train accuracy in the third one, and test and train f1-score in the fourth one.\n# code for test and train precision\n# code for test and train recall\n# code for test and train accuracy\n# code for test and train F1-score\nSummary\nNice! In this lab, you gained some extra practice with evaluation metrics for classification algorithms. You also got some further python practice by manually coding these functions yourself, giving you a deeper understanding of how they work. Going forward, continue to think about scenarios in which you might prefer to optimize one of these metrics over another.\n'], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated May 14, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '161 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/semg101', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated May 14, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '26 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/ashvalvi111', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated May 14, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Regression with CART Trees - Lab\nIntroduction\nIn this lab, we\'ll make use of what we learned in the previous lesson to build a model for the ""Petrol Consumption Dataset"" from Kaggle. This model will be used to predict gasoline consumption for a bunch of examples, based on drivers\' features.\nObjectives\nYou will be able to:\n\nConduct a regression experiment using CART trees\nEvaluate the model fit and study the impact of hyper parameters on the final tree\nUnderstand training, prediction, evaluation and visualizations required to run regression experiments using trees\n\nImport necessary libraries\n#\xa0Import libraries \nimport pandas as pd  \nimport numpy as np  \nimport matplotlib.pyplot as plt  \n%matplotlib inline\nRead the dataset petrol_consumption.csv and view its head and dimensions\n# Read the dataset and view head and dimensions\n\n# Code here\n(48, 5)\n\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\nPetrol_tax\nAverage_income\nPaved_Highways\nPopulation_Driver_licence(%)\nPetrol_Consumption\n\n\n\n\n0\n9.0\n3571\n1976\n0.525\n541\n\n\n1\n9.0\n4092\n1250\n0.572\n524\n\n\n2\n9.0\n3865\n1586\n0.580\n561\n\n\n3\n7.5\n4870\n2351\n0.529\n414\n\n\n4\n8.0\n4399\n431\n0.544\n410\n\n\n\n\nCheck the basic statistics for the dataset and inspect the target variable Petrol_Consumption\n#\xa0Describe the dataset\n\n# Code here\n\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n\n</style>\n\n\n\n\nPetrol_tax\nAverage_income\nPaved_Highways\nPopulation_Driver_licence(%)\nPetrol_Consumption\n\n\n\n\ncount\n48.000000\n48.000000\n48.000000\n48.000000\n48.000000\n\n\nmean\n7.668333\n4241.833333\n5565.416667\n0.570333\n576.770833\n\n\nstd\n0.950770\n573.623768\n3491.507166\n0.055470\n111.885816\n\n\nmin\n5.000000\n3063.000000\n431.000000\n0.451000\n344.000000\n\n\n25%\n7.000000\n3739.000000\n3110.250000\n0.529750\n509.500000\n\n\n50%\n7.500000\n4298.000000\n4735.500000\n0.564500\n568.500000\n\n\n75%\n8.125000\n4578.750000\n7156.000000\n0.595250\n632.750000\n\n\nmax\n10.000000\n5342.000000\n17782.000000\n0.724000\n968.000000\n\n\n\n\nCreate features, labels and train/test datasets with a 80/20 split\nAs with the classification task, we will divide our data into attributes/features and labels and consequently into training and test sets.\n# Create datasets for training and test\n\n\n# Code here\nCreate an instance of CART regressor and fit the data to the model\nAs mentioned earlier, for a regression task we\'ll use a different sklearn class than we did for the classification task. The class we\'ll be using here is the DecisionTreeRegressor class, as opposed to the DecisionTreeClassifier from before.\n# Train a regression tree model with training data \n\n\n# Code here \nDecisionTreeRegressor(criterion=\'mse\', max_depth=None, max_features=None,\n                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n                      min_impurity_split=None, min_samples_leaf=1,\n                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n                      presort=False, random_state=0, splitter=\'best\')\n\nUsing test set, make predictions and calculate the MAE, MSE and RMSE\nJust as with Decision Trees for classification, there are several commonly used metrics for evaluating the performance of our model. The most common metrics are:\n\nMean Absolute Error (MAE)\nMean Squared Error (MSE)\nRoot Mean Squared Error (RMSE)\n\nIf these look familiar, it\'s likely because you have already seen them before--they are common evaluation metrics for any sort of regression model, and as we can see, regressions performed with Decision Tree models are no exception!\nSince these are common evaluation metrics, sklearn has functions for each of them that we can use to make our job easier. You\'ll find these functions inside the metrics module. In the cell below, calculate each of the three evaluation metrics listed above!\n# Predict and evaluate the predictions\n\n\n# Code here\nMean Absolute Error: 50.8\nMean Squared Error: 4535.4\nRoot Mean Squared Error: 67.34537846058926\n\nLevel Up - Optional\n\n\nIn order to understand and interpret a tree structure, we need some domain knowledge in which the data was generated. That can help us inspect each leaf and investigate/prune the tree based on qualitative analysis.\n\n\nLook at the hyper parameters used in the regression tree, check their values ranges in official doc and try running some optimization by growing a number of trees in a loop.\n\n\nUse a dataset that you are familiar with and run tree regression to see if you can interpret the results.\n\n\nCheck for outliers, try normalization and see the impact on the output\n\n\nSummary\nIn this lesson, we developed a tree regressor architecture to train the regressor and predict values for unseen data. We saw that with a vanilla approach, the results were not so great, and this requires further pre-tuning of the model (what we described as hyper parameter optimization OR pruning in the case of trees.\n'], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated May 14, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['Regression Trees and Model Optimization - Lab\nIntroduction\nIn this final lab, we\'ll see how to apply regression analysis using CART trees for regression while making use of some hyperparameter tuning to improve our model. For a comparison of predictive capabilities and computational cost, we\'ll work the ""Boston Housing"" dataset. This will allow us to compare different regression approaches in terms of their accuracy and cost involved.\nObjectives\nYou will be able to:\n\nApply predictive regression analysis with CART trees\nGet the data ready for modeling\nTune the key hyper parameters based a various models developed during training\nStudy the impact of tree pruning on the quality of predictions\n\nBoston Housing Dataset - Again !\nThe dataset is available in the repo as boston.csv.\n\nLoad the Dataset and print its head and dimensions\n\n#\xa0Your code here \nIdentify Features and Target Data\nIn this lab, we shall use three features from the Boston housing dataset: \'RM\', \'LSTAT\', and \'PTRATIO\'. You\'ll find a brief description of each predictor below:\nFeatures\n\n\'RM\' is the average number of rooms among homes in the neighborhood.\n\'LSTAT\' is the percentage of homeowners in the neighborhood considered ""lower class"" (working poor).\n\'PTRATIO\' is the ratio of students to teachers in primary and secondary schools in the neighborhood.\n\nTarget\n\n\nMEDV\',the median value of the home.\n\n\nCreate dataframes for features and target as shown above.\n\n\nInspect the contents for validity\n\n\n#\xa0Your code here \nInspect Correlations\n\nUse scatter plots to show the correlation between chosen features and target variable\nComment on each scatter plot\n\n#\xa0Your code here \nCreate Evaluation Metrics\n\nCreate a function performance(true, predicted) to calculate and return the r-squared score and MSE for two equal sized arrays showing true and predicted values\nTEst the function with given data\n\n# Evaluation Metrics\n#\xa0Import metrics\n\ndef performance(y_true, y_predict):\n    """""" Calculates and returns the performance score between \n        true and predicted values based on the metric chosen. """"""\n    \n    \n    #\xa0Your code here \n    \n    \n    pass\n\n# Calculate the performance - TEST\nscore = performance([3, -0.5, 2, 7, 4.2], [2.5, 0.0, 2.1, 7.8, 5.3])\nscore\n\n# [0.9228556485355649, 0.4719999999999998]\nSupervised Training\n\nFor supervised learning, split the features and target datasets into training/test data (80/20).\nFor reproducibility, use random_state=42\n\n#\xa0Your code here \nGrow a Vanilla Regression Tree\n\nRun a baseline model for later comparison using the datasets created above\nGenerate predictions for test dataset and calculate the performance measures using the function created above.\nUse random_state=45 for tree instance\nRecord your observations\n\n#\xa0Your code here \n\n# (0.4712438851035674, 38.7756862745098)  - R2, MSE\nHyperparameter Tuning\n\nFind the best tree depth for a depth range: 1-30\nRun the regressor repeatedly in a for loop for each depth value.\nUse random_state=45 for reproducibility\nCalculate MSE and r-squared for each run\nPlot both performance measures, for all runs.\nComment on the output\n\n#\xa0Your code here \nMore Hyperparameter Tuning\n\n\nRepeat the above process for min_samples_split parameter\n\n\nUse a a range of values from 2-10 for this parameter\n\n\nUse random_state=45 for reproducibility\n\n\nVisualize the output and comment on results as above\n\n\n#\xa0Your code here \nRun the ""Optimized"" Model\n\nUse the best values for max_depth and min_samples_split found in previous runs and run an optimized model with these values.\nCalculate the performance and comment on the output\n\n#\xa0Your code here \nLevel Up - Optional\n\nHow about bringing in some more features from the original dataset which may be good predictors?\nAlso , try tuning more hyperparameters like max-features to find the optimal version of the model.\n\nSummary\nIn this lab, we looked at applying a decision tree based regression analysis on the Boston Housing Dataset. We saw how to train various models to find the optimal values for pruning and limiting the growth of the trees. We also looked at how to extract some rules from visualizing trees , that might be used for decision making later.\n'], 'url_profile': 'https://github.com/learn-co-students', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated May 14, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Egypt', 'stats_list': [], 'contributions': '88 contributions\n        in the last year', 'description': ['Predicting-Real-State-Prices\n\n\n\n'], 'url_profile': 'https://github.com/Muhammad-Yousef', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated May 14, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'New York City', 'stats_list': [], 'contributions': '77 contributions\n        in the last year', 'description': [""KNN Regressor model from scratch (python)\nGlitched Failure YouTube Video Walkthrough (< 30 min)\nThis repo merely contains the Jupyter notebook I used when implementing the K-Nearest Neighbor's Regressor Algorithm from scratch (using only the default Python environment).\n""], 'url_profile': 'https://github.com/Shaddyjr', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated May 14, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '467 contributions\n        in the last year', 'description': ['ReviewPredictor\nPython Notebook For Board Games Review Predictor using Linear Regressor and Random Forest Techniques\nReviews can make or break a product; as a result, it becomes important for companies take drastic measures to ensure that their product receives good reviews.  When it comes to board games, reviews and word-of-mouth are everything.\nIn this project,  a linear regression model has been used to predict the average review a board game will receive based on characteristics such as minimum and maximum number of players, playing time, complexity, etc.\nUsed mean squared error as a performance metric to evaluate Linear regression model & ensemble model trained.\nCompared linear regressor model results with the performance of an ensemble method.\n'], 'url_profile': 'https://github.com/AasthaGithub', 'info_list': ['1', 'Jupyter Notebook', 'MIT license', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Python', 'Updated May 14, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['\n\napp-bold-time-series\nAn app to get nuisance regressed time series from a preprocessed bold, confounds, and a parc. Before running this app, you need to have run fMRIPrep. The outputs of this app will be average bold magnitudes in each volume of your input parcellation. Such data can then be used to construct networks.\nAuthors\n\nJosh Faskowitz (joshua.faskowitz@gmail.com)\n\nFunding\n\n\n\n\n\n\nCitations\nPlease cite the following articles when publishing papers that used data, code or other resources created by the brainlife.io community.\nAvesani, P., McPherson, B., Hayashi, S. et al. The open diffusion data derivatives, brain data upcycling via integrated publishing of derivatives and reproducible open cloud services. Sci Data 6, 69 (2019). https://doi.org/10.1038/s41597-019-0073-y\nRunning Locally (on your machine)\n\ngit clone this repo.\nInside the cloned directory, create config.json with something like the following content with paths to your input files.\n\n{\n        ""fmri"": ""/path/to/bold.nii.gz"",\n        ""parc"": ""/path/to/parcellation.nii.gz"",\n        ""confounds"": ""/path/to/confounds.tsv"",\n        ""mask"": ""/path/to/mask.nii.gz""\n}\nOther optional arguments include: confjson, smoothfwhm, tr , lowpass, highpass, and inspace. These have default settings, but can be changed for better fit to your data.\n\nLaunch the App by executing main\n\n./main\nOutput\nAll output files will be generated under the current working directory (pwd), in directories called output_ts. In this directory, there will be the following files:\ntimeseries.hdf5\nkey.txt\nlabel.json\n\nDependencies\nThis App uses singularity to run. If you don\'t have singularity, you can run this script in a unix enviroment with:\n\npython3: https://www.python.org/downloads/\njq: https://stedolan.github.io/jq/\n\nMIT Copyright (c) Josh Faskowitz & brainlife.io\n This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. 1342962. Any opinion, findings, and conclusions or recommendations expressed in this material are those of the authors(s) and do not necessarily reflect the views of the National Science Foundation. \n'], 'url_profile': 'https://github.com/brainlife', 'info_list': ['1', 'Python', 'Updated Oct 6, 2020', '1', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Apache-2.0 license', 'Updated Jan 22, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Dec 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Aug 4, 2020', 'HTML', 'Updated May 12, 2020', 'Python', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '47 contributions\n        in the last year', 'description': ['salesforecasting\nThe proposed model\nUtilize 2 machine learning models (eXtreme Gradient Boosting and Support Vector Regression) to improve forecast results of 2 traditional methods (Holt’s Exponential Smoothing and Winter’s Exponential Smoothing).\nPerformance\n102 furniture items of a major retailer in Taiwan are applied to the proposed model and the average accuracy (sMAPE) of the best result achieves 93.77%. Additionally, compared to pure Exponential Smoothing models, forecast errors (sMAPE) of the proposed model decreases 46.47% (from 11.64% to 6.23%).\n'], 'url_profile': 'https://github.com/mengshanli', 'info_list': ['1', 'Python', 'Updated Oct 6, 2020', '1', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Apache-2.0 license', 'Updated Jan 22, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Dec 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Aug 4, 2020', 'HTML', 'Updated May 12, 2020', 'Python', 'Updated May 12, 2020']}","{'location': 'Tiruchirappalli, India', 'stats_list': [], 'contributions': '1,207 contributions\n        in the last year', 'description': ['COVID 19 Prediction in India\nAbout:\nThe code predicts the number of COVID-19 cases and deaths in India for the respective date which is provided. It is implemented using TensorFlow. There are 2 models where is one model is used to predict the number of cases and the other one is used to predict the number of deaths. Both of these models are achieving a maximum accuracy of 99.95%.\nSupported Operating Systems:\nRuns on Windows, Linux and MacOS.\nTested with:\n\nPython 3.8.5 64-bit\nTensorFlow 2.4.0\nPop OS 20.04 LTS\n\nDeveloped by:\nVigneshwar Ravichandar\nExecution Instructions:\nExecute the following command in the terminal to run with default procedure.\npython3 main.py --test=True\nCommand Line Arguments:\n\n\n-tr (or) --train - Used to train the Neural Network.\n\nArgument type: str\nParameter type: Optional\nValues:\n\ncases - Used for training the model_cases only.\ndeaths - Used for training the model_deaths only.\nall - Used for training both the models.\n\n\n\n\n\n-t (or) --test - Used to test the Neural Network with custom inputs.\n\nArgument type: bool\nParameter type: Mandatory\n\n\n\n-v (or) --visualize - Used to vizualize the metrics.\n\nArgument type: bool\nParameter type: Optional\n\n\n\n-req (or) --install_requirements - Used to install the required dependancies.\n\nArgument type: bool\nParameter type: Optional\n\n\n\nImages:\n\n                          *Screenshot mentioning the training command* \n\n\n                          *Screenshot mentioning the testing command*  \n\n\n                        *Screenshot mentioning the visualizing command*  \n\n'], 'url_profile': 'https://github.com/ToastCoder', 'info_list': ['1', 'Python', 'Updated Oct 6, 2020', '1', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Apache-2.0 license', 'Updated Jan 22, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Dec 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Aug 4, 2020', 'HTML', 'Updated May 12, 2020', 'Python', 'Updated May 12, 2020']}","{'location': 'washington dc/bay area', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/smasood00', 'info_list': ['1', 'Python', 'Updated Oct 6, 2020', '1', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Apache-2.0 license', 'Updated Jan 22, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Dec 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Aug 4, 2020', 'HTML', 'Updated May 12, 2020', 'Python', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '23 contributions\n        in the last year', 'description': ['The depreciation of vehicles in the world market -\nthis project is completed\n'], 'url_profile': 'https://github.com/effieklestz', 'info_list': ['1', 'Python', 'Updated Oct 6, 2020', '1', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Apache-2.0 license', 'Updated Jan 22, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Dec 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Aug 4, 2020', 'HTML', 'Updated May 12, 2020', 'Python', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '185 contributions\n        in the last year', 'description': ['Board-Game-Review-Prediction\nIn this project, i will be using a linear regression model to predict the average review a board game will receive based on characteristics such as minimum and maximum number of players, playing time, complexity, etc.\n'], 'url_profile': 'https://github.com/bkp3', 'info_list': ['1', 'Python', 'Updated Oct 6, 2020', '1', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Apache-2.0 license', 'Updated Jan 22, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Dec 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Aug 4, 2020', 'HTML', 'Updated May 12, 2020', 'Python', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/8999848370', 'info_list': ['1', 'Python', 'Updated Oct 6, 2020', '1', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Apache-2.0 license', 'Updated Jan 22, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Dec 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Aug 4, 2020', 'HTML', 'Updated May 12, 2020', 'Python', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '92 contributions\n        in the last year', 'description': ['Loan_Approval_Predictor\nData Science project to predict whether a person would get approved for a loan.\nAchieved an accuracy of 80% on the Logistic Regression Model.\nPython libraries used include Pandas, Numpy, Scikit-Learn, Matplotlib with Dataset from Kaggle.\n'], 'url_profile': 'https://github.com/chowdhuryqaizar', 'info_list': ['1', 'Python', 'Updated Oct 6, 2020', '1', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Apache-2.0 license', 'Updated Jan 22, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Dec 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Aug 4, 2020', 'HTML', 'Updated May 12, 2020', 'Python', 'Updated May 12, 2020']}","{'location': 'Chicago', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/dharun1996', 'info_list': ['1', 'Python', 'Updated Oct 6, 2020', '1', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Apache-2.0 license', 'Updated Jan 22, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Dec 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Aug 4, 2020', 'HTML', 'Updated May 12, 2020', 'Python', 'Updated May 12, 2020']}","{'location': 'California', 'stats_list': [], 'contributions': '10 contributions\n        in the last year', 'description': ['Driver-Drowsiness-Detection\nBaseline Temporal Model for Early Drowsiness Detection\nThis proposed temporal model uses blink features to detect both early and deep drowsiness with an intermediate regression step, where drowsiness is estimated with a score from 0 to 10.\nLink to the Presentation:\nhttps://docs.google.com/presentation/d/1VELjSNJeFqIzrCvELx0mfGipy2OBvVXr3RwuxkOmxc8/edit?usp=sharing\n\nSteps to Run the Code\n1- Run Blink_Video.py\n  This file is fed by the input video(the directory should be given to the path variable). Then, it detects the blinks and   outputs four features of all blinks in a text file.\n\n  (""Trained_SVM_C=1000_gamma=0.1_for 7kNegSample.sav"" is used for blink detection.) \n\n  *Use the link below to download ""shape_predictor_68_face_landmarks.dat""\n\n  https://drive.google.com/open?id=1nrfc-_pdIxNn2yO1_e7CxTyJQIk3A-vX\n\n2- Run Preprocessing.py\n  This file gets three text files (blink features in three drowsiness levels) as the main input and preprocesses them for the subsequent steps. The outputs are .npy files.\n\n    For convenience, these .npy files ({Blinks, BlinksTest, Labels, LabelsTest}_30_FoldX.npy) are provided for each X as the test fold used for five fold cross validation. For example Blinks_30_Fold4.npy is the training set consisted of all the folds except fold 4, and BlinksTest_30_Fold4.npy is the data from fold 4. If decided to apply this method to a different dataset, then the hard coded ""start_indices"" array in Training.py should be adjusted accordingly. More info about ""start_indices is mentioned in the Training.py"". Finally, to clarify, these .npy files are generated from step 1 and 2 on the UTA-RLDD dataset so one might decide to generate their own .npy files to train.\n\n3- Run Training.py\n  This code is used to train based on the .npy files generated in step 2. The model details and hyperparameters are all set here. This code is also used for testing. Here, one fold from the dataset (UTA-RLDD in this case) is picked as the test fold and the other four are used for training. The output is the training and test results and accuracies based on the pre-defined metrics in the paper.\n\n  For convenience, five pre-trained models are provided, where each model used one of the folds as the test set in a five fold cross validation.\n\n  These three files are pre-trained models for the training session of fold X, where fold X had been used as the test fold:\n\n          my_modelX.data-00000-of-00001\n\n          my_modelX.index\n\n          my_modelX.meta\n\nCitation:\nAll documents (such as publications, presentations, posters, etc.) that report results, analysis, research, or equivalent that were obtained by using this source should cite the following research paper: https://arxiv.org/abs/1904.07312\nLink to the UTA-RLDD dataset:\nhttps://sites.google.com/view/utarldd/home\n'], 'url_profile': 'https://github.com/AnushaMadapati', 'info_list': ['1', 'Python', 'Updated Oct 6, 2020', '1', 'Python', 'Updated May 11, 2020', '1', 'Python', 'Apache-2.0 license', 'Updated Jan 22, 2021', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Dec 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated Aug 4, 2020', 'HTML', 'Updated May 12, 2020', 'Python', 'Updated May 12, 2020']}"
"{'location': 'Los Angeles', 'stats_list': [], 'contributions': '65 contributions\n        in the last year', 'description': ['Project 2 - Ames Housing Data and Kaggle Challenge\n1) Introduction\nThis project is focused on creating a regression model based on the Ames Housing Dataset in order to predict house prices for interested buyers and sellers. Since market value of a house is more than its square footage and location, we would like to find out all features that add value to a house. The success of the model will be evaluated on unseen data provided on Kaggle.\nData set contains information from the Ames Assessor’s Office used in computing assessed values for individual residential properties sold in Ames, IA from 2006 to 2010. There are 2930 observations and 82 variables:\n23 nominal\n23 ordinal\n14 discrete\n20 continuous\n2 identifier\nThe variables can roughly fall under each of below categories:\nLocation\nArea measurements\nLot / Land\nAge\nAppearance\nRoof\nGarage\nKitchen\nRooms / Bathrooms\nUtilities\nExternal (Deck, pool, porch etc.)\nSale Price Distribution\nIt\'s almost a normal distribution with a slight positive skewness due to outliers. It shows that very small number of houses have high pricess. As we want our target variable as normal as possible, it is a good idea to apply log transformation which reduces the impact of positive skewness.\n\nLog Price Distribution\n\n2) Data Cleaning & EDA\nThere are 5 types of functions applied to impute missing values based on data type:\n\nReplace with ""None"" (categorical variables)\nReplace with 0 (numerical variables)\nReplace with median (year variables)\nReplace with median grouped by neighborhood (Lot Frontage)\nReplace with mode (Electrical)\n\nAfter imputing missing values, removing few outliers, dummying nominal categories, mapping/scoring ordinal categories, creating interaction terms etc, I\'ve come up with approximately 60 features.\n3) Modeling\nThere are various quantitative fields with different unit measurements (sqft, age, number of rooms etc.). I used Standard Scaler to optimize their weight coefficients, and finally used Ridge and Lasso models to find out the most relevant features from my features list.\n** Most Relevant Features**\n\nOverall Quality * Condition\nTotal Square Footage\nTotal Number of Bathrooms\nOverall Quality * Condition * Functional\nFunctional\nGround Living Area\nHouse Age * Functional\n1st Floor Square Footage\nFireplace Quality\nBasement Quality * Condition\nFull Bathrooms\nKitchen Quality\nOverall Quality * House Age\nTotal Basement Square Footage\nSale Type_New (Boolean)\nOverall Quality * Condition * Total Baths\nTotal Baths * House Age\nBasement Condition\nCentral Air_Yes (Boolean)\nOverall Quality\nGarage Area\nPaved Drive_Yes (Boolean)\nExternal Quality\nGarage Condition\nLot Shape * Land Slope\nNeighborhood_Old Town (Boolean)\nNeighborhood_NridgHt (Boolean)\nSale Type_WD\nGarage Quality * Condition\n\n\nThe model performed in a way that 91.6% variance on train data, 89.8% on test data could be explained by final model. When I submitted the unseen data result to Kaggle for evaluation, the root mean square error was $23,463.\nActual Price vs Predictions Distribution\n\n3) Summary\nMarket value of a house is dependent on various factors and these factors vary based on economical situation and geographical location. We cannot fully generalize these factors but we can come up with closest predictions when sufficient amount of time, sample data, subject matter expertise, and statistical knowledge are available.\nThis model has been produced for our tech startup company ""Pillow Predictions"" to provide house value prediction service for interested buyers and sellers and still work in progress with a goal to build best model in the market.\n'], 'url_profile': 'https://github.com/sibeltan', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'HTML', 'MIT license', 'Updated May 11, 2020', 'R', 'Updated Dec 7, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '23 contributions\n        in the last year', 'description': ['Modulation-Classification\nin this project we train the different model using different classifiers( Logistic Regression Classifier , Decision Tree , Random Forest , A fully connected dense layer , and CNN) and we used the raw data , its derivative , its integration and all possible combination to determine which is better for each classiffier , and after determning which is best for each classiffier ,the models were validated and then tested\n'], 'url_profile': 'https://github.com/Ahmed-Elshoubashy', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'HTML', 'MIT license', 'Updated May 11, 2020', 'R', 'Updated Dec 7, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '167 contributions\n        in the last year', 'description': ['Machine_Learning_project-IBM\nThis a project at the end of course Machine_Learning with python by IBM where we use KNN ,Decision tree,Logistic Regression and SVM to build models for solving Loan sanction problem\nAchived accuracy of 85%(F1 score) using SVM and Logistic regression\n To view html version of above notebook click here\n'], 'url_profile': 'https://github.com/satoru2001', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'HTML', 'MIT license', 'Updated May 11, 2020', 'R', 'Updated Dec 7, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '207 contributions\n        in the last year', 'description': ['Employee_Selection\nA statistical report reviewing applicants for a job using R and several R packages to load, clean, wrangle, and create a regression models to predict best hires based on multiple attributes. The final model produced an R-squared coefficient of 0.35 and met legal standards with an adverse impact ratio of 0.85. The model was created on training split of 75% of the data and cross validated on the remaining 25% of the data. When compared to the No-Information Rate, the model had a 13% higher true positive rate (38%), 3% higher true negative rate (78%) and a far superior selection ratio of 0.25 compared to 1.00. As hypothesized, using the regression model to is stronger in everyway than using a data-less model. It should also be noted that legal hiring issues according to adverse impact issues were still present when both fixed and sliding bands were used. The figure below provides a predicted vs. actual scatterogram using percentiles for all applicants. see the full report Globex Selection Report.docx for more information.\n\n*Note that TP = True Positive, TN = True Negative, and SR = Selection Ratio. Numbers inside each dotted line represent the number of people inside the rectangular section.\n'], 'url_profile': 'https://github.com/Jwychor', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'HTML', 'MIT license', 'Updated May 11, 2020', 'R', 'Updated Dec 7, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '43 contributions\n        in the last year', 'description': ['Student-Grade-Prediction\nIn this project I took a student dataset which has 33 features and each feature is a record of students. This project is based on machine learning algorithms. Used linear regression to predict the marks.\n'], 'url_profile': 'https://github.com/manassinha07', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'HTML', 'MIT license', 'Updated May 11, 2020', 'R', 'Updated Dec 7, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '40 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/mjs139', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'HTML', 'MIT license', 'Updated May 11, 2020', 'R', 'Updated Dec 7, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '33 contributions\n        in the last year', 'description': ['compared each part of the world’s most developed and least developed countries and after the data collection and generation we can build a correlation between vaccination rates and incidence rate of preventable disease through linear regression models and etc.\n'], 'url_profile': 'https://github.com/zengdavid8', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'HTML', 'MIT license', 'Updated May 11, 2020', 'R', 'Updated Dec 7, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '22 contributions\n        in the last year', 'description': ['Predicting-Mobile-Game-Success\nAnalyzing the data set to gain insights about game applications in the market and predicting the success of a new game application release.  Different Machine Learning algorithms are applied. Regression techniques for prediction, Logistic and SVM for classification.\nUsing Python.\n'], 'url_profile': 'https://github.com/dinaYriad', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'HTML', 'MIT license', 'Updated May 11, 2020', 'R', 'Updated Dec 7, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Hyderabad', 'stats_list': [], 'contributions': '47 contributions\n        in the last year', 'description': ['Household_power_consumption_forecasting\nperform regression over the dataset of global active power values. You are supposed to take the active power values in the past one hour and predict the next active power value.\n\n\nPerformed regression over the dataset of global\nactive power values.\n\n\nImplemented Multilayer Perceptron(MLP) as well as a linear regression model for\nthis question.\n\n\nCompared and contrasted the performance of both the models on metrics like Root Mean Squared Error(RMSE), Mean Absolute Percentage Error(MAPE) score.\n\n\nConsidered only the Global active power field.\n\n\nExperimented with different architectures(number of hidden layers, activation functions etc) and see the impact on performance.\n\n\nAlso experimented on taking some more window of past power values and reported the\nperformance (For example taking a window of two hours instead of one).\n\n\nThe dataset is available at https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip.\n'], 'url_profile': 'https://github.com/Hakai-Shin', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'HTML', 'MIT license', 'Updated May 11, 2020', 'R', 'Updated Dec 7, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}","{'location': 'Gurgaon', 'stats_list': [], 'contributions': '34 contributions\n        in the last year', 'description': ['Classification_Models_Hyperparameters_Tuning\nThe main aim behind this project is to compare different classification models on the given data set and perform hyper parameter tuning using GridSearchCV .The dataset is obtained from kaggle.\n'], 'url_profile': 'https://github.com/utkarsh-tyagi', 'info_list': ['Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 18, 2020', '1', 'HTML', 'MIT license', 'Updated May 11, 2020', 'R', 'Updated Dec 7, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 14, 2020', '1', 'Jupyter Notebook', 'Updated May 16, 2020', 'Python', 'Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 11, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '40 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/Cashcodex', 'info_list': ['Python', 'Updated Dec 29, 2020', '1', 'Python', 'Updated May 13, 2020', 'MIT license', 'Updated Jan 21, 2021', '2', 'Jupyter Notebook', 'Updated May 20, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'MATLAB', 'GPL-3.0 license', 'Updated May 24, 2020', '2', 'R', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '12 contributions\n        in the last year', 'description': ['Salesforecasting\nThe model predicts the sales for third month based on the first and second month input. The front end has been created using flask. The regression model has been deployed using flask.\n'], 'url_profile': 'https://github.com/Mamo123-git', 'info_list': ['Python', 'Updated Dec 29, 2020', '1', 'Python', 'Updated May 13, 2020', 'MIT license', 'Updated Jan 21, 2021', '2', 'Jupyter Notebook', 'Updated May 20, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'MATLAB', 'GPL-3.0 license', 'Updated May 24, 2020', '2', 'R', 'Updated May 12, 2020']}","{'location': 'San Francisco Bay Area, CA', 'stats_list': [], 'contributions': '247 contributions\n        in the last year', 'description': ['Teen Fertility and Eductaion\nProject Overview\nDoes improving a country’s secondary school enrollment rate lower its teen fertility rate? To answer the question, this econometric study is conducted by using OLS regression and difference-in-difference estimate on R.\nContents\nFor the report, please read the markdown file\n'], 'url_profile': 'https://github.com/charliezcr', 'info_list': ['Python', 'Updated Dec 29, 2020', '1', 'Python', 'Updated May 13, 2020', 'MIT license', 'Updated Jan 21, 2021', '2', 'Jupyter Notebook', 'Updated May 20, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'MATLAB', 'GPL-3.0 license', 'Updated May 24, 2020', '2', 'R', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '13 contributions\n        in the last year', 'description': ['Subsidy-Yaraneh-\n\nMy data is related with some properties of households in States: Hamedan, Qom, Qazvin, Alborz.\nThe goal is not to subsidize the households which are in 3 decile of richer households. So this means predicting True positive is more important.\n\n\nAfter doing some visualization and preprocessing, I splitted data in two set: train and test and I did crossvalidation over all models and used test set just one time after selecting the best model. \nFor this binary classification I tried diffrent machine learning algorithms: KNeighbors , Logistic Regression, SVM , Decision Tree, Random Forest, Gradient Boosting.\nSince our data is a little imbalanced and predicting True positive is important acuuracy score was not useful so I selected : ""average-precision"" to evaluate models. And at last after selecting best model, for selecting best threshold, The best way was to compare ""macro-averages"" on train-set.\nFor the last step after picking model and best threshold all without using test-set, The model will be evaluate on the test set.\n\n'], 'url_profile': 'https://github.com/sohrabfaridi', 'info_list': ['Python', 'Updated Dec 29, 2020', '1', 'Python', 'Updated May 13, 2020', 'MIT license', 'Updated Jan 21, 2021', '2', 'Jupyter Notebook', 'Updated May 20, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'MATLAB', 'GPL-3.0 license', 'Updated May 24, 2020', '2', 'R', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '20 contributions\n        in the last year', 'description': [""StockMarketPred-MapReduce\nThe repository consists of the Hadoop MapReduce code extracting only the information required by the ML algorithm for processing. The ML algorithm(linear regression) uses daily close/adj_close prices to get the next day's price. Some MR is done for demonstration purposes and can also be used for analysis. Also general analysis is done on the output of MR code using python.\nGitHub \tlink1:  https://github.com/loCoder/StockMarketPred-MapReduce\n(alternate) link2: https://github.com/smaransandri/Big-Data\nThe Project has two parts:\nPart1: Apache Hadoop Mapreduce\nIt has MapReduce code in Java, and is implemented on single-node Apache Hadoop v2.6.0 on (Linux-based) Ubuntu 14.04 OS.\nThere are three directories in MapReduce\nbash\n: contains bash shell script to run the job(should be modified according to the final directory structure)\n!!Some additional shell commands may be required to complete the MR job. Refer Hadoop documentation here -> https://hadoop.apache.org/docs/r2.6.0/.\nTest1:\nProcessing is done on 30 different(files) stocks from 2015-2020. Has two versions: v1 eliminates null values, v2 replaces null values(if any) with -1; obtained from online APIs like Yahoo finance, Google finance, MSN money etc.(use gsqlcmd for getting datsets easily, with varying frequency)\nTest2:\nProcessing is done on one file of 50MB, consisting data from 500 companies for the period 2010-2016; dataset taken from kaggle (https://www.kaggle.com/borismarjanovic/price-volume-data-for-all-us-stocks-etfs)\nEach Test folder contains a dataset csv folder, and three folders with source code, class files and outputs, one each for daily, monthly and yearly analysis on the data.\nRefer INFO for more data in MapReduce folder.\nPart2: Python Visualization and Prediction\nThis part can be readily executed by running these files on jupyter notebook.\nHere we use python libraries to visualize and predict the stock price using linear regression.\nIt has four .ipynb files.\nStockAnalysis\nData Analysis is done for 1 company of choice out of 500companies DS.\nStock30Analysis\nData Analysis is done for 1 company of choice out of 30companies DS.\nStockPrediction\nPrediction done using linear regression for 1 company of choice out of 500companies.\nStock30Prediction\nPrediction done using linear regression for 1 company of choice out of 30companies.\nFurther/Future scope/improvements: XGBoost as Prediction model.\nFor further details refer markdown cells of the .ipynb files.\nCredits:\nAP (Data Analysis and improvements in ML)\nSSS (Machine Learning and dataset extraction)\nJF (MapReduce and improvements in Data Analysis and Predictions)\n""], 'url_profile': 'https://github.com/loCoder', 'info_list': ['Python', 'Updated Dec 29, 2020', '1', 'Python', 'Updated May 13, 2020', 'MIT license', 'Updated Jan 21, 2021', '2', 'Jupyter Notebook', 'Updated May 20, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'MATLAB', 'GPL-3.0 license', 'Updated May 24, 2020', '2', 'R', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '247 contributions\n        in the last year', 'description': ['tensorFlow_\nUsing the Linear Regressor class in TensorFlow to predict median housing price, at the granularity of city blocks.\n'], 'url_profile': 'https://github.com/Bigg-Iron', 'info_list': ['Python', 'Updated Dec 29, 2020', '1', 'Python', 'Updated May 13, 2020', 'MIT license', 'Updated Jan 21, 2021', '2', 'Jupyter Notebook', 'Updated May 20, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'MATLAB', 'GPL-3.0 license', 'Updated May 24, 2020', '2', 'R', 'Updated May 12, 2020']}","{'location': 'Greater Noida | Noida | Chennai', 'stats_list': [], 'contributions': '288 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/prateekagrawaliiit', 'info_list': ['Python', 'Updated Dec 29, 2020', '1', 'Python', 'Updated May 13, 2020', 'MIT license', 'Updated Jan 21, 2021', '2', 'Jupyter Notebook', 'Updated May 20, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'MATLAB', 'GPL-3.0 license', 'Updated May 24, 2020', '2', 'R', 'Updated May 12, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '88 contributions\n        in the last year', 'description': ['MIT-xPRO-DSxCase-Study-2.2-Gender-Wage-Gap\nCase Study 2.2: Gender Wage Gap Instructor: Victor Chernuzkov Activity Type: Optional  Case Study Description: Estimate the difference in predicted wages between men and women with the same job characteristics. Why this Case Study? Participants can pose an economic question and investigate that question using a linear regression model. Self-Help Package Contents:   The video that covers this case study is given in Module 2, Segment 1.6.  Self-help-package.zip  Codebook.txt contains the description of worker job-relevant characteristics. pay.discrimination.Rdata: the CPS (2012) data on wages and job-relevant worker characteristics, such as experience exp, gender, education. Regression1.6.CaseStudy.R estimates gender wage gap, i.e., difference in predicted wages between men and women with same job-relevant characteristics. The gap is estimated in two steps: (1) residualizing the outcome (wages) and covariate of interest (gender) (taking residuals from corresponding regressions on worker characteristics), and (2) computing the correlation between residualised wages on residualised gender. Both linear and quadratic specifications are tried at residualizing step. Regression.1.6.pdf is the set of slides that describes the estimation technique and present the results. .Rhistory\n'], 'url_profile': 'https://github.com/claudio-toledo', 'info_list': ['Python', 'Updated Dec 29, 2020', '1', 'Python', 'Updated May 13, 2020', 'MIT license', 'Updated Jan 21, 2021', '2', 'Jupyter Notebook', 'Updated May 20, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'MATLAB', 'GPL-3.0 license', 'Updated May 24, 2020', '2', 'R', 'Updated May 12, 2020']}","{'location': 'Beijing', 'stats_list': [], 'contributions': '139 contributions\n        in the last year', 'description': ['ElasticNetADMM\nThis is the source code for our paper: 面向物联网隐私数据分析的分布式弹性网络回归学习算法. A brief introduction of this work is as follows:\n\nIn order to solve the problems caused by the traditional data analysis based on the centralized algorithm in the IoT, such as excessive bandwidth occupation, high communication latency and data privacy leakage, considering the typical linear regression model of elastic net regression, a distributed learning algorithm for Internet of Things (IoT) is proposed in this paper. This algorithm is based on the the Alternating Direction Method of Multipliers (ADMM) framework. It decomposes the objective problem of elastic net regression into several sub-problems that can be solved independently by each IoT node using its local data. Different from traditional centralized algorithms, the proposed algorithm does not require the IoT node to upload its private data to the server for training, but rather the locally trained intermediate parameters to the server for aggregation. In such a collaborative manner, the server can finally obtain the objective model after several iterations. The experimental results on two typical datasets indicate that the proposed algorithm can quickly converge to the optimal solution within dozens of iterations. As compared to the localized algorithm in which each node trains the model solely based on its own local data, the proposed algorithm improves the validity and the accuracy of training models; as compared to the centralized algorithm, the proposed algorithm can guarantee the accuracy and the scalability of model training, and well protect the individual private data from leakage.\n\n中文摘要：\n\n为了解决基于集中式算法的传统物联网数据分析处理方式易引发网络带宽压力过大、延迟过高以及数据隐私安全等问题，该文针对弹性网络回归这一典型的线性回归模型，提出一种面向物联网(IoT)的分布式学习算法。该算法基于交替方向乘子法(ADMM)，将弹性网络回归目标优化问题分解为多个能够由物联网节点利用本地数据进行独立求解的子问题。不同于传统的集中式算法，该算法并不要求物联网节点将隐私数据上传至服务器进行训练，而仅仅传递本地训练的中间参数，再由服务器进行简单整合，以这样的协作方式经过多轮迭代获得最终结果。基于两个典型数据集的实验结果表明：该算法能够在几十轮迭代内快速收敛到最优解。相比于由单个节点独立训练模型的本地化算法，该算法提高了模型结果的有效性和准确性；相比于集中式算法，该算法在确保计算准确性和可扩展性的同时，可有效地保护个体隐私数据的安全性。\n\nThis paper has been accepted and will be published by the Chinese journal 电子与信息学报, and can be downloaded from here.\nRequired software\nMatlab\nDataset\nPlease check the datasets in the ElasticNetADMM\\Source Code\\数据集 folder.\nCitation\nPlease visit the journal webpage for the citation information.\nContact\nMengran Liu (18120381@bjtu.edu.cn)\nWeiwei Fang (fangvv@qq.com)\n'], 'url_profile': 'https://github.com/fangvv', 'info_list': ['Python', 'Updated Dec 29, 2020', '1', 'Python', 'Updated May 13, 2020', 'MIT license', 'Updated Jan 21, 2021', '2', 'Jupyter Notebook', 'Updated May 20, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'MATLAB', 'GPL-3.0 license', 'Updated May 24, 2020', '2', 'R', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '100 contributions\n        in the last year', 'description': ['fifaPrediction\nA project based on FIFA players dataset from www.kaggale.com\nWritten in: R\nDISCLAIMER\n\nThis project is done only for educational purpose\nIf you are interested in creating any web scraper, you can learn through my projects\nI am not responsible for any future controversies/copyright issues\nMaking use of my project for any illegal activities does not count as my responsibility\n\nInstruction Video on Youtube.\nShall be released soon.\nWhy is it in R?\nR for data science.\n\nPrerequisite (for Windows)\n\nFirstly you need R and RStudio in your computer.\n\n\nHow to predict?\n\nUse the dataset which is given in the rep OR follow step 2.\nDownload the recent database from kaggle, name it as ""raw_downloaded_data.csv"".\nDownload the each and every file from the rep.\nRun the r files in sequence:\n\n""0_clean.r""-> will produce partially cleansed data named ""0_raw_downloaded_data.csv""\n""1_cleaning_data.r"" -> will produce completely cleaned data ""1_cleaned_data.csv""\n""2_norm_stand.r"" -> will produce different normalized csv files\n""3_visualization.r"" -> will give you the visualization\n""4_correlation.r"" -> does as the name says\n""5_hypothesis_testing.r"" -> does as the name says\n""6_regression.r"" -> does as the name says\n\n\nThats it and exit.\n\n\n#### Thank You\n'], 'url_profile': 'https://github.com/abhishek-aar', 'info_list': ['Python', 'Updated Dec 29, 2020', '1', 'Python', 'Updated May 13, 2020', 'MIT license', 'Updated Jan 21, 2021', '2', 'Jupyter Notebook', 'Updated May 20, 2020', '2', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'Python', 'Updated May 15, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'MATLAB', 'GPL-3.0 license', 'Updated May 24, 2020', '2', 'R', 'Updated May 12, 2020']}"
"{'location': 'Greater Noida | Noida | Chennai', 'stats_list': [], 'contributions': '288 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/prateekagrawaliiit', 'info_list': ['Python', 'Updated May 15, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'R', 'Updated Feb 23, 2021', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated Nov 25, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020']}","{'location': 'srikakulam', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['breastcancer-prediction\nperformance comparison between different machine learning algorithms: Linear Regression ,Decision tree and SVM, on the Wisconsin Breast Cancer datasets is done. We have to predict the Stage of Breast Cancer - M (Malignant) and B (Benign). The main objective is to assess the correctness in classifying data with respect to accuracy and efficiency of each algorithm.\n'], 'url_profile': 'https://github.com/vuritiaditya', 'info_list': ['Python', 'Updated May 15, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'R', 'Updated Feb 23, 2021', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated Nov 25, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020']}","{'location': 'Hanoi, Vietnam', 'stats_list': [], 'contributions': '385 contributions\n        in the last year', 'description': ['geneSA v0.1.1\nI. Introduction\n\nThe package geneSA is built to serve as a support tool for the paper ""Improving existing analysis pipeline to identify and analyze cancer driver genes using multi-omics data"".  A log-rank test in univariate Cox regression analysis with a proportional hazards model is performed to examine an association between each gene and the survival rates of patients separately, and then adjust identified log-rank P-values following Benjamini-Hochberg FDR. Genes with adjusted log-rank P-values (also known as Q-values) <= 0.05 are preserved. \nII. Understanding the tool\n\nThe following are parameters provided by geneSA:\n\n\ndata: data frame or matrix. It represents its rows are samples and its columns are genomic features .\nNote that samples in rows of data are also included in your clinical data and in exactly the same order.\nUsers can feed any -omics data to this parameter; e.g., gene expression, copy number alteration,\nmethylation, or the like. NOTE that you must code values/observations in data as labels in advance.\nFor example, expresison levels of genes usually are divided into highly expressed genes (""up"") and lowly\nexpressed genes (""down""), or into highly expressed genes (""up""), moderately expressed genes (""mid""), and\nlowly expressed genes (""down"").\n\n\ntime: numeric or integer column vector. It is overall survival time of all samples extracted from\nyour clinical data. Note that samples in rows of clinical data are included in data and in exactly the\nsame order before extracting it.\n\n\nstatus: binary column vector. It is overall survival status of all samples extracted from your clinical\ndata (usually coded as 1 = death, 0 = alive). Note that samples in rows of clinical data are included in data and\nin exactly the same order before extracting it.\n\n\nPlease see & download data data_n_code as examples to well grasp the GeneSA\'s requirement\non data structure and its usage. \nIII. Pipeline\n\n\nFigure: Pipeline of the package geneSA.\nIV. Implementation\n\nUse the following command to install directly from GitHub;\ndevtools::install_github(""huynguyen250896/geneSA"")\nCall the library;\nlibrary(geneSA)\nrunning example:\n# exp is a matrix whose rows are samples and columns are genomic features\n#>median is up-regulated genes and <median is down regulated genes\nexp1 <- apply(exp,2, function(x) ifelse(x > median(x),""up"",""down"")) %>% as.data.frame()\n\n#Make sure samples that in rows of exp1 are also included in rows of clinical_exp and in exactly the same order\nall(rownames(exp1) == rownames(clinical_exp))\n#[1] FALSE\nexp1 = exp1[rownames(clinical_exp),]\n\n#RUN!!!\ngeneSA(data = exp1, time = clinical_exp$OS_MONTHS, status = clinical_exp$status)\nV. Citation\n\nPlease kindly cite the following paper (and Star this Github repository if you find this tool of interest) if you use the tool in this repo: \nReference Type: Journal Article\nAuthor: Nguyen, Quang-Huy\nLe, Duc-Hau\nYear: 2020\nTitle: Improving existing analysis pipeline to identify and analyze cancer driver genes using multi-omics data\nJournal: Scientific Reports\nVolume: 10\nIssue: 1\nPages: 20521\nDate: 2020/11/25\nISSN: 2045-2322\nDOI: 10.1038/s41598-020-77318-1\nFeel free to contact Quang-Huy Nguyen <huynguyen96.dnu AT gmail DOT com> for any questions about the code and results.\n'], 'url_profile': 'https://github.com/huynguyen250896', 'info_list': ['Python', 'Updated May 15, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'R', 'Updated Feb 23, 2021', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated Nov 25, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020']}","{'location': 'Bengaluru, India', 'stats_list': [], 'contributions': '156 contributions\n        in the last year', 'description': ['BigMart-Sales-Prediction\nRetail is another industry which extensively uses analytics to optimize business processes. Tasks like product placement, inventory management, customized offers, product bundling, etc. are being smartly handled using data science techniques. As the name suggests, this data comprises of transaction records of a sales store. This is a regression problem. The data has 8523 rows of 12 variables.\n'], 'url_profile': 'https://github.com/ikigai-aa', 'info_list': ['Python', 'Updated May 15, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'R', 'Updated Feb 23, 2021', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated Nov 25, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '18 contributions\n        in the last year', 'description': ['CreditRiskAnalysis\n#In Credit risk analysis my main aim is to analyze data from the datasets to find people with high credit risk. In this project we analyze the efficacy of CART, Random forest and logistic regression models by analyzing the experimental data set and making predictions on the credit risk of a customer.\nThe dataset was obtained from a Kaggle python notebook . The original dataset which the Kaggle notebook utilized was from UCI’s Machine Learning Repository and contains 1000 entries with 20 categorial/symbolic attributes prepared by Prof. Hofmann. In this dataset, each entry represents a person who takes a credit by a bank. Each person is classified as good or bad credit risks according to the set of attributes. The dataset has 1000 observations and 10 columns. Out of 10 columns, 8 variables are categorical, and the rest 2 numerical variables are age and credit amount. Each row represents a customer, each column contains customer’s attributes like age, sex, job, housing etc. Risk is the target variable. So, our outcome is to predict whether the risk is Good or Bad. The variables are:\n●\tAge: The age of customers varies from 19 to 75.\n●\tSex: Male and Female\n●\tJob: 0 1 2 3 (can be considered as unskilled, skilled, highly skilled)\n●\tHousing: The type of housing customers are living in - own, free and rent.\n●\tSaving account: Whether their savings account is little, moderate, rich or quite rich\n●\tCredit account: Whether their credit account is little, moderate or rich.\n●\tCredit amount: Customer’s credit amount varies from $250 to $18424.\n●\tDuration: The duration to pay back the loan varies from 4 months to 72 months (6 years).\n●\tRisk: This represents whether our customer has a good credit or bad credit. (Good/Bad).\n'], 'url_profile': 'https://github.com/naveen2110', 'info_list': ['Python', 'Updated May 15, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'R', 'Updated Feb 23, 2021', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated Nov 25, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': 'NONE', 'description': ['NONE'], 'url_profile': 'https://github.com/cran', 'info_list': ['Python', 'Updated May 15, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'R', 'Updated Feb 23, 2021', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated Nov 25, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020']}","{'location': 'Greater Noida | Noida | Chennai', 'stats_list': [], 'contributions': '288 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/prateekagrawaliiit', 'info_list': ['Python', 'Updated May 15, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'R', 'Updated Feb 23, 2021', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated Nov 25, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '62 contributions\n        in the last year', 'description': ['Breast-Cancer-Prediction\n'], 'url_profile': 'https://github.com/abhisheksuraj21', 'info_list': ['Python', 'Updated May 15, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'R', 'Updated Feb 23, 2021', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated Nov 25, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020']}","{'location': 'Indore <-> Ranchi', 'stats_list': [], 'contributions': '100 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/rooky1905', 'info_list': ['Python', 'Updated May 15, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'R', 'Updated Feb 23, 2021', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated Nov 25, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '52 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/DimovDimitar', 'info_list': ['Python', 'Updated May 15, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'R', 'Updated Feb 23, 2021', 'Jupyter Notebook', 'Apache-2.0 license', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 14, 2020', 'R', 'Updated Nov 25, 2020', 'Python', 'Updated May 15, 2020', 'Jupyter Notebook', 'Updated May 12, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020']}"
"{'location': 'NONE', 'stats_list': [], 'contributions': '135 contributions\n        in the last year', 'description': ['Install\nLinux\nFor Debian-based Linux distributions, you can install k6 from the private deb repo like this:\nsudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 379CE192D401AB61\necho ""deb https://dl.bintray.com/loadimpact/deb stable main"" | sudo tee -a /etc/apt/sources.list\nsudo apt-get update\nsudo apt-get install k6\nRunning\nLinux\nStandard output\nk6 run script.js\nSummary export json\n$ k6 run --summary-export=export.json script.js\n'], 'url_profile': 'https://github.com/fairusatoir', 'info_list': ['JavaScript', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '52 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/DimovDimitar', 'info_list': ['JavaScript', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020']}","{'location': 'UK', 'stats_list': [], 'contributions': '66 contributions\n        in the last year', 'description': [""In this project, two types of analyzes for predicting avocado prices are displayed;\nTime Series Analysis and Machine Learning Analysis.\nI used Prophet for Time Series analysis (it's open source software released by Facebook's Core Data Science team).\nAnd then I applied Regression and Machine Learning Algorithms to the data;\n\nLinear Regression,\nRidge Regression,\nLasso Regression,\nKNN,\nSVR,\nDecision Tree, andRandom Forest.\n\n""], 'url_profile': 'https://github.com/weakchicken-19', 'info_list': ['JavaScript', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020']}","{'location': 'Washington, D.C', 'stats_list': [], 'contributions': '7 contributions\n        in the last year', 'description': [""Predecting-patient-length-of-stay\nThis study deals with predicting a patient's length of stay at a hospital using Logistic Regression, Naïve Bayes classifier and Random Forest model. The models are trained to predict how much longer a patient would stay at a hospital based on the first 24 hours of their admission. Required tables are drawn from the MIMIC III database.\n""], 'url_profile': 'https://github.com/camarkhe', 'info_list': ['JavaScript', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '60 contributions\n        in the last year', 'description': [""Predicting the Error of Election Polling in US Federal Elections\nIntroduction:\nProblem Statement:\nIn Presidential, Senatorial, and Congressional elections across the United States, all campaigns and media outlets rely on polling. Exit polls help determine decisions on election day. Polls of Iowa in presidential primaries help determine the front-runner for a given race. But how often do these polls reflect the actual outcome of elections? More importantly, how wrong are they? My goal is to create a regression model that predicts the error of a polls prediction from the actual election.\nData Set:\nI plan on using data from the data news site FiveThirtyEight on polls. It is roughly 10000 rows by 25 columns from polls since 1998. It not only includes data of polls of race by party, but also the year, partisan lean of both the pollster and the district, and real percentage of votes obtained by a candidate. FiveThirtyEight is famous for its election prediction modeling, and they make their data open to the public.\nThe data can be found here via FiveThirtyEight's GitHub\nApplication:\nBeing able to reliably predict the percent error on a poll is arguably one of the single most important things for political campaigns. In knowing the error, polls can be determined as reliable or not, and percent error can be used to make key choices about the campaign moving forward.\nConclusions\nAfter exploring a variety of algorithms including standard Linear Regression, Lasso Regression, Ridge Regression, and XGBoost Regression, XGBoost ended up providing the best prediction of the error of US Federal election polling. XGBoost's gradient boosting method helps handle model complexity and has fast computation speed. It was able to correctly predict the error of the poll 82% of the time, and those correct predictions had an absolute error of 0.92%. For practical application, this model is a great first step in providing a roadmap for political decision making. Being able to predict the error of a poll can help candidates and the media know how to lead strategy and report on good polling, respectively.\n""], 'url_profile': 'https://github.com/cmatthewburgess', 'info_list': ['JavaScript', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020']}","{'location': 'Greater Seattle Area', 'stats_list': [], 'contributions': '12 contributions\n        in the last year', 'description': ['disease-detector\nClassifies whether a patient is suffering from heart disease, utilizing the UCI Heart Disease dataset. Cleans and filters data, identifying categorical and numerical features. Implements and tunes SVM, logistic regression, and KNN models. Evaluates effectiveness using recall score, achieving a best score of 0.83. Python.\n'], 'url_profile': 'https://github.com/iiguelmamene', 'info_list': ['JavaScript', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020']}","{'location': 'Greater Noida, India', 'stats_list': [], 'contributions': '11 contributions\n        in the last year', 'description': [""Personal_Bank_loan_prediction\nThe dataset contains information of 5000 costumers of a bank. It contains personal information of the user like age, income, years of job experience, education and number of family numbers. It also contains information about costumer's association with the bank: value of house mortgage, average credit card spending, Securities Account:Does the customer have a securities account with the bank? ,CD Account:Does the customer have a certificate of deposit (CD) account with the bank?, Online:Does the customer use internet banking facilities?, Credit Card:Does the customer use a credit card issued by UniversalBank? Based on the information, we predict the likelihood of a liability customer buying personal loan from the bank using K nearest neighbours algorithm, logistic regression, SVM using Gaussian kernel and compare the result obtained from the three algorithms.\n""], 'url_profile': 'https://github.com/aparna308', 'info_list': ['JavaScript', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '56 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/harshitanand2k', 'info_list': ['JavaScript', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '38 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/yourbaur', 'info_list': ['JavaScript', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020']}","{'location': 'New York, NY', 'stats_list': [], 'contributions': '4 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/geraldsteven21', 'info_list': ['JavaScript', 'Updated May 11, 2020', 'Python', 'Updated May 19, 2020', '1', 'Jupyter Notebook', 'Updated May 15, 2020', 'Updated May 13, 2020', 'Jupyter Notebook', 'Updated May 15, 2020', 'Python', 'Updated May 16, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 11, 2020', 'Jupyter Notebook', 'Updated May 17, 2020', 'HTML', 'Updated May 14, 2020']}"
"{'location': 'new york', 'stats_list': [], 'contributions': '50 contributions\n        in the last year', 'description': ['covid19-prediction-model-using-R\n#----------Predicting confirmed cases in USA for next 120 days using Arima Model-------------#\n#Importing libraries\nlibrary(data.table)\nlibrary(tseries)\nlibrary(forecast)\ncovidConfirmed<-read.csv(""covid19_confirmed_global.csv"")\ncovidDeaths<-read.csv(""covid19_deaths_global.csv"")\ncovidRecovered<-read.csv(""covid19_recovered_global.csv"")\n#Preparing US confirmed cases dataset\ncovidConfirmed <- covidConfirmed[c(-1,-2,-3, -4)]\ncovidConfirmed\ncovidConfirmedUS <- covidConfirmed[226,]\ncovidConfirmedUS\nconfirmed <- transpose(covidConfirmedUS)\nconfirmed\n#rownames(confirmed) <- colnames(covidConfirmedUS)\ncolnames(confirmed) <- rownames(covidConfirmedUS)\nconfirmed\ncolnames(confirmed)[colnames(confirmed) == ""226""] <- ""confirmedCases""\nconfirmed\nsummary(confirmed)\n#converting our dataset to a time series format\nconfirmed<-ts(confirmed)\nconfirmed\nplot.ts(confirmed, xlab=""Time in days"")\nclass(confirmed)\nfrequency(confirmed)\nsummary(confirmed)\nplot(confirmed, xlab=""Time in days"")\nabline(reg=lm(confirmed~time(confirmed)))\ncycle(confirmed)\nplot(aggregate(confirmed,FUN=mean), xlab=""Time in days"")\nboxplot(confirmed~cycle(confirmed))\nDetermining that our time series is stationary enough to do any form of time series modelling\nAugmented Dickey Fullers Test\nadf.test(diff(log(confirmed)), alternative=""stationary"", k=1)\nacf(log(confirmed))\nacf(diff(log(confirmed)))\npacf(diff(log(confirmed)))\n(fit <- arima(log(confirmed), c(0, 1, 1),seasonal = list(order = c(0, 1, 1), period = 1)))\nPrediction using manual p,d,q values\npred <- predict(fit, n.ahead = 120*1)\nts.plot(confirmed,2.718^pred$pred, log = ""y"", lty = c(1,3), ylab=""Confirmed Cases"", xlab=""Time in days"")\nUsing auto arima to get best values for p, d, q\nourModelConfirmed <- auto.arima(confirmed)\nourModelConfirmed\nauto.arima(confirmed, ic=""aic"", trace=TRUE)\n#adf.test(myModel)\nplot.ts(ourModelConfirmed$residuals)\nacf(ts(ourModelConfirmed$residuals), main = \'ACF Residual\')\npacf(ts(ourModelConfirmed$residuals), main = \'PACF Residual\')\nUsing the model to forecast for the next 120 days\nourForecast<-forecast(ourModelConfirmed, level=c(95), h=120*1)\nplot(ourForecast, ylab=""Confirmed Cases"", xlab=""Time in days"")\nTesting our model\nBox.test(ourModelConfirmed$residuals, lag=5, type=""Ljung-Box"")\nBox.test(ourModelConfirmed$residuals, lag=10, type=""Ljung-Box"")\nBox.test(ourModelConfirmed$residuals, lag=15, type=""Ljung-Box"")\n#---------------------------------------------------------------------------\n#Preparing US deaths cases dataset\ncovidDeaths <- covidDeaths[c(-1,-2,-3)]\ncovidDeaths\ncovidDeathsUS <- covidDeaths[226,]\ncovidDeathsUS\ndeaths <- transpose(covidDeathsUS)\ndeaths\n#rownames(confirmed) <- colnames(covidConfirmedUS)\ncolnames(deaths) <- rownames(covidDeathsUS)\ndeaths\ncolnames(deaths)[colnames(deaths) == ""226""] <- ""deathCases""\ndeaths\nsummary(deaths)\n#converting our dataset to a time series format\ndeaths<-ts(deaths)\ndeaths\nplot.ts(deaths)\nclass(deaths)\nfrequency(deaths)\nsummary(deaths)\nplot(deaths)\nabline(reg=lm(deaths~time(deaths)))\ncycle(deaths)\nplot(aggregate(deaths,FUN=mean))\nboxplot(deaths~cycle(deaths))\nDetermining that our time series is stationary enough to do any form of time series modelling\nAugmented Dickey Fullers Test\nadf.test(diff(log(deaths)), alternative=""stationary"", k=1)\nacf(log(deaths))\nUsing auto arima to get best values for p, d, q\nourModelDeaths <- auto.arima(deaths)\nourModelDeaths\nauto.arima(ourModelDeaths, ic=""aic"", trace=TRUE)\nplot.ts(ourModelDeaths$residuals)\nacf(ts(ourModelDeaths$residuals), main = \'ACF Residual\')\npacf(ts(ourModelDeaths$residuals), main = \'PACF Residual\')\nUsing the model to forecast for the next 120 days\nourForecast<-forecast(ourModelDeaths, level=c(95), h=120*1)\nplot(ourForecast,ylab=""Death Cases"", xlab=""Time in days"" )\nTesting our model\nBox.test(ourModelDeaths$residuals, lag=5, type=""Ljung-Box"")\nBox.test(ourModelDeaths$residuals, lag=10, type=""Ljung-Box"")\nBox.test(ourModelDeaths$residuals, lag=15, type=""Ljung-Box"")\n#-------------------------------------------------------------------\n#Preparing US recovered cases dataset\ncovidRecovered <- covidRecovered[c(-1,-2,-3)]\ncovidRecovered\ncovidRecoveredUS <- covidRecovered[226,]\ncovidRecoveredUS\nrecovered <- transpose(covidRecoveredUS)\nrecovered\n#rownames(recovered) <- colnames(covidRecoveredUS)\ncolnames(recovered) <- rownames(covidRecoveredUS)\nrecovered\ncolnames(recovered)[colnames(recovered) == ""226""] <- ""recoveredCases""\nrecovered\nsummary(recovered)\n#converting our dataset to a time series format\nrecovered<-ts(recovered)\nrecovered\nplot.ts(recovered)\nclass(recovered)\nfrequency(recovered)\nsummary(recovered)\nplot(recovered)\nabline(reg=lm(recovered~time(recovered)))\ncycle(recovered)\nplot(aggregate(recovered,FUN=mean))\nboxplot(deaths~cycle(recovered))\nDetermining that our time series is stationary enough to do any form of time series modelling\nAugmented Dickey Fullers Test\nadf.test(diff(log(recovered)), alternative=""stationary"", k=1)\nacf(log(recovered))\nUsing auto arima to get best values for p, d, q\nourModelRecovered<- auto.arima(recovered)\nourModelRecovered\nauto.arima(ourModelRecovered, ic=""aic"", trace=TRUE)\nplot.ts(ourModelRecovered$residuals)\nacf(ts(ourModelRecovered$residuals), main = \'ACF Residual\')\npacf(ts(ourModelDeaths$residuals), main = \'PACF Residual\')\nUsing the model to forecast for the next 120 days\nourForecastRecov<-forecast(ourModelDeaths, level=c(95), h=120*1)\nplot(ourForecastRecov, ylab=""Confirmed Cases"", xlab=""Time in days"")\nTesting our model\nBox.test(ourModelRecovered$residuals, lag=5, type=""Ljung-Box"")\nBox.test(ourModelRecovered$residuals, lag=10, type=""Ljung-Box"")\nBox.test(ourModelRecovered$residuals, lag=15, type=""Ljung-Box"")\n#Binding the datasets for confirmed cases, deaths and recovered cases\nncol(confirmed)\nncol(deaths)\nncol(recovered)\nconfirmed_Deaths <- cbind(confirmed,deaths)\nconfirmed_Deaths\nconfirmed_Deaths_Recovered <- cbind(confirmed_Deaths,recovered)\nconfirmed_Deaths_Recovered\n#-----Predicting confirmed, deaths and recovered cases for the top 13 countries using Arima Model-----#\nsetwd(""C:/datamining_classExamples"")\nimporting libraries\nlibrary(car)\nlibrary(dplyr)\nlibrary(plyr)\nlibrary(tseries)\nlibrary(zoo)\nlibrary(forecast )\nimporting data of confirmed, recovered and death time series for all countries.\nThe appropriate paths has been provided where the dataset resides\nconfirmed=read.csv(\'covid19_confirmed_global.csv\',\nheader = F,stringsAsFactors = F)\ndeath=read.csv(\'covid19_deaths_global.csv\',header=F,stringsAsFactors = F)\nrecovered=read.csv(\'covid19_recovered_global.csv\',header=F,stringsAsFactors = F)\nlooking at the first five rows of the confirmed data set\nhead(confirmed)\nseeing that the V2 and V3 columns are longitude and latitude which are not useful so\nmaking latitude and longitude as null.\nthis implies that those columns are being removed from all three datasets\nconfirmed$V2<-NULL\nconfirmed$V3<-NULL\nrecovered$V2<-NULL\nrecovered$V3<-NULL\ndeath$V2<-NULL\ndeath$V3<-NULL\nThe first row contains dates. Removing first row of names and date after noting the start and end\nThis has been done for all the three datasets\nconfirmed=confirmed[2:nrow(confirmed),]\nrecovered=recovered[2:nrow(recovered),]\ndeath=death[2:nrow(death),]\nThe code below converts to numeric the values of columns starting from column 2 to the last colum\nfor (j in 2:ncol(confirmed)){ # select from column 2 onwards\nconfirmed[,j]=as.numeric(confirmed[,j]) # convert to numeric\nrecovered[,j]=as.numeric(recovered[,j]) # convert to numeric\ndeath[,j]=as.numeric(death[,j]) # convert to numeric\n}\nV1 is the country name. So for each country name, the subset of the data has been selected below and\nthe columns for each day have been summed for that subset.\nThis gives the data for that day for that country as an aggregate\nThis has been done for all the three datasets below.\ndata_confirmed=ddply(confirmed,\'V1\',function(x){colSums(x[,2:ncol(x)],na.rm = T)})\ndata_recovered=ddply(recovered,\'V1\',function(x){colSums(x[,2:ncol(x)],na.rm = T)})\ndata_death=ddply(death,\'V1\',function(x){colSums(x[,2:ncol(x)],na.rm = T)})\ngetting data for US\ndata_US_confirmed=data_confirmed%>% filter(V1==\'US\') # V1 is country, so US is being selected\ndata_US_death=data_death%>% filter(V1==\'US\')# V1 is country, so US is being selected\ndata_US_recovered=data_recovered%>% filter(V1==\'US\')# V1 is country, so US is being selected\ngetting data for India\ndata_India_confirmed=data_confirmed%>% filter(V1==\'India\')# V1 is country, so India is being selected\ndata_India_death=data_death%>% filter(V1==\'India\')# V1 is country, so India is being selected\ndata_India_recovered=data_recovered%>% filter(V1==\'India\')# V1 is country, so India is being selected\ngetting data for Canada\ndata_Canada_confirmed=data_confirmed%>% filter(V1==\'Canada\') # V1 is country, so Canada is being selected\ndata_Canada_death=data_death%>% filter(V1==\'Canada\') # V1 is country, so Canada is being selected\ndata_Canada_recovered=data_recovered%>% filter(V1==\'Canada\') # V1 is country, so Canada is being selected\ndata for China\ndata_China_confirmed=data_confirmed%>% filter(V1==\'China\') # V1 is country, so China is being selected\ndata_China_death=data_death%>% filter(V1==\'China\')# V1 is country, so China is being selected\ndata_China_recovered=data_recovered%>% filter(V1==\'China\')# V1 is country, so China is being selected\ndata for france\ndata_france_confirmed=data_confirmed%>% filter(V1==\'France\')# V1 is country, so France is being selected\ndata_france_death=data_death%>% filter(V1==\'France\')# V1 is country, so France is being selected\ndata_france_recovered=data_recovered%>% filter(V1==\'France\')# V1 is country, so France is being selected\ndata for Italy\ndata_Italy_confirmed=data_confirmed%>% filter(V1==\'Italy\')# V1 is country, so Italy is being selected\ndata_Italy_death=data_death%>% filter(V1==\'Italy\')# V1 is country, so Italy is being selected\ndata_Italy_recovered=data_recovered%>% filter(V1==\'Italy\')# V1 is country, so Italy is being selected\ndata for Japan\ndata_Japan_confirmed=data_confirmed%>% filter(V1==\'Japan\')# V1 is country, so Japan is being selected\ndata_Japan_death=data_death%>% filter(V1==\'Japan\')# V1 is country, so Japan is being selected\ndata_Japan_recovered=data_recovered%>% filter(V1==\'Japan\')# V1 is country, so Japan is being selected\nData for South Korea\ndata_Skorea_confirmed=data_confirmed%>% filter(V1==""Korea, South"")# V1 is country, so ""Korea, South"" is being selected\ndata_Skorea_death=data_death%>% filter(V1==""Korea, South"")# V1 is country, so ""Korea, South"" is being selected\ndata_Skorea_recovered=data_recovered%>% filter(V1==""Korea, South"")# V1 is country, so ""Korea, South"" is being selected\nData for Spain\ndata_Spain_confirmed=data_confirmed%>% filter(V1==""Spain"")# V1 is country, so Spain is being selected\ndata_Spain_death=data_death%>% filter(V1==""Spain"")# V1 is country, so Spain is being selected\ndata_Spain_recovered=data_recovered%>% filter(V1==""Spain"")# V1 is country, so Spain is being selected\nData for ""United Arab Emirates""\ndata_UAE_confirmed=data_confirmed%>% filter(V1==""United Arab Emirates"")# V1 is country, so UAE is being selected\ndata_UAE_death=data_death%>% filter(V1==""United Arab Emirates"")# V1 is country, so UAE is being selected\ndata_UAE_recovered=data_recovered%>% filter(V1==""United Arab Emirates"")# V1 is country, so UAE is being selected\nData for UK\ndata_UK_confirmed=data_confirmed%>% filter(V1==""United Kingdom"")# V1 is country, so UK is being selected\ndata_UK_death=data_death%>% filter(V1==""United Kingdom"")# V1 is country, so UK is being selected\ndata_UK_recovered=data_recovered%>% filter(V1==""United Kingdom"")# V1 is country, so UK is being selected\nSumming all the columns from second column onwards to get data each day for the world as an aggregate\nand creating a time series starting 22-01-2020 and ending in 07-04-2020\nThis has been done using the zoo package\nconfirmed_world=zoo(as.vector(colSums(data_confirmed[,2:ncol(data_confirmed)])),\nseq(from =as.Date(""22-01-2020"",format=\'%d-%m-%Y\') ,\nto =as.Date(""07-04-2020"",format=\'%d-%m-%Y\') ,by=1 )) # confirmed in world\nrecovered_world=zoo(as.vector(colSums(data_recovered[,2:ncol(data_recovered)])),\nseq(from =as.Date(""22-01-2020"",format=\'%d-%m-%Y\') ,\nto =as.Date(""07-04-2020"",format=\'%d-%m-%Y\') ,by=1 ))#recovered in world\ndeath_world=zoo(as.vector(colSums(data_death[,2:ncol(data_death)])),\nseq(from =as.Date(""22-01-2020"",format=\'%d-%m-%Y\') ,\nto =as.Date(""07-04-2020"",format=\'%d-%m-%Y\') ,by=1 )) #death in the world\ncalculating a seris of dates from 22-01 to 07-04\ndates=seq(from =as.Date(""22-01-2020"",format=\'%d-%m-%Y\') ,\nto =as.Date(""07-04-2020"",format=\'%d-%m-%Y\') ,by=1 )\npar(mfrow=c(1,3)) # to plot three plots in same plot\nplotting confirmed cases in US\nplot(y=data_US_confirmed[,2:ncol(data_US_confirmed)],type=\'o\',\nx=dates,cex=0.4,main=\'Confirmed cases : US\',xlab=\'Date\',ylab =\'confirmed cases\')\nplotting recovered cases in US\nplot(y=data_US_recovered[,2:ncol(data_US_recovered)],type=\'o\',\nx=dates,cex=0.4,main=\'Recovered cases : US\',xlab=\'Date\',ylab =\'recovered cases\')\nplotting dead cases in US\nplot(y=data_US_death[,2:ncol(data_US_death)],type=\'o\',\nx=dates,cex=0.4,main=\'Dead cases: US\',xlab=\'Date\',ylab =\'dead cases\')\npar(mfrow=c(1,3)) # to plot three plots in same plot\nplotting confirmed cases in India\nplot(y=data_India_confirmed[,2:ncol(data_India_confirmed)],type=\'o\',\nx=dates,cex=0.4,main=\'Confirmed cases : India\',xlab=\'Date\',ylab =\'confirmed cases\')\nplotting recovered cases in India\nplot(y=data_India_recovered[,2:ncol(data_India_recovered)],type=\'o\',\nx=dates,cex=0.4,main=\'Recovered cases : India\',xlab=\'Date\',ylab =\'recovered cases\')\nplotting dead cases in India\nplot(y=data_India_death[,2:ncol(data_India_death)],type=\'o\',\nx=dates,cex=0.4,main=\'Dead cases: India\',xlab=\'Date\',ylab =\'dead cases\')\npar(mfrow=c(1,3)) # to plot three plots in same plot\nplotting confirmed cases in Canada\nplot(y=data_Canada_confirmed[,2:ncol(data_Canada_confirmed)],type=\'o\',\nx=dates,cex=0.4,main=\'Confirmed cases : Canada\',xlab=\'Date\',ylab =\'confirmed cases\')\nplotting recovered cases in Canada\nplot(y=data_Canada_recovered[,2:ncol(data_Canada_recovered)],type=\'o\',\nx=dates,cex=0.4,main=\'Recovered cases : Canada\',xlab=\'Date\',ylab =\'recovered cases\')\nplotting dead cases in Canada\nplot(y=data_Canada_death[,2:ncol(data_Canada_death)],type=\'o\',\nx=dates,cex=0.4,main=\'Dead cases : Canada\',xlab=\'Date\',ylab =\'dead cases\')\npar(mfrow=c(1,3)) # to plot three plots in same plot\nplotting confirmed cases in China\nplot(y=data_China_confirmed[,2:ncol(data_China_confirmed)],type=\'o\',\nx=dates,cex=0.4,main=\'Confirmed cases : China\',xlab=\'Date\',ylab =\'confirmed cases\')\nplotting recovered cases in China\nplot(y=data_China_recovered[,2:ncol(data_China_recovered)],type=\'o\',\nx=dates,cex=0.4,main=\'Recovered cases : China\',xlab=\'Date\',ylab =\'recovered cases\')\nplotting dead cases in China\nplot(y=data_China_death[,2:ncol(data_China_death)],type=\'o\',\nx=dates,cex=0.4,main=\'Dead cases : China\',xlab=\'Date\',ylab =\'dead cases\')\npar(mfrow=c(1,3)) # to plot three plots in same plot\nplotting confirmed cases in France\nplot(y=data_france_confirmed[,2:ncol(data_france_confirmed)],type=\'o\',\nx=dates,cex=0.4,main=\'Confirmed cases : France\',xlab=\'Date\',ylab =\'confirmed cases\')\nplotting recovered cases in France\nplot(y=data_france_recovered[,2:ncol(data_france_recovered)],type=\'o\',\nx=dates,cex=0.4,main=\'Recovered cases : France\',xlab=\'Date\',ylab =\'recovered cases\')\nplotting dead cases in France\nplot(y=data_france_death[,2:ncol(data_france_death)],type=\'o\',\nx=dates,cex=0.4,main=\'Dead cases : France\',xlab=\'Date\',ylab =\'dead cases\')\npar(mfrow=c(1,3)) # to plot three plots in same plot\nplotting confirmed cases in Italy\nplot(y=data_Italy_confirmed[,2:ncol(data_Italy_confirmed)],type=\'o\',\nx=dates,cex=0.4,main=\'Confirmed cases : Italy\',xlab=\'Date\',ylab =\'confirmed cases\')\nplotting recovered cases in Italy\nplot(y=data_Italy_recovered[,2:ncol(data_Italy_recovered)],type=\'o\',\nx=dates,cex=0.4,main=\'Recovered cases : Italy\',xlab=\'Date\',ylab =\'recovered cases\')\nplotting dead cases in Italy\nplot(y=data_Italy_death[,2:ncol(data_Italy_death)],type=\'o\',\nx=dates,cex=0.4,main=\'Dead cases : Italy\',xlab=\'Date\',ylab =\'dead cases\')\npar(mfrow=c(1,3)) # to plot three plots in same plot\nplotting confirmed cases in Japan\nplot(y=data_Japan_confirmed[,2:ncol(data_Japan_confirmed)],type=\'o\',\nx=dates,cex=0.4,main=\'Confirmed cases: Japan\',xlab=\'Date\',ylab =\'confirmed cases\')\nplotting recovered cases in Japan\nplot(y=data_Japan_recovered[,2:ncol(data_Japan_recovered)],type=\'o\',\nx=dates,cex=0.4,main=\'Recovered cases : Japan\',xlab=\'Date\',ylab =\'recovered cases\')\nplotting dead cases in Japan\nplot(y=data_Japan_death[,2:ncol(data_Japan_death)],type=\'o\',\nx=dates,cex=0.4,main=\'Dead cases : Japan\',xlab=\'Date\',ylab =\'dead cases\')\npar(mfrow=c(1,3)) # to plot three plots in same plot\nplotting confirmed cases in South Korea\nplot(y=data_Skorea_confirmed[,2:ncol(data_Skorea_confirmed)],type=\'o\',\nx=dates,cex=0.4,main=\'Confirmed cases : S. Korea\',xlab=\'Date\',ylab =\'confirmed cases\')\nplotting recovered cases in South Korea\nplot(y=data_Skorea_recovered[,2:ncol(data_Skorea_recovered)],type=\'o\',\nx=dates,cex=0.4,main=\'Recovered cases : S. Korea\',xlab=\'Date\',ylab =\'recovered cases\')\nplotting dead cases in South Korea\nplot(y=data_Skorea_death[,2:ncol(data_Skorea_death)],type=\'o\',\nx=dates,cex=0.4,main=\'Dead cases : S. Korea\',xlab=\'Date\',ylab =\'dead cases\')\npar(mfrow=c(1,3)) # to plot three plots in same plot\nplotting confirmed cases in Spain\nplot(y=data_Spain_confirmed[,2:ncol(data_Spain_confirmed)],type=\'o\',\nx=dates,cex=0.4,main=\'Confirmed cases : Spain\',xlab=\'Date\',ylab =\'confirmed cases\')\nplotting recovered cases in Spain\nplot(y=data_Spain_recovered[,2:ncol(data_Spain_recovered)],type=\'o\',\nx=dates,cex=0.4,main=\'Recovered cases : Spain\',xlab=\'Date\',ylab =\'recovered cases\')\nplotting dead cases in Spain\nplot(y=data_Spain_death[,2:ncol(data_Spain_death)],type=\'o\',\nx=dates,cex=0.4,main=\'Dead cases : Spain\',xlab=\'Date\',ylab =\'dead cases\')\npar(mfrow=c(1,3)) # to plot three plots in same plot\nplotting confirmed cases in UAE\nplot(y=data_UAE_confirmed[,2:ncol(data_UAE_confirmed)],type=\'o\',\nx=dates,cex=0.4,main=\'Confirmed cases : UAE\',xlab=\'Date\',ylab =\'confirmed cases\')\nplotting recovered cases in UAE\nplot(y=data_UAE_recovered[,2:ncol(data_UAE_recovered)],type=\'o\',\nx=dates,cex=0.4,main=\'Recovered cases: UAE\',xlab=\'Date\',ylab =\'recovered cases\')\nplotting dead cases in UAE\nplot(y=data_UAE_death[,2:ncol(data_UAE_death)],type=\'o\',\nx=dates,cex=0.4,main=\'Dead cases: UAE\',xlab=\'Date\',ylab =\'dead cases\')\npar(mfrow=c(1,3)) # to plot three plots in same plot\nplotting confirmed cases in Uk\nplot(y=data_UK_confirmed[,2:ncol(data_UK_confirmed)],type=\'o\',\nx=dates,cex=0.4,main=\'Confirmed cases: UK\',xlab=\'Date\',ylab =\'confirmed cases\')\nplotting recovered cases in US\nplot(y=data_UK_recovered[,2:ncol(data_UK_confirmed)],type=\'o\',\nx=dates,cex=0.4,main=\'Recovered cases : UK\',xlab=\'Date\',ylab =\'recovered cases\')\nplotting dead cases in UK\nplot(y=data_UK_death[,2:ncol(data_UK_confirmed)],type=\'o\',\nx=dates,cex=0.4,main=\'Dead cases : UK\',xlab=\'Date\',ylab =\'dead cases\')\nseeing that all the values show exponential pattern, the models will be fit on their logarithms\nfunction to make plots\nplot_value<-function(values,name_tag){\npar(mfrow=c(2,2))\n(plot(values,type=\'o\',cex=0.4,main=paste(\'Plot of frequency of \',name_tag),xlab=\'Date\',ylab =j))\nvalues=log(values) # converting to logarithm\n#Plot of log of time series\n(plot(values,type=\'o\',cex=0.4,main=paste(\'Plot of log frequency of \',name_tag),xlab=\'Date\',ylab =j))\nACF and PACF plots\n(acf(values,main=paste(\'ACF of log frequency of \',name_tag),lag.max = 60))\npacf(values,main=paste(\'PACF of log frequency of \',name_tag))\n}\nfunction to fit ARIMA model and return diagnostics\nfit_model<-function(values,order_arima){\nconverting to log values\nvalues=log(values)\nfitting an arima log time series\nmod<-arima(values,order = order_arima)\nprint(mod)\nplotting the model in a 2x2 window\npar(mfrow=c(2,2))\nplotting residuals from the model\nplot(mod$residuals,ylab=\'residuals\',xaxt=\'n\',main=\'plot of residuals\')\ngiving x axis labels i.e. the date values\naxis(1, at=seq(1,length(mod$residuals),12.5) , las=2, cex.axis=0.6,\nlabels=seq(as.Date(""22-01-2020"",format=\'%d-%m-%Y\'), as.Date(""22-01-2020"",format=\'%d-%m-%Y\')+length(mod$residuals)-1, length.out=7) )\nplotting the forecasted 30 days ahead value\nplot(forecast(mod,h = 30),xaxt=\'n\')\ngiving x axis labels i.e. the date values\naxis(1, at=seq(1,length(mod$residuals)+30,17.5) , las=2, cex.axis=0.6,\nlabels=seq(as.Date(""22-01-2020"",format=\'%d-%m-%Y\'), as.Date(""22-01-2020"",format=\'%d-%m-%Y\')+length(mod$residuals)+30-1, length.out=7) )\nacf(mod$residuals,main=\'ACF of residuals\',ylab=\'residuals\') # ACF of residuals\npacf(mod$residuals,main=\'PACF of residuals\',ylab=\'residuals\') # PACF of residuals\n#Durbin Watson test for stationarity check\nprint(\'Durbin Watson statistic is :\')\nprint(durbinWatsonTest(as.vector(mod$residuals)))\n}\ndrag the plot window since it has large margins we would not be able to see the plots untill we increased it to great extent. The key is to increase the plot window beforehand and then run the lines of code.\nplot for confirmed cases in world\nplot_value(confirmed_world,\'confirmed world\')\nfitting the ARIMA model of order (1,1,1) and getting diagnostics\nfit_model(confirmed_world,c(1,1,1))\nwhere first 1 indicates that it sets the lage value of\n#1 for auto regressions,uses a difference of 1 to make time series stationary\nand uses moving model of 1\nplot for recovered cases in world\nplot_value(recovered_world,\'recovered world\')\nfitting the ARIMA model of order (1,1,4) and getting diagnostics\nfit_model(recovered_world,c(1,1,4))\nplot for death cases in world\nplot_value(death_world,\'recovered world\')\nfitting the ARIMA model of order (1,1,3) and getting diagnostics\nfit_model(death_world,c(1,1,3))\n'], 'url_profile': 'https://github.com/kanuptiwari', 'info_list': ['Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'HTML', 'MIT license', 'Updated Oct 13, 2020', 'HTML', 'Updated May 21, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'College Station, Texas', 'stats_list': [], 'contributions': '172 contributions\n        in the last year', 'description': ['House-Price-Prediction\nThis Project was completed as part of a competition on Kaggle. In this I have used myriad approaches to predict Sale Price of Houses present in the dataset, on basis of 80 distinct features. Different feature scaling and binarization techniques and different regression algorithms were used to arrive at a Root Mean Squared Log Error of 0.1265.\nMethods Used -\n\nLinear Regression with Numerical Features\nLinear Regression with complete binarized feature space\nLinear Regression with extensive feature scaling and selection\nRandom Forest Regression\nXGBoost Regression\nLight Gradient Boosting Regression\n\n'], 'url_profile': 'https://github.com/karan7798z', 'info_list': ['Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'HTML', 'MIT license', 'Updated Oct 13, 2020', 'HTML', 'Updated May 21, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Madurai', 'stats_list': [], 'contributions': '184 contributions\n        in the last year', 'description': ['COVID-19-Death-Prediction\nThe objective of this research is to propose a forecasting model using the COVID-19 available dataset from top affected regions across the world using machine learning algorithms. Machine Learning algorithms help us achieve this objective. Regression models are one of the supervised machine learning techniques to classify large-scale data. This research aims to apply Multivariate Linear Regression to predict the number of confirmed and death COVID-19 cases for a span of one and two weeks. The experimental results explain 99% variability in prediction with the R-squared statistics scores of 0.992. The algorithms are evaluated using the error matrix such as Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and accuracy for top affected regions across the world.\n'], 'url_profile': 'https://github.com/ArunadeviRamesh', 'info_list': ['Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'HTML', 'MIT license', 'Updated Oct 13, 2020', 'HTML', 'Updated May 21, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '41 contributions\n        in the last year', 'description': ['Regression with R --> Hitters: Baseball Data\nDescription - Major League Baseball Data from the 1986 and 1987 seasons.\nSource - This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\nThis is part of the data that was used in the 1988 ASA Graphics Section Poster Session.\nThe salary data were originally from Sports Illustrated, April 20, 1987.\nThe 1986 and career statistics were obtained from The 1987 Baseball Encyclopedia Update published by Collier Books, Macmillan Publishing Company, New York.\n'], 'url_profile': 'https://github.com/bharanianand', 'info_list': ['Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'HTML', 'MIT license', 'Updated Oct 13, 2020', 'HTML', 'Updated May 21, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'srikakulam', 'stats_list': [], 'contributions': '14 contributions\n        in the last year', 'description': ['NIDS\nNetwork Intrusion Detection System (NIDS) is a software application that monitors the network or system activities for malicious activities and unauthorized access to devices. The objective of designing NIDS is to protect the data confidential.  This project includes the implementation of different data mining algorithms including Logistic regression, Gaussian NB and Decision tree to generate the rules for classify network activities. A comparative analysis of these techniques to detect intrusions has also been made.UNSW-NB15 dataset has been used for implementation.\n'], 'url_profile': 'https://github.com/vuritiaditya', 'info_list': ['Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'HTML', 'MIT license', 'Updated Oct 13, 2020', 'HTML', 'Updated May 21, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Dehradun ', 'stats_list': [], 'contributions': '57 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/aish0233', 'info_list': ['Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'HTML', 'MIT license', 'Updated Oct 13, 2020', 'HTML', 'Updated May 21, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Patiala, India', 'stats_list': [], 'contributions': '28 contributions\n        in the last year', 'description': ['Board-Game-Review-Prediction\n'], 'url_profile': 'https://github.com/aakritimittal11', 'info_list': ['Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'HTML', 'MIT license', 'Updated Oct 13, 2020', 'HTML', 'Updated May 21, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Mumbai', 'stats_list': [], 'contributions': '2 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/meerajgawde', 'info_list': ['Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'HTML', 'MIT license', 'Updated Oct 13, 2020', 'HTML', 'Updated May 21, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'United States', 'stats_list': [], 'contributions': '29 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/PriyadharsiniNarahari', 'info_list': ['Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'HTML', 'MIT license', 'Updated Oct 13, 2020', 'HTML', 'Updated May 21, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}","{'location': 'Delhi, India', 'stats_list': [], 'contributions': '542 contributions\n        in the last year', 'description': ['Facebook-dataset\n\nBasic info-\nThis project contains visualizations based on facebook data.\n\nDataset-\nThe dataset is already provided in the repository.\n'], 'url_profile': 'https://github.com/Ravjot03', 'info_list': ['Updated May 12, 2020', 'Jupyter Notebook', 'Updated May 20, 2020', 'HTML', 'MIT license', 'Updated Oct 13, 2020', 'HTML', 'Updated May 21, 2020', 'Apache-2.0 license', 'Updated May 11, 2020', 'Python', 'Updated May 17, 2020', '1', 'Jupyter Notebook', 'Updated May 17, 2020', 'Updated May 15, 2020', 'Updated May 17, 2020', 'Jupyter Notebook', 'Updated May 16, 2020']}"
"{'location': 'United States', 'stats_list': [], 'contributions': '29 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/PriyadharsiniNarahari', 'info_list': ['R', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Aug 2, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '31 contributions\n        in the last year', 'description': ['StramlitApp for Real Estate Analysis and Prediction\nThe Streamlit app analyse the the house price data and filter it out further for the prediction of house price.The project uses Random Forest Regressor for the prediction of the house price using 14 highly correlated features found out during the anlysis of the dataset.\n'], 'url_profile': 'https://github.com/dheerajk786', 'info_list': ['R', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Aug 2, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'NONE', 'stats_list': [], 'contributions': '237 contributions\n        in the last year', 'description': ['Applied-Machine-Learning-University-of-Michigan-coursera-\n\nModule-1 introduces basic Machine Learning concepts, tasks, and workflow using an example classification problem based on the K-nearest neighbors method, and implemented using the scikit-learn library.\nModule-2 delves into a wider variety of supervised learning methods for both classification and regression.\nModule-3 covers evaluation and model selection methods that you can use to help understand and optimize the performance of your machine learning models.\nModule-4  covers more advanced supervised learning methods that include ensembles of trees (random forests, gradient boosted trees), and neural networks (with an optional summary on deep learning). You will also learn about the critical problem of data leakage in machine learning and how to detect and avoid it.\n\n'], 'url_profile': 'https://github.com/khokhriya', 'info_list': ['R', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Aug 2, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020']}","{'location': 'London', 'stats_list': [], 'contributions': '88 contributions\n        in the last year', 'description': ['NONE'], 'url_profile': 'https://github.com/claudio-toledo', 'info_list': ['R', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated May 16, 2020', 'Jupyter Notebook', 'Updated Aug 2, 2020', '1', 'Jupyter Notebook', 'Updated May 12, 2020']}",,,,,,
